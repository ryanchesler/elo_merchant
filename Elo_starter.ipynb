{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "332fa118684da9a9278d2caf565620686fd73a68"
   },
   "source": [
    "# Elo world \n",
    "\n",
    "In this kernel, I build a LGBM model that aggregates the `new_merchant_transactions.csv` and `historical_transactions.csv` tables to the main train table. New features are built by successive grouping on`card_id` and `month_lag`, in order to recover some information from the time serie.\n",
    "\n",
    "## Notebook  Content\n",
    "1. [Loading the data](#1)\n",
    "1. [Feature engineering](#2)\n",
    "1. [Training the model](#3)\n",
    "1. [Feature importance](#4)\n",
    "1. [Submission](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a059a8dcf9d93a650f1ccaa8e2bfa3e087219f3"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## 1. Loading the data\n",
    "\n",
    "First, we load the `new_merchant_transactions.csv` and `historical_transactions.csv`. In practice, these two files contain the same variables and the difference between the two tables only concern the position with respect to a reference date.  Also, booleans features are made numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7a7877dff5c337c09ca111cdcbf527362c9217c7"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b6b5a505bfecabd70c6dac0ee30386d074b03953"
   },
   "outputs": [],
   "source": [
    "new_transactions = pd.read_csv('../input/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "historical_transactions = pd.read_csv('../input/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "156acd1e83dfba2c2896561b75a6a5a7782cab1d"
   },
   "source": [
    "We then load the main files, formatting the dates and extracting the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "a24cf99ad6b0785b5af2b101e06b400e26360d1e"
   },
   "outputs": [],
   "source": [
    "def read_data(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days\n",
    "    return df\n",
    "#_________________________________________\n",
    "train = read_data('../input/train.csv')\n",
    "test = read_data('../input/test.csv')\n",
    "\n",
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.720386</td>\n",
       "      <td>2017-08-09 22:04:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>2017-09-02 10:06:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.722865</td>\n",
       "      <td>2017-03-10 01:14:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_50af771f8d</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.734887</td>\n",
       "      <td>2018-02-24 08:45:05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_5e8220e564</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.716855</td>\n",
       "      <td>2017-03-21 00:10:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_9d41786a50</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.657049</td>\n",
       "      <td>2017-11-18 20:05:55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.737967</td>\n",
       "      <td>2017-06-01 22:02:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_74ba14b5fc</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.715352</td>\n",
       "      <td>2017-03-16 15:41:22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>683</td>\n",
       "      <td>M_ID_1449f22bfb</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.734135</td>\n",
       "      <td>2017-05-09 12:42:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_7c5e93af2f</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.727929</td>\n",
       "      <td>2018-02-08 20:05:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.741649</td>\n",
       "      <td>2017-06-08 18:02:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>130</td>\n",
       "      <td>M_ID_e8fb39882d</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.727373</td>\n",
       "      <td>2017-07-14 12:59:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_97e86eae5f</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.731881</td>\n",
       "      <td>2017-10-24 13:29:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.738192</td>\n",
       "      <td>2017-06-14 07:40:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>879</td>\n",
       "      <td>M_ID_00a6ca8a8a</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.725871</td>\n",
       "      <td>2018-02-07 12:19:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_21e1552dab</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.734887</td>\n",
       "      <td>2017-07-07 13:03:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_4524a562f3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.699725</td>\n",
       "      <td>2018-01-08 23:54:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>2017-08-11 17:53:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_21e1552dab</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.734887</td>\n",
       "      <td>2017-08-30 12:53:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.737967</td>\n",
       "      <td>2017-07-01 21:27:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.739545</td>\n",
       "      <td>2017-07-14 22:06:02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.726998</td>\n",
       "      <td>2017-05-06 12:29:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>511</td>\n",
       "      <td>M_ID_79db784180</td>\n",
       "      <td>-13</td>\n",
       "      <td>-0.731881</td>\n",
       "      <td>2017-01-20 09:16:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_50af771f8d</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.735638</td>\n",
       "      <td>2018-02-26 14:54:38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.726472</td>\n",
       "      <td>2017-04-29 12:30:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_979ed661fc</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.726772</td>\n",
       "      <td>2017-06-23 21:43:17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_21e1552dab</td>\n",
       "      <td>-11</td>\n",
       "      <td>-0.721363</td>\n",
       "      <td>2017-03-10 15:46:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_dc7356f06d</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.692211</td>\n",
       "      <td>2017-08-05 19:10:32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112331</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_e43fce4842</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>879</td>\n",
       "      <td>M_ID_00a6ca8a8a</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.744774</td>\n",
       "      <td>2017-07-12 18:01:13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112332</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_e43fce4842</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>C</td>\n",
       "      <td>544</td>\n",
       "      <td>M_ID_3111c6df35</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.040692</td>\n",
       "      <td>2017-08-03 15:06:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112333</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_112832329d</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>C</td>\n",
       "      <td>210</td>\n",
       "      <td>M_ID_cfa9a773ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502952</td>\n",
       "      <td>2018-01-29 15:08:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112334</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_112832329d</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>210</td>\n",
       "      <td>M_ID_6464db3b45</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.506889</td>\n",
       "      <td>2017-12-11 19:03:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112335</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_2a8874827b</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_0bd214d6c8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.681542</td>\n",
       "      <td>2017-01-06 14:54:55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112336</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_2a8874827b</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>607</td>\n",
       "      <td>M_ID_b98db225f5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.708891</td>\n",
       "      <td>2017-02-07 16:02:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112337</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c356aa384</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>307</td>\n",
       "      <td>M_ID_69c092c26e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.596643</td>\n",
       "      <td>2017-12-05 12:38:59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112338</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c356aa384</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_b872abf8ca</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.550316</td>\n",
       "      <td>2017-10-07 20:00:40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112339</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c356aa384</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>879</td>\n",
       "      <td>M_ID_00a6ca8a8a</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.605659</td>\n",
       "      <td>2017-10-02 00:35:15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112340</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_f9f906a4a2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>661</td>\n",
       "      <td>M_ID_fc7d7969c3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.704984</td>\n",
       "      <td>2018-01-01 18:33:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112341</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_f9f906a4a2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>661</td>\n",
       "      <td>M_ID_fc7d7969c3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.704984</td>\n",
       "      <td>2018-02-01 18:06:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112342</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_f9f906a4a2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>661</td>\n",
       "      <td>M_ID_fc7d7969c3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>2017-12-24 00:19:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112343</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5cf3187742</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_4b5760f37b</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.666065</td>\n",
       "      <td>2017-11-26 02:27:39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112344</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5cf3187742</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>68</td>\n",
       "      <td>M_ID_9a72bcd3b4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.686817</td>\n",
       "      <td>2017-12-30 19:36:04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112345</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5cf3187742</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_bf86e8edcd</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.735638</td>\n",
       "      <td>2017-09-23 22:42:58</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112346</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_803aa0aed4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_1ada7c0ceb</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.718523</td>\n",
       "      <td>2018-02-20 14:18:46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112347</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_803aa0aed4</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_393b4b8cec</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.702504</td>\n",
       "      <td>2017-06-01 16:55:08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112348</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_803aa0aed4</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>879</td>\n",
       "      <td>M_ID_00a6ca8a8a</td>\n",
       "      <td>-9</td>\n",
       "      <td>-0.724067</td>\n",
       "      <td>2017-05-20 16:55:17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112349</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_62df280b20</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>489</td>\n",
       "      <td>M_ID_244299ea12</td>\n",
       "      <td>-2</td>\n",
       "      <td>1.363355</td>\n",
       "      <td>2017-09-18 20:35:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112350</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_62df280b20</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>489</td>\n",
       "      <td>M_ID_244299ea12</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>2017-08-08 14:36:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112351</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_62df280b20</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>506</td>\n",
       "      <td>M_ID_aa18020893</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.612631</td>\n",
       "      <td>2017-08-29 11:43:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112352</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_62df280b20</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>87</td>\n",
       "      <td>M_ID_94f6f392c4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.459451</td>\n",
       "      <td>2017-08-29 11:28:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112353</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_e49b1996b0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>705</td>\n",
       "      <td>M_ID_b692f6f5d1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-0.618747</td>\n",
       "      <td>2017-12-29 14:43:53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112354</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_e49b1996b0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>550</td>\n",
       "      <td>M_ID_09d7a200d1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.656749</td>\n",
       "      <td>2018-01-23 01:52:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112355</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_e49b1996b0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>130</td>\n",
       "      <td>M_ID_ea5d727248</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.694315</td>\n",
       "      <td>2018-02-07 18:17:01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112356</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_2863d2fa95</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>360</td>\n",
       "      <td>M_ID_edd92b6720</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.632706</td>\n",
       "      <td>2017-01-20 08:52:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112357</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_2863d2fa95</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>360</td>\n",
       "      <td>M_ID_edd92b6720</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.632706</td>\n",
       "      <td>2017-02-20 04:40:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112358</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c240d6e3c</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>278</td>\n",
       "      <td>M_ID_9cdcfe8673</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.657740</td>\n",
       "      <td>2017-12-26 18:37:51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112359</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c240d6e3c</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>514</td>\n",
       "      <td>M_ID_1a75f94f92</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.770620</td>\n",
       "      <td>2017-11-24 14:18:15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112360</th>\n",
       "      <td>1</td>\n",
       "      <td>C_ID_5c240d6e3c</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>514</td>\n",
       "      <td>M_ID_1a75f94f92</td>\n",
       "      <td>-2</td>\n",
       "      <td>1.134411</td>\n",
       "      <td>2017-10-26 14:09:40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29112361 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          authorized_flag          card_id  city_id  category_1  installments  \\\n",
       "0                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "1                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "2                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "3                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "4                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "5                       1  C_ID_4e6213e9bc      333           0             0   \n",
       "6                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "7                       1  C_ID_4e6213e9bc        3           0             0   \n",
       "8                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "9                       1  C_ID_4e6213e9bc       88           0             0   \n",
       "10                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "11                      1  C_ID_4e6213e9bc       -1           0             0   \n",
       "12                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "13                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "14                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "15                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "16                      1  C_ID_4e6213e9bc       69           0             0   \n",
       "17                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "18                      1  C_ID_4e6213e9bc      233           0             0   \n",
       "19                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "20                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "21                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "22                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "23                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "24                      1  C_ID_4e6213e9bc        3           0             0   \n",
       "25                      1  C_ID_4e6213e9bc      333           0             0   \n",
       "26                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "27                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "28                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "29                      1  C_ID_4e6213e9bc       88           0             0   \n",
       "...                   ...              ...      ...         ...           ...   \n",
       "29112331                1  C_ID_e43fce4842       69           0             1   \n",
       "29112332                1  C_ID_e43fce4842       -1           1            10   \n",
       "29112333                1  C_ID_112832329d       -1           1             8   \n",
       "29112334                1  C_ID_112832329d       -1           1             4   \n",
       "29112335                1  C_ID_2a8874827b       19           0             0   \n",
       "29112336                1  C_ID_2a8874827b       19           0             0   \n",
       "29112337                1  C_ID_5c356aa384       20           0             0   \n",
       "29112338                1  C_ID_5c356aa384      330           0             0   \n",
       "29112339                1  C_ID_5c356aa384       69           0             0   \n",
       "29112340                1  C_ID_f9f906a4a2       -1           1             1   \n",
       "29112341                1  C_ID_f9f906a4a2       -1           1             1   \n",
       "29112342                1  C_ID_f9f906a4a2       -1           1             1   \n",
       "29112343                1  C_ID_5cf3187742      277           0             0   \n",
       "29112344                1  C_ID_5cf3187742      277           0             0   \n",
       "29112345                1  C_ID_5cf3187742      277           0             0   \n",
       "29112346                1  C_ID_803aa0aed4       30           0             0   \n",
       "29112347                1  C_ID_803aa0aed4      330           0             0   \n",
       "29112348                1  C_ID_803aa0aed4       69           0             0   \n",
       "29112349                1  C_ID_62df280b20       -1           1             2   \n",
       "29112350                1  C_ID_62df280b20       -1           1             2   \n",
       "29112351                1  C_ID_62df280b20      168           0             2   \n",
       "29112352                1  C_ID_62df280b20       24           0             3   \n",
       "29112353                1  C_ID_e49b1996b0       11           0             1   \n",
       "29112354                1  C_ID_e49b1996b0       -1           1             1   \n",
       "29112355                1  C_ID_e49b1996b0       11           0             1   \n",
       "29112356                1  C_ID_2863d2fa95       -1           1             1   \n",
       "29112357                1  C_ID_2863d2fa95       -1           1             1   \n",
       "29112358                1  C_ID_5c240d6e3c        3           0             0   \n",
       "29112359                1  C_ID_5c240d6e3c      331           0             0   \n",
       "29112360                1  C_ID_5c240d6e3c      331           0             0   \n",
       "\n",
       "         category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0                 A                    80  M_ID_e020e9b302         -8   \n",
       "1                 A                   367  M_ID_86ec983688         -7   \n",
       "2                 A                    80  M_ID_979ed661fc         -6   \n",
       "3                 A                   560  M_ID_e6d5ae8ea6         -5   \n",
       "4                 A                    80  M_ID_e020e9b302        -11   \n",
       "5                 A                    80  M_ID_50af771f8d          0   \n",
       "6                 A                   278  M_ID_5e8220e564        -11   \n",
       "7                 A                    80  M_ID_9d41786a50         -3   \n",
       "8                 A                    80  M_ID_979ed661fc         -8   \n",
       "9                 A                    80  M_ID_74ba14b5fc        -11   \n",
       "10                A                   683  M_ID_1449f22bfb         -9   \n",
       "11                A                   560  M_ID_7c5e93af2f          0   \n",
       "12                A                    80  M_ID_e020e9b302         -8   \n",
       "13                A                   130  M_ID_e8fb39882d         -7   \n",
       "14                A                    80  M_ID_97e86eae5f         -4   \n",
       "15                A                   560  M_ID_e6d5ae8ea6         -8   \n",
       "16                A                   879  M_ID_00a6ca8a8a          0   \n",
       "17                A                   278  M_ID_21e1552dab         -7   \n",
       "18                A                    80  M_ID_4524a562f3         -1   \n",
       "19                A                    80  M_ID_e020e9b302         -6   \n",
       "20                A                   278  M_ID_21e1552dab         -6   \n",
       "21                A                    80  M_ID_979ed661fc         -7   \n",
       "22                A                    80  M_ID_979ed661fc         -7   \n",
       "23                A                   278  M_ID_e020e9b302         -9   \n",
       "24                A                   511  M_ID_79db784180        -13   \n",
       "25                A                    80  M_ID_50af771f8d          0   \n",
       "26                A                   278  M_ID_e020e9b302        -10   \n",
       "27                A                    80  M_ID_979ed661fc         -8   \n",
       "28                A                   278  M_ID_21e1552dab        -11   \n",
       "29                A                    80  M_ID_dc7356f06d         -6   \n",
       "...             ...                   ...              ...        ...   \n",
       "29112331          B                   879  M_ID_00a6ca8a8a         -7   \n",
       "29112332          C                   544  M_ID_3111c6df35         -6   \n",
       "29112333          C                   210  M_ID_cfa9a773ca          0   \n",
       "29112334          C                   210  M_ID_6464db3b45         -1   \n",
       "29112335          A                   307  M_ID_0bd214d6c8         -1   \n",
       "29112336          A                   607  M_ID_b98db225f5          0   \n",
       "29112337          A                   307  M_ID_69c092c26e         -1   \n",
       "29112338          A                   705  M_ID_b872abf8ca         -3   \n",
       "29112339          A                   879  M_ID_00a6ca8a8a         -3   \n",
       "29112340          B                   661  M_ID_fc7d7969c3         -1   \n",
       "29112341          B                   661  M_ID_fc7d7969c3          0   \n",
       "29112342          B                   661  M_ID_fc7d7969c3         -2   \n",
       "29112343          A                   278  M_ID_4b5760f37b         -3   \n",
       "29112344          A                    68  M_ID_9a72bcd3b4         -2   \n",
       "29112345          A                   367  M_ID_bf86e8edcd         -5   \n",
       "29112346          A                   705  M_ID_1ada7c0ceb          0   \n",
       "29112347          A                   705  M_ID_393b4b8cec         -8   \n",
       "29112348          A                   879  M_ID_00a6ca8a8a         -9   \n",
       "29112349          C                   489  M_ID_244299ea12         -2   \n",
       "29112350          C                   489  M_ID_244299ea12         -3   \n",
       "29112351          C                   506  M_ID_aa18020893         -3   \n",
       "29112352          C                    87  M_ID_94f6f392c4         -3   \n",
       "29112353          B                   705  M_ID_b692f6f5d1         -2   \n",
       "29112354          B                   550  M_ID_09d7a200d1         -1   \n",
       "29112355          B                   130  M_ID_ea5d727248          0   \n",
       "29112356          B                   360  M_ID_edd92b6720         -1   \n",
       "29112357          B                   360  M_ID_edd92b6720          0   \n",
       "29112358          A                   278  M_ID_9cdcfe8673          0   \n",
       "29112359          A                   514  M_ID_1a75f94f92         -1   \n",
       "29112360          A                   514  M_ID_1a75f94f92         -2   \n",
       "\n",
       "          purchase_amount       purchase_date  category_2  state_id  \\\n",
       "0               -0.703331 2017-06-25 15:33:07         1.0        16   \n",
       "1               -0.733128 2017-07-15 12:10:45         1.0        16   \n",
       "2               -0.720386 2017-08-09 22:04:29         1.0        16   \n",
       "3               -0.735352 2017-09-02 10:06:26         1.0        16   \n",
       "4               -0.722865 2017-03-10 01:14:19         1.0        16   \n",
       "5               -0.734887 2018-02-24 08:45:05         1.0         9   \n",
       "6               -0.716855 2017-03-21 00:10:51         1.0        16   \n",
       "7               -0.657049 2017-11-18 20:05:55         1.0        16   \n",
       "8               -0.737967 2017-06-01 22:02:56         1.0        16   \n",
       "9               -0.715352 2017-03-16 15:41:22         1.0        16   \n",
       "10              -0.734135 2017-05-09 12:42:07         1.0        16   \n",
       "11              -0.727929 2018-02-08 20:05:45         NaN        -1   \n",
       "12              -0.741649 2017-06-08 18:02:29         1.0        16   \n",
       "13              -0.727373 2017-07-14 12:59:38         1.0        16   \n",
       "14              -0.731881 2017-10-24 13:29:29         1.0        16   \n",
       "15              -0.738192 2017-06-14 07:40:48         1.0        16   \n",
       "16              -0.725871 2018-02-07 12:19:33         1.0         9   \n",
       "17              -0.734887 2017-07-07 13:03:27         1.0        16   \n",
       "18              -0.699725 2018-01-08 23:54:29         1.0         9   \n",
       "19              -0.745405 2017-08-11 17:53:00         1.0        16   \n",
       "20              -0.734887 2017-08-30 12:53:57         1.0        16   \n",
       "21              -0.737967 2017-07-01 21:27:23         1.0        16   \n",
       "22              -0.739545 2017-07-14 22:06:02         1.0        16   \n",
       "23              -0.726998 2017-05-06 12:29:50         1.0        16   \n",
       "24              -0.731881 2017-01-20 09:16:43         1.0        16   \n",
       "25              -0.735638 2018-02-26 14:54:38         1.0         9   \n",
       "26              -0.726472 2017-04-29 12:30:03         1.0        16   \n",
       "27              -0.726772 2017-06-23 21:43:17         1.0        16   \n",
       "28              -0.721363 2017-03-10 15:46:19         1.0        16   \n",
       "29              -0.692211 2017-08-05 19:10:32         1.0        16   \n",
       "...                   ...                 ...         ...       ...   \n",
       "29112331        -0.744774 2017-07-12 18:01:13         1.0         9   \n",
       "29112332        -0.040692 2017-08-03 15:06:50         NaN        -1   \n",
       "29112333         0.502952 2018-01-29 15:08:56         NaN        -1   \n",
       "29112334         0.506889 2017-12-11 19:03:31         NaN        -1   \n",
       "29112335        -0.681542 2017-01-06 14:54:55         1.0         9   \n",
       "29112336        -0.708891 2017-02-07 16:02:48         1.0         9   \n",
       "29112337        -0.596643 2017-12-05 12:38:59         3.0        19   \n",
       "29112338        -0.550316 2017-10-07 20:00:40         3.0        17   \n",
       "29112339        -0.605659 2017-10-02 00:35:15         1.0         9   \n",
       "29112340        -0.704984 2018-01-01 18:33:46         NaN        -1   \n",
       "29112341        -0.704984 2018-02-01 18:06:30         NaN        -1   \n",
       "29112342        -0.745405 2017-12-24 00:19:52         NaN        -1   \n",
       "29112343        -0.666065 2017-11-26 02:27:39         4.0        13   \n",
       "29112344        -0.686817 2017-12-30 19:36:04         4.0        13   \n",
       "29112345        -0.735638 2017-09-23 22:42:58         4.0        13   \n",
       "29112346        -0.718523 2018-02-20 14:18:46         3.0        17   \n",
       "29112347        -0.702504 2017-06-01 16:55:08         3.0        17   \n",
       "29112348        -0.724067 2017-05-20 16:55:17         1.0         9   \n",
       "29112349         1.363355 2017-09-18 20:35:39         NaN        -1   \n",
       "29112350         0.032638 2017-08-08 14:36:26         NaN        -1   \n",
       "29112351        -0.612631 2017-08-29 11:43:46         1.0         9   \n",
       "29112352        -0.459451 2017-08-29 11:28:25         1.0         9   \n",
       "29112353        -0.618747 2017-12-29 14:43:53         2.0        23   \n",
       "29112354        -0.656749 2018-01-23 01:52:28         NaN        -1   \n",
       "29112355        -0.694315 2018-02-07 18:17:01         2.0        23   \n",
       "29112356        -0.632706 2017-01-20 08:52:04         NaN        -1   \n",
       "29112357        -0.632706 2017-02-20 04:40:50         NaN        -1   \n",
       "29112358        -0.657740 2017-12-26 18:37:51         1.0        16   \n",
       "29112359         0.770620 2017-11-24 14:18:15         1.0        16   \n",
       "29112360         1.134411 2017-10-26 14:09:40         1.0        16   \n",
       "\n",
       "          subsector_id  \n",
       "0                   37  \n",
       "1                   16  \n",
       "2                   37  \n",
       "3                   34  \n",
       "4                   37  \n",
       "5                   37  \n",
       "6                   37  \n",
       "7                   37  \n",
       "8                   37  \n",
       "9                   37  \n",
       "10                  34  \n",
       "11                  34  \n",
       "12                  37  \n",
       "13                  41  \n",
       "14                  37  \n",
       "15                  34  \n",
       "16                  29  \n",
       "17                  37  \n",
       "18                  37  \n",
       "19                  37  \n",
       "20                  37  \n",
       "21                  37  \n",
       "22                  37  \n",
       "23                  37  \n",
       "24                   7  \n",
       "25                  37  \n",
       "26                  37  \n",
       "27                  37  \n",
       "28                  37  \n",
       "29                  37  \n",
       "...                ...  \n",
       "29112331            29  \n",
       "29112332            29  \n",
       "29112333            35  \n",
       "29112334            35  \n",
       "29112335            19  \n",
       "29112336            29  \n",
       "29112337            19  \n",
       "29112338            33  \n",
       "29112339            29  \n",
       "29112340             8  \n",
       "29112341             8  \n",
       "29112342             8  \n",
       "29112343            37  \n",
       "29112344            27  \n",
       "29112345            16  \n",
       "29112346            33  \n",
       "29112347            33  \n",
       "29112348            29  \n",
       "29112349            16  \n",
       "29112350            16  \n",
       "29112351            30  \n",
       "29112352            27  \n",
       "29112353            33  \n",
       "29112354             3  \n",
       "29112355            41  \n",
       "29112356            34  \n",
       "29112357            34  \n",
       "29112358            37  \n",
       "29112359             9  \n",
       "29112360             9  \n",
       "\n",
       "[29112361 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b1da58e20da9fbb6d200119b242c168ae8fc5843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1304.89 Mb (54.8% reduction)\n",
      "Mem. usage decreased to 84.24 Mb (56.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "historical_transactions = pd.get_dummies(historical_transactions, columns=['category_2', 'category_3'])\n",
    "new_transactions = pd.get_dummies(new_transactions, columns=['category_2', 'category_3'])\n",
    "\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "agg_fun = {'authorized_flag': ['sum', 'mean']}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d0142e5b8a9c7e012d306c496c452c70dbd5fdcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>category_2_1.0</th>\n",
       "      <th>category_2_2.0</th>\n",
       "      <th>category_2_3.0</th>\n",
       "      <th>category_2_4.0</th>\n",
       "      <th>category_2_5.0</th>\n",
       "      <th>category_3_A</th>\n",
       "      <th>category_3_B</th>\n",
       "      <th>category_3_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>842</td>\n",
       "      <td>M_ID_22c9cfa265</td>\n",
       "      <td>-10</td>\n",
       "      <td>-0.730379</td>\n",
       "      <td>2017-04-07 12:58:09</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.723782</td>\n",
       "      <td>2017-09-17 22:40:27</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-5</td>\n",
       "      <td>-0.723782</td>\n",
       "      <td>2017-09-17 22:40:26</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>605</td>\n",
       "      <td>M_ID_c2ae34c2ef</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>2018-02-20 10:57:50</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>M_ID_e6d5ae8ea6</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.738132</td>\n",
       "      <td>2017-07-08 07:33:31</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     authorized_flag          card_id  city_id  category_1  installments  \\\n",
       "115                0  C_ID_4e6213e9bc       88           0             0   \n",
       "132                0  C_ID_4e6213e9bc       88           0             0   \n",
       "148                0  C_ID_4e6213e9bc       88           0             0   \n",
       "168                0  C_ID_4e6213e9bc      333           0             0   \n",
       "213                0  C_ID_4e6213e9bc       88           0             0   \n",
       "\n",
       "     merchant_category_id      merchant_id  month_lag  purchase_amount  \\\n",
       "115                   842  M_ID_22c9cfa265        -10        -0.730379   \n",
       "132                   367  M_ID_86ec983688         -5        -0.723782   \n",
       "148                   367  M_ID_86ec983688         -5        -0.723782   \n",
       "168                   605  M_ID_c2ae34c2ef          0        -0.664262   \n",
       "213                   560  M_ID_e6d5ae8ea6         -7        -0.738132   \n",
       "\n",
       "          purchase_date  state_id  subsector_id  category_2_1.0  \\\n",
       "115 2017-04-07 12:58:09        16            37               1   \n",
       "132 2017-09-17 22:40:27        16            16               1   \n",
       "148 2017-09-17 22:40:26        16            16               1   \n",
       "168 2018-02-20 10:57:50         9             2               1   \n",
       "213 2017-07-08 07:33:31        16            34               1   \n",
       "\n",
       "     category_2_2.0  category_2_3.0  category_2_4.0  category_2_5.0  \\\n",
       "115               0               0               0               0   \n",
       "132               0               0               0               0   \n",
       "148               0               0               0               0   \n",
       "168               0               0               0               0   \n",
       "213               0               0               0               0   \n",
       "\n",
       "     category_3_A  category_3_B  category_3_C  \n",
       "115             1             0             0  \n",
       "132             1             0             0  \n",
       "148             1             0             0  \n",
       "168             1             0             0  \n",
       "213             1             0             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_transactions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73e0936c181e4cec16da05d6987cd96b99ed87d1"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## Feature engineering\n",
    "First, following [Robin Denz](https://www.kaggle.com/denzo123/a-closer-look-at-date-variables) analysis, I define a few dates features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "76c41ff3af21c7bfa9194f873f6f47c5849eb4d8"
   },
   "outputs": [],
   "source": [
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7493b32cb783d6fb6afdad60964eb41c9e42c2e3"
   },
   "source": [
    "Then I define two functions that aggregate the info contained in these two tables. The first function aggregates the function by grouping on `card_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "82c25c7cd0d075195fb7bd63211c66f0dac9304b"
   },
   "outputs": [],
   "source": [
    "def aggregate_transactions(history):\n",
    "    \n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n",
    "                                      astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['min', 'max']\n",
    "        }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "44ea0524d0af0001c5ea57a6593be35e2402d0b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_category_2_1.0_mean</th>\n",
       "      <th>hist_category_2_2.0_mean</th>\n",
       "      <th>hist_category_2_3.0_mean</th>\n",
       "      <th>hist_category_2_4.0_mean</th>\n",
       "      <th>hist_category_2_5.0_mean</th>\n",
       "      <th>hist_category_3_A_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_installments_std</th>\n",
       "      <th>hist_purchase_month_mean</th>\n",
       "      <th>hist_purchase_month_max</th>\n",
       "      <th>hist_purchase_month_min</th>\n",
       "      <th>hist_purchase_month_std</th>\n",
       "      <th>hist_purchase_date_ptp</th>\n",
       "      <th>hist_purchase_date_min</th>\n",
       "      <th>hist_purchase_date_max</th>\n",
       "      <th>hist_month_lag_min</th>\n",
       "      <th>hist_month_lag_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667367</td>\n",
       "      <td>5.914286</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.071419</td>\n",
       "      <td>28858113.0</td>\n",
       "      <td>1.489250e+09</td>\n",
       "      <td>1.518108e+09</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5.773503</td>\n",
       "      <td>3609150.0</td>\n",
       "      <td>1.514660e+09</td>\n",
       "      <td>1.518269e+09</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4.725816</td>\n",
       "      <td>22098875.0</td>\n",
       "      <td>1.496772e+09</td>\n",
       "      <td>1.518871e+09</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395847</td>\n",
       "      <td>6.481481</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2.375684</td>\n",
       "      <td>16780236.0</td>\n",
       "      <td>1.488636e+09</td>\n",
       "      <td>1.505416e+09</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.288689</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>6701589.0</td>\n",
       "      <td>1.502099e+09</td>\n",
       "      <td>1.508801e+09</td>\n",
       "      <td>-6</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  hist_transactions_count  hist_category_1_sum  \\\n",
       "0  C_ID_00007093c1                       35                  4.0   \n",
       "1  C_ID_0001238066                        3                  0.0   \n",
       "2  C_ID_0001506ef0                        4                  0.0   \n",
       "3  C_ID_0001793786                       27                  2.0   \n",
       "4  C_ID_000183fdda                        7                  0.0   \n",
       "\n",
       "   hist_category_1_mean  hist_category_2_1.0_mean  hist_category_2_2.0_mean  \\\n",
       "0              0.114286                  0.000000                  0.000000   \n",
       "1              0.000000                  0.333333                  0.000000   \n",
       "2              0.000000                  0.000000                  0.000000   \n",
       "3              0.074074                  0.111111                  0.296296   \n",
       "4              0.000000                  0.000000                  0.000000   \n",
       "\n",
       "   hist_category_2_3.0_mean  hist_category_2_4.0_mean  \\\n",
       "0                  0.885714                       0.0   \n",
       "1                  0.000000                       0.0   \n",
       "2                  1.000000                       0.0   \n",
       "3                  0.111111                       0.0   \n",
       "4                  1.000000                       0.0   \n",
       "\n",
       "   hist_category_2_5.0_mean  hist_category_3_A_mean         ...          \\\n",
       "0                  0.000000                0.000000         ...           \n",
       "1                  0.666667                0.000000         ...           \n",
       "2                  0.000000                0.750000         ...           \n",
       "3                  0.000000                0.814815         ...           \n",
       "4                  0.000000                0.000000         ...           \n",
       "\n",
       "   hist_installments_std  hist_purchase_month_mean  hist_purchase_month_max  \\\n",
       "0               0.667367                  5.914286                       12   \n",
       "1               0.000000                  8.666667                       12   \n",
       "2               0.500000                  5.500000                       12   \n",
       "3               0.395847                  6.481481                        9   \n",
       "4               2.288689                  8.285714                       10   \n",
       "\n",
       "   hist_purchase_month_min  hist_purchase_month_std  hist_purchase_date_ptp  \\\n",
       "0                        1                 3.071419              28858113.0   \n",
       "1                        2                 5.773503               3609150.0   \n",
       "2                        2                 4.725816              22098875.0   \n",
       "3                        3                 2.375684              16780236.0   \n",
       "4                        8                 0.755929               6701589.0   \n",
       "\n",
       "   hist_purchase_date_min  hist_purchase_date_max  hist_month_lag_min  \\\n",
       "0            1.489250e+09            1.518108e+09                 -11   \n",
       "1            1.514660e+09            1.518269e+09                  -2   \n",
       "2            1.496772e+09            1.518871e+09                  -8   \n",
       "3            1.488636e+09            1.505416e+09                  -7   \n",
       "4            1.502099e+09            1.508801e+09                  -6   \n",
       "\n",
       "   hist_month_lag_max  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                  -1  \n",
       "4                  -4  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "history[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "be09e1a7d4f307beb59c18bf61261239877da4e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>auth_transactions_count</th>\n",
       "      <th>auth_category_1_sum</th>\n",
       "      <th>auth_category_1_mean</th>\n",
       "      <th>auth_category_2_1.0_mean</th>\n",
       "      <th>auth_category_2_2.0_mean</th>\n",
       "      <th>auth_category_2_3.0_mean</th>\n",
       "      <th>auth_category_2_4.0_mean</th>\n",
       "      <th>auth_category_2_5.0_mean</th>\n",
       "      <th>auth_category_3_A_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>auth_installments_std</th>\n",
       "      <th>auth_purchase_month_mean</th>\n",
       "      <th>auth_purchase_month_max</th>\n",
       "      <th>auth_purchase_month_min</th>\n",
       "      <th>auth_purchase_month_std</th>\n",
       "      <th>auth_purchase_date_ptp</th>\n",
       "      <th>auth_purchase_date_min</th>\n",
       "      <th>auth_purchase_date_max</th>\n",
       "      <th>auth_month_lag_min</th>\n",
       "      <th>auth_month_lag_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>114</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795159</td>\n",
       "      <td>6.517544</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.371490</td>\n",
       "      <td>32627654.0</td>\n",
       "      <td>1.487081e+09</td>\n",
       "      <td>1.519708e+09</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>120</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501050</td>\n",
       "      <td>7.275000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4.895483</td>\n",
       "      <td>13110825.0</td>\n",
       "      <td>1.506638e+09</td>\n",
       "      <td>1.519748e+09</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.887097</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4.538017</td>\n",
       "      <td>34460275.0</td>\n",
       "      <td>1.484411e+09</td>\n",
       "      <td>1.518871e+09</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.359788</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.698413</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.301491</td>\n",
       "      <td>24487497.0</td>\n",
       "      <td>1.484994e+09</td>\n",
       "      <td>1.509481e+09</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>137</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.108912</td>\n",
       "      <td>6.810219</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4.538289</td>\n",
       "      <td>15148616.0</td>\n",
       "      <td>1.504444e+09</td>\n",
       "      <td>1.519592e+09</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  auth_transactions_count  auth_category_1_sum  \\\n",
       "0  C_ID_00007093c1                      114                 24.0   \n",
       "1  C_ID_0001238066                      120                  2.0   \n",
       "2  C_ID_0001506ef0                       62                  0.0   \n",
       "3  C_ID_0001793786                      189                  0.0   \n",
       "4  C_ID_000183fdda                      137                  4.0   \n",
       "\n",
       "   auth_category_1_mean  auth_category_2_1.0_mean  auth_category_2_2.0_mean  \\\n",
       "0              0.210526                  0.000000                  0.000000   \n",
       "1              0.016667                  0.783333                  0.000000   \n",
       "2              0.000000                  0.032258                  0.000000   \n",
       "3              0.000000                  0.042328                  0.359788   \n",
       "4              0.029197                  0.051095                  0.007299   \n",
       "\n",
       "   auth_category_2_3.0_mean  auth_category_2_4.0_mean  \\\n",
       "0                  0.780702                       0.0   \n",
       "1                  0.000000                       0.0   \n",
       "2                  0.967742                       0.0   \n",
       "3                  0.063492                       0.0   \n",
       "4                  0.905109                       0.0   \n",
       "\n",
       "   auth_category_2_5.0_mean  auth_category_3_A_mean         ...          \\\n",
       "0                  0.008772                     0.0         ...           \n",
       "1                  0.150000                     0.0         ...           \n",
       "2                  0.000000                     1.0         ...           \n",
       "3                  0.000000                     1.0         ...           \n",
       "4                  0.007299                     0.0         ...           \n",
       "\n",
       "   auth_installments_std  auth_purchase_month_mean  auth_purchase_month_max  \\\n",
       "0               0.795159                  6.517544                       12   \n",
       "1               1.501050                  7.275000                       12   \n",
       "2               0.000000                  6.887097                       12   \n",
       "3               0.000000                  6.698413                       10   \n",
       "4               2.108912                  6.810219                       12   \n",
       "\n",
       "   auth_purchase_month_min  auth_purchase_month_std  auth_purchase_date_ptp  \\\n",
       "0                        1                 3.371490              32627654.0   \n",
       "1                        1                 4.895483              13110825.0   \n",
       "2                        1                 4.538017              34460275.0   \n",
       "3                        1                 2.301491              24487497.0   \n",
       "4                        1                 4.538289              15148616.0   \n",
       "\n",
       "   auth_purchase_date_min  auth_purchase_date_max  auth_month_lag_min  \\\n",
       "0            1.487081e+09            1.519708e+09                 -12   \n",
       "1            1.506638e+09            1.519748e+09                  -5   \n",
       "2            1.484411e+09            1.518871e+09                 -13   \n",
       "3            1.484994e+09            1.509481e+09                  -9   \n",
       "4            1.504444e+09            1.519592e+09                  -5   \n",
       "\n",
       "   auth_month_lag_max  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "authorized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "78b87a7863b62fa3758ef3167504d3ad8c279f3d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>new_transactions_count</th>\n",
       "      <th>new_category_1_sum</th>\n",
       "      <th>new_category_1_mean</th>\n",
       "      <th>new_category_2_1.0_mean</th>\n",
       "      <th>new_category_2_2.0_mean</th>\n",
       "      <th>new_category_2_3.0_mean</th>\n",
       "      <th>new_category_2_4.0_mean</th>\n",
       "      <th>new_category_2_5.0_mean</th>\n",
       "      <th>new_category_3_A_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>new_installments_std</th>\n",
       "      <th>new_purchase_month_mean</th>\n",
       "      <th>new_purchase_month_max</th>\n",
       "      <th>new_purchase_month_min</th>\n",
       "      <th>new_purchase_month_std</th>\n",
       "      <th>new_purchase_date_ptp</th>\n",
       "      <th>new_purchase_date_min</th>\n",
       "      <th>new_purchase_date_max</th>\n",
       "      <th>new_month_lag_min</th>\n",
       "      <th>new_month_lag_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>537024.0</td>\n",
       "      <td>1.522754e+09</td>\n",
       "      <td>1.523291e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079941</td>\n",
       "      <td>3.346154</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485165</td>\n",
       "      <td>5195343.0</td>\n",
       "      <td>1.519923e+09</td>\n",
       "      <td>1.525118e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>471152.0</td>\n",
       "      <td>1.521239e+09</td>\n",
       "      <td>1.521710e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.16129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.322581</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.475191</td>\n",
       "      <td>3981096.0</td>\n",
       "      <td>1.510761e+09</td>\n",
       "      <td>1.514742e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.293340</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.467099</td>\n",
       "      <td>5106807.0</td>\n",
       "      <td>1.519994e+09</td>\n",
       "      <td>1.525100e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  new_transactions_count  new_category_1_sum  \\\n",
       "0  C_ID_00007093c1                       2                   0   \n",
       "1  C_ID_0001238066                      26                   2   \n",
       "2  C_ID_0001506ef0                       2                   0   \n",
       "3  C_ID_0001793786                      31                   0   \n",
       "4  C_ID_000183fdda                      11                   0   \n",
       "\n",
       "   new_category_1_mean  new_category_2_1.0_mean  new_category_2_2.0_mean  \\\n",
       "0             0.000000                 0.500000                 0.000000   \n",
       "1             0.076923                 0.769231                 0.000000   \n",
       "2             0.000000                 0.000000                 0.000000   \n",
       "3             0.000000                 0.483871                 0.258065   \n",
       "4             0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   new_category_2_3.0_mean  new_category_2_4.0_mean  new_category_2_5.0_mean  \\\n",
       "0                  0.50000                      0.0                 0.000000   \n",
       "1                  0.00000                      0.0                 0.115385   \n",
       "2                  1.00000                      0.0                 0.000000   \n",
       "3                  0.16129                      0.0                 0.032258   \n",
       "4                  1.00000                      0.0                 0.000000   \n",
       "\n",
       "   new_category_3_A_mean        ...          new_installments_std  \\\n",
       "0                    0.0        ...                      0.000000   \n",
       "1                    0.0        ...                      2.079941   \n",
       "2                    1.0        ...                      0.000000   \n",
       "3                    1.0        ...                      0.000000   \n",
       "4                    0.0        ...                      1.293340   \n",
       "\n",
       "   new_purchase_month_mean  new_purchase_month_max  new_purchase_month_min  \\\n",
       "0                 4.000000                       4                       4   \n",
       "1                 3.346154                       4                       3   \n",
       "2                 3.000000                       3                       3   \n",
       "3                11.322581                      12                      11   \n",
       "4                 3.272727                       4                       3   \n",
       "\n",
       "   new_purchase_month_std  new_purchase_date_ptp  new_purchase_date_min  \\\n",
       "0                0.000000               537024.0           1.522754e+09   \n",
       "1                0.485165              5195343.0           1.519923e+09   \n",
       "2                0.000000               471152.0           1.521239e+09   \n",
       "3                0.475191              3981096.0           1.510761e+09   \n",
       "4                0.467099              5106807.0           1.519994e+09   \n",
       "\n",
       "   new_purchase_date_max  new_month_lag_min  new_month_lag_max  \n",
       "0           1.523291e+09                  2                  2  \n",
       "1           1.525118e+09                  1                  2  \n",
       "2           1.521710e+09                  1                  1  \n",
       "3           1.514742e+09                  1                  2  \n",
       "4           1.525100e+09                  1                  2  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "new[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "843a929ddea5e317f882c58c3b69f5e5a4476a38"
   },
   "source": [
    "The second function first aggregates on the two variables `card_id` and `month_lag`. Then a second grouping is performed to aggregate over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "f210acd074326ea74c1b9316eec3136f4ab73855",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>month_lag_mean</th>\n",
       "      <th>month_lag_std</th>\n",
       "      <th>purchase_amount_count_mean</th>\n",
       "      <th>purchase_amount_count_std</th>\n",
       "      <th>purchase_amount_sum_mean</th>\n",
       "      <th>purchase_amount_sum_std</th>\n",
       "      <th>purchase_amount_mean_mean</th>\n",
       "      <th>purchase_amount_mean_std</th>\n",
       "      <th>purchase_amount_min_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>installments_sum_mean</th>\n",
       "      <th>installments_sum_std</th>\n",
       "      <th>installments_mean_mean</th>\n",
       "      <th>installments_mean_std</th>\n",
       "      <th>installments_min_mean</th>\n",
       "      <th>installments_min_std</th>\n",
       "      <th>installments_max_mean</th>\n",
       "      <th>installments_max_std</th>\n",
       "      <th>installments_std_mean</th>\n",
       "      <th>installments_std_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>-5.500000</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>1.621354</td>\n",
       "      <td>-1.200164</td>\n",
       "      <td>0.999049</td>\n",
       "      <td>-0.431906</td>\n",
       "      <td>0.260478</td>\n",
       "      <td>-0.613764</td>\n",
       "      <td>...</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.107908</td>\n",
       "      <td>1.176389</td>\n",
       "      <td>0.326634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.355262</td>\n",
       "      <td>0.480551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.894964</td>\n",
       "      <td>0.421890</td>\n",
       "      <td>-0.596643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.596643</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>4.163332</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>-0.968594</td>\n",
       "      <td>0.395645</td>\n",
       "      <td>-0.731020</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>-0.732397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_0001793786</td>\n",
       "      <td>-3.833333</td>\n",
       "      <td>2.316607</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.974842</td>\n",
       "      <td>-1.970890</td>\n",
       "      <td>2.037261</td>\n",
       "      <td>-0.423501</td>\n",
       "      <td>0.392159</td>\n",
       "      <td>-0.676499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.983192</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.400520</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.179558</td>\n",
       "      <td>0.279244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_000183fdda</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>-0.470690</td>\n",
       "      <td>0.344856</td>\n",
       "      <td>-0.376174</td>\n",
       "      <td>0.478523</td>\n",
       "      <td>-0.579708</td>\n",
       "      <td>...</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>12.020815</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>2.366432</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C_ID_00024e244b</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.397276</td>\n",
       "      <td>-1.186659</td>\n",
       "      <td>1.210810</td>\n",
       "      <td>-0.558085</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>-0.607249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.112697</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.419041</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.269338</td>\n",
       "      <td>0.312603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C_ID_0002709b5a</td>\n",
       "      <td>-7.250000</td>\n",
       "      <td>5.057997</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.929675</td>\n",
       "      <td>0.699316</td>\n",
       "      <td>-0.604163</td>\n",
       "      <td>0.156637</td>\n",
       "      <td>-0.616865</td>\n",
       "      <td>...</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.362908</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C_ID_00027503e2</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2.915476</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>-2.669652</td>\n",
       "      <td>1.128393</td>\n",
       "      <td>-0.741249</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.742989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C_ID_000298032a</td>\n",
       "      <td>-6.500000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.617958</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>-0.617958</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>-0.617958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C_ID_0002ba3c2e</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>3.559026</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.516575</td>\n",
       "      <td>-1.547448</td>\n",
       "      <td>0.910264</td>\n",
       "      <td>-0.641704</td>\n",
       "      <td>0.080430</td>\n",
       "      <td>-0.655965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  month_lag_mean  month_lag_std  purchase_amount_count_mean  \\\n",
       "0  C_ID_00007093c1       -5.500000       3.605551                    2.916667   \n",
       "1  C_ID_0001238066       -1.000000       1.414214                    1.500000   \n",
       "2  C_ID_0001506ef0       -3.333333       4.163332                    1.333333   \n",
       "3  C_ID_0001793786       -3.833333       2.316607                    4.500000   \n",
       "4  C_ID_000183fdda       -5.000000       1.414214                    3.500000   \n",
       "5  C_ID_00024e244b       -5.000000       4.000000                    2.428571   \n",
       "6  C_ID_0002709b5a       -7.250000       5.057997                    1.500000   \n",
       "7  C_ID_00027503e2       -4.000000       2.915476                    3.600000   \n",
       "8  C_ID_000298032a       -6.500000       3.535534                    1.000000   \n",
       "9  C_ID_0002ba3c2e       -3.666667       3.559026                    2.500000   \n",
       "\n",
       "   purchase_amount_count_std  purchase_amount_sum_mean  \\\n",
       "0                   1.621354                 -1.200164   \n",
       "1                   0.707107                 -0.894964   \n",
       "2                   0.577350                 -0.968594   \n",
       "3                   1.974842                 -1.970890   \n",
       "4                   3.535534                 -0.470690   \n",
       "5                   1.397276                 -1.186659   \n",
       "6                   1.000000                 -0.929675   \n",
       "7                   1.516575                 -2.669652   \n",
       "8                   0.000000                 -0.617958   \n",
       "9                   1.516575                 -1.547448   \n",
       "\n",
       "   purchase_amount_sum_std  purchase_amount_mean_mean  \\\n",
       "0                 0.999049                  -0.431906   \n",
       "1                 0.421890                  -0.596643   \n",
       "2                 0.395645                  -0.731020   \n",
       "3                 2.037261                  -0.423501   \n",
       "4                 0.344856                  -0.376174   \n",
       "5                 1.210810                  -0.558085   \n",
       "6                 0.699316                  -0.604163   \n",
       "7                 1.128393                  -0.741249   \n",
       "8                 0.093896                  -0.617958   \n",
       "9                 0.910264                  -0.641704   \n",
       "\n",
       "   purchase_amount_mean_std  purchase_amount_min_mean          ...           \\\n",
       "0                  0.260478                 -0.613764          ...            \n",
       "1                  0.000000                 -0.596643          ...            \n",
       "2                  0.015849                 -0.732397          ...            \n",
       "3                  0.392159                 -0.676499          ...            \n",
       "4                  0.478523                 -0.579708          ...            \n",
       "5                  0.326273                 -0.607249          ...            \n",
       "6                  0.156637                 -0.616865          ...            \n",
       "7                  0.002457                 -0.742989          ...            \n",
       "8                  0.093896                 -0.617958          ...            \n",
       "9                  0.080430                 -0.655965          ...            \n",
       "\n",
       "   installments_sum_mean  installments_sum_std  installments_mean_mean  \\\n",
       "0               3.750000              3.107908                1.176389   \n",
       "1               1.500000              0.707107                1.000000   \n",
       "2               0.333333              0.577350                0.166667   \n",
       "3               0.833333              0.983192                0.291667   \n",
       "4               9.500000             12.020815                2.000000   \n",
       "5               0.714286              1.112697                0.297619   \n",
       "6               2.750000              2.362908                2.250000   \n",
       "7               0.000000              0.000000                0.000000   \n",
       "8               0.000000              0.000000                0.000000   \n",
       "9               0.000000              0.000000                0.000000   \n",
       "\n",
       "   installments_mean_std  installments_min_mean  installments_min_std  \\\n",
       "0               0.326634               1.000000              0.000000   \n",
       "1               0.000000               1.000000              0.000000   \n",
       "2               0.288675               0.000000              0.000000   \n",
       "3               0.400520               0.166667              0.408248   \n",
       "4               1.414214               1.000000              0.000000   \n",
       "5               0.419041               0.142857              0.377964   \n",
       "6               2.500000               2.250000              2.500000   \n",
       "7               0.000000               0.000000              0.000000   \n",
       "8               0.000000               0.000000              0.000000   \n",
       "9               0.000000               0.000000              0.000000   \n",
       "\n",
       "   installments_max_mean  installments_max_std  installments_std_mean  \\\n",
       "0               1.500000              0.797724               0.355262   \n",
       "1               1.000000              0.000000               0.000000   \n",
       "2               0.333333              0.577350               0.707107   \n",
       "3               0.500000              0.547723               0.179558   \n",
       "4               3.500000              3.535534               2.366432   \n",
       "5               0.428571              0.534522               0.269338   \n",
       "6               2.250000              2.500000               0.000000   \n",
       "7               0.000000              0.000000               0.000000   \n",
       "8               0.000000              0.000000                    NaN   \n",
       "9               0.000000              0.000000               0.000000   \n",
       "\n",
       "   installments_std_std  \n",
       "0              0.480551  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3              0.279244  \n",
       "4                   NaN  \n",
       "5              0.312603  \n",
       "6                   NaN  \n",
       "7              0.000000  \n",
       "8                   NaN  \n",
       "9              0.000000  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aggregate_per_month(history):\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "            'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "            }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "#___________________________________________________________\n",
    "final_group =  aggregate_per_month(historical_transactions) \n",
    "final_group[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dcf0403c10b8ee817257a51e5edf8f1f81fcd593"
   },
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## 3. Training the model\n",
    "We now train the model with the features we previously defined. A first step consists in merging all the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "d27264c6c7f0af6af7ba141177bfd38f7a68dec3"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e06ddc8d941360b1b3e32bc59221e5f6fe729763"
   },
   "source": [
    "and to define the features we want to keep to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "6b0eba3e733ecdbab96d631eb46d42453d82aa20"
   },
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]\n",
    "categorical_feats = [c for c in features if 'feature_' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e67399b25b3886e306b274069ab240af7d060397"
   },
   "source": [
    "We then set the hyperparameters of the LGBM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "evals_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 100,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.005,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c610f51450145101732f4e9ed3247f2a9fa0b091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['outliers'] = 0\n",
    "train.loc[target < -30, 'outliers'] = 1\n",
    "train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7a7377cd7401f2cbd13ea707fbc2a2bebe229a6"
   },
   "source": [
    "We now train the model. Here, we use a standard KFold split of the dataset in order to validate the results and to stop the training. Interstingly, during the writing of this kernel, the model was enriched adding new features, which improved the CV score. The variations observed on the CV were found to be quite similar to the variations on the LB: it seems that the current competition won't give us headaches to define the correct validation scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_category_2_1.0_mean</th>\n",
       "      <th>hist_category_2_2.0_mean</th>\n",
       "      <th>hist_category_2_3.0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>installments_mean_mean</th>\n",
       "      <th>installments_mean_std</th>\n",
       "      <th>installments_min_mean</th>\n",
       "      <th>installments_min_std</th>\n",
       "      <th>installments_max_mean</th>\n",
       "      <th>installments_max_std</th>\n",
       "      <th>installments_std_mean</th>\n",
       "      <th>installments_std_std</th>\n",
       "      <th>authorized_flag_sum</th>\n",
       "      <th>authorized_flag_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.423007</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.269338</td>\n",
       "      <td>0.312603</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.033333</td>\n",
       "      <td>3.522310</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.728270</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.289522</td>\n",
       "      <td>1.781853</td>\n",
       "      <td>2.519921</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.968571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.962406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>427</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.934615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.306186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.876106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>488</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.917526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.892308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809524</td>\n",
       "      <td>1.864454</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.889822</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.914854</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>0.436436</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.831579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.216506</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.713043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.989059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>854</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.788854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.927711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>671</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097789</td>\n",
       "      <td>0.169017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.468807</td>\n",
       "      <td>0.178554</td>\n",
       "      <td>0.264950</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.927083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.127294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.262892</td>\n",
       "      <td>0.250995</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.814371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201887</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.643146</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.646670</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.674200</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201888</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.483046</td>\n",
       "      <td>0.262048</td>\n",
       "      <td>0.290282</td>\n",
       "      <td>454.0</td>\n",
       "      <td>0.941909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201889</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.971154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201890</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199074</td>\n",
       "      <td>0.371382</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.116363</td>\n",
       "      <td>0.223610</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.941558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201891</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>488</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.956989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201892</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.853659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201893</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201894</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201895</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.845070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201896</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201897</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201898</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.985714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201899</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>5.126524</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>6.363961</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>0.629153</td>\n",
       "      <td>0.889757</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201900</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.330830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>0.589039</td>\n",
       "      <td>0.419302</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.920680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201902</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>2.983845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.725816</td>\n",
       "      <td>1.976501</td>\n",
       "      <td>2.605795</td>\n",
       "      <td>395.0</td>\n",
       "      <td>0.970516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201903</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>641</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.970238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201904</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201905</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.140546</td>\n",
       "      <td>0.243432</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.917012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201906</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201907</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201909</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201911</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201912</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201913</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>854</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201914</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201915</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201916</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.880597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201917 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_1  feature_2  feature_3  elapsed_time  \\\n",
       "0               5          2          1           245   \n",
       "1               4          1          0           396   \n",
       "2               2          2          0           549   \n",
       "3               4          3          0           153   \n",
       "4               1          3          0            92   \n",
       "5               4          2          0           518   \n",
       "6               3          2          1           427   \n",
       "7               3          2          1           153   \n",
       "8               2          1          0           184   \n",
       "9               2          2          0           549   \n",
       "10              5          2          1           488   \n",
       "11              2          2          0           702   \n",
       "12              5          2          1           153   \n",
       "13              2          1          0           306   \n",
       "14              3          2          1           184   \n",
       "15              2          1          0           365   \n",
       "16              2          2          0           580   \n",
       "17              4          2          0           427   \n",
       "18              2          1          0            92   \n",
       "19              4          1          0           396   \n",
       "20              5          2          1           153   \n",
       "21              1          2          0           610   \n",
       "22              2          2          0           153   \n",
       "23              2          2          0           123   \n",
       "24              5          1          1           854   \n",
       "25              2          2          0           671   \n",
       "26              2          3          0           215   \n",
       "27              3          3          1           153   \n",
       "28              5          1          1           762   \n",
       "29              5          2          1           610   \n",
       "...           ...        ...        ...           ...   \n",
       "201887          2          2          0           396   \n",
       "201888          4          2          0           549   \n",
       "201889          3          2          1           215   \n",
       "201890          2          2          0           884   \n",
       "201891          5          2          1           488   \n",
       "201892          4          3          0           306   \n",
       "201893          5          1          1           123   \n",
       "201894          2          2          0           946   \n",
       "201895          5          1          1           396   \n",
       "201896          3          3          1          1068   \n",
       "201897          5          2          1           457   \n",
       "201898          1          1          0           245   \n",
       "201899          5          1          1           123   \n",
       "201900          3          2          1           215   \n",
       "201901          3          2          1            92   \n",
       "201902          1          3          0           396   \n",
       "201903          3          2          1           641   \n",
       "201904          3          3          1           396   \n",
       "201905          3          2          1           245   \n",
       "201906          3          2          1           365   \n",
       "201907          2          1          0           245   \n",
       "201908          3          3          1           610   \n",
       "201909          5          1          1          1219   \n",
       "201910          2          3          0           123   \n",
       "201911          3          3          1          1096   \n",
       "201912          3          2          1           153   \n",
       "201913          3          1          1           854   \n",
       "201914          4          3          0           184   \n",
       "201915          3          2          1           580   \n",
       "201916          3          1          1           215   \n",
       "\n",
       "        hist_transactions_count  hist_category_1_sum  hist_category_1_mean  \\\n",
       "0                          13.0                  0.0              0.000000   \n",
       "1                          11.0                  2.0              0.181818   \n",
       "2                           2.0                  0.0              0.000000   \n",
       "3                           NaN                  NaN                   NaN   \n",
       "4                           5.0                  3.0              0.600000   \n",
       "5                           1.0                  0.0              0.000000   \n",
       "6                          17.0                  0.0              0.000000   \n",
       "7                           3.0                  0.0              0.000000   \n",
       "8                           4.0                  4.0              1.000000   \n",
       "9                          14.0                  0.0              0.000000   \n",
       "10                          8.0                  0.0              0.000000   \n",
       "11                          7.0                  0.0              0.000000   \n",
       "12                          9.0                  0.0              0.000000   \n",
       "13                          NaN                  NaN                   NaN   \n",
       "14                          7.0                  0.0              0.000000   \n",
       "15                         32.0                 12.0              0.375000   \n",
       "16                         33.0                 17.0              0.515152   \n",
       "17                          2.0                  0.0              0.000000   \n",
       "18                          NaN                  NaN                   NaN   \n",
       "19                          5.0                  5.0              1.000000   \n",
       "20                         15.0                  0.0              0.000000   \n",
       "21                          8.0                  6.0              0.750000   \n",
       "22                          NaN                  NaN                   NaN   \n",
       "23                          9.0                  0.0              0.000000   \n",
       "24                         12.0                  0.0              0.000000   \n",
       "25                         60.0                  0.0              0.000000   \n",
       "26                          7.0                  0.0              0.000000   \n",
       "27                          NaN                  NaN                   NaN   \n",
       "28                          NaN                  NaN                   NaN   \n",
       "29                         31.0                  0.0              0.000000   \n",
       "...                         ...                  ...                   ...   \n",
       "201887                     22.0                  3.0              0.136364   \n",
       "201888                     28.0                  0.0              0.000000   \n",
       "201889                      6.0                  0.0              0.000000   \n",
       "201890                     27.0                  0.0              0.000000   \n",
       "201891                      4.0                  0.0              0.000000   \n",
       "201892                      6.0                  0.0              0.000000   \n",
       "201893                      8.0                  2.0              0.250000   \n",
       "201894                      8.0                  0.0              0.000000   \n",
       "201895                     11.0                  4.0              0.363636   \n",
       "201896                     28.0                  0.0              0.000000   \n",
       "201897                      4.0                  0.0              0.000000   \n",
       "201898                      3.0                  0.0              0.000000   \n",
       "201899                      9.0                  5.0              0.555556   \n",
       "201900                     28.0                  9.0              0.321429   \n",
       "201901                      8.0                  1.0              0.125000   \n",
       "201902                     12.0                  3.0              0.250000   \n",
       "201903                      5.0                  0.0              0.000000   \n",
       "201904                      6.0                  0.0              0.000000   \n",
       "201905                     20.0                  8.0              0.400000   \n",
       "201906                      3.0                  0.0              0.000000   \n",
       "201907                      NaN                  NaN                   NaN   \n",
       "201908                      2.0                  0.0              0.000000   \n",
       "201909                      3.0                  0.0              0.000000   \n",
       "201910                      3.0                  0.0              0.000000   \n",
       "201911                      NaN                  NaN                   NaN   \n",
       "201912                      4.0                  0.0              0.000000   \n",
       "201913                      7.0                  0.0              0.000000   \n",
       "201914                      6.0                  2.0              0.333333   \n",
       "201915                      2.0                  0.0              0.000000   \n",
       "201916                     16.0                 15.0              0.937500   \n",
       "\n",
       "        hist_category_2_1.0_mean  hist_category_2_2.0_mean  \\\n",
       "0                       1.000000                       0.0   \n",
       "1                       0.818182                       0.0   \n",
       "2                       0.000000                       0.0   \n",
       "3                            NaN                       NaN   \n",
       "4                       0.000000                       0.0   \n",
       "5                       1.000000                       0.0   \n",
       "6                       0.000000                       0.0   \n",
       "7                       0.333333                       0.0   \n",
       "8                       0.000000                       0.0   \n",
       "9                       1.000000                       0.0   \n",
       "10                      0.000000                       0.0   \n",
       "11                      1.000000                       0.0   \n",
       "12                      0.222222                       0.0   \n",
       "13                           NaN                       NaN   \n",
       "14                      0.428571                       0.0   \n",
       "15                      0.000000                       0.0   \n",
       "16                      0.090909                       0.0   \n",
       "17                      0.000000                       0.0   \n",
       "18                           NaN                       NaN   \n",
       "19                      0.000000                       0.0   \n",
       "20                      0.866667                       0.0   \n",
       "21                      0.000000                       0.0   \n",
       "22                           NaN                       NaN   \n",
       "23                      0.000000                       0.0   \n",
       "24                      1.000000                       0.0   \n",
       "25                      1.000000                       0.0   \n",
       "26                      0.000000                       0.0   \n",
       "27                           NaN                       NaN   \n",
       "28                           NaN                       NaN   \n",
       "29                      1.000000                       0.0   \n",
       "...                          ...                       ...   \n",
       "201887                  0.000000                       0.0   \n",
       "201888                  1.000000                       0.0   \n",
       "201889                  1.000000                       0.0   \n",
       "201890                  1.000000                       0.0   \n",
       "201891                  1.000000                       0.0   \n",
       "201892                  0.000000                       0.0   \n",
       "201893                  0.750000                       0.0   \n",
       "201894                  1.000000                       0.0   \n",
       "201895                  0.000000                       0.0   \n",
       "201896                  0.000000                       0.0   \n",
       "201897                  1.000000                       0.0   \n",
       "201898                  0.000000                       0.0   \n",
       "201899                  0.444444                       0.0   \n",
       "201900                  0.107143                       0.0   \n",
       "201901                  0.250000                       0.0   \n",
       "201902                  0.750000                       0.0   \n",
       "201903                  1.000000                       0.0   \n",
       "201904                  0.000000                       0.0   \n",
       "201905                  0.000000                       0.0   \n",
       "201906                  1.000000                       0.0   \n",
       "201907                       NaN                       NaN   \n",
       "201908                  1.000000                       0.0   \n",
       "201909                  1.000000                       0.0   \n",
       "201910                  1.000000                       0.0   \n",
       "201911                       NaN                       NaN   \n",
       "201912                  0.500000                       0.0   \n",
       "201913                  1.000000                       0.0   \n",
       "201914                  0.000000                       0.0   \n",
       "201915                  1.000000                       0.0   \n",
       "201916                  0.000000                       0.0   \n",
       "\n",
       "        hist_category_2_3.0_mean          ...           \\\n",
       "0                       0.000000          ...            \n",
       "1                       0.000000          ...            \n",
       "2                       0.000000          ...            \n",
       "3                            NaN          ...            \n",
       "4                       0.000000          ...            \n",
       "5                       0.000000          ...            \n",
       "6                       0.000000          ...            \n",
       "7                       0.000000          ...            \n",
       "8                       0.000000          ...            \n",
       "9                       0.000000          ...            \n",
       "10                      0.000000          ...            \n",
       "11                      0.000000          ...            \n",
       "12                      0.777778          ...            \n",
       "13                           NaN          ...            \n",
       "14                      0.000000          ...            \n",
       "15                      0.000000          ...            \n",
       "16                      0.393939          ...            \n",
       "17                      0.000000          ...            \n",
       "18                           NaN          ...            \n",
       "19                      0.000000          ...            \n",
       "20                      0.066667          ...            \n",
       "21                      0.000000          ...            \n",
       "22                           NaN          ...            \n",
       "23                      0.888889          ...            \n",
       "24                      0.000000          ...            \n",
       "25                      0.000000          ...            \n",
       "26                      1.000000          ...            \n",
       "27                           NaN          ...            \n",
       "28                           NaN          ...            \n",
       "29                      0.000000          ...            \n",
       "...                          ...          ...            \n",
       "201887                  0.136364          ...            \n",
       "201888                  0.000000          ...            \n",
       "201889                  0.000000          ...            \n",
       "201890                  0.000000          ...            \n",
       "201891                  0.000000          ...            \n",
       "201892                  1.000000          ...            \n",
       "201893                  0.000000          ...            \n",
       "201894                  0.000000          ...            \n",
       "201895                  0.545455          ...            \n",
       "201896                  0.000000          ...            \n",
       "201897                  0.000000          ...            \n",
       "201898                  0.666667          ...            \n",
       "201899                  0.000000          ...            \n",
       "201900                  0.000000          ...            \n",
       "201901                  0.625000          ...            \n",
       "201902                  0.000000          ...            \n",
       "201903                  0.000000          ...            \n",
       "201904                  1.000000          ...            \n",
       "201905                  0.000000          ...            \n",
       "201906                  0.000000          ...            \n",
       "201907                       NaN          ...            \n",
       "201908                  0.000000          ...            \n",
       "201909                  0.000000          ...            \n",
       "201910                  0.000000          ...            \n",
       "201911                       NaN          ...            \n",
       "201912                  0.500000          ...            \n",
       "201913                  0.000000          ...            \n",
       "201914                  0.166667          ...            \n",
       "201915                  0.000000          ...            \n",
       "201916                  0.062500          ...            \n",
       "\n",
       "        installments_mean_mean  installments_mean_std  installments_min_mean  \\\n",
       "0                     0.319444               0.423007               0.166667   \n",
       "1                     4.033333               3.522310               3.500000   \n",
       "2                     0.000000               0.000000               0.000000   \n",
       "3                          NaN                    NaN                    NaN   \n",
       "4                     6.500000               7.778175               6.500000   \n",
       "5                     1.000000                    NaN               1.000000   \n",
       "6                     0.000000               0.000000               0.000000   \n",
       "7                     0.000000                    NaN               0.000000   \n",
       "8                     1.000000                    NaN               1.000000   \n",
       "9                     0.125000               0.306186               0.000000   \n",
       "10                    0.250000               0.500000               0.250000   \n",
       "11                    0.000000               0.000000               0.000000   \n",
       "12                    0.000000               0.000000               0.000000   \n",
       "13                         NaN                    NaN                    NaN   \n",
       "14                    0.000000               0.000000               0.000000   \n",
       "15                    1.809524               1.864454               1.714286   \n",
       "16                    1.047619               0.487950               0.857143   \n",
       "17                    0.000000               0.000000               0.000000   \n",
       "18                         NaN                    NaN                    NaN   \n",
       "19                    1.000000               0.000000               1.000000   \n",
       "20                    0.066667               0.149071               0.000000   \n",
       "21                    1.000000                    NaN               0.000000   \n",
       "22                         NaN                    NaN                    NaN   \n",
       "23                    0.000000               0.000000               0.000000   \n",
       "24                    1.800000               1.788854               1.800000   \n",
       "25                    0.097789               0.169017               0.000000   \n",
       "26                    1.222222               0.384900               1.000000   \n",
       "27                         NaN                    NaN                    NaN   \n",
       "28                         NaN                    NaN                    NaN   \n",
       "29                    0.111111               0.127294               0.000000   \n",
       "...                        ...                    ...                    ...   \n",
       "201887                0.318182               0.643146               0.272727   \n",
       "201888                0.113333               0.206200               0.000000   \n",
       "201889                0.333333               0.577350               0.333333   \n",
       "201890                0.199074               0.371382               0.111111   \n",
       "201891                0.000000               0.000000               0.000000   \n",
       "201892                1.000000               0.000000               1.000000   \n",
       "201893                3.750000               5.500000               3.750000   \n",
       "201894                0.250000               0.500000               0.250000   \n",
       "201895                1.000000               0.000000               1.000000   \n",
       "201896                0.000000               0.000000               0.000000   \n",
       "201897                0.000000               0.000000               0.000000   \n",
       "201898                1.000000               0.000000               1.000000   \n",
       "201899                6.375000               5.126524               5.500000   \n",
       "201900                0.388889               0.330830               0.000000   \n",
       "201901                0.333333               0.577350               0.333333   \n",
       "201902                2.966667               2.983845               1.000000   \n",
       "201903                0.000000               0.000000               0.000000   \n",
       "201904                0.000000               0.000000               0.000000   \n",
       "201905                0.133333               0.326599               0.000000   \n",
       "201906                0.333333               0.577350               0.333333   \n",
       "201907                     NaN                    NaN                    NaN   \n",
       "201908                0.000000               0.000000               0.000000   \n",
       "201909                1.000000               0.000000               1.000000   \n",
       "201910                1.000000                    NaN               1.000000   \n",
       "201911                     NaN                    NaN                    NaN   \n",
       "201912                0.166667               0.288675               0.000000   \n",
       "201913                0.083333               0.144338               0.000000   \n",
       "201914                1.250000               0.500000               1.250000   \n",
       "201915                0.000000               0.000000               0.000000   \n",
       "201916                1.166667               0.408248               1.166667   \n",
       "\n",
       "        installments_min_std  installments_max_mean  installments_max_std  \\\n",
       "0                   0.408248               0.500000              0.547723   \n",
       "1                   3.728270               5.000000              4.289522   \n",
       "2                   0.000000               0.000000              0.000000   \n",
       "3                        NaN                    NaN                   NaN   \n",
       "4                   7.778175               6.500000              7.778175   \n",
       "5                        NaN               1.000000                   NaN   \n",
       "6                   0.000000               0.000000              0.000000   \n",
       "7                        NaN               0.000000                   NaN   \n",
       "8                        NaN               1.000000                   NaN   \n",
       "9                   0.000000               0.166667              0.408248   \n",
       "10                  0.500000               0.250000              0.500000   \n",
       "11                  0.000000               0.000000              0.000000   \n",
       "12                  0.000000               0.000000              0.000000   \n",
       "13                       NaN                    NaN                   NaN   \n",
       "14                  0.000000               0.000000              0.000000   \n",
       "15                  1.889822               2.000000              1.914854   \n",
       "16                  0.899735               1.142857              0.377964   \n",
       "17                  0.000000               0.000000              0.000000   \n",
       "18                       NaN                    NaN                   NaN   \n",
       "19                  0.000000               1.000000              0.000000   \n",
       "20                  0.000000               0.200000              0.447214   \n",
       "21                       NaN               2.000000                   NaN   \n",
       "22                       NaN                    NaN                   NaN   \n",
       "23                  0.000000               0.000000              0.000000   \n",
       "24                  1.788854               1.800000              1.788854   \n",
       "25                  0.000000               0.285714              0.468807   \n",
       "26                  0.000000               1.333333              0.577350   \n",
       "27                       NaN                    NaN                   NaN   \n",
       "28                       NaN                    NaN                   NaN   \n",
       "29                  0.000000               0.666667              0.577350   \n",
       "...                      ...                    ...                   ...   \n",
       "201887              0.646670               0.363636              0.674200   \n",
       "201888              0.000000               0.300000              0.483046   \n",
       "201889              0.577350               0.333333              0.577350   \n",
       "201890              0.333333               0.333333              0.500000   \n",
       "201891              0.000000               0.000000              0.000000   \n",
       "201892              0.000000               1.000000              0.000000   \n",
       "201893              5.500000               3.750000              5.500000   \n",
       "201894              0.500000               0.250000              0.500000   \n",
       "201895              0.000000               1.000000              0.000000   \n",
       "201896              0.000000               0.000000              0.000000   \n",
       "201897              0.000000               0.000000              0.000000   \n",
       "201898              0.000000               1.000000              0.000000   \n",
       "201899              6.363961               7.000000              4.242641   \n",
       "201900              0.000000               1.000000              1.095445   \n",
       "201901              0.577350               0.333333              0.577350   \n",
       "201902              0.000000               4.666667              4.725816   \n",
       "201903              0.000000               0.000000              0.000000   \n",
       "201904              0.000000               0.000000              0.000000   \n",
       "201905              0.000000               0.166667              0.408248   \n",
       "201906              0.577350               0.333333              0.577350   \n",
       "201907                   NaN                    NaN                   NaN   \n",
       "201908              0.000000               0.000000              0.000000   \n",
       "201909              0.000000               1.000000              0.000000   \n",
       "201910                   NaN               1.000000                   NaN   \n",
       "201911                   NaN                    NaN                   NaN   \n",
       "201912              0.000000               0.333333              0.577350   \n",
       "201913              0.000000               0.333333              0.577350   \n",
       "201914              0.500000               1.250000              0.500000   \n",
       "201915              0.000000               0.000000              0.000000   \n",
       "201916              0.408248               1.166667              0.408248   \n",
       "\n",
       "        installments_std_mean  installments_std_std  authorized_flag_sum  \\\n",
       "0                    0.269338              0.312603                247.0   \n",
       "1                    1.781853              2.519921                339.0   \n",
       "2                         NaN                   NaN                 41.0   \n",
       "3                         NaN                   NaN                 77.0   \n",
       "4                    0.000000              0.000000                128.0   \n",
       "5                         NaN                   NaN                 32.0   \n",
       "6                    0.000000              0.000000                243.0   \n",
       "7                    0.000000                   NaN                 19.0   \n",
       "8                    0.000000                   NaN                 11.0   \n",
       "9                    0.166667              0.288675                 99.0   \n",
       "10                   0.000000                   NaN                 89.0   \n",
       "11                   0.000000              0.000000                 12.0   \n",
       "12                   0.000000              0.000000                 28.0   \n",
       "13                        NaN                   NaN                 20.0   \n",
       "14                   0.000000              0.000000                 58.0   \n",
       "15                   0.164957              0.436436                158.0   \n",
       "16                   0.216506              0.433013                 82.0   \n",
       "17                        NaN                   NaN                 80.0   \n",
       "18                        NaN                   NaN                 27.0   \n",
       "19                   0.000000                   NaN                452.0   \n",
       "20                   0.144338              0.288675                165.0   \n",
       "21                   0.534522                   NaN                 20.0   \n",
       "22                        NaN                   NaN                 16.0   \n",
       "23                   0.000000              0.000000                123.0   \n",
       "24                   0.000000              0.000000                154.0   \n",
       "25                   0.178554              0.264950                 75.0   \n",
       "26                   0.288675              0.408248                 89.0   \n",
       "27                        NaN                   NaN                 20.0   \n",
       "28                        NaN                   NaN                110.0   \n",
       "29                   0.262892              0.250995                136.0   \n",
       "...                       ...                   ...                  ...   \n",
       "201887               0.133631              0.267261                160.0   \n",
       "201888               0.262048              0.290282                454.0   \n",
       "201889               0.000000              0.000000                202.0   \n",
       "201890               0.116363              0.223610                435.0   \n",
       "201891               0.000000                   NaN                 89.0   \n",
       "201892               0.000000              0.000000                 35.0   \n",
       "201893               0.000000              0.000000                 29.0   \n",
       "201894               0.000000              0.000000                 68.0   \n",
       "201895               0.000000              0.000000                 60.0   \n",
       "201896               0.000000              0.000000                200.0   \n",
       "201897               0.000000                   NaN                 36.0   \n",
       "201898                    NaN                   NaN                207.0   \n",
       "201899               0.629153              0.889757                  8.0   \n",
       "201900               0.589039              0.419302                325.0   \n",
       "201901               0.000000              0.000000                 84.0   \n",
       "201902               1.976501              2.605795                395.0   \n",
       "201903               0.000000                   NaN                163.0   \n",
       "201904               0.000000                   NaN                 45.0   \n",
       "201905               0.140546              0.243432                221.0   \n",
       "201906                    NaN                   NaN                120.0   \n",
       "201907                    NaN                   NaN                 20.0   \n",
       "201908                    NaN                   NaN                 20.0   \n",
       "201909               0.000000                   NaN                 24.0   \n",
       "201910               0.000000                   NaN                 27.0   \n",
       "201911                    NaN                   NaN                  7.0   \n",
       "201912               0.707107                   NaN                 42.0   \n",
       "201913               0.250000              0.353553                 40.0   \n",
       "201914               0.000000                   NaN                 81.0   \n",
       "201915                    NaN                   NaN                 24.0   \n",
       "201916               0.000000              0.000000                118.0   \n",
       "\n",
       "        authorized_flag_mean  \n",
       "0                   0.950000  \n",
       "1                   0.968571  \n",
       "2                   0.953488  \n",
       "3                   1.000000  \n",
       "4                   0.962406  \n",
       "5                   0.969697  \n",
       "6                   0.934615  \n",
       "7                   0.863636  \n",
       "8                   0.733333  \n",
       "9                   0.876106  \n",
       "10                  0.917526  \n",
       "11                  0.631579  \n",
       "12                  0.756757  \n",
       "13                  1.000000  \n",
       "14                  0.892308  \n",
       "15                  0.831579  \n",
       "16                  0.713043  \n",
       "17                  0.975610  \n",
       "18                  1.000000  \n",
       "19                  0.989059  \n",
       "20                  0.916667  \n",
       "21                  0.714286  \n",
       "22                  1.000000  \n",
       "23                  0.931818  \n",
       "24                  0.927711  \n",
       "25                  0.555556  \n",
       "26                  0.927083  \n",
       "27                  1.000000  \n",
       "28                  1.000000  \n",
       "29                  0.814371  \n",
       "...                      ...  \n",
       "201887              0.879121  \n",
       "201888              0.941909  \n",
       "201889              0.971154  \n",
       "201890              0.941558  \n",
       "201891              0.956989  \n",
       "201892              0.853659  \n",
       "201893              0.783784  \n",
       "201894              0.894737  \n",
       "201895              0.845070  \n",
       "201896              0.877193  \n",
       "201897              0.900000  \n",
       "201898              0.985714  \n",
       "201899              0.470588  \n",
       "201900              0.920680  \n",
       "201901              0.913043  \n",
       "201902              0.970516  \n",
       "201903              0.970238  \n",
       "201904              0.882353  \n",
       "201905              0.917012  \n",
       "201906              0.975610  \n",
       "201907              1.000000  \n",
       "201908              0.909091  \n",
       "201909              0.888889  \n",
       "201910              0.900000  \n",
       "201911              1.000000  \n",
       "201912              0.913043  \n",
       "201913              0.851064  \n",
       "201914              0.931034  \n",
       "201915              0.923077  \n",
       "201916              0.880597  \n",
       "\n",
       "[201917 rows x 137 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embed = pd.read_csv(\"train_embed.csv\")\n",
    "test_embed = pd.read_csv(\"test_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embed[\"embed\"] = train_embed[\"embed\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(categorical_feats, axis = 1)\n",
    "test = test.drop(categorical_feats, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_embed, on='card_id', how='left')\n",
    "test = pd.merge(test, test_embed, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_features = train['embed'].apply(pd.Series).columns\n",
    "train = pd.concat([train, train['embed'].apply(pd.Series)], axis = 1)\n",
    "train = train.drop(\"embed\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, test['embed'].apply(pd.Series)], axis = 1)\n",
    "test = test.drop(\"embed\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b23550968ef3fb49ae0fcc5533551d702297c990",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 0.066293\tvalid_1's rmse: 0.0663835\n",
      "[200]\ttraining's rmse: 0.0422878\tvalid_1's rmse: 0.0423772\n",
      "[300]\ttraining's rmse: 0.0266138\tvalid_1's rmse: 0.0266982\n",
      "[400]\ttraining's rmse: 0.0168463\tvalid_1's rmse: 0.0169311\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, train[\"outliers\"].values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=train[\"outliers\"].iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=train[\"outliers\"].iloc[val_idx])\n",
    "\n",
    "    num_round = 1000\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                   early_stopping_rounds = 200,\n",
    "#                     feval=lgb_f1_score,\n",
    "#                     evals_result=evals_result\n",
    "                   )\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201917,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features.append(\"embed\")\n",
    "np.array(train[\"embed\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'['"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"embed\"].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, train[\"outliers\"].values)):\n",
    "    if fold_ > 0:\n",
    "        continue\n",
    "    val_idx1 = val_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39942\n",
       "1      442\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"outliers\"].iloc[val_idx1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "ast.literal_eval(train[\"embed\"].tolist())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof1 = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1, precision, recall = [], [], []\n",
    "thresh_range = np.arange(0, 1, .01)\n",
    "for threshold in thresh_range:\n",
    "    oof_thresholded = [0 if a_ > threshold else 1 for a_ in oof[val_idx1]]\n",
    "    f1.append(f1_score(oof_thresholded, train[\"outliers\"].iloc[val_idx1]))\n",
    "    precision.append(precision_score(oof_thresholded, train[\"outliers\"].iloc[val_idx1]))\n",
    "    recall.append(recall_score(oof_thresholded, train[\"outliers\"].iloc[val_idx1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x212deee1278>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresh_range, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x212436ae160>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGLJJREFUeJzt3X9wXGd97/H3V5IlWbL8U3LtyLLlBDtESRoclJhLeiE0QJO0tQulXLtwgdyUXGjTdoDS5g63gQkznSm9twy0bsEFmvKjCQ604DLu5LaJAxTiYBkSJ3awI/8Wcm39cCRb0kpa7ff+sWuxkXa1x/Zqj87Zz2tGM3t2H+1+H6/08dFznn0ec3dERCReKsIuQEREik/hLiISQwp3EZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgMKdxFRGKoKqwXbmxs9NbW1rBeXkQkkvbt29fr7k2F2oUW7q2trXR0dIT18iIikWRmJ4K007CMiEgMKdxFRGJI4S4iEkMKdxGRGFK4i4jEUMFwN7MvmdlZM3shz+NmZp81s04z229mNxe/TBERuRRBztwfBu6c4fG7gHWZr/uAv73yskRE5EoUnOfu7t8zs9YZmmwGvuzp/fr2mNliM1vp7qeLVKOIzCGJ8QnGJlIAeAr+czDBsd4LHO8bZng0GXJ10XDHdb/ATS2LZ/U1ivEhpmbgVNZxV+a+aeFuZveRPrtn9erVRXhpkZ9LjE/Q/fIIE6lo7AucTDld50Y41nuBk/3DjCVTYZeUVzLl/OzcCMf7hjgzOJq3nVkJi4qw5QtrIxHuud7OnL9d7r4d2A7Q3t4ejd9AmVVDo0mO9Q5xbnhs8r7zifR9x3uHOHM+f5BcNJ5McbJ/mO6BEaK63/viunnMn1cZdhl5GbBy8Xx+6VVNtC6rY371z2ttaqjh6sYFtDbW0VA7L7wi5RWKEe5dQEvW8SqguwjPKxEwMDLO8d4hTvQPMzo+AYA7nBlMpAO6b4ih0Ylp3+c454bH6ZkhvJsaarhqUS1W4HSwssJob11C67JVrF5aR828aEwCqzDjqsXzWbusnkV1CkUprmKE+07gfjN7FNgIDGi8PV7GkilSmVPikbEJfnikj92HzvL9l3pm/BN95aJaWpfVs7yhNufjDbVVtDbWs7axnqaGmsk/AWvnVdLaWM+CmtCWPhKJvIK/PWb2CHA70GhmXcDHgXkA7v45YBdwN9AJDAP3zFaxMjv6Lozy1KEenut6eTLEx5IpTvQNc6x3iLM5zq4XzZ/Hf13XyI3Ni2htrKd1WT11WX+qNy6oecWf7iJSWkFmy2wt8LgDv1e0iuSKJcYnMsF8gWO9wxzvHaJvaCxn257zCfb/bAB3WFBTRU1VekijssJoWVrHG9Y30bKkjurJ+2HD6iVsaFlMVWU0hj9EypH+7o24A90DPH2kb3J8+3jv9AuLjQuqaWqozXnle0FNFR9683redO1yrr9qIRUVmu4gEgcK94iaSDl//WQnn3niMClPD5O0NtZzS+sS1ja20NpYx9rGelob61moGQwiZUfhHgHu6ZklicxslPOJJH/67Rf40bF+fuM1V/GxX22jqaEm5CpFZC5RuM8xh8+c52D3IEcz87yP9w1xrHeI84lXfvKvrrqSv3znTbz95lUhVSoic5nCfY5wd7bt7uT//L/DAFQY6TnQjfW8bUMza5bVs6Dm57NPXn9NIy1L68IqV0TmOIX7HDA+keJPv/UCj+49xds2NPN7b7qGlqV11FRpKqGIXB6Fe0jOnk9w5Gx62OVfnuvmh0f6+INffhUfesv6gp/IFBEpROFeIu7OnqP9PPnTM+w+1EPn2QuTj9VVV/Lnv3kj/+0WLaYmIsWhcC+B3guj/NFjz/HUoR6qKyvYePVSttzSwrUrGmhdVs9Vi+dTqfnlIlJECvdZ9v2XevjQ159jMDHOx3+9jXe2t1CvNVNEZJYpZYrM3Xnp7AWe/OlZdv/0LM8c62fd8gV89Xdu5dUrFoZdnoiUCYV7EZ0bGuOPv7mffzt4BoDrVi7kD+9YxwfeeI0W0RKRklK4F8nTR/r40NefpX9ojI/+yrW8/eZmVi6aH3ZZIlKmFO5XKDmR4rNPvMRf7e5k7bJ6vvDe13ND86KwyxKRMqdwvwJd54b5w0efZd+Jc/zWa1fxiU3X62KpiMwJSqLLtOv50/zJN/fjDp/Z8ho2v6Y57JJERCYp3C/RyNgED33nII/86CQ3tSzmr7ZsYPUyrfEiInOLwv0SHD5znt/92o850nOBD95+DR9+y3rmaTciEZmDFO4BjU+k+J9f2cf5RJKv/I+N/NK6xrBLEhHJS+Ee0GMdXRzrHeKL721XsIvInKcxhQAS4xN85onDvHbNEn751cvDLkdEpCCFewD/8MPjnBkc5Y9/5VotxysikaBwL2AwMc7ffvcIt1/bxMarl4VdjohIIAr3Aj731BFeHh7nj956bdiliIgEpnCfwY69p/ibp47w9pubtaSAiESKwj2Pb+zr4k/+aT9vWN/En73txrDLERG5JAr3HL797M/46Dee47ZrGtn+319L7Twt1ysi0aJwn+I/XurlIzueY+Papfzde9oV7CISSQr3LIfPnOeDX93HNU0L2P6edm2wISKRpXDP6Dk/yj1/v5fa6kq+dM8tLKydF3ZJIiKXLVC4m9mdZnbIzDrN7IEcj682s91m9hMz229mdxe/1Nnj7nzgq/voGxrli+9tp3mxdlASkWgrGO5mVglsA+4C2oCtZtY2pdn/Bna4+wZgC/A3xS50Nn33cA/7Tpzj479+Pb+4anHY5YiIXLEgZ+63Ap3uftTdx4BHgc1T2jiwMHN7EdBdvBJn3+e/e5QVC2v5zZtXhV2KiEhRBAn3ZuBU1nFX5r5snwDebWZdwC7g94tSXQk83zXA00f7uOe2VqqrdAlCROIhSJrlWinLpxxvBR5291XA3cBXzGzac5vZfWbWYWYdPT09l17tLPj8947QUFPF1o2rwy5FRKRogoR7F9CSdbyK6cMu9wI7ANz9aaAWmLboubtvd/d2d29vamq6vIqL6FT/MLueP81vb1yt2TEiEitBwn0vsM7M1ppZNekLpjuntDkJ3AFgZteRDve5cWo+gy98/yiVFcY9t60NuxQRkaIqGO7ungTuBx4HXiQ9K+aAmT1kZpsyzT4CvN/MngMeAd7n7lOHbuaUgZFxdnR0semmZlYsqg27HBGRogq0zZ677yJ9oTT7vgezbh8EbituabPrn3/cxcj4BPfc1hp2KSIiRVeW00Pcna89c5KbVi3SUr4iEktlGe4dJ87x0tkLvGvjmrBLERGZFWUZ7l/bc4KGmip+7aaVYZciIjIryi7c+4fG2PXCf/L2m5upqw50yUFEJHLKLty/ua+LsWSK39aQjIjEWFmFu7vzyI9O0r5mCdeuaAi7HBGRWVNW4f4fnb0c7R3iXa/TUgMiEm9lFe4P/+A4jQtquPtGXUgVkXgrm3A/3jvEk4fO8q6Nq6mp0vZ5IhJvZRPuX376BFUVxru0+qOIlIGyCPcLo0ke6zjF3TeuZPlCrSMjIvFXFuH+Tz/u4vxokve9vjXsUkRESiL24Z5KOQ//8Dg3tSxmw+olYZcjIlISsQ/3g6cHOdozpLF2ESkr8Q/37kEAbmldGnIlIiKlE/9wPz1IXXUla5bWhV2KiEjJlEW4v3pFAxUVufb5FhGJp1iHu7vzYvcgbVctDLsUEZGSinW4d50b4fxokutWKtxFpLzEOtwPnk5fTG1TuItImYl3uHcPYoaW9xWRshPrcH/x9CBrG+u145KIlJ1Yh/vB04MabxeRshTbcB8YGafr3IjG20WkLMU23H+qi6kiUsZiG+6TM2U0x11EylBsw/3F04Msq69meUNN2KWIiJRcbMP94sVUMy07ICLlJ5bhPj6R4vCZCxqSEZGyFctwP9ozxFgyxXUr9eElESlPsQz3g6cHAGhbuSjkSkREwhEo3M3sTjM7ZGadZvZAnjbvNLODZnbAzP6xuGVemgM/G6SmqoJrmurDLENEJDQFP5dvZpXANuAtQBew18x2uvvBrDbrgP8F3Obu58xs+WwVHMSB7vQa7lWVsfzDRESkoCDpdyvQ6e5H3X0MeBTYPKXN+4Ft7n4OwN3PFrfM4NydA90DtF2lIRkRKV9Bwr0ZOJV13JW5L9t6YL2Z/cDM9pjZnbmeyMzuM7MOM+vo6em5vIoL6Do3wmAiyfWaKSMiZSxIuOeaKO5TjquAdcDtwFbgC2a2eNo3uW9393Z3b29qarrUWgM50K1PpoqIBAn3LqAl63gV0J2jzbfdfdzdjwGHSId9yR08PUiFwXUrFO4iUr6ChPteYJ2ZrTWzamALsHNKm28BbwIws0bSwzRHi1loUAe7B7i6aQHzqyvDeHkRkTmhYLi7exK4H3gceBHY4e4HzOwhM9uUafY40GdmB4HdwEfdvW+2ip7Jge5BjbeLSNkLtEWRu+8Cdk2578Gs2w58OPMVmv6hMU4PJBTuIlL2YjUR/EB3+pOp12sapIiUuZiFe3qmjM7cRaTcxSrcD3YP0rx4PovrqsMuRUQkVLEK9wPdA9oQW0SEGIX78FiSo71DGpIRESFG4f7i6fO4a7xdRARiFO5Hzl4A4NoV2qBDRCQ24X6if4iqCqN58fywSxERCV18wr1vmOYl87WGu4gIMQr3k/3DrF5aF3YZIiJzQmzC/XjvEGuWKdxFRCAm4f7y8BiDiSRrlmrPVBERiEm4n+gbBmC1ztxFRIC4hHt/Otxbl+nMXUQEYhLuJ/uGAHRBVUQkIxbhfrxvmOUNNdp9SUQkIxbhfrJvWDNlRESyxCLcT/QPsVozZUREJkU+3BPjE5wZHKVVZ+4iIpMiH+4n+zUNUkRkqsiH+/He9EyZNZoGKSIyKfLhfvHMfY2mQYqITIp8uJ/oG6ahtorFdfPCLkVEZM6Ifrj3D9O6rB4zC7sUEZE5I/LhfrJvSBdTRUSmiHS4JydSdJ0b0Xi7iMgUkQ737pcTJFOuT6eKiEwR6XA/0X9xwTBNgxQRyRbpcD/9cgKAVUu0KbaISLZIh/vwWBKA+pqqkCsREZlbAoW7md1pZofMrNPMHpih3TvMzM2svXgl5jcyngKgdl6k/48SESm6gqloZpXANuAuoA3YamZtOdo1AH8APFPsIvNJjE8AUFulddxFRLIFOeW9Feh096PuPgY8CmzO0e6TwKeARBHrm1EiOUF1VQUVFfoAk4hItiDh3gycyjruytw3ycw2AC3u/p0i1lZQYmyC2ioNyYiITBUkGXOdFvvkg2YVwKeBjxR8IrP7zKzDzDp6enqCV5lHYjxF7TwNyYiITBUk3LuAlqzjVUB31nEDcAPwlJkdB14H7Mx1UdXdt7t7u7u3NzU1XX7VGYnkhPZNFRHJIUi47wXWmdlaM6sGtgA7Lz7o7gPu3ujure7eCuwBNrl7x6xUnGVkbEIXU0VEcigY7u6eBO4HHgdeBHa4+wEze8jMNs12gTNJJFOaBikikkOgT/+4+y5g15T7HszT9vYrLyuYxPiExtxFRHKI9Gmvwl1EJLcYhHukuyAiMisinYyJ8RTzdeYuIjJNxMNdwzIiIrlEOtxHFO4iIjlFOtxH9QlVEZGcIhvuEylnbELz3EVEcolsMk4u96szdxGRaSIf7potIyIyXXTDPaldmERE8olsMo6MaVhGRCSfyIb7xWGZGq0KKSIyTWTDfTSZGXPXeu4iItNENtxHxjJj7tpmT0Rkmsgmo6ZCiojkF91w17CMiEhekQ33ydkyuqAqIjJNZMNd89xFRPKLbDKOXhxz17CMiMg0kQ33yQuqGpYREZkmsuE+Mj5BhcG8Sgu7FBGROSey4X5xiz0zhbuIyFQRDnftwiQikk9kw11b7ImI5BfZcE9vsRfZ8kVEZlVk01HDMiIi+UU23DUsIyKSX2TDPTE+oS32RETyiHC4a8xdRCSfyKZjYnyCGp25i4jkFOlw19IDIiK5BQp3M7vTzA6ZWaeZPZDj8Q+b2UEz229mT5jZmuKX+kqJZIr51ZH9v0lEZFYVTEczqwS2AXcBbcBWM2ub0uwnQLu7/yLwDeBTxS50Kp25i4jkF+TU91ag092PuvsY8CiwObuBu+929+HM4R5gVXHLfCV311RIEZEZBAn3ZuBU1nFX5r587gX+NdcDZnafmXWYWUdPT0/wKqcYm0jhri32RETyCRLuuZZd9JwNzd4NtAN/ketxd9/u7u3u3t7U1BS8yikS4+ldmGqqNOYuIpJLVYA2XUBL1vEqoHtqIzN7M/Ax4I3uPlqc8nKb3KhDwzIiIjkFOfXdC6wzs7VmVg1sAXZmNzCzDcDngU3ufrb4Zb7SxXDXJ1RFRHIrGO7ungTuBx4HXgR2uPsBM3vIzDZlmv0FsAB4zMyeNbOdeZ6uKC4Oy+jMXUQktyDDMrj7LmDXlPsezLr95iLXNaORyWEZjbmLiOQSyXTUsIyIyMwiHe5aW0ZEJLdIh7uGZUREcotkOl68oKphGRGR3CIa7prnLiIyk0iG+4jCXURkRpEMdw3LiIjMLKLhnpkto7VlRERyimQ6JpITVFdVUFGRa00zERGJZriPTVCrs3YRkbwimZCJ8ZTWchcRmUE0wz2pXZhERGYSyXAfGdP+qSIiM4lkuCeSKWo1LCMiklc0w31cF1RFRGYSyYRMjGvMXURkJpENd306VUQkv4iGe0rL/YqIzCCSCTmiYRkRkRlFMtw15i4iMrNIhvvoeErhLiIyg8iF+0TKGZvQmLuIyEwil5AXl/vVbBkRkfwiG+4alhERyS964Z5M78KkYRkRkfwil5AjYzpzFxEpJHLhrmEZEZHCIhfuo0mFu4hIIZEL95GxzJi7VoUUEckrcgk5ORVS67mLiOQVKNzN7E4zO2RmnWb2QI7Ha8zs65nHnzGz1mIXelFCwzIiIgUVDHczqwS2AXcBbcBWM2ub0uxe4Jy7vwr4NPDnxS70osnZMtpmT0QkryBn7rcCne5+1N3HgEeBzVPabAb+IXP7G8AdZmbFK/PnJue5V0duRElEpGSCJGQzcCrruCtzX8427p4EBoBlxShwqlFNhRQRKShIuOc6A/fLaIOZ3WdmHWbW0dPTE6S+aVYvreOuG1ZobRkRkRlUBWjTBbRkHa8CuvO06TKzKmAR0D/1idx9O7AdoL29fVr4B/HW61fw1utXXM63ioiUjSBn7nuBdWa21syqgS3AziltdgLvzdx+B/Cku19WeIuIyJUreObu7kkzux94HKgEvuTuB8zsIaDD3XcCXwS+YmadpM/Yt8xm0SIiMrMgwzK4+y5g15T7Hsy6nQB+q7iliYjI5dJ8QhGRGFK4i4jEkMJdRCSGFO4iIjGkcBcRiSELazq6mfUAJy7z2xuB3iKWExXl2O9y7DOUZ7/Lsc9w6f1e4+5NhRqFFu5Xwsw63L097DpKrRz7XY59hvLsdzn2GWav3xqWERGJIYW7iEgMRTXct4ddQEjKsd/l2Gcoz36XY59hlvodyTF3ERGZWVTP3EVEZAZzOtzn0sbcpRKgzx82s4Nmtt/MnjCzNWHUWWyF+p3V7h1m5mYW+VkVQfpsZu/MvN8HzOwfS13jbAjwM77azHab2U8yP+d3h1FnMZnZl8zsrJm9kOdxM7PPZv5N9pvZzVf8ou4+J79ILy98BLgaqAaeA9qmtPld4HOZ21uAr4dddwn6/CagLnP7g1Hvc9B+Z9o1AN8D9gDtYdddgvd6HfATYEnmeHnYdZeo39uBD2ZutwHHw667CP1+A3Az8EKex+8G/pX0rnavA5650tecy2fuc2pj7hIp2Gd33+3uw5nDPaR3xoq6IO81wCeBTwGJUhY3S4L0+f3ANnc/B+DuZ0tc42wI0m8HFmZuL2L6zm+R4+7fI8fudFk2A1/2tD3AYjNbeSWvOZfDfU5tzF0iQfqc7V7S/9tHXcF+m9kGoMXdv1PKwmZRkPd6PbDezH5gZnvM7M6SVTd7gvT7E8C7zayL9D4Sv1+a0kJ1qb/7BQXarCMkRduYO0IC98fM3g20A2+c1YpKY8Z+m1kF8GngfaUqqASCvNdVpIdmbif9F9r3zewGd395lmubTUH6vRV42N3/r5n9F9K7vN3g7qnZLy80Rc+yuXzmfikbczPTxtwREqTPmNmbgY8Bm9x9tES1zaZC/W4AbgCeMrPjpMckd0b8omrQn+9vu/u4ux8DDpEO+ygL0u97gR0A7v40UEt6/ZU4C/S7fynmcriX48bcBfucGZ74POlgj8MYLBTot7sPuHuju7e6eyvpaw2b3L0jnHKLIsjP97dIX0DHzBpJD9McLWmVxRek3yeBOwDM7DrS4d5T0ipLbyfwnsysmdcBA+5++oqeMeyryAWuMN8NHCZ9df1jmfseIv2LDek3/TGgE/gRcHXYNZegz/8OnAGezXztDLvmUvR7StuniPhsmYDvtQF/CRwEnge2hF1zifrdBvyA9EyaZ4G3hl1zEfr8CHAaGCd9ln4v8AHgA1nv9bbMv8nzxfj51idURURiaC4Py4iIyGVSuIuIxJDCXUQkhhTuIiIxpHAXEYkhhbuISAwp3EVEYkjhLiISQ/8fUpMTIooF5r0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresh_range, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x212dacf7668>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresh_range, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  153,     0, 39789,   442], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_thresholded = [1 if a_ > .000001 else 0 for a_ in oof[val_idx1]]\n",
    "cnf_matrix = confusion_matrix(oof_thresholded, train[\"outliers\"].iloc[val_idx1])\n",
    "cnf_matrix.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39939,   439,     3,     3], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a1f0a866e05f8a450960e2d787a641fc35991a1"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## 4. Feature importance\n",
    "Finally, we can have a look at the features that were used by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "d479e83032448481b40c216264a039cacdb2f9a1",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2119ab249b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train[train[\"outliers\"] == True][train.columns[0]].hist()\n",
    "train[train[\"outliers\"] == False][train.columns[0]].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "003ae1b1bd522b1b0d992ff220ed98d2a6d7477a"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## 5. Submission\n",
    "Now, we just need to prepare the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "82d5ac08a13603b2a66c59d98584c4b709daee2d"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1c6c1d40dbb2137ddd6404670b5f3dd3d381207"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "3900aa85af1f706015c7e8ed219395348f9852ae"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "e155324a5fd4a7e07b06a5e00b7fb4a02afc38d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   bagging_freq |   colsample_bytree |   feature_fraction |   max_depth |   min_child_samples |   min_child_weight |   min_data_in_leaf |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\lightgbm\\basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\lightgbm\\basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60957\tvalid_1's rmse: 3.71282\n",
      "[1000]\ttraining's rmse: 3.5423\tvalid_1's rmse: 3.69211\n",
      "[1500]\ttraining's rmse: 3.49252\tvalid_1's rmse: 3.68575\n",
      "[2000]\ttraining's rmse: 3.45004\tvalid_1's rmse: 3.68396\n",
      "[2500]\ttraining's rmse: 3.4107\tvalid_1's rmse: 3.68399\n",
      "Early stopping, best iteration is:\n",
      "[2399]\ttraining's rmse: 3.41788\tvalid_1's rmse: 3.68292\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62147\tvalid_1's rmse: 3.65169\n",
      "[1000]\ttraining's rmse: 3.55137\tvalid_1's rmse: 3.63536\n",
      "[1500]\ttraining's rmse: 3.50277\tvalid_1's rmse: 3.63069\n",
      "[2000]\ttraining's rmse: 3.45954\tvalid_1's rmse: 3.62792\n",
      "Early stopping, best iteration is:\n",
      "[2257]\ttraining's rmse: 3.43808\tvalid_1's rmse: 3.62706\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62608\tvalid_1's rmse: 3.62875\n",
      "[1000]\ttraining's rmse: 3.55656\tvalid_1's rmse: 3.6121\n",
      "[1500]\ttraining's rmse: 3.50753\tvalid_1's rmse: 3.60919\n",
      "[2000]\ttraining's rmse: 3.46441\tvalid_1's rmse: 3.60787\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's rmse: 3.46619\tvalid_1's rmse: 3.60765\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58025\tvalid_1's rmse: 3.81693\n",
      "[1000]\ttraining's rmse: 3.51194\tvalid_1's rmse: 3.80115\n",
      "[1500]\ttraining's rmse: 3.46224\tvalid_1's rmse: 3.79629\n",
      "[2000]\ttraining's rmse: 3.41925\tvalid_1's rmse: 3.79559\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 3.40564\tvalid_1's rmse: 3.79493\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62199\tvalid_1's rmse: 3.64637\n",
      "[1000]\ttraining's rmse: 3.55223\tvalid_1's rmse: 3.63234\n",
      "[1500]\ttraining's rmse: 3.50242\tvalid_1's rmse: 3.62849\n",
      "[2000]\ttraining's rmse: 3.459\tvalid_1's rmse: 3.62662\n",
      "Early stopping, best iteration is:\n",
      "[2281]\ttraining's rmse: 3.43609\tvalid_1's rmse: 3.62557\n",
      "    1 | 02m28s | \u001b[35m  -3.66826\u001b[0m | \u001b[32m            0.4294\u001b[0m | \u001b[32m       12.2414\u001b[0m | \u001b[32m            0.7958\u001b[0m | \u001b[32m            0.5446\u001b[0m | \u001b[32m     9.4854\u001b[0m | \u001b[32m            10.5495\u001b[0m | \u001b[32m           41.8569\u001b[0m | \u001b[32m           51.1937\u001b[0m | \u001b[32m          0.4802\u001b[0m | \u001b[32m     38.4286\u001b[0m | \u001b[32m     3.8050\u001b[0m | \u001b[32m      9.7846\u001b[0m | \u001b[32m     0.5833\u001b[0m | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64413\tvalid_1's rmse: 3.71493\n",
      "[1000]\ttraining's rmse: 3.59312\tvalid_1's rmse: 3.6948\n",
      "[1500]\ttraining's rmse: 3.55801\tvalid_1's rmse: 3.6924\n",
      "[2000]\ttraining's rmse: 3.52822\tvalid_1's rmse: 3.68925\n",
      "Early stopping, best iteration is:\n",
      "[2242]\ttraining's rmse: 3.51321\tvalid_1's rmse: 3.68764\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65931\tvalid_1's rmse: 3.65389\n",
      "[1000]\ttraining's rmse: 3.60975\tvalid_1's rmse: 3.64043\n",
      "Early stopping, best iteration is:\n",
      "[1233]\ttraining's rmse: 3.59364\tvalid_1's rmse: 3.63781\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66102\tvalid_1's rmse: 3.63028\n",
      "[1000]\ttraining's rmse: 3.61256\tvalid_1's rmse: 3.61787\n",
      "[1500]\ttraining's rmse: 3.5775\tvalid_1's rmse: 3.61517\n",
      "[2000]\ttraining's rmse: 3.54468\tvalid_1's rmse: 3.61391\n",
      "Early stopping, best iteration is:\n",
      "[2110]\ttraining's rmse: 3.53842\tvalid_1's rmse: 3.61277\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6207\tvalid_1's rmse: 3.82736\n",
      "[1000]\ttraining's rmse: 3.56722\tvalid_1's rmse: 3.81167\n",
      "[1500]\ttraining's rmse: 3.53139\tvalid_1's rmse: 3.80909\n",
      "Early stopping, best iteration is:\n",
      "[1706]\ttraining's rmse: 3.51845\tvalid_1's rmse: 3.80757\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65601\tvalid_1's rmse: 3.65134\n",
      "[1000]\ttraining's rmse: 3.60693\tvalid_1's rmse: 3.6387\n",
      "[1500]\ttraining's rmse: 3.5687\tvalid_1's rmse: 3.63419\n",
      "Early stopping, best iteration is:\n",
      "[1504]\ttraining's rmse: 3.56843\tvalid_1's rmse: 3.63414\n",
      "    2 | 01m45s |   -3.67666 |             0.1545 |        19.7174 |             0.9696 |             0.6878 |      9.7092 |             46.4337 |            37.1447 |            56.9646 |           0.5165 |      35.9859 |      9.6129 |       9.0853 |      0.1232 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68429\tvalid_1's rmse: 3.74226\n",
      "[1000]\ttraining's rmse: 3.63638\tvalid_1's rmse: 3.71196\n",
      "[1500]\ttraining's rmse: 3.60805\tvalid_1's rmse: 3.70023\n",
      "[2000]\ttraining's rmse: 3.58591\tvalid_1's rmse: 3.69459\n",
      "[2500]\ttraining's rmse: 3.5664\tvalid_1's rmse: 3.6914\n",
      "[3000]\ttraining's rmse: 3.54796\tvalid_1's rmse: 3.68921\n",
      "[3500]\ttraining's rmse: 3.53059\tvalid_1's rmse: 3.68776\n",
      "[4000]\ttraining's rmse: 3.51423\tvalid_1's rmse: 3.68689\n",
      "[4500]\ttraining's rmse: 3.49861\tvalid_1's rmse: 3.68588\n",
      "[5000]\ttraining's rmse: 3.4831\tvalid_1's rmse: 3.68553\n",
      "[5500]\ttraining's rmse: 3.46783\tvalid_1's rmse: 3.68501\n",
      "Early stopping, best iteration is:\n",
      "[5531]\ttraining's rmse: 3.46676\tvalid_1's rmse: 3.68495\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69896\tvalid_1's rmse: 3.67844\n",
      "[1000]\ttraining's rmse: 3.64935\tvalid_1's rmse: 3.65228\n",
      "[1500]\ttraining's rmse: 3.62043\tvalid_1's rmse: 3.64205\n",
      "[2000]\ttraining's rmse: 3.59784\tvalid_1's rmse: 3.63677\n",
      "[2500]\ttraining's rmse: 3.57797\tvalid_1's rmse: 3.63372\n",
      "[3000]\ttraining's rmse: 3.55976\tvalid_1's rmse: 3.63129\n",
      "[3500]\ttraining's rmse: 3.54217\tvalid_1's rmse: 3.62996\n",
      "[4000]\ttraining's rmse: 3.52549\tvalid_1's rmse: 3.62898\n",
      "[4500]\ttraining's rmse: 3.5098\tvalid_1's rmse: 3.62819\n",
      "[5000]\ttraining's rmse: 3.49446\tvalid_1's rmse: 3.62778\n",
      "[5500]\ttraining's rmse: 3.47963\tvalid_1's rmse: 3.62736\n",
      "[6000]\ttraining's rmse: 3.46493\tvalid_1's rmse: 3.62705\n",
      "Early stopping, best iteration is:\n",
      "[5939]\ttraining's rmse: 3.46665\tvalid_1's rmse: 3.62704\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.7038\tvalid_1's rmse: 3.65177\n",
      "[1000]\ttraining's rmse: 3.65419\tvalid_1's rmse: 3.62651\n",
      "[1500]\ttraining's rmse: 3.62486\tvalid_1's rmse: 3.61694\n",
      "[2000]\ttraining's rmse: 3.60187\tvalid_1's rmse: 3.61229\n",
      "[2500]\ttraining's rmse: 3.58165\tvalid_1's rmse: 3.60998\n",
      "[3000]\ttraining's rmse: 3.56335\tvalid_1's rmse: 3.60861\n",
      "Early stopping, best iteration is:\n",
      "[3298]\ttraining's rmse: 3.55289\tvalid_1's rmse: 3.60817\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65587\tvalid_1's rmse: 3.84872\n",
      "[1000]\ttraining's rmse: 3.60693\tvalid_1's rmse: 3.82153\n",
      "[1500]\ttraining's rmse: 3.57788\tvalid_1's rmse: 3.81098\n",
      "[2000]\ttraining's rmse: 3.55611\tvalid_1's rmse: 3.80586\n",
      "[2500]\ttraining's rmse: 3.53691\tvalid_1's rmse: 3.80291\n",
      "[3000]\ttraining's rmse: 3.51831\tvalid_1's rmse: 3.80081\n",
      "[3500]\ttraining's rmse: 3.5009\tvalid_1's rmse: 3.79939\n",
      "[4000]\ttraining's rmse: 3.48458\tvalid_1's rmse: 3.7984\n",
      "[4500]\ttraining's rmse: 3.46897\tvalid_1's rmse: 3.79805\n",
      "[5000]\ttraining's rmse: 3.45315\tvalid_1's rmse: 3.79741\n",
      "[5500]\ttraining's rmse: 3.43733\tvalid_1's rmse: 3.797\n",
      "Early stopping, best iteration is:\n",
      "[5608]\ttraining's rmse: 3.43394\tvalid_1's rmse: 3.79672\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69936\tvalid_1's rmse: 3.67026\n",
      "[1000]\ttraining's rmse: 3.64881\tvalid_1's rmse: 3.64539\n",
      "[1500]\ttraining's rmse: 3.61921\tvalid_1's rmse: 3.6364\n",
      "[2000]\ttraining's rmse: 3.59689\tvalid_1's rmse: 3.63236\n",
      "[2500]\ttraining's rmse: 3.57732\tvalid_1's rmse: 3.63028\n",
      "[3000]\ttraining's rmse: 3.55869\tvalid_1's rmse: 3.62858\n",
      "[3500]\ttraining's rmse: 3.54131\tvalid_1's rmse: 3.62797\n",
      "[4000]\ttraining's rmse: 3.52538\tvalid_1's rmse: 3.62744\n",
      "Early stopping, best iteration is:\n",
      "[4172]\ttraining's rmse: 3.52007\tvalid_1's rmse: 3.62728\n",
      "    3 | 03m33s |   -3.66948 |             0.7819 |         1.9599 |             0.4063 |             0.1620 |      5.7474 |             24.2604 |            30.9821 |            41.5315 |           0.2713 |      40.5173 |      9.5885 |       9.1056 |      0.2420 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61205\tvalid_1's rmse: 3.71436\n",
      "[1000]\ttraining's rmse: 3.54156\tvalid_1's rmse: 3.6924\n",
      "[1500]\ttraining's rmse: 3.49563\tvalid_1's rmse: 3.68557\n",
      "[2000]\ttraining's rmse: 3.45668\tvalid_1's rmse: 3.68305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\ttraining's rmse: 3.42352\tvalid_1's rmse: 3.68209\n",
      "[3000]\ttraining's rmse: 3.39343\tvalid_1's rmse: 3.68134\n",
      "[3500]\ttraining's rmse: 3.36415\tvalid_1's rmse: 3.68078\n",
      "[4000]\ttraining's rmse: 3.33692\tvalid_1's rmse: 3.68062\n",
      "Early stopping, best iteration is:\n",
      "[3940]\ttraining's rmse: 3.34026\tvalid_1's rmse: 3.68052\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62513\tvalid_1's rmse: 3.6542\n",
      "[1000]\ttraining's rmse: 3.55234\tvalid_1's rmse: 3.63491\n",
      "[1500]\ttraining's rmse: 3.5052\tvalid_1's rmse: 3.62819\n",
      "[2000]\ttraining's rmse: 3.46664\tvalid_1's rmse: 3.62563\n",
      "[2500]\ttraining's rmse: 3.43301\tvalid_1's rmse: 3.62409\n",
      "[3000]\ttraining's rmse: 3.40225\tvalid_1's rmse: 3.62363\n",
      "Early stopping, best iteration is:\n",
      "[3049]\ttraining's rmse: 3.39948\tvalid_1's rmse: 3.62335\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62989\tvalid_1's rmse: 3.63109\n",
      "[1000]\ttraining's rmse: 3.55782\tvalid_1's rmse: 3.61209\n",
      "[1500]\ttraining's rmse: 3.51163\tvalid_1's rmse: 3.60606\n",
      "[2000]\ttraining's rmse: 3.4734\tvalid_1's rmse: 3.6041\n",
      "[2500]\ttraining's rmse: 3.43931\tvalid_1's rmse: 3.60393\n",
      "Early stopping, best iteration is:\n",
      "[2304]\ttraining's rmse: 3.45246\tvalid_1's rmse: 3.60362\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58473\tvalid_1's rmse: 3.81861\n",
      "[1000]\ttraining's rmse: 3.51243\tvalid_1's rmse: 3.7993\n",
      "[1500]\ttraining's rmse: 3.46582\tvalid_1's rmse: 3.79396\n",
      "[2000]\ttraining's rmse: 3.42741\tvalid_1's rmse: 3.79145\n",
      "[2500]\ttraining's rmse: 3.39514\tvalid_1's rmse: 3.7906\n",
      "Early stopping, best iteration is:\n",
      "[2389]\ttraining's rmse: 3.4022\tvalid_1's rmse: 3.79054\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62436\tvalid_1's rmse: 3.65029\n",
      "[1000]\ttraining's rmse: 3.55174\tvalid_1's rmse: 3.63209\n",
      "[1500]\ttraining's rmse: 3.50516\tvalid_1's rmse: 3.62643\n",
      "[2000]\ttraining's rmse: 3.46806\tvalid_1's rmse: 3.62378\n",
      "[2500]\ttraining's rmse: 3.43472\tvalid_1's rmse: 3.62337\n",
      "Early stopping, best iteration is:\n",
      "[2401]\ttraining's rmse: 3.44104\tvalid_1's rmse: 3.62319\n",
      "    4 | 04m06s | \u001b[35m  -3.66488\u001b[0m | \u001b[32m            0.9377\u001b[0m | \u001b[32m        8.2341\u001b[0m | \u001b[32m            0.9250\u001b[0m | \u001b[32m            0.3879\u001b[0m | \u001b[32m    11.8786\u001b[0m | \u001b[32m            25.6624\u001b[0m | \u001b[32m           44.8628\u001b[0m | \u001b[32m           77.0871\u001b[0m | \u001b[32m          0.7615\u001b[0m | \u001b[32m     33.1706\u001b[0m | \u001b[32m     8.8336\u001b[0m | \u001b[32m      6.8161\u001b[0m | \u001b[32m     0.8542\u001b[0m | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63541\tvalid_1's rmse: 3.72043\n",
      "[1000]\ttraining's rmse: 3.57615\tvalid_1's rmse: 3.69762\n",
      "[1500]\ttraining's rmse: 3.53385\tvalid_1's rmse: 3.69037\n",
      "[2000]\ttraining's rmse: 3.49781\tvalid_1's rmse: 3.68789\n",
      "[2500]\ttraining's rmse: 3.46437\tvalid_1's rmse: 3.68656\n",
      "Early stopping, best iteration is:\n",
      "[2490]\ttraining's rmse: 3.46497\tvalid_1's rmse: 3.68649\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64934\tvalid_1's rmse: 3.66066\n",
      "[1000]\ttraining's rmse: 3.58844\tvalid_1's rmse: 3.64161\n",
      "[1500]\ttraining's rmse: 3.54729\tvalid_1's rmse: 3.63538\n",
      "[2000]\ttraining's rmse: 3.51089\tvalid_1's rmse: 3.63165\n",
      "[2500]\ttraining's rmse: 3.47734\tvalid_1's rmse: 3.63035\n",
      "[3000]\ttraining's rmse: 3.4463\tvalid_1's rmse: 3.62989\n",
      "Early stopping, best iteration is:\n",
      "[2955]\ttraining's rmse: 3.44913\tvalid_1's rmse: 3.62961\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65367\tvalid_1's rmse: 3.63383\n",
      "[1000]\ttraining's rmse: 3.59292\tvalid_1's rmse: 3.61691\n",
      "[1500]\ttraining's rmse: 3.55068\tvalid_1's rmse: 3.61197\n",
      "[2000]\ttraining's rmse: 3.51355\tvalid_1's rmse: 3.61024\n",
      "Early stopping, best iteration is:\n",
      "[2035]\ttraining's rmse: 3.51133\tvalid_1's rmse: 3.61013\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6073\tvalid_1's rmse: 3.82505\n",
      "[1000]\ttraining's rmse: 3.54538\tvalid_1's rmse: 3.80688\n",
      "[1500]\ttraining's rmse: 3.50309\tvalid_1's rmse: 3.80204\n",
      "[2000]\ttraining's rmse: 3.46705\tvalid_1's rmse: 3.8002\n",
      "[2500]\ttraining's rmse: 3.43388\tvalid_1's rmse: 3.79934\n",
      "Early stopping, best iteration is:\n",
      "[2668]\ttraining's rmse: 3.42319\tvalid_1's rmse: 3.79874\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64909\tvalid_1's rmse: 3.65402\n",
      "[1000]\ttraining's rmse: 3.58797\tvalid_1's rmse: 3.63719\n",
      "[1500]\ttraining's rmse: 3.54555\tvalid_1's rmse: 3.63225\n",
      "[2000]\ttraining's rmse: 3.50783\tvalid_1's rmse: 3.63079\n",
      "Early stopping, best iteration is:\n",
      "[2210]\ttraining's rmse: 3.4938\tvalid_1's rmse: 3.62986\n",
      "    5 | 02m54s |   -3.67161 |             0.2913 |         2.8543 |             0.3056 |             0.4423 |      9.2961 |             30.2085 |            40.1219 |            19.5254 |           0.8179 |      30.7211 |      5.9142 |       9.5614 |      0.4371 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56194\tvalid_1's rmse: 3.70831\n",
      "[1000]\ttraining's rmse: 3.46902\tvalid_1's rmse: 3.68885\n",
      "[1500]\ttraining's rmse: 3.40389\tvalid_1's rmse: 3.6838\n",
      "[2000]\ttraining's rmse: 3.35012\tvalid_1's rmse: 3.68116\n",
      "Early stopping, best iteration is:\n",
      "[2167]\ttraining's rmse: 3.33445\tvalid_1's rmse: 3.68061\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57505\tvalid_1's rmse: 3.65186\n",
      "[1000]\ttraining's rmse: 3.47901\tvalid_1's rmse: 3.63471\n",
      "[1500]\ttraining's rmse: 3.41453\tvalid_1's rmse: 3.62981\n",
      "[2000]\ttraining's rmse: 3.36035\tvalid_1's rmse: 3.62789\n",
      "Early stopping, best iteration is:\n",
      "[2050]\ttraining's rmse: 3.35529\tvalid_1's rmse: 3.62767\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58161\tvalid_1's rmse: 3.62773\n",
      "[1000]\ttraining's rmse: 3.48527\tvalid_1's rmse: 3.61133\n",
      "[1500]\ttraining's rmse: 3.42093\tvalid_1's rmse: 3.60728\n",
      "[2000]\ttraining's rmse: 3.36623\tvalid_1's rmse: 3.60692\n",
      "Early stopping, best iteration is:\n",
      "[1920]\ttraining's rmse: 3.37463\tvalid_1's rmse: 3.6067\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.53613\tvalid_1's rmse: 3.8116\n",
      "[1000]\ttraining's rmse: 3.43984\tvalid_1's rmse: 3.79692\n",
      "[1500]\ttraining's rmse: 3.37628\tvalid_1's rmse: 3.79296\n",
      "[2000]\ttraining's rmse: 3.32151\tvalid_1's rmse: 3.79155\n",
      "Early stopping, best iteration is:\n",
      "[2223]\ttraining's rmse: 3.29973\tvalid_1's rmse: 3.79131\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57383\tvalid_1's rmse: 3.6475\n",
      "[1000]\ttraining's rmse: 3.47897\tvalid_1's rmse: 3.63215\n",
      "[1500]\ttraining's rmse: 3.41516\tvalid_1's rmse: 3.62913\n",
      "[2000]\ttraining's rmse: 3.36113\tvalid_1's rmse: 3.62793\n",
      "Early stopping, best iteration is:\n",
      "[2099]\ttraining's rmse: 3.35149\tvalid_1's rmse: 3.62766\n",
      "    6 | 03m58s |   -3.66740 |             0.7802 |        16.3573 |             0.2074 |             0.7833 |     14.7342 |             43.8778 |            33.0978 |            44.3712 |           0.9106 |      41.6062 |      2.2834 |       7.3798 |      0.8862 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60726\tvalid_1's rmse: 3.70321\n",
      "[1000]\ttraining's rmse: 3.55027\tvalid_1's rmse: 3.68571\n",
      "[1500]\ttraining's rmse: 3.50991\tvalid_1's rmse: 3.68147\n",
      "[2000]\ttraining's rmse: 3.47493\tvalid_1's rmse: 3.68019\n",
      "[2500]\ttraining's rmse: 3.44142\tvalid_1's rmse: 3.67931\n",
      "Early stopping, best iteration is:\n",
      "[2468]\ttraining's rmse: 3.44348\tvalid_1's rmse: 3.67912\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62137\tvalid_1's rmse: 3.64503\n",
      "[1000]\ttraining's rmse: 3.56163\tvalid_1's rmse: 3.63091\n",
      "[1500]\ttraining's rmse: 3.52069\tvalid_1's rmse: 3.6263\n",
      "[2000]\ttraining's rmse: 3.4854\tvalid_1's rmse: 3.62462\n",
      "[2500]\ttraining's rmse: 3.45254\tvalid_1's rmse: 3.62418\n",
      "Early stopping, best iteration is:\n",
      "[2425]\ttraining's rmse: 3.45675\tvalid_1's rmse: 3.62401\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62557\tvalid_1's rmse: 3.62151\n",
      "[1000]\ttraining's rmse: 3.56463\tvalid_1's rmse: 3.60796\n",
      "[1500]\ttraining's rmse: 3.52274\tvalid_1's rmse: 3.60491\n",
      "Early stopping, best iteration is:\n",
      "[1436]\ttraining's rmse: 3.52761\tvalid_1's rmse: 3.60464\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.57911\tvalid_1's rmse: 3.80825\n",
      "[1000]\ttraining's rmse: 3.52088\tvalid_1's rmse: 3.79589\n",
      "[1500]\ttraining's rmse: 3.47961\tvalid_1's rmse: 3.79298\n",
      "[2000]\ttraining's rmse: 3.44484\tvalid_1's rmse: 3.79243\n",
      "Early stopping, best iteration is:\n",
      "[2165]\ttraining's rmse: 3.43297\tvalid_1's rmse: 3.7921\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62175\tvalid_1's rmse: 3.63884\n",
      "[1000]\ttraining's rmse: 3.56325\tvalid_1's rmse: 3.62723\n",
      "[1500]\ttraining's rmse: 3.52257\tvalid_1's rmse: 3.62478\n",
      "Early stopping, best iteration is:\n",
      "[1672]\ttraining's rmse: 3.50911\tvalid_1's rmse: 3.62438\n",
      "    7 | 03m11s |   -3.66549 |             0.5916 |         2.6548 |             0.1684 |             0.8102 |      7.0195 |             37.8373 |            39.5031 |            85.4895 |           0.5238 |      42.8043 |      5.1800 |       2.0286 |      0.8079 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6328\tvalid_1's rmse: 3.7131\n",
      "[1000]\ttraining's rmse: 3.58182\tvalid_1's rmse: 3.69424\n",
      "[1500]\ttraining's rmse: 3.54726\tvalid_1's rmse: 3.68843\n",
      "[2000]\ttraining's rmse: 3.51717\tvalid_1's rmse: 3.68687\n",
      "[2500]\ttraining's rmse: 3.48832\tvalid_1's rmse: 3.68639\n",
      "Early stopping, best iteration is:\n",
      "[2425]\ttraining's rmse: 3.49269\tvalid_1's rmse: 3.68596\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64566\tvalid_1's rmse: 3.65356\n",
      "[1000]\ttraining's rmse: 3.59438\tvalid_1's rmse: 3.63715\n",
      "[1500]\ttraining's rmse: 3.55917\tvalid_1's rmse: 3.632\n",
      "[2000]\ttraining's rmse: 3.52909\tvalid_1's rmse: 3.62965\n",
      "[2500]\ttraining's rmse: 3.50037\tvalid_1's rmse: 3.62837\n",
      "[3000]\ttraining's rmse: 3.47432\tvalid_1's rmse: 3.62802\n",
      "Early stopping, best iteration is:\n",
      "[2908]\ttraining's rmse: 3.47902\tvalid_1's rmse: 3.62774\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65058\tvalid_1's rmse: 3.62591\n",
      "[1000]\ttraining's rmse: 3.59783\tvalid_1's rmse: 3.6117\n",
      "[1500]\ttraining's rmse: 3.5613\tvalid_1's rmse: 3.60849\n",
      "[2000]\ttraining's rmse: 3.52952\tvalid_1's rmse: 3.60712\n",
      "Early stopping, best iteration is:\n",
      "[2049]\ttraining's rmse: 3.52643\tvalid_1's rmse: 3.60685\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60309\tvalid_1's rmse: 3.81637\n",
      "[1000]\ttraining's rmse: 3.5515\tvalid_1's rmse: 3.80219\n",
      "[1500]\ttraining's rmse: 3.51489\tvalid_1's rmse: 3.79864\n",
      "[2000]\ttraining's rmse: 3.48486\tvalid_1's rmse: 3.79731\n",
      "[2500]\ttraining's rmse: 3.45664\tvalid_1's rmse: 3.79652\n",
      "Early stopping, best iteration is:\n",
      "[2715]\ttraining's rmse: 3.44466\tvalid_1's rmse: 3.79603\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64533\tvalid_1's rmse: 3.64386\n",
      "[1000]\ttraining's rmse: 3.59261\tvalid_1's rmse: 3.62977\n",
      "[1500]\ttraining's rmse: 3.55726\tvalid_1's rmse: 3.62531\n",
      "[2000]\ttraining's rmse: 3.52504\tvalid_1's rmse: 3.62402\n",
      "Early stopping, best iteration is:\n",
      "[1942]\ttraining's rmse: 3.52871\tvalid_1's rmse: 3.62392\n",
      "    8 | 03m00s |   -3.66875 |             0.4371 |         1.1027 |             0.8673 |             0.8282 |      6.2610 |             12.2552 |            38.3969 |            44.0954 |           0.4650 |      30.9736 |      7.5146 |       8.0152 |      0.8574 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61311\tvalid_1's rmse: 3.71678\n",
      "[1000]\ttraining's rmse: 3.53869\tvalid_1's rmse: 3.69346\n",
      "[1500]\ttraining's rmse: 3.49191\tvalid_1's rmse: 3.68617\n",
      "[2000]\ttraining's rmse: 3.45248\tvalid_1's rmse: 3.68391\n",
      "[2500]\ttraining's rmse: 3.41809\tvalid_1's rmse: 3.68271\n",
      "[3000]\ttraining's rmse: 3.3871\tvalid_1's rmse: 3.68235\n",
      "Early stopping, best iteration is:\n",
      "[2991]\ttraining's rmse: 3.38769\tvalid_1's rmse: 3.68229\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62611\tvalid_1's rmse: 3.65522\n",
      "[1000]\ttraining's rmse: 3.5511\tvalid_1's rmse: 3.63508\n",
      "[1500]\ttraining's rmse: 3.50349\tvalid_1's rmse: 3.62848\n",
      "[2000]\ttraining's rmse: 3.46359\tvalid_1's rmse: 3.62591\n",
      "[2500]\ttraining's rmse: 3.42859\tvalid_1's rmse: 3.62532\n",
      "[3000]\ttraining's rmse: 3.39734\tvalid_1's rmse: 3.62448\n",
      "[3500]\ttraining's rmse: 3.36755\tvalid_1's rmse: 3.62409\n",
      "Early stopping, best iteration is:\n",
      "[3532]\ttraining's rmse: 3.36572\tvalid_1's rmse: 3.62404\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63046\tvalid_1's rmse: 3.63296\n",
      "[1000]\ttraining's rmse: 3.55508\tvalid_1's rmse: 3.61254\n",
      "[1500]\ttraining's rmse: 3.50701\tvalid_1's rmse: 3.60684\n",
      "[2000]\ttraining's rmse: 3.46699\tvalid_1's rmse: 3.60457\n",
      "[2500]\ttraining's rmse: 3.43219\tvalid_1's rmse: 3.60373\n",
      "Early stopping, best iteration is:\n",
      "[2557]\ttraining's rmse: 3.42813\tvalid_1's rmse: 3.60358\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58426\tvalid_1's rmse: 3.82217\n",
      "[1000]\ttraining's rmse: 3.50905\tvalid_1's rmse: 3.8016\n",
      "[1500]\ttraining's rmse: 3.46175\tvalid_1's rmse: 3.79585\n",
      "[2000]\ttraining's rmse: 3.42319\tvalid_1's rmse: 3.79378\n",
      "[2500]\ttraining's rmse: 3.38971\tvalid_1's rmse: 3.79251\n",
      "[3000]\ttraining's rmse: 3.35867\tvalid_1's rmse: 3.7919\n",
      "Early stopping, best iteration is:\n",
      "[3163]\ttraining's rmse: 3.34861\tvalid_1's rmse: 3.79172\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62534\tvalid_1's rmse: 3.65047\n",
      "[1000]\ttraining's rmse: 3.54894\tvalid_1's rmse: 3.63227\n",
      "[1500]\ttraining's rmse: 3.50026\tvalid_1's rmse: 3.62592\n",
      "[2000]\ttraining's rmse: 3.46114\tvalid_1's rmse: 3.62345\n",
      "[2500]\ttraining's rmse: 3.42795\tvalid_1's rmse: 3.62284\n",
      "Early stopping, best iteration is:\n",
      "[2567]\ttraining's rmse: 3.42369\tvalid_1's rmse: 3.62277\n",
      "    9 | 03m21s |   -3.66553 |             0.9794 |         5.8015 |             0.1354 |             0.2885 |     11.4362 |             28.4786 |            36.2690 |            91.3605 |           0.6728 |      38.7932 |      6.7810 |       4.4560 |      0.4632 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6154\tvalid_1's rmse: 3.71945\n",
      "[1000]\ttraining's rmse: 3.54124\tvalid_1's rmse: 3.6974\n",
      "[1500]\ttraining's rmse: 3.48877\tvalid_1's rmse: 3.69063\n",
      "[2000]\ttraining's rmse: 3.44312\tvalid_1's rmse: 3.68726\n",
      "[2500]\ttraining's rmse: 3.40143\tvalid_1's rmse: 3.68534\n",
      "Early stopping, best iteration is:\n",
      "[2676]\ttraining's rmse: 3.38718\tvalid_1's rmse: 3.68523\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62927\tvalid_1's rmse: 3.65959\n",
      "[1000]\ttraining's rmse: 3.55385\tvalid_1's rmse: 3.64057\n",
      "[1500]\ttraining's rmse: 3.50065\tvalid_1's rmse: 3.63392\n",
      "[2000]\ttraining's rmse: 3.45549\tvalid_1's rmse: 3.63011\n",
      "[2500]\ttraining's rmse: 3.41407\tvalid_1's rmse: 3.62847\n",
      "Early stopping, best iteration is:\n",
      "[2594]\ttraining's rmse: 3.40704\tvalid_1's rmse: 3.62823\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63498\tvalid_1's rmse: 3.63568\n",
      "[1000]\ttraining's rmse: 3.56004\tvalid_1's rmse: 3.61715\n",
      "[1500]\ttraining's rmse: 3.50606\tvalid_1's rmse: 3.6131\n",
      "[2000]\ttraining's rmse: 3.45993\tvalid_1's rmse: 3.61121\n",
      "Early stopping, best iteration is:\n",
      "[2046]\ttraining's rmse: 3.45593\tvalid_1's rmse: 3.6109\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58734\tvalid_1's rmse: 3.8252\n",
      "[1000]\ttraining's rmse: 3.5126\tvalid_1's rmse: 3.80545\n",
      "[1500]\ttraining's rmse: 3.45963\tvalid_1's rmse: 3.79993\n",
      "[2000]\ttraining's rmse: 3.41564\tvalid_1's rmse: 3.79677\n",
      "[2500]\ttraining's rmse: 3.37425\tvalid_1's rmse: 3.79574\n",
      "Early stopping, best iteration is:\n",
      "[2376]\ttraining's rmse: 3.38412\tvalid_1's rmse: 3.79551\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62897\tvalid_1's rmse: 3.65492\n",
      "[1000]\ttraining's rmse: 3.55122\tvalid_1's rmse: 3.63852\n",
      "[1500]\ttraining's rmse: 3.49832\tvalid_1's rmse: 3.6343\n",
      "[2000]\ttraining's rmse: 3.45222\tvalid_1's rmse: 3.63274\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's rmse: 3.45812\tvalid_1's rmse: 3.63237\n",
      "   10 | 02m07s |   -3.67107 |             0.4127 |         5.8158 |             0.2008 |             0.3256 |     12.7008 |             46.8404 |            41.1508 |            36.9027 |           0.9670 |      37.8831 |      7.0561 |       4.8642 |      0.2576 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6325\tvalid_1's rmse: 3.71201\n",
      "[1000]\ttraining's rmse: 3.58244\tvalid_1's rmse: 3.69654\n",
      "[1500]\ttraining's rmse: 3.54477\tvalid_1's rmse: 3.69204\n",
      "[2000]\ttraining's rmse: 3.51317\tvalid_1's rmse: 3.69016\n",
      "Early stopping, best iteration is:\n",
      "[1910]\ttraining's rmse: 3.51845\tvalid_1's rmse: 3.68983\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64625\tvalid_1's rmse: 3.65336\n",
      "[1000]\ttraining's rmse: 3.59482\tvalid_1's rmse: 3.64065\n",
      "[1500]\ttraining's rmse: 3.55823\tvalid_1's rmse: 3.63575\n",
      "[2000]\ttraining's rmse: 3.52659\tvalid_1's rmse: 3.63289\n",
      "Early stopping, best iteration is:\n",
      "[2072]\ttraining's rmse: 3.52226\tvalid_1's rmse: 3.63211\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64873\tvalid_1's rmse: 3.62548\n",
      "[1000]\ttraining's rmse: 3.59676\tvalid_1's rmse: 3.61335\n",
      "[1500]\ttraining's rmse: 3.55767\tvalid_1's rmse: 3.6114\n",
      "Early stopping, best iteration is:\n",
      "[1442]\ttraining's rmse: 3.56227\tvalid_1's rmse: 3.6101\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60255\tvalid_1's rmse: 3.81481\n",
      "[1000]\ttraining's rmse: 3.55178\tvalid_1's rmse: 3.80728\n",
      "Early stopping, best iteration is:\n",
      "[881]\ttraining's rmse: 3.56086\tvalid_1's rmse: 3.80692\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6474\tvalid_1's rmse: 3.64487\n",
      "[1000]\ttraining's rmse: 3.59588\tvalid_1's rmse: 3.6308\n",
      "[1500]\ttraining's rmse: 3.55677\tvalid_1's rmse: 3.62693\n",
      "Early stopping, best iteration is:\n",
      "[1543]\ttraining's rmse: 3.55365\tvalid_1's rmse: 3.62683\n",
      "   11 | 01m47s |   -3.67387 |             0.2108 |        14.0904 |             0.3209 |             0.7495 |      8.3502 |             32.6862 |            32.0497 |            60.8342 |           0.6567 |      38.4394 |      0.9141 |       4.0139 |      0.3190 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63376\tvalid_1's rmse: 3.71873\n",
      "[1000]\ttraining's rmse: 3.57579\tvalid_1's rmse: 3.69842\n",
      "[1500]\ttraining's rmse: 3.53575\tvalid_1's rmse: 3.69303\n",
      "[2000]\ttraining's rmse: 3.50107\tvalid_1's rmse: 3.69032\n",
      "Early stopping, best iteration is:\n",
      "[1894]\ttraining's rmse: 3.50811\tvalid_1's rmse: 3.69004\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64564\tvalid_1's rmse: 3.656\n",
      "[1000]\ttraining's rmse: 3.58832\tvalid_1's rmse: 3.63894\n",
      "[1500]\ttraining's rmse: 3.55211\tvalid_1's rmse: 3.63393\n",
      "[2000]\ttraining's rmse: 3.51837\tvalid_1's rmse: 3.63132\n",
      "Early stopping, best iteration is:\n",
      "[1847]\ttraining's rmse: 3.52798\tvalid_1's rmse: 3.6311\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64742\tvalid_1's rmse: 3.63252\n",
      "[1000]\ttraining's rmse: 3.58943\tvalid_1's rmse: 3.61784\n",
      "[1500]\ttraining's rmse: 3.54987\tvalid_1's rmse: 3.6158\n",
      "Early stopping, best iteration is:\n",
      "[1370]\ttraining's rmse: 3.559\tvalid_1's rmse: 3.61508\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60334\tvalid_1's rmse: 3.82286\n",
      "[1000]\ttraining's rmse: 3.54642\tvalid_1's rmse: 3.80792\n",
      "[1500]\ttraining's rmse: 3.506\tvalid_1's rmse: 3.80387\n",
      "[2000]\ttraining's rmse: 3.47231\tvalid_1's rmse: 3.80099\n",
      "Early stopping, best iteration is:\n",
      "[2194]\ttraining's rmse: 3.46014\tvalid_1's rmse: 3.79999\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64492\tvalid_1's rmse: 3.65084\n",
      "[1000]\ttraining's rmse: 3.58521\tvalid_1's rmse: 3.63618\n",
      "[1500]\ttraining's rmse: 3.54568\tvalid_1's rmse: 3.63308\n",
      "[2000]\ttraining's rmse: 3.51178\tvalid_1's rmse: 3.62978\n",
      "[2500]\ttraining's rmse: 3.47738\tvalid_1's rmse: 3.62837\n",
      "Early stopping, best iteration is:\n",
      "[2787]\ttraining's rmse: 3.45862\tvalid_1's rmse: 3.62802\n",
      "   12 | 01m45s |   -3.67349 |             0.2706 |        17.9347 |             0.9292 |             0.3751 |      7.5351 |             27.9801 |            38.6495 |            28.5865 |           0.0679 |      40.7065 |      7.5611 |       1.7739 |      0.9609 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6624\tvalid_1's rmse: 3.71686\n",
      "[1000]\ttraining's rmse: 3.63201\tvalid_1's rmse: 3.70018\n",
      "[1500]\ttraining's rmse: 3.61047\tvalid_1's rmse: 3.69509\n",
      "Early stopping, best iteration is:\n",
      "[1715]\ttraining's rmse: 3.60225\tvalid_1's rmse: 3.69245\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67769\tvalid_1's rmse: 3.65731\n",
      "[1000]\ttraining's rmse: 3.64749\tvalid_1's rmse: 3.64445\n",
      "[1500]\ttraining's rmse: 3.62687\tvalid_1's rmse: 3.64052\n",
      "Early stopping, best iteration is:\n",
      "[1799]\ttraining's rmse: 3.61489\tvalid_1's rmse: 3.63849\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68067\tvalid_1's rmse: 3.63377\n",
      "[1000]\ttraining's rmse: 3.64983\tvalid_1's rmse: 3.624\n",
      "[1500]\ttraining's rmse: 3.6269\tvalid_1's rmse: 3.61924\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's rmse: 3.62187\tvalid_1's rmse: 3.61848\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63295\tvalid_1's rmse: 3.82755\n",
      "[1000]\ttraining's rmse: 3.5988\tvalid_1's rmse: 3.8151\n",
      "[1500]\ttraining's rmse: 3.57687\tvalid_1's rmse: 3.81277\n",
      "Early stopping, best iteration is:\n",
      "[1476]\ttraining's rmse: 3.57782\tvalid_1's rmse: 3.81232\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67653\tvalid_1's rmse: 3.64635\n",
      "[1000]\ttraining's rmse: 3.6432\tvalid_1's rmse: 3.63855\n",
      "[1500]\ttraining's rmse: 3.62162\tvalid_1's rmse: 3.63443\n",
      "[2000]\ttraining's rmse: 3.60143\tvalid_1's rmse: 3.63365\n",
      "Early stopping, best iteration is:\n",
      "[2185]\ttraining's rmse: 3.59517\tvalid_1's rmse: 3.63262\n",
      "   13 | 01m29s |   -3.67956 |             0.1206 |         5.9094 |             0.1893 |             0.9084 |      6.5635 |             33.8190 |            31.9518 |            66.4372 |           0.9251 |      41.9056 |      0.1682 |       8.2407 |      0.6524 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6038\tvalid_1's rmse: 3.71096\n",
      "[1000]\ttraining's rmse: 3.53321\tvalid_1's rmse: 3.69095\n",
      "[1500]\ttraining's rmse: 3.48448\tvalid_1's rmse: 3.68667\n",
      "[2000]\ttraining's rmse: 3.44313\tvalid_1's rmse: 3.68527\n",
      "Early stopping, best iteration is:\n",
      "[2016]\ttraining's rmse: 3.44194\tvalid_1's rmse: 3.68518\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61875\tvalid_1's rmse: 3.65338\n",
      "[1000]\ttraining's rmse: 3.5477\tvalid_1's rmse: 3.63582\n",
      "[1500]\ttraining's rmse: 3.49884\tvalid_1's rmse: 3.63092\n",
      "[2000]\ttraining's rmse: 3.45703\tvalid_1's rmse: 3.62921\n",
      "Early stopping, best iteration is:\n",
      "[2217]\ttraining's rmse: 3.43923\tvalid_1's rmse: 3.62876\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62324\tvalid_1's rmse: 3.62834\n",
      "[1000]\ttraining's rmse: 3.55287\tvalid_1's rmse: 3.61191\n",
      "[1500]\ttraining's rmse: 3.5037\tvalid_1's rmse: 3.60862\n",
      "[2000]\ttraining's rmse: 3.46146\tvalid_1's rmse: 3.60673\n",
      "Early stopping, best iteration is:\n",
      "[2138]\ttraining's rmse: 3.45056\tvalid_1's rmse: 3.60667\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57802\tvalid_1's rmse: 3.81446\n",
      "[1000]\ttraining's rmse: 3.50627\tvalid_1's rmse: 3.79792\n",
      "[1500]\ttraining's rmse: 3.45593\tvalid_1's rmse: 3.79272\n",
      "Early stopping, best iteration is:\n",
      "[1731]\ttraining's rmse: 3.43683\tvalid_1's rmse: 3.79204\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6174\tvalid_1's rmse: 3.64951\n",
      "[1000]\ttraining's rmse: 3.54459\tvalid_1's rmse: 3.63441\n",
      "[1500]\ttraining's rmse: 3.49481\tvalid_1's rmse: 3.62984\n",
      "Early stopping, best iteration is:\n",
      "[1659]\ttraining's rmse: 3.48068\tvalid_1's rmse: 3.62939\n",
      "   14 | 02m26s |   -3.66902 |             0.5961 |        15.5436 |             0.4503 |             0.7116 |     13.2630 |             26.1298 |            31.2974 |            60.3825 |           0.1945 |      31.7622 |      5.7556 |       5.5858 |      0.7726 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66733\tvalid_1's rmse: 3.72645\n",
      "[1000]\ttraining's rmse: 3.62643\tvalid_1's rmse: 3.70305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.60116\tvalid_1's rmse: 3.69507\n",
      "[2000]\ttraining's rmse: 3.57999\tvalid_1's rmse: 3.69093\n",
      "[2500]\ttraining's rmse: 3.56005\tvalid_1's rmse: 3.68711\n",
      "[3000]\ttraining's rmse: 3.54211\tvalid_1's rmse: 3.68552\n",
      "[3500]\ttraining's rmse: 3.5248\tvalid_1's rmse: 3.68497\n",
      "Early stopping, best iteration is:\n",
      "[3351]\ttraining's rmse: 3.52969\tvalid_1's rmse: 3.68477\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68253\tvalid_1's rmse: 3.66624\n",
      "[1000]\ttraining's rmse: 3.63982\tvalid_1's rmse: 3.64628\n",
      "[1500]\ttraining's rmse: 3.61303\tvalid_1's rmse: 3.63818\n",
      "[2000]\ttraining's rmse: 3.59157\tvalid_1's rmse: 3.63383\n",
      "[2500]\ttraining's rmse: 3.57328\tvalid_1's rmse: 3.63201\n",
      "[3000]\ttraining's rmse: 3.55551\tvalid_1's rmse: 3.62998\n",
      "[3500]\ttraining's rmse: 3.53818\tvalid_1's rmse: 3.62872\n",
      "[4000]\ttraining's rmse: 3.52181\tvalid_1's rmse: 3.62788\n",
      "[4500]\ttraining's rmse: 3.5055\tvalid_1's rmse: 3.62709\n",
      "[5000]\ttraining's rmse: 3.49041\tvalid_1's rmse: 3.62655\n",
      "[5500]\ttraining's rmse: 3.4745\tvalid_1's rmse: 3.62585\n",
      "Early stopping, best iteration is:\n",
      "[5485]\ttraining's rmse: 3.47498\tvalid_1's rmse: 3.62581\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6867\tvalid_1's rmse: 3.63905\n",
      "[1000]\ttraining's rmse: 3.64362\tvalid_1's rmse: 3.61878\n",
      "[1500]\ttraining's rmse: 3.6181\tvalid_1's rmse: 3.61219\n",
      "[2000]\ttraining's rmse: 3.59451\tvalid_1's rmse: 3.60877\n",
      "[2500]\ttraining's rmse: 3.57396\tvalid_1's rmse: 3.60803\n",
      "[3000]\ttraining's rmse: 3.555\tvalid_1's rmse: 3.60715\n",
      "Early stopping, best iteration is:\n",
      "[3299]\ttraining's rmse: 3.54424\tvalid_1's rmse: 3.60664\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64022\tvalid_1's rmse: 3.83339\n",
      "[1000]\ttraining's rmse: 3.59655\tvalid_1's rmse: 3.81247\n",
      "[1500]\ttraining's rmse: 3.57106\tvalid_1's rmse: 3.80581\n",
      "[2000]\ttraining's rmse: 3.55044\tvalid_1's rmse: 3.80222\n",
      "[2500]\ttraining's rmse: 3.53143\tvalid_1's rmse: 3.80009\n",
      "[3000]\ttraining's rmse: 3.51282\tvalid_1's rmse: 3.79859\n",
      "[3500]\ttraining's rmse: 3.49558\tvalid_1's rmse: 3.79774\n",
      "[4000]\ttraining's rmse: 3.4781\tvalid_1's rmse: 3.79728\n",
      "Early stopping, best iteration is:\n",
      "[3947]\ttraining's rmse: 3.47976\tvalid_1's rmse: 3.79716\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68363\tvalid_1's rmse: 3.65704\n",
      "[1000]\ttraining's rmse: 3.64017\tvalid_1's rmse: 3.63764\n",
      "[1500]\ttraining's rmse: 3.61395\tvalid_1's rmse: 3.63175\n",
      "[2000]\ttraining's rmse: 3.59141\tvalid_1's rmse: 3.62875\n",
      "[2500]\ttraining's rmse: 3.57241\tvalid_1's rmse: 3.62736\n",
      "[3000]\ttraining's rmse: 3.55422\tvalid_1's rmse: 3.62646\n",
      "[3500]\ttraining's rmse: 3.53764\tvalid_1's rmse: 3.62605\n",
      "Early stopping, best iteration is:\n",
      "[3782]\ttraining's rmse: 3.52853\tvalid_1's rmse: 3.62576\n",
      "   15 | 02m31s |   -3.66869 |             0.5500 |         9.7239 |             0.8316 |             0.3043 |      5.1041 |             23.6644 |            35.3312 |            56.7743 |           0.5140 |      44.2965 |      8.9459 |       9.0995 |      0.6690 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66837\tvalid_1's rmse: 3.75046\n",
      "[1000]\ttraining's rmse: 3.59871\tvalid_1's rmse: 3.72018\n",
      "[1500]\ttraining's rmse: 3.55204\tvalid_1's rmse: 3.70824\n",
      "[2000]\ttraining's rmse: 3.51324\tvalid_1's rmse: 3.7014\n",
      "[2500]\ttraining's rmse: 3.47978\tvalid_1's rmse: 3.69756\n",
      "[3000]\ttraining's rmse: 3.44943\tvalid_1's rmse: 3.69468\n",
      "[3500]\ttraining's rmse: 3.42113\tvalid_1's rmse: 3.69374\n",
      "[4000]\ttraining's rmse: 3.39355\tvalid_1's rmse: 3.69242\n",
      "Early stopping, best iteration is:\n",
      "[4038]\ttraining's rmse: 3.39163\tvalid_1's rmse: 3.69235\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68384\tvalid_1's rmse: 3.68593\n",
      "[1000]\ttraining's rmse: 3.61224\tvalid_1's rmse: 3.66029\n",
      "[1500]\ttraining's rmse: 3.56431\tvalid_1's rmse: 3.64945\n",
      "[2000]\ttraining's rmse: 3.52485\tvalid_1's rmse: 3.64347\n",
      "[2500]\ttraining's rmse: 3.49167\tvalid_1's rmse: 3.63974\n",
      "[3000]\ttraining's rmse: 3.46178\tvalid_1's rmse: 3.63776\n",
      "[3500]\ttraining's rmse: 3.43241\tvalid_1's rmse: 3.63663\n",
      "[4000]\ttraining's rmse: 3.40517\tvalid_1's rmse: 3.63593\n",
      "[4500]\ttraining's rmse: 3.37932\tvalid_1's rmse: 3.63554\n",
      "Early stopping, best iteration is:\n",
      "[4675]\ttraining's rmse: 3.37015\tvalid_1's rmse: 3.63539\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68839\tvalid_1's rmse: 3.66018\n",
      "[1000]\ttraining's rmse: 3.61732\tvalid_1's rmse: 3.63543\n",
      "[1500]\ttraining's rmse: 3.56886\tvalid_1's rmse: 3.6254\n",
      "[2000]\ttraining's rmse: 3.53038\tvalid_1's rmse: 3.62055\n",
      "[2500]\ttraining's rmse: 3.49673\tvalid_1's rmse: 3.61805\n",
      "[3000]\ttraining's rmse: 3.46622\tvalid_1's rmse: 3.61633\n",
      "[3500]\ttraining's rmse: 3.4372\tvalid_1's rmse: 3.61505\n",
      "[4000]\ttraining's rmse: 3.4101\tvalid_1's rmse: 3.61463\n",
      "Early stopping, best iteration is:\n",
      "[3833]\ttraining's rmse: 3.41922\tvalid_1's rmse: 3.61448\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64001\tvalid_1's rmse: 3.85755\n",
      "[1000]\ttraining's rmse: 3.56931\tvalid_1's rmse: 3.82876\n",
      "[1500]\ttraining's rmse: 3.52139\tvalid_1's rmse: 3.81745\n",
      "[2000]\ttraining's rmse: 3.48318\tvalid_1's rmse: 3.81136\n",
      "[2500]\ttraining's rmse: 3.44932\tvalid_1's rmse: 3.80773\n",
      "[3000]\ttraining's rmse: 3.41915\tvalid_1's rmse: 3.80546\n",
      "[3500]\ttraining's rmse: 3.3907\tvalid_1's rmse: 3.80354\n",
      "[4000]\ttraining's rmse: 3.36329\tvalid_1's rmse: 3.80204\n",
      "[4500]\ttraining's rmse: 3.33654\tvalid_1's rmse: 3.80168\n",
      "Early stopping, best iteration is:\n",
      "[4716]\ttraining's rmse: 3.32537\tvalid_1's rmse: 3.80143\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68368\tvalid_1's rmse: 3.67971\n",
      "[1000]\ttraining's rmse: 3.61078\tvalid_1's rmse: 3.65634\n",
      "[1500]\ttraining's rmse: 3.56246\tvalid_1's rmse: 3.64649\n",
      "[2000]\ttraining's rmse: 3.5235\tvalid_1's rmse: 3.64073\n",
      "[2500]\ttraining's rmse: 3.48999\tvalid_1's rmse: 3.63787\n",
      "[3000]\ttraining's rmse: 3.4588\tvalid_1's rmse: 3.63605\n",
      "[3500]\ttraining's rmse: 3.43043\tvalid_1's rmse: 3.63476\n",
      "[4000]\ttraining's rmse: 3.40348\tvalid_1's rmse: 3.63446\n",
      "Early stopping, best iteration is:\n",
      "[3972]\ttraining's rmse: 3.40487\tvalid_1's rmse: 3.63434\n",
      "   16 | 02m32s |   -3.67623 |             0.6389 |        15.4368 |             0.6865 |             0.1038 |     11.2049 |             40.3645 |            34.1957 |            43.5110 |           0.6579 |      32.4746 |      8.6548 |       1.8557 |      0.1305 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61958\tvalid_1's rmse: 3.71752\n",
      "[1000]\ttraining's rmse: 3.54882\tvalid_1's rmse: 3.69439\n",
      "[1500]\ttraining's rmse: 3.49933\tvalid_1's rmse: 3.68753\n",
      "[2000]\ttraining's rmse: 3.45659\tvalid_1's rmse: 3.68481\n",
      "[2500]\ttraining's rmse: 3.41728\tvalid_1's rmse: 3.68375\n",
      "Early stopping, best iteration is:\n",
      "[2486]\ttraining's rmse: 3.41836\tvalid_1's rmse: 3.68367\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63365\tvalid_1's rmse: 3.65809\n",
      "[1000]\ttraining's rmse: 3.56034\tvalid_1's rmse: 3.63833\n",
      "[1500]\ttraining's rmse: 3.51052\tvalid_1's rmse: 3.63206\n",
      "[2000]\ttraining's rmse: 3.46689\tvalid_1's rmse: 3.62814\n",
      "Early stopping, best iteration is:\n",
      "[2248]\ttraining's rmse: 3.44682\tvalid_1's rmse: 3.62744\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63905\tvalid_1's rmse: 3.63293\n",
      "[1000]\ttraining's rmse: 3.56685\tvalid_1's rmse: 3.61533\n",
      "[1500]\ttraining's rmse: 3.51595\tvalid_1's rmse: 3.61077\n",
      "[2000]\ttraining's rmse: 3.47225\tvalid_1's rmse: 3.60901\n",
      "Early stopping, best iteration is:\n",
      "[1968]\ttraining's rmse: 3.4751\tvalid_1's rmse: 3.60885\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59151\tvalid_1's rmse: 3.82363\n",
      "[1000]\ttraining's rmse: 3.51958\tvalid_1's rmse: 3.80358\n",
      "[1500]\ttraining's rmse: 3.46946\tvalid_1's rmse: 3.79788\n",
      "[2000]\ttraining's rmse: 3.42598\tvalid_1's rmse: 3.79553\n",
      "Early stopping, best iteration is:\n",
      "[2105]\ttraining's rmse: 3.41738\tvalid_1's rmse: 3.79482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63297\tvalid_1's rmse: 3.65333\n",
      "[1000]\ttraining's rmse: 3.56054\tvalid_1's rmse: 3.6364\n",
      "[1500]\ttraining's rmse: 3.51058\tvalid_1's rmse: 3.63226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's rmse: 3.46669\tvalid_1's rmse: 3.63109\n",
      "[2500]\ttraining's rmse: 3.42711\tvalid_1's rmse: 3.63134\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's rmse: 3.43832\tvalid_1's rmse: 3.63069\n",
      "   17 | 02m13s |   -3.66972 |             0.4504 |         4.9576 |             0.3511 |             0.3070 |     10.8493 |             41.1802 |            37.0603 |            56.4156 |           0.9501 |      40.4725 |      6.6928 |       7.5959 |      0.5425 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6159\tvalid_1's rmse: 3.72471\n",
      "[1000]\ttraining's rmse: 3.53417\tvalid_1's rmse: 3.7003\n",
      "[1500]\ttraining's rmse: 3.47943\tvalid_1's rmse: 3.69166\n",
      "[2000]\ttraining's rmse: 3.43336\tvalid_1's rmse: 3.68818\n",
      "[2500]\ttraining's rmse: 3.39099\tvalid_1's rmse: 3.68614\n",
      "[3000]\ttraining's rmse: 3.35153\tvalid_1's rmse: 3.68479\n",
      "[3500]\ttraining's rmse: 3.31442\tvalid_1's rmse: 3.6847\n",
      "Early stopping, best iteration is:\n",
      "[3329]\ttraining's rmse: 3.32684\tvalid_1's rmse: 3.68435\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63049\tvalid_1's rmse: 3.66583\n",
      "[1000]\ttraining's rmse: 3.54696\tvalid_1's rmse: 3.64486\n",
      "[1500]\ttraining's rmse: 3.49099\tvalid_1's rmse: 3.63717\n",
      "[2000]\ttraining's rmse: 3.44327\tvalid_1's rmse: 3.63236\n",
      "[2500]\ttraining's rmse: 3.40197\tvalid_1's rmse: 3.63074\n",
      "[3000]\ttraining's rmse: 3.3631\tvalid_1's rmse: 3.62954\n",
      "[3500]\ttraining's rmse: 3.32539\tvalid_1's rmse: 3.62878\n",
      "Early stopping, best iteration is:\n",
      "[3510]\ttraining's rmse: 3.32464\tvalid_1's rmse: 3.6287\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63556\tvalid_1's rmse: 3.64065\n",
      "[1000]\ttraining's rmse: 3.55252\tvalid_1's rmse: 3.62037\n",
      "[1500]\ttraining's rmse: 3.49711\tvalid_1's rmse: 3.61408\n",
      "[2000]\ttraining's rmse: 3.44913\tvalid_1's rmse: 3.61126\n",
      "[2500]\ttraining's rmse: 3.40743\tvalid_1's rmse: 3.61023\n",
      "Early stopping, best iteration is:\n",
      "[2643]\ttraining's rmse: 3.39559\tvalid_1's rmse: 3.61001\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58756\tvalid_1's rmse: 3.82976\n",
      "[1000]\ttraining's rmse: 3.50443\tvalid_1's rmse: 3.80879\n",
      "[1500]\ttraining's rmse: 3.44929\tvalid_1's rmse: 3.80157\n",
      "[2000]\ttraining's rmse: 3.40215\tvalid_1's rmse: 3.79857\n",
      "[2500]\ttraining's rmse: 3.35965\tvalid_1's rmse: 3.79697\n",
      "[3000]\ttraining's rmse: 3.32128\tvalid_1's rmse: 3.79591\n",
      "Early stopping, best iteration is:\n",
      "[2893]\ttraining's rmse: 3.32935\tvalid_1's rmse: 3.79574\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62967\tvalid_1's rmse: 3.66008\n",
      "[1000]\ttraining's rmse: 3.54625\tvalid_1's rmse: 3.6415\n",
      "[1500]\ttraining's rmse: 3.49088\tvalid_1's rmse: 3.6355\n",
      "[2000]\ttraining's rmse: 3.44358\tvalid_1's rmse: 3.63207\n",
      "[2500]\ttraining's rmse: 3.40162\tvalid_1's rmse: 3.63021\n",
      "Early stopping, best iteration is:\n",
      "[2660]\ttraining's rmse: 3.38869\tvalid_1's rmse: 3.63\n",
      "   18 | 02m35s |   -3.67038 |             0.5600 |         3.8286 |             0.2585 |             0.2494 |     13.0858 |             18.1052 |            32.7236 |            33.3868 |           0.4924 |      35.2368 |      2.0003 |       4.3194 |      0.1976 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60256\tvalid_1's rmse: 3.70551\n",
      "[1000]\ttraining's rmse: 3.54408\tvalid_1's rmse: 3.68885\n",
      "[1500]\ttraining's rmse: 3.50213\tvalid_1's rmse: 3.68347\n",
      "[2000]\ttraining's rmse: 3.46381\tvalid_1's rmse: 3.6828\n",
      "Early stopping, best iteration is:\n",
      "[1806]\ttraining's rmse: 3.47888\tvalid_1's rmse: 3.68223\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61664\tvalid_1's rmse: 3.64761\n",
      "[1000]\ttraining's rmse: 3.55546\tvalid_1's rmse: 3.63117\n",
      "[1500]\ttraining's rmse: 3.51231\tvalid_1's rmse: 3.62604\n",
      "Early stopping, best iteration is:\n",
      "[1625]\ttraining's rmse: 3.50386\tvalid_1's rmse: 3.62528\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61895\tvalid_1's rmse: 3.6231\n",
      "[1000]\ttraining's rmse: 3.55756\tvalid_1's rmse: 3.60845\n",
      "[1500]\ttraining's rmse: 3.51157\tvalid_1's rmse: 3.60524\n",
      "[2000]\ttraining's rmse: 3.47349\tvalid_1's rmse: 3.60443\n",
      "Early stopping, best iteration is:\n",
      "[1890]\ttraining's rmse: 3.48139\tvalid_1's rmse: 3.60408\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5738\tvalid_1's rmse: 3.80941\n",
      "[1000]\ttraining's rmse: 3.51341\tvalid_1's rmse: 3.79523\n",
      "[1500]\ttraining's rmse: 3.47073\tvalid_1's rmse: 3.7919\n",
      "[2000]\ttraining's rmse: 3.43353\tvalid_1's rmse: 3.79102\n",
      "Early stopping, best iteration is:\n",
      "[1957]\ttraining's rmse: 3.43651\tvalid_1's rmse: 3.79076\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6167\tvalid_1's rmse: 3.64291\n",
      "[1000]\ttraining's rmse: 3.55396\tvalid_1's rmse: 3.6297\n",
      "[1500]\ttraining's rmse: 3.51074\tvalid_1's rmse: 3.62684\n",
      "Early stopping, best iteration is:\n",
      "[1721]\ttraining's rmse: 3.49321\tvalid_1's rmse: 3.6262\n",
      "   19 | 03m14s |   -3.66634 |             0.8274 |        14.7138 |             0.2792 |             0.8855 |      7.4675 |             24.1707 |            33.5970 |            76.0452 |           0.0889 |      39.1171 |      4.4745 |       4.9651 |      0.1059 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61659\tvalid_1's rmse: 3.71198\n",
      "[1000]\ttraining's rmse: 3.55159\tvalid_1's rmse: 3.69117\n",
      "[1500]\ttraining's rmse: 3.50443\tvalid_1's rmse: 3.68571\n",
      "[2000]\ttraining's rmse: 3.46371\tvalid_1's rmse: 3.68425\n",
      "[2500]\ttraining's rmse: 3.42582\tvalid_1's rmse: 3.68377\n",
      "Early stopping, best iteration is:\n",
      "[2371]\ttraining's rmse: 3.43552\tvalid_1's rmse: 3.68338\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62965\tvalid_1's rmse: 3.65275\n",
      "[1000]\ttraining's rmse: 3.56427\tvalid_1's rmse: 3.63519\n",
      "[1500]\ttraining's rmse: 3.51704\tvalid_1's rmse: 3.62965\n",
      "[2000]\ttraining's rmse: 3.4748\tvalid_1's rmse: 3.62652\n",
      "Early stopping, best iteration is:\n",
      "[2258]\ttraining's rmse: 3.45409\tvalid_1's rmse: 3.62606\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63523\tvalid_1's rmse: 3.62849\n",
      "[1000]\ttraining's rmse: 3.569\tvalid_1's rmse: 3.61194\n",
      "[1500]\ttraining's rmse: 3.52142\tvalid_1's rmse: 3.60926\n",
      "[2000]\ttraining's rmse: 3.47971\tvalid_1's rmse: 3.6076\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's rmse: 3.48121\tvalid_1's rmse: 3.60728\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58892\tvalid_1's rmse: 3.81794\n",
      "[1000]\ttraining's rmse: 3.52257\tvalid_1's rmse: 3.8013\n",
      "[1500]\ttraining's rmse: 3.47545\tvalid_1's rmse: 3.79693\n",
      "[2000]\ttraining's rmse: 3.43431\tvalid_1's rmse: 3.79568\n",
      "Early stopping, best iteration is:\n",
      "[1878]\ttraining's rmse: 3.44388\tvalid_1's rmse: 3.79524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6308\tvalid_1's rmse: 3.64852\n",
      "[1000]\ttraining's rmse: 3.56333\tvalid_1's rmse: 3.63327\n",
      "[1500]\ttraining's rmse: 3.51569\tvalid_1's rmse: 3.62787\n",
      "[2000]\ttraining's rmse: 3.47442\tvalid_1's rmse: 3.62637\n",
      "Early stopping, best iteration is:\n",
      "[2039]\ttraining's rmse: 3.47127\tvalid_1's rmse: 3.6262\n",
      "   20 | 02m09s |   -3.66828 |             0.4437 |        12.3748 |             0.3010 |             0.4352 |     11.5230 |             17.6964 |            40.5936 |            75.1940 |           0.6255 |      37.8625 |      9.1096 |       1.9917 |      0.3997 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66375\tvalid_1's rmse: 3.73382\n",
      "[1000]\ttraining's rmse: 3.60906\tvalid_1's rmse: 3.7088\n",
      "[1500]\ttraining's rmse: 3.57424\tvalid_1's rmse: 3.7002\n",
      "[2000]\ttraining's rmse: 3.54558\tvalid_1's rmse: 3.69546\n",
      "[2500]\ttraining's rmse: 3.51843\tvalid_1's rmse: 3.69473\n",
      "[3000]\ttraining's rmse: 3.49276\tvalid_1's rmse: 3.69155\n",
      "[3500]\ttraining's rmse: 3.46774\tvalid_1's rmse: 3.69054\n",
      "Early stopping, best iteration is:\n",
      "[3598]\ttraining's rmse: 3.46269\tvalid_1's rmse: 3.68995\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67796\tvalid_1's rmse: 3.67151\n",
      "[1000]\ttraining's rmse: 3.62552\tvalid_1's rmse: 3.64954\n",
      "[1500]\ttraining's rmse: 3.59036\tvalid_1's rmse: 3.64203\n",
      "[2000]\ttraining's rmse: 3.56004\tvalid_1's rmse: 3.63745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\ttraining's rmse: 3.53147\tvalid_1's rmse: 3.63443\n",
      "Early stopping, best iteration is:\n",
      "[2670]\ttraining's rmse: 3.52307\tvalid_1's rmse: 3.63409\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68134\tvalid_1's rmse: 3.64472\n",
      "[1000]\ttraining's rmse: 3.62785\tvalid_1's rmse: 3.62703\n",
      "[1500]\ttraining's rmse: 3.59133\tvalid_1's rmse: 3.62242\n",
      "[2000]\ttraining's rmse: 3.55972\tvalid_1's rmse: 3.62042\n",
      "Early stopping, best iteration is:\n",
      "[2165]\ttraining's rmse: 3.55116\tvalid_1's rmse: 3.61948\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63488\tvalid_1's rmse: 3.84218\n",
      "[1000]\ttraining's rmse: 3.58084\tvalid_1's rmse: 3.82015\n",
      "[1500]\ttraining's rmse: 3.54416\tvalid_1's rmse: 3.81282\n",
      "[2000]\ttraining's rmse: 3.51556\tvalid_1's rmse: 3.80906\n",
      "[2500]\ttraining's rmse: 3.48814\tvalid_1's rmse: 3.80657\n",
      "[3000]\ttraining's rmse: 3.46237\tvalid_1's rmse: 3.80604\n",
      "Early stopping, best iteration is:\n",
      "[2838]\ttraining's rmse: 3.47053\tvalid_1's rmse: 3.80538\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67736\tvalid_1's rmse: 3.66439\n",
      "[1000]\ttraining's rmse: 3.62196\tvalid_1's rmse: 3.64461\n",
      "[1500]\ttraining's rmse: 3.58602\tvalid_1's rmse: 3.63924\n",
      "[2000]\ttraining's rmse: 3.55638\tvalid_1's rmse: 3.63639\n",
      "[2500]\ttraining's rmse: 3.52717\tvalid_1's rmse: 3.63518\n",
      "Early stopping, best iteration is:\n",
      "[2397]\ttraining's rmse: 3.53244\tvalid_1's rmse: 3.63476\n",
      "   21 | 01m44s |   -3.67737 |             0.1816 |        17.2883 |             0.4716 |             0.2151 |      7.6614 |             43.4367 |            31.2326 |            14.3443 |           0.1310 |      35.7612 |      2.5623 |       6.9129 |      0.6201 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6657\tvalid_1's rmse: 3.73522\n",
      "[1000]\ttraining's rmse: 3.60957\tvalid_1's rmse: 3.707\n",
      "[1500]\ttraining's rmse: 3.57226\tvalid_1's rmse: 3.69602\n",
      "[2000]\ttraining's rmse: 3.54298\tvalid_1's rmse: 3.69098\n",
      "[2500]\ttraining's rmse: 3.51635\tvalid_1's rmse: 3.68799\n",
      "[3000]\ttraining's rmse: 3.49184\tvalid_1's rmse: 3.68643\n",
      "[3500]\ttraining's rmse: 3.4687\tvalid_1's rmse: 3.6858\n",
      "[4000]\ttraining's rmse: 3.44584\tvalid_1's rmse: 3.68526\n",
      "Early stopping, best iteration is:\n",
      "[4033]\ttraining's rmse: 3.44453\tvalid_1's rmse: 3.68519\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67917\tvalid_1's rmse: 3.67176\n",
      "[1000]\ttraining's rmse: 3.62243\tvalid_1's rmse: 3.64839\n",
      "[1500]\ttraining's rmse: 3.58496\tvalid_1's rmse: 3.63854\n",
      "[2000]\ttraining's rmse: 3.55523\tvalid_1's rmse: 3.6336\n",
      "[2500]\ttraining's rmse: 3.52829\tvalid_1's rmse: 3.63092\n",
      "[3000]\ttraining's rmse: 3.50347\tvalid_1's rmse: 3.62938\n",
      "[3500]\ttraining's rmse: 3.48062\tvalid_1's rmse: 3.62845\n",
      "[4000]\ttraining's rmse: 3.45782\tvalid_1's rmse: 3.62802\n",
      "[4500]\ttraining's rmse: 3.43641\tvalid_1's rmse: 3.62768\n",
      "[5000]\ttraining's rmse: 3.41608\tvalid_1's rmse: 3.62746\n",
      "Early stopping, best iteration is:\n",
      "[4889]\ttraining's rmse: 3.42065\tvalid_1's rmse: 3.62737\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68445\tvalid_1's rmse: 3.64692\n",
      "[1000]\ttraining's rmse: 3.62674\tvalid_1's rmse: 3.62424\n",
      "[1500]\ttraining's rmse: 3.58907\tvalid_1's rmse: 3.61635\n",
      "[2000]\ttraining's rmse: 3.55918\tvalid_1's rmse: 3.61262\n",
      "[2500]\ttraining's rmse: 3.53321\tvalid_1's rmse: 3.61107\n",
      "Early stopping, best iteration is:\n",
      "[2731]\ttraining's rmse: 3.52121\tvalid_1's rmse: 3.61058\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63682\tvalid_1's rmse: 3.84397\n",
      "[1000]\ttraining's rmse: 3.58048\tvalid_1's rmse: 3.81818\n",
      "[1500]\ttraining's rmse: 3.54359\tvalid_1's rmse: 3.80819\n",
      "[2000]\ttraining's rmse: 3.51494\tvalid_1's rmse: 3.80398\n",
      "[2500]\ttraining's rmse: 3.48809\tvalid_1's rmse: 3.8012\n",
      "[3000]\ttraining's rmse: 3.46284\tvalid_1's rmse: 3.79969\n",
      "[3500]\ttraining's rmse: 3.43948\tvalid_1's rmse: 3.79849\n",
      "[4000]\ttraining's rmse: 3.41658\tvalid_1's rmse: 3.79777\n",
      "Early stopping, best iteration is:\n",
      "[3843]\ttraining's rmse: 3.4235\tvalid_1's rmse: 3.79769\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67972\tvalid_1's rmse: 3.66528\n",
      "[1000]\ttraining's rmse: 3.6216\tvalid_1's rmse: 3.64386\n",
      "[1500]\ttraining's rmse: 3.58446\tvalid_1's rmse: 3.63556\n",
      "[2000]\ttraining's rmse: 3.5553\tvalid_1's rmse: 3.63268\n",
      "[2500]\ttraining's rmse: 3.52917\tvalid_1's rmse: 3.6309\n",
      "[3000]\ttraining's rmse: 3.50415\tvalid_1's rmse: 3.63004\n",
      "[3500]\ttraining's rmse: 3.48118\tvalid_1's rmse: 3.62933\n",
      "Early stopping, best iteration is:\n",
      "[3637]\ttraining's rmse: 3.47512\tvalid_1's rmse: 3.62908\n",
      "   22 | 03m03s |   -3.67062 |             0.6177 |         3.6201 |             0.9516 |             0.1508 |      7.7788 |              7.5401 |            31.9310 |            99.3888 |           0.4883 |      36.4193 |      9.0619 |       0.6199 |      0.1558 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64074\tvalid_1's rmse: 3.72122\n",
      "[1000]\ttraining's rmse: 3.57929\tvalid_1's rmse: 3.6981\n",
      "[1500]\ttraining's rmse: 3.53965\tvalid_1's rmse: 3.6909\n",
      "[2000]\ttraining's rmse: 3.50453\tvalid_1's rmse: 3.68736\n",
      "[2500]\ttraining's rmse: 3.47314\tvalid_1's rmse: 3.68562\n",
      "Early stopping, best iteration is:\n",
      "[2747]\ttraining's rmse: 3.4584\tvalid_1's rmse: 3.68498\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6552\tvalid_1's rmse: 3.66081\n",
      "[1000]\ttraining's rmse: 3.59238\tvalid_1's rmse: 3.64056\n",
      "[1500]\ttraining's rmse: 3.55238\tvalid_1's rmse: 3.63346\n",
      "[2000]\ttraining's rmse: 3.51818\tvalid_1's rmse: 3.6294\n",
      "[2500]\ttraining's rmse: 3.48723\tvalid_1's rmse: 3.62698\n",
      "Early stopping, best iteration is:\n",
      "[2581]\ttraining's rmse: 3.48238\tvalid_1's rmse: 3.6268\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65942\tvalid_1's rmse: 3.63731\n",
      "[1000]\ttraining's rmse: 3.59709\tvalid_1's rmse: 3.61694\n",
      "[1500]\ttraining's rmse: 3.55755\tvalid_1's rmse: 3.61117\n",
      "[2000]\ttraining's rmse: 3.52295\tvalid_1's rmse: 3.60812\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's rmse: 3.50527\tvalid_1's rmse: 3.6073\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61387\tvalid_1's rmse: 3.82561\n",
      "[1000]\ttraining's rmse: 3.55205\tvalid_1's rmse: 3.80553\n",
      "[1500]\ttraining's rmse: 3.51177\tvalid_1's rmse: 3.80003\n",
      "[2000]\ttraining's rmse: 3.47671\tvalid_1's rmse: 3.79746\n",
      "[2500]\ttraining's rmse: 3.44578\tvalid_1's rmse: 3.79587\n",
      "[3000]\ttraining's rmse: 3.41713\tvalid_1's rmse: 3.79494\n",
      "[3500]\ttraining's rmse: 3.38835\tvalid_1's rmse: 3.79436\n",
      "Early stopping, best iteration is:\n",
      "[3522]\ttraining's rmse: 3.38712\tvalid_1's rmse: 3.79423\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65347\tvalid_1's rmse: 3.6561\n",
      "[1000]\ttraining's rmse: 3.59213\tvalid_1's rmse: 3.63698\n",
      "[1500]\ttraining's rmse: 3.5509\tvalid_1's rmse: 3.63156\n",
      "[2000]\ttraining's rmse: 3.51752\tvalid_1's rmse: 3.62814\n",
      "[2500]\ttraining's rmse: 3.486\tvalid_1's rmse: 3.62706\n",
      "Early stopping, best iteration is:\n",
      "[2696]\ttraining's rmse: 3.47521\tvalid_1's rmse: 3.62646\n",
      "   23 | 02m15s |   -3.66859 |             0.5740 |        19.7463 |             0.9277 |             0.2997 |     14.6794 |             17.4053 |            32.9399 |            91.5441 |           0.9402 |      30.1900 |      9.3028 |       9.0332 |      0.6977 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66369\tvalid_1's rmse: 3.73998\n",
      "[1000]\ttraining's rmse: 3.60419\tvalid_1's rmse: 3.71551\n",
      "[1500]\ttraining's rmse: 3.56192\tvalid_1's rmse: 3.70563\n",
      "[2000]\ttraining's rmse: 3.52741\tvalid_1's rmse: 3.70153\n",
      "[2500]\ttraining's rmse: 3.4969\tvalid_1's rmse: 3.69852\n",
      "Early stopping, best iteration is:\n",
      "[2460]\ttraining's rmse: 3.49938\tvalid_1's rmse: 3.69847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6776\tvalid_1's rmse: 3.67354\n",
      "[1000]\ttraining's rmse: 3.61581\tvalid_1's rmse: 3.64998\n",
      "[1500]\ttraining's rmse: 3.57519\tvalid_1's rmse: 3.64133\n",
      "[2000]\ttraining's rmse: 3.54162\tvalid_1's rmse: 3.63792\n",
      "[2500]\ttraining's rmse: 3.50982\tvalid_1's rmse: 3.63505\n",
      "[3000]\ttraining's rmse: 3.48069\tvalid_1's rmse: 3.63312\n",
      "Early stopping, best iteration is:\n",
      "[3089]\ttraining's rmse: 3.47577\tvalid_1's rmse: 3.63289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68237\tvalid_1's rmse: 3.6487\n",
      "[1000]\ttraining's rmse: 3.62057\tvalid_1's rmse: 3.62799\n",
      "[1500]\ttraining's rmse: 3.5807\tvalid_1's rmse: 3.62101\n",
      "[2000]\ttraining's rmse: 3.54607\tvalid_1's rmse: 3.61963\n",
      "[2500]\ttraining's rmse: 3.51421\tvalid_1's rmse: 3.61848\n",
      "Early stopping, best iteration is:\n",
      "[2306]\ttraining's rmse: 3.52694\tvalid_1's rmse: 3.61833\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63576\tvalid_1's rmse: 3.84683\n",
      "[1000]\ttraining's rmse: 3.57572\tvalid_1's rmse: 3.82252\n",
      "[1500]\ttraining's rmse: 3.53413\tvalid_1's rmse: 3.81503\n",
      "[2000]\ttraining's rmse: 3.49971\tvalid_1's rmse: 3.81141\n",
      "[2500]\ttraining's rmse: 3.46729\tvalid_1's rmse: 3.80939\n",
      "[3000]\ttraining's rmse: 3.43711\tvalid_1's rmse: 3.80797\n",
      "Early stopping, best iteration is:\n",
      "[2847]\ttraining's rmse: 3.44604\tvalid_1's rmse: 3.80767\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67711\tvalid_1's rmse: 3.66824\n",
      "[1000]\ttraining's rmse: 3.61607\tvalid_1's rmse: 3.64943\n",
      "[1500]\ttraining's rmse: 3.57365\tvalid_1's rmse: 3.64253\n",
      "[2000]\ttraining's rmse: 3.5399\tvalid_1's rmse: 3.63943\n",
      "Early stopping, best iteration is:\n",
      "[2161]\ttraining's rmse: 3.52883\tvalid_1's rmse: 3.63872\n",
      "   24 | 01m39s |   -3.67988 |             0.2019 |        18.4979 |             0.9443 |             0.1767 |     10.6928 |             20.0024 |            38.8894 |            21.1210 |           0.5417 |      35.4925 |      1.8001 |       5.9948 |      0.9271 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62894\tvalid_1's rmse: 3.71024\n",
      "[1000]\ttraining's rmse: 3.57806\tvalid_1's rmse: 3.69192\n",
      "[1500]\ttraining's rmse: 3.54166\tvalid_1's rmse: 3.68648\n",
      "[2000]\ttraining's rmse: 3.51017\tvalid_1's rmse: 3.68467\n",
      "Early stopping, best iteration is:\n",
      "[2130]\ttraining's rmse: 3.50219\tvalid_1's rmse: 3.68422\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64162\tvalid_1's rmse: 3.65016\n",
      "[1000]\ttraining's rmse: 3.59018\tvalid_1's rmse: 3.63417\n",
      "[1500]\ttraining's rmse: 3.55116\tvalid_1's rmse: 3.62872\n",
      "[2000]\ttraining's rmse: 3.51882\tvalid_1's rmse: 3.62667\n",
      "Early stopping, best iteration is:\n",
      "[1921]\ttraining's rmse: 3.52356\tvalid_1's rmse: 3.62665\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6466\tvalid_1's rmse: 3.62684\n",
      "[1000]\ttraining's rmse: 3.5926\tvalid_1's rmse: 3.61149\n",
      "[1500]\ttraining's rmse: 3.55444\tvalid_1's rmse: 3.60889\n",
      "Early stopping, best iteration is:\n",
      "[1518]\ttraining's rmse: 3.55329\tvalid_1's rmse: 3.60869\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59905\tvalid_1's rmse: 3.81538\n",
      "[1000]\ttraining's rmse: 3.54864\tvalid_1's rmse: 3.80197\n",
      "[1500]\ttraining's rmse: 3.51159\tvalid_1's rmse: 3.79812\n",
      "[2000]\ttraining's rmse: 3.47988\tvalid_1's rmse: 3.79688\n",
      "[2500]\ttraining's rmse: 3.45052\tvalid_1's rmse: 3.79623\n",
      "Early stopping, best iteration is:\n",
      "[2443]\ttraining's rmse: 3.45346\tvalid_1's rmse: 3.796\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64176\tvalid_1's rmse: 3.64515\n",
      "[1000]\ttraining's rmse: 3.58677\tvalid_1's rmse: 3.631\n",
      "[1500]\ttraining's rmse: 3.5515\tvalid_1's rmse: 3.6266\n",
      "Early stopping, best iteration is:\n",
      "[1620]\ttraining's rmse: 3.54324\tvalid_1's rmse: 3.62626\n",
      "   25 | 02m19s |   -3.66901 |             0.5426 |        11.8493 |             0.6363 |             0.7294 |      7.8474 |             45.1948 |            38.4475 |            81.4404 |           0.1871 |      30.8930 |      1.9694 |       8.5325 |      0.9791 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60411\tvalid_1's rmse: 3.71055\n",
      "[1000]\ttraining's rmse: 3.53231\tvalid_1's rmse: 3.68987\n",
      "[1500]\ttraining's rmse: 3.48231\tvalid_1's rmse: 3.68375\n",
      "[2000]\ttraining's rmse: 3.43859\tvalid_1's rmse: 3.68171\n",
      "[2500]\ttraining's rmse: 3.39868\tvalid_1's rmse: 3.68045\n",
      "[3000]\ttraining's rmse: 3.36141\tvalid_1's rmse: 3.6796\n",
      "Early stopping, best iteration is:\n",
      "[3037]\ttraining's rmse: 3.35896\tvalid_1's rmse: 3.67946\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61814\tvalid_1's rmse: 3.65244\n",
      "[1000]\ttraining's rmse: 3.54575\tvalid_1's rmse: 3.63518\n",
      "[1500]\ttraining's rmse: 3.49561\tvalid_1's rmse: 3.63042\n",
      "[2000]\ttraining's rmse: 3.452\tvalid_1's rmse: 3.62756\n",
      "Early stopping, best iteration is:\n",
      "[2189]\ttraining's rmse: 3.43684\tvalid_1's rmse: 3.62708\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62274\tvalid_1's rmse: 3.62902\n",
      "[1000]\ttraining's rmse: 3.55003\tvalid_1's rmse: 3.61257\n",
      "[1500]\ttraining's rmse: 3.4987\tvalid_1's rmse: 3.60803\n",
      "[2000]\ttraining's rmse: 3.45477\tvalid_1's rmse: 3.60664\n",
      "Early stopping, best iteration is:\n",
      "[1808]\ttraining's rmse: 3.47071\tvalid_1's rmse: 3.6066\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57752\tvalid_1's rmse: 3.81383\n",
      "[1000]\ttraining's rmse: 3.50501\tvalid_1's rmse: 3.79813\n",
      "[1500]\ttraining's rmse: 3.4538\tvalid_1's rmse: 3.79289\n",
      "[2000]\ttraining's rmse: 3.41043\tvalid_1's rmse: 3.79229\n",
      "[2500]\ttraining's rmse: 3.37078\tvalid_1's rmse: 3.79081\n",
      "Early stopping, best iteration is:\n",
      "[2485]\ttraining's rmse: 3.37178\tvalid_1's rmse: 3.7907\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6178\tvalid_1's rmse: 3.6475\n",
      "[1000]\ttraining's rmse: 3.54402\tvalid_1's rmse: 3.63172\n",
      "[1500]\ttraining's rmse: 3.49373\tvalid_1's rmse: 3.62782\n",
      "[2000]\ttraining's rmse: 3.45005\tvalid_1's rmse: 3.6262\n",
      "Early stopping, best iteration is:\n",
      "[2069]\ttraining's rmse: 3.4441\tvalid_1's rmse: 3.62591\n",
      "   26 | 02m35s |   -3.66656 |             0.5599 |         5.4162 |             0.7803 |             0.5460 |     14.5694 |             47.9309 |            42.6290 |            60.3356 |           0.5707 |      33.3872 |      4.5975 |       1.7554 |      0.6349 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57901\tvalid_1's rmse: 3.70116\n",
      "[1000]\ttraining's rmse: 3.49875\tvalid_1's rmse: 3.68339\n",
      "[1500]\ttraining's rmse: 3.44256\tvalid_1's rmse: 3.68014\n",
      "[2000]\ttraining's rmse: 3.39432\tvalid_1's rmse: 3.6793\n",
      "Early stopping, best iteration is:\n",
      "[1948]\ttraining's rmse: 3.399\tvalid_1's rmse: 3.67892\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5901\tvalid_1's rmse: 3.64702\n",
      "[1000]\ttraining's rmse: 3.51215\tvalid_1's rmse: 3.63183\n",
      "[1500]\ttraining's rmse: 3.45478\tvalid_1's rmse: 3.62708\n",
      "Early stopping, best iteration is:\n",
      "[1782]\ttraining's rmse: 3.42582\tvalid_1's rmse: 3.62572\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59483\tvalid_1's rmse: 3.62292\n",
      "[1000]\ttraining's rmse: 3.51436\tvalid_1's rmse: 3.60821\n",
      "[1500]\ttraining's rmse: 3.4556\tvalid_1's rmse: 3.60557\n",
      "Early stopping, best iteration is:\n",
      "[1617]\ttraining's rmse: 3.44346\tvalid_1's rmse: 3.60518\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54949\tvalid_1's rmse: 3.8075\n",
      "[1000]\ttraining's rmse: 3.47131\tvalid_1's rmse: 3.79366\n",
      "[1500]\ttraining's rmse: 3.41501\tvalid_1's rmse: 3.79072\n",
      "Early stopping, best iteration is:\n",
      "[1623]\ttraining's rmse: 3.40266\tvalid_1's rmse: 3.79058\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58898\tvalid_1's rmse: 3.64183\n",
      "[1000]\ttraining's rmse: 3.50869\tvalid_1's rmse: 3.62883\n",
      "[1500]\ttraining's rmse: 3.45318\tvalid_1's rmse: 3.62652\n",
      "Early stopping, best iteration is:\n",
      "[1716]\ttraining's rmse: 3.43152\tvalid_1's rmse: 3.62614\n",
      "   27 | 03m27s |   -3.66592 |             0.7887 |         7.8525 |             0.3562 |             0.8828 |     11.8181 |             15.7371 |            30.1472 |            92.2129 |           0.0127 |      44.3855 |      7.2354 |       5.5644 |      0.8498 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61807\tvalid_1's rmse: 3.71595\n",
      "[1000]\ttraining's rmse: 3.54678\tvalid_1's rmse: 3.69279\n",
      "[1500]\ttraining's rmse: 3.50036\tvalid_1's rmse: 3.68618\n",
      "[2000]\ttraining's rmse: 3.46043\tvalid_1's rmse: 3.68322\n",
      "[2500]\ttraining's rmse: 3.42599\tvalid_1's rmse: 3.68179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2685]\ttraining's rmse: 3.41425\tvalid_1's rmse: 3.68169\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63089\tvalid_1's rmse: 3.65555\n",
      "[1000]\ttraining's rmse: 3.55981\tvalid_1's rmse: 3.63579\n",
      "[1500]\ttraining's rmse: 3.5128\tvalid_1's rmse: 3.62888\n",
      "[2000]\ttraining's rmse: 3.47316\tvalid_1's rmse: 3.62643\n",
      "[2500]\ttraining's rmse: 3.43827\tvalid_1's rmse: 3.62521\n",
      "[3000]\ttraining's rmse: 3.40606\tvalid_1's rmse: 3.62466\n",
      "[3500]\ttraining's rmse: 3.37418\tvalid_1's rmse: 3.62417\n",
      "Early stopping, best iteration is:\n",
      "[3682]\ttraining's rmse: 3.36308\tvalid_1's rmse: 3.62364\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63563\tvalid_1's rmse: 3.63124\n",
      "[1000]\ttraining's rmse: 3.56517\tvalid_1's rmse: 3.61237\n",
      "[1500]\ttraining's rmse: 3.51741\tvalid_1's rmse: 3.6073\n",
      "[2000]\ttraining's rmse: 3.47804\tvalid_1's rmse: 3.60523\n",
      "Early stopping, best iteration is:\n",
      "[2101]\ttraining's rmse: 3.47082\tvalid_1's rmse: 3.60498\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59017\tvalid_1's rmse: 3.8201\n",
      "[1000]\ttraining's rmse: 3.52037\tvalid_1's rmse: 3.80074\n",
      "[1500]\ttraining's rmse: 3.47348\tvalid_1's rmse: 3.79477\n",
      "[2000]\ttraining's rmse: 3.4341\tvalid_1's rmse: 3.79284\n",
      "Early stopping, best iteration is:\n",
      "[1955]\ttraining's rmse: 3.43723\tvalid_1's rmse: 3.79272\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63093\tvalid_1's rmse: 3.65193\n",
      "[1000]\ttraining's rmse: 3.55855\tvalid_1's rmse: 3.63354\n",
      "[1500]\ttraining's rmse: 3.51093\tvalid_1's rmse: 3.62792\n",
      "[2000]\ttraining's rmse: 3.47127\tvalid_1's rmse: 3.62505\n",
      "[2500]\ttraining's rmse: 3.43588\tvalid_1's rmse: 3.62425\n",
      "Early stopping, best iteration is:\n",
      "[2767]\ttraining's rmse: 3.41848\tvalid_1's rmse: 3.62375\n",
      "   28 | 02m35s |   -3.66600 |             0.7798 |        14.1163 |             0.4232 |             0.3705 |     13.5038 |             41.9817 |            33.8135 |            76.3025 |           0.6157 |      32.0038 |      0.6324 |       4.5522 |      0.2562 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65971\tvalid_1's rmse: 3.71914\n",
      "[1000]\ttraining's rmse: 3.62503\tvalid_1's rmse: 3.70048\n",
      "[1500]\ttraining's rmse: 3.60229\tvalid_1's rmse: 3.69371\n",
      "[2000]\ttraining's rmse: 3.58391\tvalid_1's rmse: 3.69178\n",
      "[2500]\ttraining's rmse: 3.56744\tvalid_1's rmse: 3.68976\n",
      "[3000]\ttraining's rmse: 3.55107\tvalid_1's rmse: 3.68924\n",
      "[3500]\ttraining's rmse: 3.53671\tvalid_1's rmse: 3.68778\n",
      "Early stopping, best iteration is:\n",
      "[3309]\ttraining's rmse: 3.54202\tvalid_1's rmse: 3.68743\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67355\tvalid_1's rmse: 3.65734\n",
      "[1000]\ttraining's rmse: 3.63899\tvalid_1's rmse: 3.64301\n",
      "[1500]\ttraining's rmse: 3.61576\tvalid_1's rmse: 3.63587\n",
      "[2000]\ttraining's rmse: 3.59737\tvalid_1's rmse: 3.63311\n",
      "[2500]\ttraining's rmse: 3.5815\tvalid_1's rmse: 3.63083\n",
      "[3000]\ttraining's rmse: 3.56622\tvalid_1's rmse: 3.63002\n",
      "[3500]\ttraining's rmse: 3.55139\tvalid_1's rmse: 3.6289\n",
      "[4000]\ttraining's rmse: 3.5386\tvalid_1's rmse: 3.62877\n",
      "Early stopping, best iteration is:\n",
      "[3801]\ttraining's rmse: 3.54422\tvalid_1's rmse: 3.62825\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6796\tvalid_1's rmse: 3.63086\n",
      "[1000]\ttraining's rmse: 3.64407\tvalid_1's rmse: 3.61638\n",
      "[1500]\ttraining's rmse: 3.62122\tvalid_1's rmse: 3.61237\n",
      "Early stopping, best iteration is:\n",
      "[1722]\ttraining's rmse: 3.61194\tvalid_1's rmse: 3.61182\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63205\tvalid_1's rmse: 3.82386\n",
      "[1000]\ttraining's rmse: 3.59543\tvalid_1's rmse: 3.81012\n",
      "[1500]\ttraining's rmse: 3.57276\tvalid_1's rmse: 3.80545\n",
      "[2000]\ttraining's rmse: 3.55502\tvalid_1's rmse: 3.80274\n",
      "[2500]\ttraining's rmse: 3.53733\tvalid_1's rmse: 3.8014\n",
      "Early stopping, best iteration is:\n",
      "[2527]\ttraining's rmse: 3.53651\tvalid_1's rmse: 3.80112\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67508\tvalid_1's rmse: 3.64952\n",
      "[1000]\ttraining's rmse: 3.6381\tvalid_1's rmse: 3.63354\n",
      "[1500]\ttraining's rmse: 3.61673\tvalid_1's rmse: 3.62949\n",
      "[2000]\ttraining's rmse: 3.59969\tvalid_1's rmse: 3.6275\n",
      "[2500]\ttraining's rmse: 3.58166\tvalid_1's rmse: 3.62592\n",
      "Early stopping, best iteration is:\n",
      "[2401]\ttraining's rmse: 3.58505\tvalid_1's rmse: 3.62566\n",
      "   29 | 02m16s |   -3.67153 |             0.3807 |         7.9037 |             0.8493 |             0.8915 |      5.6029 |              7.1970 |            44.1478 |            97.6788 |           0.8153 |      30.0460 |      3.9937 |       5.1002 |      0.7406 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65913\tvalid_1's rmse: 3.74573\n",
      "[1000]\ttraining's rmse: 3.58345\tvalid_1's rmse: 3.71561\n",
      "[1500]\ttraining's rmse: 3.5319\tvalid_1's rmse: 3.70302\n",
      "[2000]\ttraining's rmse: 3.4917\tvalid_1's rmse: 3.69638\n",
      "[2500]\ttraining's rmse: 3.45777\tvalid_1's rmse: 3.69266\n",
      "[3000]\ttraining's rmse: 3.42641\tvalid_1's rmse: 3.69007\n",
      "[3500]\ttraining's rmse: 3.39848\tvalid_1's rmse: 3.68842\n",
      "[4000]\ttraining's rmse: 3.37223\tvalid_1's rmse: 3.6876\n",
      "[4500]\ttraining's rmse: 3.34838\tvalid_1's rmse: 3.68718\n",
      "Early stopping, best iteration is:\n",
      "[4342]\ttraining's rmse: 3.3557\tvalid_1's rmse: 3.68711\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67354\tvalid_1's rmse: 3.68119\n",
      "[1000]\ttraining's rmse: 3.59616\tvalid_1's rmse: 3.65563\n",
      "[1500]\ttraining's rmse: 3.54382\tvalid_1's rmse: 3.64468\n",
      "[2000]\ttraining's rmse: 3.50281\tvalid_1's rmse: 3.63921\n",
      "[2500]\ttraining's rmse: 3.46851\tvalid_1's rmse: 3.63613\n",
      "[3000]\ttraining's rmse: 3.43706\tvalid_1's rmse: 3.63388\n",
      "[3500]\ttraining's rmse: 3.40929\tvalid_1's rmse: 3.63235\n",
      "[4000]\ttraining's rmse: 3.38336\tvalid_1's rmse: 3.63128\n",
      "[4500]\ttraining's rmse: 3.35911\tvalid_1's rmse: 3.63048\n",
      "[5000]\ttraining's rmse: 3.33608\tvalid_1's rmse: 3.62985\n",
      "[5500]\ttraining's rmse: 3.31408\tvalid_1's rmse: 3.62961\n",
      "[6000]\ttraining's rmse: 3.2923\tvalid_1's rmse: 3.62916\n",
      "Early stopping, best iteration is:\n",
      "[5940]\ttraining's rmse: 3.29457\tvalid_1's rmse: 3.62911\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67842\tvalid_1's rmse: 3.65518\n",
      "[1000]\ttraining's rmse: 3.60139\tvalid_1's rmse: 3.63111\n",
      "[1500]\ttraining's rmse: 3.54952\tvalid_1's rmse: 3.6207\n",
      "[2000]\ttraining's rmse: 3.50887\tvalid_1's rmse: 3.61589\n",
      "[2500]\ttraining's rmse: 3.47456\tvalid_1's rmse: 3.61326\n",
      "[3000]\ttraining's rmse: 3.44336\tvalid_1's rmse: 3.61158\n",
      "[3500]\ttraining's rmse: 3.41608\tvalid_1's rmse: 3.61039\n",
      "[4000]\ttraining's rmse: 3.39008\tvalid_1's rmse: 3.60967\n",
      "Early stopping, best iteration is:\n",
      "[4288]\ttraining's rmse: 3.37598\tvalid_1's rmse: 3.60929\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63\tvalid_1's rmse: 3.85356\n",
      "[1000]\ttraining's rmse: 3.55384\tvalid_1's rmse: 3.82499\n",
      "[1500]\ttraining's rmse: 3.50153\tvalid_1's rmse: 3.81268\n",
      "[2000]\ttraining's rmse: 3.46174\tvalid_1's rmse: 3.80704\n",
      "[2500]\ttraining's rmse: 3.4284\tvalid_1's rmse: 3.80412\n",
      "[3000]\ttraining's rmse: 3.39836\tvalid_1's rmse: 3.80147\n",
      "[3500]\ttraining's rmse: 3.371\tvalid_1's rmse: 3.79991\n",
      "[4000]\ttraining's rmse: 3.34609\tvalid_1's rmse: 3.79883\n",
      "[4500]\ttraining's rmse: 3.32268\tvalid_1's rmse: 3.79816\n",
      "[5000]\ttraining's rmse: 3.30011\tvalid_1's rmse: 3.79772\n",
      "[5500]\ttraining's rmse: 3.27878\tvalid_1's rmse: 3.79738\n",
      "[6000]\ttraining's rmse: 3.25767\tvalid_1's rmse: 3.79704\n",
      "Early stopping, best iteration is:\n",
      "[6198]\ttraining's rmse: 3.2499\tvalid_1's rmse: 3.79698\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67234\tvalid_1's rmse: 3.6751\n",
      "[1000]\ttraining's rmse: 3.59455\tvalid_1's rmse: 3.65213\n",
      "[1500]\ttraining's rmse: 3.54298\tvalid_1's rmse: 3.64255\n",
      "[2000]\ttraining's rmse: 3.50236\tvalid_1's rmse: 3.63786\n",
      "[2500]\ttraining's rmse: 3.4676\tvalid_1's rmse: 3.63507\n",
      "[3000]\ttraining's rmse: 3.43683\tvalid_1's rmse: 3.63312\n",
      "[3500]\ttraining's rmse: 3.40914\tvalid_1's rmse: 3.63194\n",
      "[4000]\ttraining's rmse: 3.38411\tvalid_1's rmse: 3.63131\n",
      "Early stopping, best iteration is:\n",
      "[4270]\ttraining's rmse: 3.37087\tvalid_1's rmse: 3.63104\n",
      "   30 | 02m58s |   -3.67134 |             0.9470 |         0.7204 |             0.6458 |             0.1128 |     13.0854 |              7.0720 |            38.1921 |            61.3309 |           0.5058 |      35.4246 |      7.5330 |       4.3595 |      0.9030 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66656\tvalid_1's rmse: 3.74014\n",
      "[1000]\ttraining's rmse: 3.60371\tvalid_1's rmse: 3.71153\n",
      "[1500]\ttraining's rmse: 3.56143\tvalid_1's rmse: 3.70091\n",
      "[2000]\ttraining's rmse: 3.52665\tvalid_1's rmse: 3.69536\n",
      "[2500]\ttraining's rmse: 3.49472\tvalid_1's rmse: 3.69294\n",
      "[3000]\ttraining's rmse: 3.4655\tvalid_1's rmse: 3.69124\n",
      "[3500]\ttraining's rmse: 3.43753\tvalid_1's rmse: 3.69059\n",
      "Early stopping, best iteration is:\n",
      "[3623]\ttraining's rmse: 3.43067\tvalid_1's rmse: 3.68998\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68254\tvalid_1's rmse: 3.67719\n",
      "[1000]\ttraining's rmse: 3.61832\tvalid_1's rmse: 3.65296\n",
      "[1500]\ttraining's rmse: 3.57528\tvalid_1's rmse: 3.6428\n",
      "[2000]\ttraining's rmse: 3.53942\tvalid_1's rmse: 3.63739\n",
      "[2500]\ttraining's rmse: 3.50731\tvalid_1's rmse: 3.63429\n",
      "[3000]\ttraining's rmse: 3.47865\tvalid_1's rmse: 3.63278\n",
      "[3500]\ttraining's rmse: 3.45037\tvalid_1's rmse: 3.63228\n",
      "[4000]\ttraining's rmse: 3.42349\tvalid_1's rmse: 3.63131\n",
      "Early stopping, best iteration is:\n",
      "[4025]\ttraining's rmse: 3.42227\tvalid_1's rmse: 3.63126\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6868\tvalid_1's rmse: 3.65164\n",
      "[1000]\ttraining's rmse: 3.62303\tvalid_1's rmse: 3.62811\n",
      "[1500]\ttraining's rmse: 3.57985\tvalid_1's rmse: 3.61974\n",
      "[2000]\ttraining's rmse: 3.54412\tvalid_1's rmse: 3.61501\n",
      "[2500]\ttraining's rmse: 3.51273\tvalid_1's rmse: 3.61305\n",
      "[3000]\ttraining's rmse: 3.48365\tvalid_1's rmse: 3.61194\n",
      "Early stopping, best iteration is:\n",
      "[3020]\ttraining's rmse: 3.48249\tvalid_1's rmse: 3.61178\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63751\tvalid_1's rmse: 3.84919\n",
      "[1000]\ttraining's rmse: 3.57497\tvalid_1's rmse: 3.82316\n",
      "[1500]\ttraining's rmse: 3.53195\tvalid_1's rmse: 3.81325\n",
      "[2000]\ttraining's rmse: 3.49698\tvalid_1's rmse: 3.80876\n",
      "[2500]\ttraining's rmse: 3.46553\tvalid_1's rmse: 3.80629\n",
      "[3000]\ttraining's rmse: 3.4367\tvalid_1's rmse: 3.80465\n",
      "[3500]\ttraining's rmse: 3.4093\tvalid_1's rmse: 3.80333\n",
      "[4000]\ttraining's rmse: 3.38294\tvalid_1's rmse: 3.80279\n",
      "Early stopping, best iteration is:\n",
      "[4039]\ttraining's rmse: 3.38093\tvalid_1's rmse: 3.80273\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68161\tvalid_1's rmse: 3.66894\n",
      "[1000]\ttraining's rmse: 3.6168\tvalid_1's rmse: 3.64734\n",
      "[1500]\ttraining's rmse: 3.57406\tvalid_1's rmse: 3.63882\n",
      "[2000]\ttraining's rmse: 3.53858\tvalid_1's rmse: 3.6348\n",
      "[2500]\ttraining's rmse: 3.50632\tvalid_1's rmse: 3.6329\n",
      "[3000]\ttraining's rmse: 3.47723\tvalid_1's rmse: 3.63185\n",
      "[3500]\ttraining's rmse: 3.44894\tvalid_1's rmse: 3.63128\n",
      "Early stopping, best iteration is:\n",
      "[3520]\ttraining's rmse: 3.44777\tvalid_1's rmse: 3.63118\n",
      "   31 | 02m32s |   -3.67405 |             0.4402 |         3.2839 |             0.8242 |             0.1325 |     11.4496 |              8.1113 |            35.7680 |            84.5282 |           0.2582 |      38.1951 |      6.7941 |       9.6290 |      0.1199 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6209\tvalid_1's rmse: 3.70718\n",
      "[1000]\ttraining's rmse: 3.57281\tvalid_1's rmse: 3.68934\n",
      "[1500]\ttraining's rmse: 3.53759\tvalid_1's rmse: 3.68474\n",
      "[2000]\ttraining's rmse: 3.50837\tvalid_1's rmse: 3.68374\n",
      "[2500]\ttraining's rmse: 3.48404\tvalid_1's rmse: 3.68274\n",
      "Early stopping, best iteration is:\n",
      "[2400]\ttraining's rmse: 3.4881\tvalid_1's rmse: 3.68262\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63406\tvalid_1's rmse: 3.64841\n",
      "[1000]\ttraining's rmse: 3.58387\tvalid_1's rmse: 3.63402\n",
      "[1500]\ttraining's rmse: 3.54984\tvalid_1's rmse: 3.62983\n",
      "[2000]\ttraining's rmse: 3.52108\tvalid_1's rmse: 3.62867\n",
      "[2500]\ttraining's rmse: 3.49396\tvalid_1's rmse: 3.62774\n",
      "[3000]\ttraining's rmse: 3.46674\tvalid_1's rmse: 3.62752\n",
      "Early stopping, best iteration is:\n",
      "[2920]\ttraining's rmse: 3.47044\tvalid_1's rmse: 3.62716\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63791\tvalid_1's rmse: 3.62293\n",
      "[1000]\ttraining's rmse: 3.58538\tvalid_1's rmse: 3.60864\n",
      "[1500]\ttraining's rmse: 3.54916\tvalid_1's rmse: 3.60672\n",
      "[2000]\ttraining's rmse: 3.51826\tvalid_1's rmse: 3.606\n",
      "Early stopping, best iteration is:\n",
      "[1950]\ttraining's rmse: 3.52099\tvalid_1's rmse: 3.60587\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59194\tvalid_1's rmse: 3.81031\n",
      "[1000]\ttraining's rmse: 3.53976\tvalid_1's rmse: 3.79523\n",
      "[1500]\ttraining's rmse: 3.50553\tvalid_1's rmse: 3.79238\n",
      "[2000]\ttraining's rmse: 3.47692\tvalid_1's rmse: 3.79099\n",
      "[2500]\ttraining's rmse: 3.45076\tvalid_1's rmse: 3.79033\n",
      "Early stopping, best iteration is:\n",
      "[2341]\ttraining's rmse: 3.4591\tvalid_1's rmse: 3.78997\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63599\tvalid_1's rmse: 3.64052\n",
      "[1000]\ttraining's rmse: 3.58284\tvalid_1's rmse: 3.62699\n",
      "[1500]\ttraining's rmse: 3.54841\tvalid_1's rmse: 3.62264\n",
      "Early stopping, best iteration is:\n",
      "[1787]\ttraining's rmse: 3.53098\tvalid_1's rmse: 3.62135\n",
      "   32 | 03m40s |   -3.66601 |             0.8709 |        10.5855 |             0.6804 |             0.8583 |      6.6847 |             40.6668 |            33.5611 |            91.2234 |           0.8826 |      42.6809 |      4.8069 |       9.9159 |      0.2750 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63303\tvalid_1's rmse: 3.72554\n",
      "[1000]\ttraining's rmse: 3.56224\tvalid_1's rmse: 3.70036\n",
      "[1500]\ttraining's rmse: 3.51435\tvalid_1's rmse: 3.69226\n",
      "[2000]\ttraining's rmse: 3.47354\tvalid_1's rmse: 3.68825\n",
      "[2500]\ttraining's rmse: 3.43788\tvalid_1's rmse: 3.68663\n",
      "[3000]\ttraining's rmse: 3.40476\tvalid_1's rmse: 3.68544\n",
      "Early stopping, best iteration is:\n",
      "[3100]\ttraining's rmse: 3.39752\tvalid_1's rmse: 3.68496\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64722\tvalid_1's rmse: 3.66473\n",
      "[1000]\ttraining's rmse: 3.57498\tvalid_1's rmse: 3.64301\n",
      "[1500]\ttraining's rmse: 3.52692\tvalid_1's rmse: 3.63577\n",
      "[2000]\ttraining's rmse: 3.48686\tvalid_1's rmse: 3.63303\n",
      "[2500]\ttraining's rmse: 3.44979\tvalid_1's rmse: 3.63082\n",
      "[3000]\ttraining's rmse: 3.41509\tvalid_1's rmse: 3.62927\n",
      "[3500]\ttraining's rmse: 3.38145\tvalid_1's rmse: 3.62853\n",
      "Early stopping, best iteration is:\n",
      "[3432]\ttraining's rmse: 3.3856\tvalid_1's rmse: 3.62833\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65172\tvalid_1's rmse: 3.64026\n",
      "[1000]\ttraining's rmse: 3.57884\tvalid_1's rmse: 3.6203\n",
      "[1500]\ttraining's rmse: 3.5306\tvalid_1's rmse: 3.61343\n",
      "[2000]\ttraining's rmse: 3.4898\tvalid_1's rmse: 3.6112\n",
      "[2500]\ttraining's rmse: 3.45309\tvalid_1's rmse: 3.61038\n",
      "[3000]\ttraining's rmse: 3.41893\tvalid_1's rmse: 3.61015\n",
      "Early stopping, best iteration is:\n",
      "[2931]\ttraining's rmse: 3.42361\tvalid_1's rmse: 3.60987\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60533\tvalid_1's rmse: 3.83297\n",
      "[1000]\ttraining's rmse: 3.53398\tvalid_1's rmse: 3.8106\n",
      "[1500]\ttraining's rmse: 3.48459\tvalid_1's rmse: 3.80306\n",
      "[2000]\ttraining's rmse: 3.44415\tvalid_1's rmse: 3.7999\n",
      "[2500]\ttraining's rmse: 3.40704\tvalid_1's rmse: 3.79721\n",
      "[3000]\ttraining's rmse: 3.37311\tvalid_1's rmse: 3.79632\n",
      "[3500]\ttraining's rmse: 3.34126\tvalid_1's rmse: 3.79557\n",
      "Early stopping, best iteration is:\n",
      "[3620]\ttraining's rmse: 3.33388\tvalid_1's rmse: 3.79523\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64685\tvalid_1's rmse: 3.65924\n",
      "[1000]\ttraining's rmse: 3.57338\tvalid_1's rmse: 3.64005\n",
      "[1500]\ttraining's rmse: 3.52443\tvalid_1's rmse: 3.63337\n",
      "[2000]\ttraining's rmse: 3.48463\tvalid_1's rmse: 3.6299\n",
      "[2500]\ttraining's rmse: 3.44813\tvalid_1's rmse: 3.62906\n",
      "Early stopping, best iteration is:\n",
      "[2437]\ttraining's rmse: 3.45245\tvalid_1's rmse: 3.62898\n",
      "   33 | 02m29s |   -3.67010 |             0.6411 |        16.1041 |             0.4511 |             0.2031 |     11.1668 |             29.7210 |            44.4012 |            71.9968 |           0.7681 |      38.6527 |      2.6352 |       4.8250 |      0.1188 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68657\tvalid_1's rmse: 3.74147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.65053\tvalid_1's rmse: 3.72157\n",
      "[1500]\ttraining's rmse: 3.62664\tvalid_1's rmse: 3.71408\n",
      "[2000]\ttraining's rmse: 3.60404\tvalid_1's rmse: 3.70832\n",
      "Early stopping, best iteration is:\n",
      "[2184]\ttraining's rmse: 3.59701\tvalid_1's rmse: 3.70762\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70115\tvalid_1's rmse: 3.67413\n",
      "[1000]\ttraining's rmse: 3.66287\tvalid_1's rmse: 3.65782\n",
      "[1500]\ttraining's rmse: 3.63871\tvalid_1's rmse: 3.65093\n",
      "[2000]\ttraining's rmse: 3.61827\tvalid_1's rmse: 3.64921\n",
      "Early stopping, best iteration is:\n",
      "[1824]\ttraining's rmse: 3.62441\tvalid_1's rmse: 3.64788\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70972\tvalid_1's rmse: 3.65238\n",
      "[1000]\ttraining's rmse: 3.66897\tvalid_1's rmse: 3.63683\n",
      "[1500]\ttraining's rmse: 3.64489\tvalid_1's rmse: 3.63397\n",
      "[2000]\ttraining's rmse: 3.6241\tvalid_1's rmse: 3.63199\n",
      "Early stopping, best iteration is:\n",
      "[1832]\ttraining's rmse: 3.63074\tvalid_1's rmse: 3.63149\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65789\tvalid_1's rmse: 3.84756\n",
      "[1000]\ttraining's rmse: 3.62089\tvalid_1's rmse: 3.83179\n",
      "[1500]\ttraining's rmse: 3.59698\tvalid_1's rmse: 3.82636\n",
      "[2000]\ttraining's rmse: 3.57409\tvalid_1's rmse: 3.82278\n",
      "Early stopping, best iteration is:\n",
      "[2010]\ttraining's rmse: 3.57362\tvalid_1's rmse: 3.82256\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70367\tvalid_1's rmse: 3.66664\n",
      "[1000]\ttraining's rmse: 3.66656\tvalid_1's rmse: 3.65299\n",
      "[1500]\ttraining's rmse: 3.64063\tvalid_1's rmse: 3.64867\n",
      "[2000]\ttraining's rmse: 3.61904\tvalid_1's rmse: 3.64373\n",
      "Early stopping, best iteration is:\n",
      "[2272]\ttraining's rmse: 3.6069\tvalid_1's rmse: 3.64206\n",
      "   34 | 01m18s |   -3.69101 |             0.0534 |         8.7950 |             0.6937 |             0.3211 |      9.2009 |             40.2390 |            34.4275 |            48.4631 |           0.0351 |      33.6015 |      0.6608 |       2.3585 |      0.4826 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65397\tvalid_1's rmse: 3.71996\n",
      "[1000]\ttraining's rmse: 3.61113\tvalid_1's rmse: 3.6987\n",
      "[1500]\ttraining's rmse: 3.58202\tvalid_1's rmse: 3.69057\n",
      "[2000]\ttraining's rmse: 3.55777\tvalid_1's rmse: 3.68719\n",
      "[2500]\ttraining's rmse: 3.53652\tvalid_1's rmse: 3.68544\n",
      "[3000]\ttraining's rmse: 3.51643\tvalid_1's rmse: 3.68443\n",
      "Early stopping, best iteration is:\n",
      "[2943]\ttraining's rmse: 3.5186\tvalid_1's rmse: 3.68431\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66835\tvalid_1's rmse: 3.6608\n",
      "[1000]\ttraining's rmse: 3.62304\tvalid_1's rmse: 3.6415\n",
      "[1500]\ttraining's rmse: 3.59445\tvalid_1's rmse: 3.63457\n",
      "[2000]\ttraining's rmse: 3.57053\tvalid_1's rmse: 3.6311\n",
      "[2500]\ttraining's rmse: 3.54917\tvalid_1's rmse: 3.62858\n",
      "[3000]\ttraining's rmse: 3.52818\tvalid_1's rmse: 3.62744\n",
      "[3500]\ttraining's rmse: 3.50791\tvalid_1's rmse: 3.62653\n",
      "[4000]\ttraining's rmse: 3.49\tvalid_1's rmse: 3.62573\n",
      "[4500]\ttraining's rmse: 3.47215\tvalid_1's rmse: 3.62531\n",
      "[5000]\ttraining's rmse: 3.45404\tvalid_1's rmse: 3.62481\n",
      "Early stopping, best iteration is:\n",
      "[5030]\ttraining's rmse: 3.4528\tvalid_1's rmse: 3.62476\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67381\tvalid_1's rmse: 3.63241\n",
      "[1000]\ttraining's rmse: 3.62797\tvalid_1's rmse: 3.61319\n",
      "[1500]\ttraining's rmse: 3.59903\tvalid_1's rmse: 3.60773\n",
      "[2000]\ttraining's rmse: 3.57573\tvalid_1's rmse: 3.60587\n",
      "[2500]\ttraining's rmse: 3.55414\tvalid_1's rmse: 3.60484\n",
      "Early stopping, best iteration is:\n",
      "[2696]\ttraining's rmse: 3.5459\tvalid_1's rmse: 3.6043\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62643\tvalid_1's rmse: 3.825\n",
      "[1000]\ttraining's rmse: 3.58022\tvalid_1's rmse: 3.80604\n",
      "[1500]\ttraining's rmse: 3.55209\tvalid_1's rmse: 3.80037\n",
      "[2000]\ttraining's rmse: 3.529\tvalid_1's rmse: 3.79728\n",
      "[2500]\ttraining's rmse: 3.50671\tvalid_1's rmse: 3.79557\n",
      "[3000]\ttraining's rmse: 3.48501\tvalid_1's rmse: 3.79415\n",
      "[3500]\ttraining's rmse: 3.46514\tvalid_1's rmse: 3.79361\n",
      "[4000]\ttraining's rmse: 3.44578\tvalid_1's rmse: 3.79342\n",
      "Early stopping, best iteration is:\n",
      "[3891]\ttraining's rmse: 3.44957\tvalid_1's rmse: 3.79338\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66898\tvalid_1's rmse: 3.65195\n",
      "[1000]\ttraining's rmse: 3.62251\tvalid_1's rmse: 3.63306\n",
      "[1500]\ttraining's rmse: 3.59388\tvalid_1's rmse: 3.6268\n",
      "[2000]\ttraining's rmse: 3.56929\tvalid_1's rmse: 3.62382\n",
      "[2500]\ttraining's rmse: 3.54802\tvalid_1's rmse: 3.62289\n",
      "Early stopping, best iteration is:\n",
      "[2670]\ttraining's rmse: 3.54124\tvalid_1's rmse: 3.62251\n",
      "   35 | 03m06s |   -3.66651 |             0.8665 |         5.1958 |             0.9874 |             0.4126 |      5.8548 |             16.4260 |            41.9875 |            26.2373 |           0.6915 |      35.1863 |      0.7249 |       2.8023 |      0.6986 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61972\tvalid_1's rmse: 3.71312\n",
      "[1000]\ttraining's rmse: 3.55725\tvalid_1's rmse: 3.69357\n",
      "[1500]\ttraining's rmse: 3.51104\tvalid_1's rmse: 3.6876\n",
      "[2000]\ttraining's rmse: 3.47185\tvalid_1's rmse: 3.6843\n",
      "Early stopping, best iteration is:\n",
      "[1989]\ttraining's rmse: 3.47259\tvalid_1's rmse: 3.68417\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63148\tvalid_1's rmse: 3.65431\n",
      "[1000]\ttraining's rmse: 3.56609\tvalid_1's rmse: 3.63712\n",
      "[1500]\ttraining's rmse: 3.5218\tvalid_1's rmse: 3.6327\n",
      "[2000]\ttraining's rmse: 3.48261\tvalid_1's rmse: 3.63136\n",
      "[2500]\ttraining's rmse: 3.44626\tvalid_1's rmse: 3.62887\n",
      "Early stopping, best iteration is:\n",
      "[2669]\ttraining's rmse: 3.43457\tvalid_1's rmse: 3.62864\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6376\tvalid_1's rmse: 3.62978\n",
      "[1000]\ttraining's rmse: 3.57186\tvalid_1's rmse: 3.61368\n",
      "[1500]\ttraining's rmse: 3.52558\tvalid_1's rmse: 3.61002\n",
      "[2000]\ttraining's rmse: 3.48533\tvalid_1's rmse: 3.60811\n",
      "Early stopping, best iteration is:\n",
      "[2034]\ttraining's rmse: 3.4825\tvalid_1's rmse: 3.60788\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59045\tvalid_1's rmse: 3.81877\n",
      "[1000]\ttraining's rmse: 3.52532\tvalid_1's rmse: 3.80336\n",
      "[1500]\ttraining's rmse: 3.4796\tvalid_1's rmse: 3.79916\n",
      "[2000]\ttraining's rmse: 3.44195\tvalid_1's rmse: 3.79818\n",
      "[2500]\ttraining's rmse: 3.40541\tvalid_1's rmse: 3.79656\n",
      "Early stopping, best iteration is:\n",
      "[2687]\ttraining's rmse: 3.39149\tvalid_1's rmse: 3.79519\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63074\tvalid_1's rmse: 3.65014\n",
      "[1000]\ttraining's rmse: 3.56389\tvalid_1's rmse: 3.63556\n",
      "[1500]\ttraining's rmse: 3.5194\tvalid_1's rmse: 3.63158\n",
      "[2000]\ttraining's rmse: 3.47892\tvalid_1's rmse: 3.62958\n",
      "Early stopping, best iteration is:\n",
      "[1999]\ttraining's rmse: 3.47903\tvalid_1's rmse: 3.62955\n",
      "   36 | 02m09s |   -3.66972 |             0.3737 |        17.8118 |             0.6813 |             0.5277 |      8.9002 |             42.1649 |            36.1492 |            36.9262 |           0.6996 |      33.4518 |      0.8863 |       6.5304 |      0.6526 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.606\tvalid_1's rmse: 3.7108\n",
      "[1000]\ttraining's rmse: 3.54523\tvalid_1's rmse: 3.6911\n",
      "[1500]\ttraining's rmse: 3.50053\tvalid_1's rmse: 3.68669\n",
      "[2000]\ttraining's rmse: 3.46312\tvalid_1's rmse: 3.68483\n",
      "Early stopping, best iteration is:\n",
      "[2179]\ttraining's rmse: 3.44924\tvalid_1's rmse: 3.68425\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62033\tvalid_1's rmse: 3.65259\n",
      "[1000]\ttraining's rmse: 3.55648\tvalid_1's rmse: 3.63461\n",
      "[1500]\ttraining's rmse: 3.51173\tvalid_1's rmse: 3.63048\n",
      "[2000]\ttraining's rmse: 3.47273\tvalid_1's rmse: 3.6287\n",
      "Early stopping, best iteration is:\n",
      "[1824]\ttraining's rmse: 3.48608\tvalid_1's rmse: 3.62856\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62408\tvalid_1's rmse: 3.62833\n",
      "[1000]\ttraining's rmse: 3.55931\tvalid_1's rmse: 3.61192\n",
      "[1500]\ttraining's rmse: 3.5165\tvalid_1's rmse: 3.60826\n",
      "[2000]\ttraining's rmse: 3.47632\tvalid_1's rmse: 3.60732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1906]\ttraining's rmse: 3.48282\tvalid_1's rmse: 3.60679\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58123\tvalid_1's rmse: 3.8122\n",
      "[1000]\ttraining's rmse: 3.51652\tvalid_1's rmse: 3.79577\n",
      "[1500]\ttraining's rmse: 3.47226\tvalid_1's rmse: 3.79274\n",
      "Early stopping, best iteration is:\n",
      "[1454]\ttraining's rmse: 3.47628\tvalid_1's rmse: 3.79261\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61843\tvalid_1's rmse: 3.6443\n",
      "[1000]\ttraining's rmse: 3.55354\tvalid_1's rmse: 3.62993\n",
      "[1500]\ttraining's rmse: 3.50987\tvalid_1's rmse: 3.62506\n",
      "Early stopping, best iteration is:\n",
      "[1771]\ttraining's rmse: 3.48805\tvalid_1's rmse: 3.62431\n",
      "   37 | 02m55s |   -3.66793 |             0.8865 |        16.9529 |             0.1413 |             0.7843 |      7.2846 |              9.5609 |            42.1854 |            32.7484 |           0.6050 |      32.9459 |      2.2513 |       3.9613 |      0.2200 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56605\tvalid_1's rmse: 3.70574\n",
      "[1000]\ttraining's rmse: 3.4795\tvalid_1's rmse: 3.68912\n",
      "[1500]\ttraining's rmse: 3.41773\tvalid_1's rmse: 3.6858\n",
      "[2000]\ttraining's rmse: 3.36531\tvalid_1's rmse: 3.68444\n",
      "[2500]\ttraining's rmse: 3.31683\tvalid_1's rmse: 3.68394\n",
      "Early stopping, best iteration is:\n",
      "[2424]\ttraining's rmse: 3.32407\tvalid_1's rmse: 3.68367\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5773\tvalid_1's rmse: 3.64737\n",
      "[1000]\ttraining's rmse: 3.49013\tvalid_1's rmse: 3.63204\n",
      "[1500]\ttraining's rmse: 3.42876\tvalid_1's rmse: 3.62847\n",
      "[2000]\ttraining's rmse: 3.37671\tvalid_1's rmse: 3.62676\n",
      "Early stopping, best iteration is:\n",
      "[2143]\ttraining's rmse: 3.36302\tvalid_1's rmse: 3.62639\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58463\tvalid_1's rmse: 3.62278\n",
      "[1000]\ttraining's rmse: 3.49669\tvalid_1's rmse: 3.60998\n",
      "[1500]\ttraining's rmse: 3.43561\tvalid_1's rmse: 3.60768\n",
      "Early stopping, best iteration is:\n",
      "[1459]\ttraining's rmse: 3.43997\tvalid_1's rmse: 3.60736\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.53919\tvalid_1's rmse: 3.80759\n",
      "[1000]\ttraining's rmse: 3.45013\tvalid_1's rmse: 3.79339\n",
      "[1500]\ttraining's rmse: 3.38962\tvalid_1's rmse: 3.78943\n",
      "Early stopping, best iteration is:\n",
      "[1598]\ttraining's rmse: 3.37861\tvalid_1's rmse: 3.78927\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5779\tvalid_1's rmse: 3.64407\n",
      "[1000]\ttraining's rmse: 3.48986\tvalid_1's rmse: 3.63037\n",
      "[1500]\ttraining's rmse: 3.4295\tvalid_1's rmse: 3.62734\n",
      "Early stopping, best iteration is:\n",
      "[1670]\ttraining's rmse: 3.41028\tvalid_1's rmse: 3.62684\n",
      "   38 | 03m08s |   -3.66731 |             0.7329 |         8.5684 |             0.4151 |             0.8094 |     14.4532 |             34.9694 |            42.2510 |            61.1456 |           0.6247 |      41.6893 |      2.1252 |       0.1746 |      0.2624 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59051\tvalid_1's rmse: 3.70968\n",
      "[1000]\ttraining's rmse: 3.51437\tvalid_1's rmse: 3.69037\n",
      "[1500]\ttraining's rmse: 3.45997\tvalid_1's rmse: 3.68542\n",
      "[2000]\ttraining's rmse: 3.4116\tvalid_1's rmse: 3.68358\n",
      "Early stopping, best iteration is:\n",
      "[1889]\ttraining's rmse: 3.42195\tvalid_1's rmse: 3.68329\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60259\tvalid_1's rmse: 3.6533\n",
      "[1000]\ttraining's rmse: 3.52272\tvalid_1's rmse: 3.63496\n",
      "[1500]\ttraining's rmse: 3.4695\tvalid_1's rmse: 3.63079\n",
      "[2000]\ttraining's rmse: 3.42189\tvalid_1's rmse: 3.62861\n",
      "[2500]\ttraining's rmse: 3.3793\tvalid_1's rmse: 3.6268\n",
      "[3000]\ttraining's rmse: 3.33886\tvalid_1's rmse: 3.62606\n",
      "Early stopping, best iteration is:\n",
      "[3252]\ttraining's rmse: 3.31906\tvalid_1's rmse: 3.62556\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60874\tvalid_1's rmse: 3.62612\n",
      "[1000]\ttraining's rmse: 3.53099\tvalid_1's rmse: 3.61045\n",
      "[1500]\ttraining's rmse: 3.47658\tvalid_1's rmse: 3.60588\n",
      "[2000]\ttraining's rmse: 3.42989\tvalid_1's rmse: 3.60465\n",
      "Early stopping, best iteration is:\n",
      "[1885]\ttraining's rmse: 3.4405\tvalid_1's rmse: 3.60439\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56273\tvalid_1's rmse: 3.81071\n",
      "[1000]\ttraining's rmse: 3.48444\tvalid_1's rmse: 3.79588\n",
      "[1500]\ttraining's rmse: 3.42998\tvalid_1's rmse: 3.79201\n",
      "[2000]\ttraining's rmse: 3.38299\tvalid_1's rmse: 3.79061\n",
      "Early stopping, best iteration is:\n",
      "[1895]\ttraining's rmse: 3.39258\tvalid_1's rmse: 3.79024\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60217\tvalid_1's rmse: 3.647\n",
      "[1000]\ttraining's rmse: 3.5234\tvalid_1's rmse: 3.63217\n",
      "[1500]\ttraining's rmse: 3.46831\tvalid_1's rmse: 3.62837\n",
      "[2000]\ttraining's rmse: 3.42155\tvalid_1's rmse: 3.62716\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's rmse: 3.43372\tvalid_1's rmse: 3.62701\n",
      "   39 | 02m38s |   -3.66672 |             0.6081 |         8.2041 |             0.9052 |             0.6225 |     14.4163 |              5.9903 |            40.1884 |            52.0177 |           0.4020 |      34.1516 |      3.1737 |       0.3110 |      0.3542 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60151\tvalid_1's rmse: 3.71476\n",
      "[1000]\ttraining's rmse: 3.5225\tvalid_1's rmse: 3.69268\n",
      "[1500]\ttraining's rmse: 3.46804\tvalid_1's rmse: 3.68666\n",
      "[2000]\ttraining's rmse: 3.42145\tvalid_1's rmse: 3.68394\n",
      "Early stopping, best iteration is:\n",
      "[1998]\ttraining's rmse: 3.42161\tvalid_1's rmse: 3.68392\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61523\tvalid_1's rmse: 3.65478\n",
      "[1000]\ttraining's rmse: 3.53392\tvalid_1's rmse: 3.63426\n",
      "[1500]\ttraining's rmse: 3.47982\tvalid_1's rmse: 3.6278\n",
      "[2000]\ttraining's rmse: 3.43399\tvalid_1's rmse: 3.62539\n",
      "[2500]\ttraining's rmse: 3.39282\tvalid_1's rmse: 3.62467\n",
      "Early stopping, best iteration is:\n",
      "[2796]\ttraining's rmse: 3.36969\tvalid_1's rmse: 3.62367\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62047\tvalid_1's rmse: 3.63307\n",
      "[1000]\ttraining's rmse: 3.53999\tvalid_1's rmse: 3.61427\n",
      "[1500]\ttraining's rmse: 3.48597\tvalid_1's rmse: 3.60959\n",
      "[2000]\ttraining's rmse: 3.43854\tvalid_1's rmse: 3.60734\n",
      "Early stopping, best iteration is:\n",
      "[2176]\ttraining's rmse: 3.42332\tvalid_1's rmse: 3.60661\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57401\tvalid_1's rmse: 3.81916\n",
      "[1000]\ttraining's rmse: 3.49525\tvalid_1's rmse: 3.8004\n",
      "[1500]\ttraining's rmse: 3.43975\tvalid_1's rmse: 3.79447\n",
      "[2000]\ttraining's rmse: 3.39331\tvalid_1's rmse: 3.79238\n",
      "[2500]\ttraining's rmse: 3.35221\tvalid_1's rmse: 3.79104\n",
      "[3000]\ttraining's rmse: 3.31436\tvalid_1's rmse: 3.79051\n",
      "Early stopping, best iteration is:\n",
      "[3010]\ttraining's rmse: 3.31359\tvalid_1's rmse: 3.79045\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61513\tvalid_1's rmse: 3.65067\n",
      "[1000]\ttraining's rmse: 3.53264\tvalid_1's rmse: 3.63285\n",
      "[1500]\ttraining's rmse: 3.47855\tvalid_1's rmse: 3.62763\n",
      "[2000]\ttraining's rmse: 3.4323\tvalid_1's rmse: 3.62602\n",
      "Early stopping, best iteration is:\n",
      "[2167]\ttraining's rmse: 3.41816\tvalid_1's rmse: 3.62543\n",
      "   40 | 02m30s |   -3.66664 |             0.7230 |        15.8214 |             0.4254 |             0.3483 |     13.5106 |             30.4237 |            33.1994 |            61.2999 |           0.7402 |      39.3425 |      5.7171 |       6.4618 |      0.5864 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67941\tvalid_1's rmse: 3.7303\n",
      "[1000]\ttraining's rmse: 3.64512\tvalid_1's rmse: 3.71017\n",
      "[1500]\ttraining's rmse: 3.62185\tvalid_1's rmse: 3.70216\n",
      "[2000]\ttraining's rmse: 3.60201\tvalid_1's rmse: 3.69813\n",
      "[2500]\ttraining's rmse: 3.58473\tvalid_1's rmse: 3.69607\n",
      "[3000]\ttraining's rmse: 3.56931\tvalid_1's rmse: 3.69498\n",
      "[3500]\ttraining's rmse: 3.55429\tvalid_1's rmse: 3.69444\n",
      "Early stopping, best iteration is:\n",
      "[3634]\ttraining's rmse: 3.55025\tvalid_1's rmse: 3.69378\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.69432\tvalid_1's rmse: 3.66438\n",
      "[1000]\ttraining's rmse: 3.65882\tvalid_1's rmse: 3.64774\n",
      "[1500]\ttraining's rmse: 3.63609\tvalid_1's rmse: 3.6412\n",
      "[2000]\ttraining's rmse: 3.61658\tvalid_1's rmse: 3.63787\n",
      "[2500]\ttraining's rmse: 3.59953\tvalid_1's rmse: 3.63647\n",
      "[3000]\ttraining's rmse: 3.5843\tvalid_1's rmse: 3.63467\n",
      "Early stopping, best iteration is:\n",
      "[3000]\ttraining's rmse: 3.5843\tvalid_1's rmse: 3.63467\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69845\tvalid_1's rmse: 3.64078\n",
      "[1000]\ttraining's rmse: 3.66336\tvalid_1's rmse: 3.62508\n",
      "[1500]\ttraining's rmse: 3.64067\tvalid_1's rmse: 3.62002\n",
      "[2000]\ttraining's rmse: 3.62021\tvalid_1's rmse: 3.61732\n",
      "[2500]\ttraining's rmse: 3.6027\tvalid_1's rmse: 3.61605\n",
      "[3000]\ttraining's rmse: 3.58622\tvalid_1's rmse: 3.61515\n",
      "Early stopping, best iteration is:\n",
      "[3032]\ttraining's rmse: 3.58525\tvalid_1's rmse: 3.61475\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65035\tvalid_1's rmse: 3.83903\n",
      "[1000]\ttraining's rmse: 3.61529\tvalid_1's rmse: 3.82266\n",
      "[1500]\ttraining's rmse: 3.59205\tvalid_1's rmse: 3.81797\n",
      "[2000]\ttraining's rmse: 3.57257\tvalid_1's rmse: 3.81444\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 3.57199\tvalid_1's rmse: 3.81438\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69344\tvalid_1's rmse: 3.65777\n",
      "[1000]\ttraining's rmse: 3.65954\tvalid_1's rmse: 3.64404\n",
      "[1500]\ttraining's rmse: 3.63548\tvalid_1's rmse: 3.63906\n",
      "[2000]\ttraining's rmse: 3.61643\tvalid_1's rmse: 3.63694\n",
      "[2500]\ttraining's rmse: 3.59871\tvalid_1's rmse: 3.63583\n",
      "Early stopping, best iteration is:\n",
      "[2484]\ttraining's rmse: 3.59932\tvalid_1's rmse: 3.63571\n",
      "   41 | 02m04s |   -3.67938 |             0.0775 |         2.1754 |             0.8604 |             0.4836 |      8.0908 |             24.4307 |            35.9456 |            91.9740 |           0.7400 |      41.5905 |      9.0151 |       6.0727 |      0.1148 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61032\tvalid_1's rmse: 3.72274\n",
      "[1000]\ttraining's rmse: 3.52614\tvalid_1's rmse: 3.69824\n",
      "[1500]\ttraining's rmse: 3.47099\tvalid_1's rmse: 3.68964\n",
      "[2000]\ttraining's rmse: 3.42702\tvalid_1's rmse: 3.68665\n",
      "[2500]\ttraining's rmse: 3.38974\tvalid_1's rmse: 3.68554\n",
      "[3000]\ttraining's rmse: 3.35714\tvalid_1's rmse: 3.68484\n",
      "[3500]\ttraining's rmse: 3.32791\tvalid_1's rmse: 3.68472\n",
      "Early stopping, best iteration is:\n",
      "[3360]\ttraining's rmse: 3.33581\tvalid_1's rmse: 3.68456\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62452\tvalid_1's rmse: 3.66078\n",
      "[1000]\ttraining's rmse: 3.5383\tvalid_1's rmse: 3.63959\n",
      "[1500]\ttraining's rmse: 3.48308\tvalid_1's rmse: 3.63166\n",
      "[2000]\ttraining's rmse: 3.43908\tvalid_1's rmse: 3.62852\n",
      "[2500]\ttraining's rmse: 3.40205\tvalid_1's rmse: 3.62725\n",
      "[3000]\ttraining's rmse: 3.36822\tvalid_1's rmse: 3.62602\n",
      "[3500]\ttraining's rmse: 3.33739\tvalid_1's rmse: 3.62543\n",
      "[4000]\ttraining's rmse: 3.30792\tvalid_1's rmse: 3.62519\n",
      "Early stopping, best iteration is:\n",
      "[4189]\ttraining's rmse: 3.29687\tvalid_1's rmse: 3.62497\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62838\tvalid_1's rmse: 3.63787\n",
      "[1000]\ttraining's rmse: 3.54317\tvalid_1's rmse: 3.61678\n",
      "[1500]\ttraining's rmse: 3.48824\tvalid_1's rmse: 3.60962\n",
      "[2000]\ttraining's rmse: 3.44407\tvalid_1's rmse: 3.6067\n",
      "[2500]\ttraining's rmse: 3.40722\tvalid_1's rmse: 3.60517\n",
      "[3000]\ttraining's rmse: 3.37344\tvalid_1's rmse: 3.60481\n",
      "Early stopping, best iteration is:\n",
      "[2837]\ttraining's rmse: 3.38389\tvalid_1's rmse: 3.60459\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58275\tvalid_1's rmse: 3.82734\n",
      "[1000]\ttraining's rmse: 3.49676\tvalid_1's rmse: 3.80474\n",
      "[1500]\ttraining's rmse: 3.44224\tvalid_1's rmse: 3.79783\n",
      "[2000]\ttraining's rmse: 3.39831\tvalid_1's rmse: 3.79455\n",
      "[2500]\ttraining's rmse: 3.36187\tvalid_1's rmse: 3.7938\n",
      "[3000]\ttraining's rmse: 3.32968\tvalid_1's rmse: 3.79336\n",
      "Early stopping, best iteration is:\n",
      "[2919]\ttraining's rmse: 3.33468\tvalid_1's rmse: 3.79323\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62392\tvalid_1's rmse: 3.65609\n",
      "[1000]\ttraining's rmse: 3.53739\tvalid_1's rmse: 3.6361\n",
      "[1500]\ttraining's rmse: 3.4813\tvalid_1's rmse: 3.62908\n",
      "[2000]\ttraining's rmse: 3.43682\tvalid_1's rmse: 3.62594\n",
      "[2500]\ttraining's rmse: 3.40022\tvalid_1's rmse: 3.62501\n",
      "[3000]\ttraining's rmse: 3.36771\tvalid_1's rmse: 3.62452\n",
      "Early stopping, best iteration is:\n",
      "[2929]\ttraining's rmse: 3.37205\tvalid_1's rmse: 3.62441\n",
      "   42 | 02m37s |   -3.66700 |             0.1618 |         0.2531 |             0.1804 |             0.2491 |     13.7711 |             23.9598 |            32.9851 |            51.1475 |           0.3637 |      37.5422 |      5.4711 |       7.7513 |      0.6855 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64643\tvalid_1's rmse: 3.7345\n",
      "[1000]\ttraining's rmse: 3.5745\tvalid_1's rmse: 3.70663\n",
      "[1500]\ttraining's rmse: 3.52585\tvalid_1's rmse: 3.69574\n",
      "[2000]\ttraining's rmse: 3.48625\tvalid_1's rmse: 3.69103\n",
      "[2500]\ttraining's rmse: 3.45071\tvalid_1's rmse: 3.68863\n",
      "[3000]\ttraining's rmse: 3.41842\tvalid_1's rmse: 3.68755\n",
      "[3500]\ttraining's rmse: 3.38846\tvalid_1's rmse: 3.68638\n",
      "Early stopping, best iteration is:\n",
      "[3489]\ttraining's rmse: 3.38907\tvalid_1's rmse: 3.68635\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65943\tvalid_1's rmse: 3.66994\n",
      "[1000]\ttraining's rmse: 3.58677\tvalid_1's rmse: 3.64591\n",
      "[1500]\ttraining's rmse: 3.53687\tvalid_1's rmse: 3.63623\n",
      "[2000]\ttraining's rmse: 3.49692\tvalid_1's rmse: 3.63178\n",
      "[2500]\ttraining's rmse: 3.46161\tvalid_1's rmse: 3.62969\n",
      "[3000]\ttraining's rmse: 3.42869\tvalid_1's rmse: 3.62887\n",
      "[3500]\ttraining's rmse: 3.39784\tvalid_1's rmse: 3.62796\n",
      "Early stopping, best iteration is:\n",
      "[3566]\ttraining's rmse: 3.39371\tvalid_1's rmse: 3.62788\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66321\tvalid_1's rmse: 3.64584\n",
      "[1000]\ttraining's rmse: 3.59119\tvalid_1's rmse: 3.6235\n",
      "[1500]\ttraining's rmse: 3.54143\tvalid_1's rmse: 3.61553\n",
      "[2000]\ttraining's rmse: 3.50102\tvalid_1's rmse: 3.61156\n",
      "[2500]\ttraining's rmse: 3.46564\tvalid_1's rmse: 3.60966\n",
      "[3000]\ttraining's rmse: 3.43252\tvalid_1's rmse: 3.60908\n",
      "Early stopping, best iteration is:\n",
      "[2961]\ttraining's rmse: 3.43509\tvalid_1's rmse: 3.60896\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61653\tvalid_1's rmse: 3.84153\n",
      "[1000]\ttraining's rmse: 3.54415\tvalid_1's rmse: 3.81563\n",
      "[1500]\ttraining's rmse: 3.49586\tvalid_1's rmse: 3.80603\n",
      "[2000]\ttraining's rmse: 3.45579\tvalid_1's rmse: 3.80186\n",
      "[2500]\ttraining's rmse: 3.4205\tvalid_1's rmse: 3.79934\n",
      "[3000]\ttraining's rmse: 3.3877\tvalid_1's rmse: 3.79797\n",
      "[3500]\ttraining's rmse: 3.35702\tvalid_1's rmse: 3.79696\n",
      "[4000]\ttraining's rmse: 3.32761\tvalid_1's rmse: 3.79636\n",
      "Early stopping, best iteration is:\n",
      "[3876]\ttraining's rmse: 3.33501\tvalid_1's rmse: 3.7962\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6592\tvalid_1's rmse: 3.66585\n",
      "[1000]\ttraining's rmse: 3.58579\tvalid_1's rmse: 3.64377\n",
      "[1500]\ttraining's rmse: 3.53536\tvalid_1's rmse: 3.63651\n",
      "[2000]\ttraining's rmse: 3.49561\tvalid_1's rmse: 3.63278\n",
      "[2500]\ttraining's rmse: 3.46018\tvalid_1's rmse: 3.63066\n",
      "[3000]\ttraining's rmse: 3.42867\tvalid_1's rmse: 3.62993\n",
      "Early stopping, best iteration is:\n",
      "[3115]\ttraining's rmse: 3.42106\tvalid_1's rmse: 3.62964\n",
      "   43 | 02m51s |   -3.67044 |             0.7726 |        19.4537 |             0.8689 |             0.1405 |      9.7645 |             12.8049 |            32.4611 |            81.4562 |           0.7222 |      44.7209 |      3.7700 |       6.4230 |      0.8033 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59894\tvalid_1's rmse: 3.71088\n",
      "[1000]\ttraining's rmse: 3.5244\tvalid_1's rmse: 3.68941\n",
      "[1500]\ttraining's rmse: 3.47372\tvalid_1's rmse: 3.68345\n",
      "[2000]\ttraining's rmse: 3.43135\tvalid_1's rmse: 3.68132\n",
      "[2500]\ttraining's rmse: 3.39418\tvalid_1's rmse: 3.68041\n",
      "[3000]\ttraining's rmse: 3.36062\tvalid_1's rmse: 3.67993\n",
      "Early stopping, best iteration is:\n",
      "[3033]\ttraining's rmse: 3.35844\tvalid_1's rmse: 3.67976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61186\tvalid_1's rmse: 3.65121\n",
      "[1000]\ttraining's rmse: 3.53505\tvalid_1's rmse: 3.63301\n",
      "[1500]\ttraining's rmse: 3.48297\tvalid_1's rmse: 3.62687\n",
      "[2000]\ttraining's rmse: 3.44111\tvalid_1's rmse: 3.62446\n",
      "[2500]\ttraining's rmse: 3.40363\tvalid_1's rmse: 3.62368\n",
      "Early stopping, best iteration is:\n",
      "[2591]\ttraining's rmse: 3.39746\tvalid_1's rmse: 3.62345\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61667\tvalid_1's rmse: 3.62779\n",
      "[1000]\ttraining's rmse: 3.5397\tvalid_1's rmse: 3.60999\n",
      "[1500]\ttraining's rmse: 3.48842\tvalid_1's rmse: 3.60568\n",
      "[2000]\ttraining's rmse: 3.44574\tvalid_1's rmse: 3.60398\n",
      "Early stopping, best iteration is:\n",
      "[2205]\ttraining's rmse: 3.42993\tvalid_1's rmse: 3.60351\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57136\tvalid_1's rmse: 3.81492\n",
      "[1000]\ttraining's rmse: 3.49409\tvalid_1's rmse: 3.797\n",
      "[1500]\ttraining's rmse: 3.44353\tvalid_1's rmse: 3.79265\n",
      "[2000]\ttraining's rmse: 3.40167\tvalid_1's rmse: 3.7911\n",
      "[2500]\ttraining's rmse: 3.36368\tvalid_1's rmse: 3.79032\n",
      "Early stopping, best iteration is:\n",
      "[2498]\ttraining's rmse: 3.36386\tvalid_1's rmse: 3.79029\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61101\tvalid_1's rmse: 3.6463\n",
      "[1000]\ttraining's rmse: 3.53292\tvalid_1's rmse: 3.62916\n",
      "[1500]\ttraining's rmse: 3.48193\tvalid_1's rmse: 3.62414\n",
      "[2000]\ttraining's rmse: 3.43958\tvalid_1's rmse: 3.62224\n",
      "Early stopping, best iteration is:\n",
      "[1981]\ttraining's rmse: 3.441\tvalid_1's rmse: 3.62217\n",
      "   44 | 03m06s | \u001b[35m  -3.66447\u001b[0m | \u001b[32m            0.9296\u001b[0m | \u001b[32m        9.5094\u001b[0m | \u001b[32m            0.3215\u001b[0m | \u001b[32m            0.4351\u001b[0m | \u001b[32m    12.8353\u001b[0m | \u001b[32m            29.3095\u001b[0m | \u001b[32m           30.1384\u001b[0m | \u001b[32m           83.0226\u001b[0m | \u001b[32m          0.7737\u001b[0m | \u001b[32m     38.3377\u001b[0m | \u001b[32m     2.3465\u001b[0m | \u001b[32m      8.1067\u001b[0m | \u001b[32m     0.1742\u001b[0m | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61762\tvalid_1's rmse: 3.70944\n",
      "[1000]\ttraining's rmse: 3.56121\tvalid_1's rmse: 3.6913\n",
      "[1500]\ttraining's rmse: 3.51932\tvalid_1's rmse: 3.6872\n",
      "[2000]\ttraining's rmse: 3.48144\tvalid_1's rmse: 3.68579\n",
      "Early stopping, best iteration is:\n",
      "[1926]\ttraining's rmse: 3.48669\tvalid_1's rmse: 3.68506\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63198\tvalid_1's rmse: 3.64945\n",
      "[1000]\ttraining's rmse: 3.57458\tvalid_1's rmse: 3.63497\n",
      "[1500]\ttraining's rmse: 3.53153\tvalid_1's rmse: 3.63008\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 3.51695\tvalid_1's rmse: 3.62865\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64082\tvalid_1's rmse: 3.62666\n",
      "[1000]\ttraining's rmse: 3.58097\tvalid_1's rmse: 3.61343\n",
      "[1500]\ttraining's rmse: 3.53651\tvalid_1's rmse: 3.6107\n",
      "[2000]\ttraining's rmse: 3.50008\tvalid_1's rmse: 3.60987\n",
      "Early stopping, best iteration is:\n",
      "[1871]\ttraining's rmse: 3.509\tvalid_1's rmse: 3.60894\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59165\tvalid_1's rmse: 3.81872\n",
      "[1000]\ttraining's rmse: 3.53127\tvalid_1's rmse: 3.80477\n",
      "[1500]\ttraining's rmse: 3.48887\tvalid_1's rmse: 3.80077\n",
      "[2000]\ttraining's rmse: 3.45063\tvalid_1's rmse: 3.79922\n",
      "Early stopping, best iteration is:\n",
      "[2058]\ttraining's rmse: 3.44648\tvalid_1's rmse: 3.79902\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63324\tvalid_1's rmse: 3.64579\n",
      "[1000]\ttraining's rmse: 3.57484\tvalid_1's rmse: 3.63464\n",
      "[1500]\ttraining's rmse: 3.53264\tvalid_1's rmse: 3.63203\n",
      "Early stopping, best iteration is:\n",
      "[1413]\ttraining's rmse: 3.53949\tvalid_1's rmse: 3.63156\n",
      "   45 | 02m06s |   -3.67130 |             0.3402 |        13.8152 |             0.3177 |             0.7888 |      9.5941 |             17.3635 |            42.5007 |            67.4510 |           0.3589 |      33.8862 |      2.4958 |       3.6537 |      0.7138 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65945\tvalid_1's rmse: 3.72365\n",
      "[1000]\ttraining's rmse: 3.61671\tvalid_1's rmse: 3.70002\n",
      "[1500]\ttraining's rmse: 3.58912\tvalid_1's rmse: 3.69135\n",
      "[2000]\ttraining's rmse: 3.56662\tvalid_1's rmse: 3.68783\n",
      "[2500]\ttraining's rmse: 3.54647\tvalid_1's rmse: 3.68565\n",
      "[3000]\ttraining's rmse: 3.52797\tvalid_1's rmse: 3.6844\n",
      "[3500]\ttraining's rmse: 3.51059\tvalid_1's rmse: 3.68375\n",
      "[4000]\ttraining's rmse: 3.49344\tvalid_1's rmse: 3.68327\n",
      "[4500]\ttraining's rmse: 3.47688\tvalid_1's rmse: 3.6831\n",
      "Early stopping, best iteration is:\n",
      "[4366]\ttraining's rmse: 3.48115\tvalid_1's rmse: 3.683\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67356\tvalid_1's rmse: 3.66279\n",
      "[1000]\ttraining's rmse: 3.62851\tvalid_1's rmse: 3.6426\n",
      "[1500]\ttraining's rmse: 3.60103\tvalid_1's rmse: 3.63476\n",
      "[2000]\ttraining's rmse: 3.57824\tvalid_1's rmse: 3.63126\n",
      "[2500]\ttraining's rmse: 3.55867\tvalid_1's rmse: 3.62956\n",
      "[3000]\ttraining's rmse: 3.53993\tvalid_1's rmse: 3.62837\n",
      "[3500]\ttraining's rmse: 3.52221\tvalid_1's rmse: 3.62746\n",
      "[4000]\ttraining's rmse: 3.50484\tvalid_1's rmse: 3.62668\n",
      "Early stopping, best iteration is:\n",
      "[4194]\ttraining's rmse: 3.49793\tvalid_1's rmse: 3.62645\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67961\tvalid_1's rmse: 3.63576\n",
      "[1000]\ttraining's rmse: 3.63389\tvalid_1's rmse: 3.6141\n",
      "[1500]\ttraining's rmse: 3.60636\tvalid_1's rmse: 3.60739\n",
      "[2000]\ttraining's rmse: 3.58427\tvalid_1's rmse: 3.60446\n",
      "[2500]\ttraining's rmse: 3.56478\tvalid_1's rmse: 3.6037\n",
      "[3000]\ttraining's rmse: 3.54548\tvalid_1's rmse: 3.60323\n",
      "Early stopping, best iteration is:\n",
      "[3040]\ttraining's rmse: 3.54386\tvalid_1's rmse: 3.60316\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63206\tvalid_1's rmse: 3.82975\n",
      "[1000]\ttraining's rmse: 3.58637\tvalid_1's rmse: 3.80848\n",
      "[1500]\ttraining's rmse: 3.55864\tvalid_1's rmse: 3.80172\n",
      "[2000]\ttraining's rmse: 3.53688\tvalid_1's rmse: 3.79861\n",
      "[2500]\ttraining's rmse: 3.51745\tvalid_1's rmse: 3.79715\n",
      "[3000]\ttraining's rmse: 3.49888\tvalid_1's rmse: 3.79624\n",
      "[3500]\ttraining's rmse: 3.48104\tvalid_1's rmse: 3.79549\n",
      "[4000]\ttraining's rmse: 3.46322\tvalid_1's rmse: 3.79492\n",
      "[4500]\ttraining's rmse: 3.44654\tvalid_1's rmse: 3.79456\n",
      "Early stopping, best iteration is:\n",
      "[4654]\ttraining's rmse: 3.44116\tvalid_1's rmse: 3.79445\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67488\tvalid_1's rmse: 3.65436\n",
      "[1000]\ttraining's rmse: 3.62772\tvalid_1's rmse: 3.63392\n",
      "[1500]\ttraining's rmse: 3.5995\tvalid_1's rmse: 3.62707\n",
      "[2000]\ttraining's rmse: 3.57711\tvalid_1's rmse: 3.62373\n",
      "[2500]\ttraining's rmse: 3.55661\tvalid_1's rmse: 3.62238\n",
      "Early stopping, best iteration is:\n",
      "[2533]\ttraining's rmse: 3.55529\tvalid_1's rmse: 3.62232\n",
      "   46 | 03m36s |   -3.66653 |             0.9705 |         2.6240 |             0.3836 |             0.3381 |      5.0428 |             27.0828 |            38.7494 |            43.3964 |           0.5041 |      34.3246 |      6.7361 |       8.8497 |      0.7344 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62698\tvalid_1's rmse: 3.71201\n",
      "[1000]\ttraining's rmse: 3.57778\tvalid_1's rmse: 3.69513\n",
      "[1500]\ttraining's rmse: 3.54132\tvalid_1's rmse: 3.69021\n",
      "[2000]\ttraining's rmse: 3.50795\tvalid_1's rmse: 3.6884\n",
      "Early stopping, best iteration is:\n",
      "[2163]\ttraining's rmse: 3.49655\tvalid_1's rmse: 3.6875\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63855\tvalid_1's rmse: 3.65069\n",
      "[1000]\ttraining's rmse: 3.5879\tvalid_1's rmse: 3.63756\n",
      "[1500]\ttraining's rmse: 3.55167\tvalid_1's rmse: 3.63308\n",
      "Early stopping, best iteration is:\n",
      "[1670]\ttraining's rmse: 3.54186\tvalid_1's rmse: 3.6321\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64578\tvalid_1's rmse: 3.62623\n",
      "[1000]\ttraining's rmse: 3.59205\tvalid_1's rmse: 3.61488\n",
      "[1500]\ttraining's rmse: 3.55376\tvalid_1's rmse: 3.6125\n",
      "Early stopping, best iteration is:\n",
      "[1470]\ttraining's rmse: 3.55622\tvalid_1's rmse: 3.61205\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.59781\tvalid_1's rmse: 3.81627\n",
      "[1000]\ttraining's rmse: 3.54685\tvalid_1's rmse: 3.80688\n",
      "[1500]\ttraining's rmse: 3.50939\tvalid_1's rmse: 3.80407\n",
      "[2000]\ttraining's rmse: 3.47814\tvalid_1's rmse: 3.80128\n",
      "Early stopping, best iteration is:\n",
      "[2030]\ttraining's rmse: 3.47634\tvalid_1's rmse: 3.80099\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64022\tvalid_1's rmse: 3.64493\n",
      "[1000]\ttraining's rmse: 3.58786\tvalid_1's rmse: 3.63613\n",
      "[1500]\ttraining's rmse: 3.55202\tvalid_1's rmse: 3.63401\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's rmse: 3.56554\tvalid_1's rmse: 3.6337\n",
      "   47 | 01m58s |   -3.67391 |             0.2054 |         7.7924 |             0.6518 |             0.8377 |      7.1868 |             40.2802 |            40.3178 |            31.9895 |           0.3740 |      42.5542 |      6.8890 |       8.3958 |      0.2781 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60331\tvalid_1's rmse: 3.70869\n",
      "[1000]\ttraining's rmse: 3.54004\tvalid_1's rmse: 3.68967\n",
      "[1500]\ttraining's rmse: 3.49536\tvalid_1's rmse: 3.68535\n",
      "Early stopping, best iteration is:\n",
      "[1794]\ttraining's rmse: 3.47094\tvalid_1's rmse: 3.68417\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61635\tvalid_1's rmse: 3.6489\n",
      "[1000]\ttraining's rmse: 3.55186\tvalid_1's rmse: 3.6329\n",
      "[1500]\ttraining's rmse: 3.50597\tvalid_1's rmse: 3.62707\n",
      "[2000]\ttraining's rmse: 3.46588\tvalid_1's rmse: 3.62495\n",
      "[2500]\ttraining's rmse: 3.42817\tvalid_1's rmse: 3.6239\n",
      "Early stopping, best iteration is:\n",
      "[2576]\ttraining's rmse: 3.42357\tvalid_1's rmse: 3.62366\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6213\tvalid_1's rmse: 3.62402\n",
      "[1000]\ttraining's rmse: 3.55528\tvalid_1's rmse: 3.60734\n",
      "[1500]\ttraining's rmse: 3.51029\tvalid_1's rmse: 3.60473\n",
      "Early stopping, best iteration is:\n",
      "[1359]\ttraining's rmse: 3.52194\tvalid_1's rmse: 3.6045\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57583\tvalid_1's rmse: 3.81021\n",
      "[1000]\ttraining's rmse: 3.50994\tvalid_1's rmse: 3.79403\n",
      "[1500]\ttraining's rmse: 3.46394\tvalid_1's rmse: 3.79009\n",
      "[2000]\ttraining's rmse: 3.42658\tvalid_1's rmse: 3.78936\n",
      "Early stopping, best iteration is:\n",
      "[1927]\ttraining's rmse: 3.43156\tvalid_1's rmse: 3.78915\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61567\tvalid_1's rmse: 3.64385\n",
      "[1000]\ttraining's rmse: 3.54862\tvalid_1's rmse: 3.62954\n",
      "[1500]\ttraining's rmse: 3.50314\tvalid_1's rmse: 3.62509\n",
      "[2000]\ttraining's rmse: 3.46324\tvalid_1's rmse: 3.62421\n",
      "Early stopping, best iteration is:\n",
      "[1851]\ttraining's rmse: 3.47507\tvalid_1's rmse: 3.62404\n",
      "   48 | 02m58s |   -3.66573 |             0.8792 |         9.9111 |             0.9633 |             0.7098 |      7.7812 |             22.2293 |            42.7647 |            27.5423 |           0.0546 |      35.0808 |      0.4003 |       5.7296 |      0.3740 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61363\tvalid_1's rmse: 3.70836\n",
      "[1000]\ttraining's rmse: 3.55889\tvalid_1's rmse: 3.69231\n",
      "Early stopping, best iteration is:\n",
      "[1270]\ttraining's rmse: 3.53495\tvalid_1's rmse: 3.68889\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63035\tvalid_1's rmse: 3.65198\n",
      "[1000]\ttraining's rmse: 3.57006\tvalid_1's rmse: 3.63744\n",
      "[1500]\ttraining's rmse: 3.53377\tvalid_1's rmse: 3.63524\n",
      "Early stopping, best iteration is:\n",
      "[1428]\ttraining's rmse: 3.53823\tvalid_1's rmse: 3.63476\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63059\tvalid_1's rmse: 3.62243\n",
      "[1000]\ttraining's rmse: 3.57127\tvalid_1's rmse: 3.61206\n",
      "[1500]\ttraining's rmse: 3.53096\tvalid_1's rmse: 3.60854\n",
      "Early stopping, best iteration is:\n",
      "[1632]\ttraining's rmse: 3.51987\tvalid_1's rmse: 3.60723\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58657\tvalid_1's rmse: 3.81201\n",
      "[1000]\ttraining's rmse: 3.53304\tvalid_1's rmse: 3.80215\n",
      "[1500]\ttraining's rmse: 3.49175\tvalid_1's rmse: 3.79944\n",
      "[2000]\ttraining's rmse: 3.45848\tvalid_1's rmse: 3.79873\n",
      "Early stopping, best iteration is:\n",
      "[1955]\ttraining's rmse: 3.46159\tvalid_1's rmse: 3.79799\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62636\tvalid_1's rmse: 3.64383\n",
      "[1000]\ttraining's rmse: 3.56718\tvalid_1's rmse: 3.63522\n",
      "Early stopping, best iteration is:\n",
      "[1139]\ttraining's rmse: 3.55582\tvalid_1's rmse: 3.63406\n",
      "   49 | 02m01s |   -3.67322 |             0.3359 |        17.7189 |             0.7721 |             0.8935 |      7.0874 |             42.2611 |            32.2689 |            52.6909 |           0.7095 |      44.2542 |      1.6463 |       8.7386 |      0.7946 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.622\tvalid_1's rmse: 3.72834\n",
      "[1000]\ttraining's rmse: 3.54378\tvalid_1's rmse: 3.70197\n",
      "[1500]\ttraining's rmse: 3.49351\tvalid_1's rmse: 3.69301\n",
      "[2000]\ttraining's rmse: 3.45323\tvalid_1's rmse: 3.68952\n",
      "[2500]\ttraining's rmse: 3.41837\tvalid_1's rmse: 3.68778\n",
      "[3000]\ttraining's rmse: 3.3869\tvalid_1's rmse: 3.68682\n",
      "Early stopping, best iteration is:\n",
      "[3210]\ttraining's rmse: 3.37457\tvalid_1's rmse: 3.68653\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63522\tvalid_1's rmse: 3.66501\n",
      "[1000]\ttraining's rmse: 3.55401\tvalid_1's rmse: 3.64257\n",
      "[1500]\ttraining's rmse: 3.50316\tvalid_1's rmse: 3.63432\n",
      "[2000]\ttraining's rmse: 3.4615\tvalid_1's rmse: 3.63083\n",
      "[2500]\ttraining's rmse: 3.42627\tvalid_1's rmse: 3.62928\n",
      "[3000]\ttraining's rmse: 3.39531\tvalid_1's rmse: 3.62798\n",
      "[3500]\ttraining's rmse: 3.36626\tvalid_1's rmse: 3.62731\n",
      "Early stopping, best iteration is:\n",
      "[3590]\ttraining's rmse: 3.36125\tvalid_1's rmse: 3.6272\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63986\tvalid_1's rmse: 3.64089\n",
      "[1000]\ttraining's rmse: 3.5599\tvalid_1's rmse: 3.61802\n",
      "[1500]\ttraining's rmse: 3.50975\tvalid_1's rmse: 3.61061\n",
      "[2000]\ttraining's rmse: 3.46867\tvalid_1's rmse: 3.60721\n",
      "[2500]\ttraining's rmse: 3.43452\tvalid_1's rmse: 3.60596\n",
      "[3000]\ttraining's rmse: 3.40413\tvalid_1's rmse: 3.6057\n",
      "Early stopping, best iteration is:\n",
      "[2966]\ttraining's rmse: 3.40612\tvalid_1's rmse: 3.60559\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59334\tvalid_1's rmse: 3.83104\n",
      "[1000]\ttraining's rmse: 3.513\tvalid_1's rmse: 3.80779\n",
      "[1500]\ttraining's rmse: 3.46285\tvalid_1's rmse: 3.8001\n",
      "[2000]\ttraining's rmse: 3.42205\tvalid_1's rmse: 3.79636\n",
      "[2500]\ttraining's rmse: 3.38889\tvalid_1's rmse: 3.79523\n",
      "[3000]\ttraining's rmse: 3.3579\tvalid_1's rmse: 3.7945\n",
      "[3500]\ttraining's rmse: 3.33006\tvalid_1's rmse: 3.79396\n",
      "Early stopping, best iteration is:\n",
      "[3725]\ttraining's rmse: 3.31828\tvalid_1's rmse: 3.79352\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63474\tvalid_1's rmse: 3.65986\n",
      "[1000]\ttraining's rmse: 3.55388\tvalid_1's rmse: 3.63841\n",
      "[1500]\ttraining's rmse: 3.50158\tvalid_1's rmse: 3.6307\n",
      "[2000]\ttraining's rmse: 3.46103\tvalid_1's rmse: 3.62729\n",
      "[2500]\ttraining's rmse: 3.42664\tvalid_1's rmse: 3.6256\n",
      "Early stopping, best iteration is:\n",
      "[2482]\ttraining's rmse: 3.42783\tvalid_1's rmse: 3.62553\n",
      "   50 | 02m17s |   -3.66831 |             0.9036 |         0.7893 |             0.4653 |             0.2306 |     10.4235 |             22.2719 |            32.3380 |            37.5592 |           0.3680 |      32.6582 |      0.9776 |       3.2596 |      0.5142 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   bagging_freq |   colsample_bytree |   feature_fraction |   max_depth |   min_child_samples |   min_child_weight |   min_data_in_leaf |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59645\tvalid_1's rmse: 3.70791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.52304\tvalid_1's rmse: 3.68914\n",
      "[1500]\ttraining's rmse: 3.47419\tvalid_1's rmse: 3.68334\n",
      "[2000]\ttraining's rmse: 3.43646\tvalid_1's rmse: 3.68216\n",
      "[2500]\ttraining's rmse: 3.40322\tvalid_1's rmse: 3.68183\n",
      "Early stopping, best iteration is:\n",
      "[2379]\ttraining's rmse: 3.41091\tvalid_1's rmse: 3.68158\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.609\tvalid_1's rmse: 3.64998\n",
      "[1000]\ttraining's rmse: 3.53478\tvalid_1's rmse: 3.63241\n",
      "[1500]\ttraining's rmse: 3.48631\tvalid_1's rmse: 3.62783\n",
      "[2000]\ttraining's rmse: 3.44698\tvalid_1's rmse: 3.62618\n",
      "[2500]\ttraining's rmse: 3.4128\tvalid_1's rmse: 3.62568\n",
      "Early stopping, best iteration is:\n",
      "[2324]\ttraining's rmse: 3.42462\tvalid_1's rmse: 3.62561\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61339\tvalid_1's rmse: 3.62615\n",
      "[1000]\ttraining's rmse: 3.5395\tvalid_1's rmse: 3.60864\n",
      "[1500]\ttraining's rmse: 3.49113\tvalid_1's rmse: 3.60426\n",
      "[2000]\ttraining's rmse: 3.45286\tvalid_1's rmse: 3.60272\n",
      "Early stopping, best iteration is:\n",
      "[2011]\ttraining's rmse: 3.45211\tvalid_1's rmse: 3.60266\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56924\tvalid_1's rmse: 3.81047\n",
      "[1000]\ttraining's rmse: 3.49388\tvalid_1's rmse: 3.79399\n",
      "[1500]\ttraining's rmse: 3.44503\tvalid_1's rmse: 3.78974\n",
      "[2000]\ttraining's rmse: 3.40712\tvalid_1's rmse: 3.78917\n",
      "Early stopping, best iteration is:\n",
      "[2126]\ttraining's rmse: 3.39812\tvalid_1's rmse: 3.78888\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60891\tvalid_1's rmse: 3.64472\n",
      "[1000]\ttraining's rmse: 3.53395\tvalid_1's rmse: 3.62921\n",
      "[1500]\ttraining's rmse: 3.48535\tvalid_1's rmse: 3.62375\n",
      "[2000]\ttraining's rmse: 3.44682\tvalid_1's rmse: 3.62129\n",
      "[2500]\ttraining's rmse: 3.41408\tvalid_1's rmse: 3.62089\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 3.41739\tvalid_1's rmse: 3.62082\n",
      "   51 | 03m38s |   -3.66454 |             0.1409 |         0.4592 |             0.9451 |             0.5980 |     14.9763 |             48.9753 |            41.9586 |            99.5263 |           0.4948 |      35.2750 |      7.6660 |       1.5160 |      0.8788 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59457\tvalid_1's rmse: 3.71352\n",
      "[1000]\ttraining's rmse: 3.51405\tvalid_1's rmse: 3.69259\n",
      "[1500]\ttraining's rmse: 3.45947\tvalid_1's rmse: 3.68517\n",
      "[2000]\ttraining's rmse: 3.41663\tvalid_1's rmse: 3.68334\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's rmse: 3.39261\tvalid_1's rmse: 3.6823\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60742\tvalid_1's rmse: 3.65612\n",
      "[1000]\ttraining's rmse: 3.52608\tvalid_1's rmse: 3.63811\n",
      "[1500]\ttraining's rmse: 3.47099\tvalid_1's rmse: 3.63234\n",
      "[2000]\ttraining's rmse: 3.42771\tvalid_1's rmse: 3.62955\n",
      "Early stopping, best iteration is:\n",
      "[1976]\ttraining's rmse: 3.4296\tvalid_1's rmse: 3.62916\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61261\tvalid_1's rmse: 3.63183\n",
      "[1000]\ttraining's rmse: 3.53132\tvalid_1's rmse: 3.61357\n",
      "[1500]\ttraining's rmse: 3.47569\tvalid_1's rmse: 3.60806\n",
      "[2000]\ttraining's rmse: 3.43235\tvalid_1's rmse: 3.60816\n",
      "Early stopping, best iteration is:\n",
      "[1823]\ttraining's rmse: 3.4474\tvalid_1's rmse: 3.60753\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56951\tvalid_1's rmse: 3.81424\n",
      "[1000]\ttraining's rmse: 3.48575\tvalid_1's rmse: 3.79821\n",
      "[1500]\ttraining's rmse: 3.43124\tvalid_1's rmse: 3.79377\n",
      "[2000]\ttraining's rmse: 3.3863\tvalid_1's rmse: 3.79259\n",
      "[2500]\ttraining's rmse: 3.34524\tvalid_1's rmse: 3.7918\n",
      "Early stopping, best iteration is:\n",
      "[2356]\ttraining's rmse: 3.35616\tvalid_1's rmse: 3.79173\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60896\tvalid_1's rmse: 3.65332\n",
      "[1000]\ttraining's rmse: 3.52643\tvalid_1's rmse: 3.63616\n",
      "[1500]\ttraining's rmse: 3.47224\tvalid_1's rmse: 3.63055\n",
      "[2000]\ttraining's rmse: 3.42656\tvalid_1's rmse: 3.62841\n",
      "Early stopping, best iteration is:\n",
      "[2166]\ttraining's rmse: 3.41245\tvalid_1's rmse: 3.62818\n",
      "   52 | 04m12s |   -3.66838 |             0.8040 |        19.8016 |             0.7530 |             0.8931 |     14.7183 |             49.9208 |            44.8945 |            14.4731 |           0.7532 |      30.3537 |      6.1431 |       7.1840 |      0.3883 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69512\tvalid_1's rmse: 3.74925\n",
      "[1000]\ttraining's rmse: 3.64886\tvalid_1's rmse: 3.71844\n",
      "[1500]\ttraining's rmse: 3.62083\tvalid_1's rmse: 3.70494\n",
      "[2000]\ttraining's rmse: 3.6006\tvalid_1's rmse: 3.69806\n",
      "[2500]\ttraining's rmse: 3.5832\tvalid_1's rmse: 3.69384\n",
      "[3000]\ttraining's rmse: 3.5682\tvalid_1's rmse: 3.69156\n",
      "[3500]\ttraining's rmse: 3.55364\tvalid_1's rmse: 3.68957\n",
      "[4000]\ttraining's rmse: 3.53993\tvalid_1's rmse: 3.68859\n",
      "[4500]\ttraining's rmse: 3.52695\tvalid_1's rmse: 3.68777\n",
      "[5000]\ttraining's rmse: 3.5151\tvalid_1's rmse: 3.68736\n",
      "Early stopping, best iteration is:\n",
      "[5094]\ttraining's rmse: 3.51286\tvalid_1's rmse: 3.68728\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70975\tvalid_1's rmse: 3.68375\n",
      "[1000]\ttraining's rmse: 3.66255\tvalid_1's rmse: 3.65745\n",
      "[1500]\ttraining's rmse: 3.63421\tvalid_1's rmse: 3.64552\n",
      "[2000]\ttraining's rmse: 3.61323\tvalid_1's rmse: 3.63866\n",
      "[2500]\ttraining's rmse: 3.59579\tvalid_1's rmse: 3.63501\n",
      "[3000]\ttraining's rmse: 3.58018\tvalid_1's rmse: 3.63252\n",
      "[3500]\ttraining's rmse: 3.56561\tvalid_1's rmse: 3.63063\n",
      "[4000]\ttraining's rmse: 3.55163\tvalid_1's rmse: 3.62927\n",
      "[4500]\ttraining's rmse: 3.53842\tvalid_1's rmse: 3.62844\n",
      "[5000]\ttraining's rmse: 3.52558\tvalid_1's rmse: 3.6273\n",
      "Early stopping, best iteration is:\n",
      "[5253]\ttraining's rmse: 3.51875\tvalid_1's rmse: 3.62695\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.71451\tvalid_1's rmse: 3.65747\n",
      "[1000]\ttraining's rmse: 3.66684\tvalid_1's rmse: 3.6317\n",
      "[1500]\ttraining's rmse: 3.63867\tvalid_1's rmse: 3.6207\n",
      "[2000]\ttraining's rmse: 3.61793\tvalid_1's rmse: 3.61518\n",
      "[2500]\ttraining's rmse: 3.5995\tvalid_1's rmse: 3.6122\n",
      "[3000]\ttraining's rmse: 3.58359\tvalid_1's rmse: 3.61019\n",
      "[3500]\ttraining's rmse: 3.5691\tvalid_1's rmse: 3.60884\n",
      "[4000]\ttraining's rmse: 3.55559\tvalid_1's rmse: 3.60848\n",
      "[4500]\ttraining's rmse: 3.54234\tvalid_1's rmse: 3.6079\n",
      "[5000]\ttraining's rmse: 3.53001\tvalid_1's rmse: 3.60779\n",
      "[5500]\ttraining's rmse: 3.51768\tvalid_1's rmse: 3.60751\n",
      "Early stopping, best iteration is:\n",
      "[5322]\ttraining's rmse: 3.52188\tvalid_1's rmse: 3.60743\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66614\tvalid_1's rmse: 3.8567\n",
      "[1000]\ttraining's rmse: 3.61928\tvalid_1's rmse: 3.82798\n",
      "[1500]\ttraining's rmse: 3.59135\tvalid_1's rmse: 3.81602\n",
      "[2000]\ttraining's rmse: 3.57129\tvalid_1's rmse: 3.80992\n",
      "[2500]\ttraining's rmse: 3.55358\tvalid_1's rmse: 3.80618\n",
      "[3000]\ttraining's rmse: 3.53692\tvalid_1's rmse: 3.80347\n",
      "[3500]\ttraining's rmse: 3.52276\tvalid_1's rmse: 3.80195\n",
      "[4000]\ttraining's rmse: 3.50934\tvalid_1's rmse: 3.80084\n",
      "[4500]\ttraining's rmse: 3.49588\tvalid_1's rmse: 3.80025\n",
      "[5000]\ttraining's rmse: 3.48297\tvalid_1's rmse: 3.79975\n",
      "[5500]\ttraining's rmse: 3.47108\tvalid_1's rmse: 3.79914\n",
      "[6000]\ttraining's rmse: 3.45941\tvalid_1's rmse: 3.79869\n",
      "Early stopping, best iteration is:\n",
      "[5889]\ttraining's rmse: 3.46208\tvalid_1's rmse: 3.79858\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70982\tvalid_1's rmse: 3.67553\n",
      "[1000]\ttraining's rmse: 3.66177\tvalid_1's rmse: 3.65035\n",
      "[1500]\ttraining's rmse: 3.63366\tvalid_1's rmse: 3.63993\n",
      "[2000]\ttraining's rmse: 3.61205\tvalid_1's rmse: 3.63453\n",
      "[2500]\ttraining's rmse: 3.59542\tvalid_1's rmse: 3.63164\n",
      "[3000]\ttraining's rmse: 3.58011\tvalid_1's rmse: 3.62997\n",
      "[3500]\ttraining's rmse: 3.56607\tvalid_1's rmse: 3.62897\n",
      "[4000]\ttraining's rmse: 3.55217\tvalid_1's rmse: 3.6283\n",
      "[4500]\ttraining's rmse: 3.5393\tvalid_1's rmse: 3.6279\n",
      "[5000]\ttraining's rmse: 3.52626\tvalid_1's rmse: 3.628\n",
      "Early stopping, best iteration is:\n",
      "[4812]\ttraining's rmse: 3.53107\tvalid_1's rmse: 3.62775\n",
      "   53 | 04m05s |   -3.67026 |             0.8612 |        17.0982 |             0.7848 |             0.1303 |      5.3016 |             49.5524 |            32.8455 |            96.9934 |           0.9691 |      31.4751 |      9.0241 |       0.4759 |      0.8011 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59359\tvalid_1's rmse: 3.70726\n",
      "[1000]\ttraining's rmse: 3.51797\tvalid_1's rmse: 3.68782\n",
      "[1500]\ttraining's rmse: 3.46332\tvalid_1's rmse: 3.68378\n",
      "[2000]\ttraining's rmse: 3.41636\tvalid_1's rmse: 3.68234\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.42177\tvalid_1's rmse: 3.68219\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60651\tvalid_1's rmse: 3.64874\n",
      "[1000]\ttraining's rmse: 3.52924\tvalid_1's rmse: 3.63136\n",
      "[1500]\ttraining's rmse: 3.475\tvalid_1's rmse: 3.62586\n",
      "[2000]\ttraining's rmse: 3.42733\tvalid_1's rmse: 3.62423\n",
      "Early stopping, best iteration is:\n",
      "[2023]\ttraining's rmse: 3.4252\tvalid_1's rmse: 3.62415\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61157\tvalid_1's rmse: 3.62489\n",
      "[1000]\ttraining's rmse: 3.53426\tvalid_1's rmse: 3.60837\n",
      "[1500]\ttraining's rmse: 3.47987\tvalid_1's rmse: 3.60493\n",
      "[2000]\ttraining's rmse: 3.43086\tvalid_1's rmse: 3.6042\n",
      "Early stopping, best iteration is:\n",
      "[1880]\ttraining's rmse: 3.44181\tvalid_1's rmse: 3.60388\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56591\tvalid_1's rmse: 3.81327\n",
      "[1000]\ttraining's rmse: 3.48961\tvalid_1's rmse: 3.79797\n",
      "[1500]\ttraining's rmse: 3.43381\tvalid_1's rmse: 3.79322\n",
      "[2000]\ttraining's rmse: 3.38663\tvalid_1's rmse: 3.79211\n",
      "Early stopping, best iteration is:\n",
      "[2133]\ttraining's rmse: 3.37481\tvalid_1's rmse: 3.79172\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60741\tvalid_1's rmse: 3.64351\n",
      "[1000]\ttraining's rmse: 3.52822\tvalid_1's rmse: 3.62812\n",
      "[1500]\ttraining's rmse: 3.47374\tvalid_1's rmse: 3.62352\n",
      "Early stopping, best iteration is:\n",
      "[1784]\ttraining's rmse: 3.4461\tvalid_1's rmse: 3.6223\n",
      "   54 | 03m34s |   -3.66549 |             0.7366 |        15.4316 |             0.1447 |             0.4402 |     13.3359 |             49.5252 |            44.9193 |            96.1962 |           0.1105 |      44.5399 |      8.4967 |       2.2124 |      0.8924 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57333\tvalid_1's rmse: 3.70498\n",
      "[1000]\ttraining's rmse: 3.48776\tvalid_1's rmse: 3.68699\n",
      "[1500]\ttraining's rmse: 3.429\tvalid_1's rmse: 3.68177\n",
      "[2000]\ttraining's rmse: 3.38149\tvalid_1's rmse: 3.67974\n",
      "[2500]\ttraining's rmse: 3.34026\tvalid_1's rmse: 3.67958\n",
      "Early stopping, best iteration is:\n",
      "[2315]\ttraining's rmse: 3.35503\tvalid_1's rmse: 3.67932\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58573\tvalid_1's rmse: 3.64849\n",
      "[1000]\ttraining's rmse: 3.4988\tvalid_1's rmse: 3.63252\n",
      "[1500]\ttraining's rmse: 3.43968\tvalid_1's rmse: 3.62803\n",
      "[2000]\ttraining's rmse: 3.3919\tvalid_1's rmse: 3.6266\n",
      "Early stopping, best iteration is:\n",
      "[1990]\ttraining's rmse: 3.39293\tvalid_1's rmse: 3.62653\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59071\tvalid_1's rmse: 3.62487\n",
      "[1000]\ttraining's rmse: 3.50353\tvalid_1's rmse: 3.60952\n",
      "[1500]\ttraining's rmse: 3.44429\tvalid_1's rmse: 3.60609\n",
      "Early stopping, best iteration is:\n",
      "[1782]\ttraining's rmse: 3.41587\tvalid_1's rmse: 3.60505\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54624\tvalid_1's rmse: 3.8083\n",
      "[1000]\ttraining's rmse: 3.45879\tvalid_1's rmse: 3.79385\n",
      "[1500]\ttraining's rmse: 3.40066\tvalid_1's rmse: 3.79047\n",
      "[2000]\ttraining's rmse: 3.35406\tvalid_1's rmse: 3.79001\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's rmse: 3.36593\tvalid_1's rmse: 3.7898\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58445\tvalid_1's rmse: 3.64429\n",
      "[1000]\ttraining's rmse: 3.49789\tvalid_1's rmse: 3.63122\n",
      "[1500]\ttraining's rmse: 3.44009\tvalid_1's rmse: 3.62657\n",
      "[2000]\ttraining's rmse: 3.39324\tvalid_1's rmse: 3.62518\n",
      "Early stopping, best iteration is:\n",
      "[2133]\ttraining's rmse: 3.38169\tvalid_1's rmse: 3.62498\n",
      "   55 | 04m29s |   -3.66575 |             0.9611 |         1.5615 |             0.4395 |             0.7733 |     14.2693 |             47.5179 |            37.1479 |            84.0370 |           0.6304 |      43.8696 |      8.8145 |       8.7445 |      0.3393 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00016657]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5983\tvalid_1's rmse: 3.70573\n",
      "[1000]\ttraining's rmse: 3.52925\tvalid_1's rmse: 3.68813\n",
      "[1500]\ttraining's rmse: 3.47959\tvalid_1's rmse: 3.6843\n",
      "[2000]\ttraining's rmse: 3.43595\tvalid_1's rmse: 3.68326\n",
      "Early stopping, best iteration is:\n",
      "[1871]\ttraining's rmse: 3.44679\tvalid_1's rmse: 3.683\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61267\tvalid_1's rmse: 3.64809\n",
      "[1000]\ttraining's rmse: 3.54205\tvalid_1's rmse: 3.63322\n",
      "[1500]\ttraining's rmse: 3.49187\tvalid_1's rmse: 3.62837\n",
      "Early stopping, best iteration is:\n",
      "[1570]\ttraining's rmse: 3.48537\tvalid_1's rmse: 3.62783\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61722\tvalid_1's rmse: 3.624\n",
      "[1000]\ttraining's rmse: 3.54737\tvalid_1's rmse: 3.60883\n",
      "[1500]\ttraining's rmse: 3.49634\tvalid_1's rmse: 3.6057\n",
      "Early stopping, best iteration is:\n",
      "[1518]\ttraining's rmse: 3.49452\tvalid_1's rmse: 3.60545\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57254\tvalid_1's rmse: 3.80982\n",
      "[1000]\ttraining's rmse: 3.50233\tvalid_1's rmse: 3.79631\n",
      "[1500]\ttraining's rmse: 3.45224\tvalid_1's rmse: 3.7941\n",
      "[2000]\ttraining's rmse: 3.40856\tvalid_1's rmse: 3.79284\n",
      "Early stopping, best iteration is:\n",
      "[2018]\ttraining's rmse: 3.40675\tvalid_1's rmse: 3.79266\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61147\tvalid_1's rmse: 3.64229\n",
      "[1000]\ttraining's rmse: 3.54179\tvalid_1's rmse: 3.62896\n",
      "[1500]\ttraining's rmse: 3.49054\tvalid_1's rmse: 3.62667\n",
      "Early stopping, best iteration is:\n",
      "[1740]\ttraining's rmse: 3.46851\tvalid_1's rmse: 3.6259\n",
      "   56 | 03m56s |   -3.66760 |             0.6189 |         3.5270 |             0.6447 |             0.9206 |     14.7927 |              5.8187 |            42.9508 |            98.7329 |           0.1909 |      36.9228 |      0.6582 |       1.4332 |      0.6364 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61141\tvalid_1's rmse: 3.70721\n",
      "[1000]\ttraining's rmse: 3.55679\tvalid_1's rmse: 3.69167\n",
      "[1500]\ttraining's rmse: 3.51601\tvalid_1's rmse: 3.68664\n",
      "[2000]\ttraining's rmse: 3.48254\tvalid_1's rmse: 3.68534\n",
      "Early stopping, best iteration is:\n",
      "[1897]\ttraining's rmse: 3.48793\tvalid_1's rmse: 3.68508\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62551\tvalid_1's rmse: 3.64936\n",
      "[1000]\ttraining's rmse: 3.57036\tvalid_1's rmse: 3.63561\n",
      "[1500]\ttraining's rmse: 3.52992\tvalid_1's rmse: 3.62998\n",
      "[2000]\ttraining's rmse: 3.49848\tvalid_1's rmse: 3.62798\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 3.49159\tvalid_1's rmse: 3.62742\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62986\tvalid_1's rmse: 3.62296\n",
      "[1000]\ttraining's rmse: 3.57059\tvalid_1's rmse: 3.60948\n",
      "[1500]\ttraining's rmse: 3.53345\tvalid_1's rmse: 3.60645\n",
      "Early stopping, best iteration is:\n",
      "[1675]\ttraining's rmse: 3.52023\tvalid_1's rmse: 3.60593\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58353\tvalid_1's rmse: 3.81165\n",
      "[1000]\ttraining's rmse: 3.52367\tvalid_1's rmse: 3.79728\n",
      "[1500]\ttraining's rmse: 3.48213\tvalid_1's rmse: 3.79465\n",
      "[2000]\ttraining's rmse: 3.44742\tvalid_1's rmse: 3.79362\n",
      "[2500]\ttraining's rmse: 3.41539\tvalid_1's rmse: 3.79245\n",
      "Early stopping, best iteration is:\n",
      "[2308]\ttraining's rmse: 3.42677\tvalid_1's rmse: 3.79225\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62577\tvalid_1's rmse: 3.64052\n",
      "[1000]\ttraining's rmse: 3.56581\tvalid_1's rmse: 3.62789\n",
      "[1500]\ttraining's rmse: 3.52848\tvalid_1's rmse: 3.62516\n",
      "[2000]\ttraining's rmse: 3.49275\tvalid_1's rmse: 3.62412\n",
      "Early stopping, best iteration is:\n",
      "[2247]\ttraining's rmse: 3.4768\tvalid_1's rmse: 3.62371\n",
      "   57 | 03m39s |   -3.66751 |             0.6945 |        18.4586 |             0.9323 |             0.6442 |      6.4224 |             47.8592 |            40.9876 |            12.3394 |           0.7844 |      44.4032 |      0.3628 |       0.7337 |      0.6973 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6238\tvalid_1's rmse: 3.70971\n",
      "[1000]\ttraining's rmse: 3.56556\tvalid_1's rmse: 3.69138\n",
      "[1500]\ttraining's rmse: 3.52366\tvalid_1's rmse: 3.6871\n",
      "[2000]\ttraining's rmse: 3.48621\tvalid_1's rmse: 3.68628\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.49063\tvalid_1's rmse: 3.68602\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63661\tvalid_1's rmse: 3.65006\n",
      "[1000]\ttraining's rmse: 3.57945\tvalid_1's rmse: 3.63536\n",
      "[1500]\ttraining's rmse: 3.5376\tvalid_1's rmse: 3.6308\n",
      "[2000]\ttraining's rmse: 3.50011\tvalid_1's rmse: 3.62847\n",
      "[2500]\ttraining's rmse: 3.46659\tvalid_1's rmse: 3.62789\n",
      "Early stopping, best iteration is:\n",
      "[2406]\ttraining's rmse: 3.47299\tvalid_1's rmse: 3.62762\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64183\tvalid_1's rmse: 3.62574\n",
      "[1000]\ttraining's rmse: 3.58306\tvalid_1's rmse: 3.61149\n",
      "[1500]\ttraining's rmse: 3.54037\tvalid_1's rmse: 3.60899\n",
      "[2000]\ttraining's rmse: 3.5027\tvalid_1's rmse: 3.6077\n",
      "Early stopping, best iteration is:\n",
      "[1974]\ttraining's rmse: 3.50461\tvalid_1's rmse: 3.60749\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5945\tvalid_1's rmse: 3.81483\n",
      "[1000]\ttraining's rmse: 3.53827\tvalid_1's rmse: 3.80158\n",
      "[1500]\ttraining's rmse: 3.49616\tvalid_1's rmse: 3.79731\n",
      "Early stopping, best iteration is:\n",
      "[1779]\ttraining's rmse: 3.47499\tvalid_1's rmse: 3.7962\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6368\tvalid_1's rmse: 3.64466\n",
      "[1000]\ttraining's rmse: 3.57854\tvalid_1's rmse: 3.63123\n",
      "[1500]\ttraining's rmse: 3.53677\tvalid_1's rmse: 3.62805\n",
      "Early stopping, best iteration is:\n",
      "[1623]\ttraining's rmse: 3.52725\tvalid_1's rmse: 3.62766\n",
      "   58 | 03m31s |   -3.66964 |             0.3766 |         3.0946 |             0.2296 |             0.9062 |     14.7341 |              5.8157 |            30.0462 |            95.9968 |           0.4395 |      31.7910 |      1.1074 |       0.7623 |      0.3665 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59942\tvalid_1's rmse: 3.70373\n",
      "[1000]\ttraining's rmse: 3.53057\tvalid_1's rmse: 3.68804\n",
      "[1500]\ttraining's rmse: 3.4773\tvalid_1's rmse: 3.68483\n",
      "Early stopping, best iteration is:\n",
      "[1752]\ttraining's rmse: 3.45329\tvalid_1's rmse: 3.68402\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61362\tvalid_1's rmse: 3.64422\n",
      "[1000]\ttraining's rmse: 3.54288\tvalid_1's rmse: 3.62991\n",
      "[1500]\ttraining's rmse: 3.48977\tvalid_1's rmse: 3.62689\n",
      "[2000]\ttraining's rmse: 3.44302\tvalid_1's rmse: 3.62585\n",
      "Early stopping, best iteration is:\n",
      "[1821]\ttraining's rmse: 3.45919\tvalid_1's rmse: 3.62578\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61837\tvalid_1's rmse: 3.62218\n",
      "[1000]\ttraining's rmse: 3.54766\tvalid_1's rmse: 3.60922\n",
      "[1500]\ttraining's rmse: 3.49403\tvalid_1's rmse: 3.60679\n",
      "Early stopping, best iteration is:\n",
      "[1650]\ttraining's rmse: 3.47948\tvalid_1's rmse: 3.60625\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57259\tvalid_1's rmse: 3.80938\n",
      "[1000]\ttraining's rmse: 3.50137\tvalid_1's rmse: 3.79808\n",
      "[1500]\ttraining's rmse: 3.44803\tvalid_1's rmse: 3.79514\n",
      "[2000]\ttraining's rmse: 3.40134\tvalid_1's rmse: 3.79495\n",
      "Early stopping, best iteration is:\n",
      "[2094]\ttraining's rmse: 3.39298\tvalid_1's rmse: 3.79449\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61397\tvalid_1's rmse: 3.64155\n",
      "[1000]\ttraining's rmse: 3.54313\tvalid_1's rmse: 3.63032\n",
      "[1500]\ttraining's rmse: 3.48999\tvalid_1's rmse: 3.62726\n",
      "Early stopping, best iteration is:\n",
      "[1710]\ttraining's rmse: 3.46969\tvalid_1's rmse: 3.62716\n",
      "   59 | 03m48s |   -3.66818 |             0.4607 |         2.7659 |             0.6318 |             0.7698 |     14.9431 |             49.5747 |            44.5819 |            96.9567 |           0.9852 |      42.5110 |      0.8502 |       0.2360 |      0.3497 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00035435]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6139\tvalid_1's rmse: 3.7071\n",
      "[1000]\ttraining's rmse: 3.55786\tvalid_1's rmse: 3.68804\n",
      "[1500]\ttraining's rmse: 3.51867\tvalid_1's rmse: 3.68314\n",
      "[2000]\ttraining's rmse: 3.48635\tvalid_1's rmse: 3.6815\n",
      "[2500]\ttraining's rmse: 3.45328\tvalid_1's rmse: 3.68039\n",
      "Early stopping, best iteration is:\n",
      "[2533]\ttraining's rmse: 3.45074\tvalid_1's rmse: 3.68026\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62853\tvalid_1's rmse: 3.64749\n",
      "[1000]\ttraining's rmse: 3.56901\tvalid_1's rmse: 3.63106\n",
      "[1500]\ttraining's rmse: 3.53024\tvalid_1's rmse: 3.6262\n",
      "[2000]\ttraining's rmse: 3.49268\tvalid_1's rmse: 3.62446\n",
      "[2500]\ttraining's rmse: 3.46277\tvalid_1's rmse: 3.62369\n",
      "[3000]\ttraining's rmse: 3.43072\tvalid_1's rmse: 3.62283\n",
      "Early stopping, best iteration is:\n",
      "[3020]\ttraining's rmse: 3.42988\tvalid_1's rmse: 3.62282\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63024\tvalid_1's rmse: 3.62229\n",
      "[1000]\ttraining's rmse: 3.57271\tvalid_1's rmse: 3.60803\n",
      "[1500]\ttraining's rmse: 3.53142\tvalid_1's rmse: 3.60392\n",
      "Early stopping, best iteration is:\n",
      "[1718]\ttraining's rmse: 3.51695\tvalid_1's rmse: 3.60335\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58437\tvalid_1's rmse: 3.8104\n",
      "[1000]\ttraining's rmse: 3.52649\tvalid_1's rmse: 3.79576\n",
      "[1500]\ttraining's rmse: 3.4868\tvalid_1's rmse: 3.79137\n",
      "[2000]\ttraining's rmse: 3.45253\tvalid_1's rmse: 3.79005\n",
      "[2500]\ttraining's rmse: 3.42116\tvalid_1's rmse: 3.78923\n",
      "Early stopping, best iteration is:\n",
      "[2502]\ttraining's rmse: 3.42098\tvalid_1's rmse: 3.78921\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6266\tvalid_1's rmse: 3.63937\n",
      "[1000]\ttraining's rmse: 3.56862\tvalid_1's rmse: 3.62547\n",
      "[1500]\ttraining's rmse: 3.52901\tvalid_1's rmse: 3.62208\n",
      "Early stopping, best iteration is:\n",
      "[1753]\ttraining's rmse: 3.51058\tvalid_1's rmse: 3.62057\n",
      "   60 | 04m09s | \u001b[35m  -3.66388\u001b[0m | \u001b[32m            0.8096\u001b[0m | \u001b[32m       17.2832\u001b[0m | \u001b[32m            0.1273\u001b[0m | \u001b[32m            0.6083\u001b[0m | \u001b[32m     7.3938\u001b[0m | \u001b[32m             6.4992\u001b[0m | \u001b[32m           30.2793\u001b[0m | \u001b[32m           97.3027\u001b[0m | \u001b[32m          0.9780\u001b[0m | \u001b[32m     40.5826\u001b[0m | \u001b[32m     2.8245\u001b[0m | \u001b[32m      9.7233\u001b[0m | \u001b[32m     0.3116\u001b[0m | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61172\tvalid_1's rmse: 3.71072\n",
      "[1000]\ttraining's rmse: 3.5456\tvalid_1's rmse: 3.69038\n",
      "[1500]\ttraining's rmse: 3.50041\tvalid_1's rmse: 3.68358\n",
      "[2000]\ttraining's rmse: 3.46495\tvalid_1's rmse: 3.68136\n",
      "[2500]\ttraining's rmse: 3.43347\tvalid_1's rmse: 3.68073\n",
      "Early stopping, best iteration is:\n",
      "[2440]\ttraining's rmse: 3.43742\tvalid_1's rmse: 3.68038\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62513\tvalid_1's rmse: 3.6522\n",
      "[1000]\ttraining's rmse: 3.55646\tvalid_1's rmse: 3.63419\n",
      "[1500]\ttraining's rmse: 3.51318\tvalid_1's rmse: 3.6284\n",
      "[2000]\ttraining's rmse: 3.47682\tvalid_1's rmse: 3.62682\n",
      "[2500]\ttraining's rmse: 3.44506\tvalid_1's rmse: 3.62605\n",
      "[3000]\ttraining's rmse: 3.41616\tvalid_1's rmse: 3.62498\n",
      "Early stopping, best iteration is:\n",
      "[3027]\ttraining's rmse: 3.41452\tvalid_1's rmse: 3.62495\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62987\tvalid_1's rmse: 3.62961\n",
      "[1000]\ttraining's rmse: 3.56211\tvalid_1's rmse: 3.6121\n",
      "[1500]\ttraining's rmse: 3.5177\tvalid_1's rmse: 3.60727\n",
      "[2000]\ttraining's rmse: 3.4819\tvalid_1's rmse: 3.60626\n",
      "Early stopping, best iteration is:\n",
      "[2195]\ttraining's rmse: 3.469\tvalid_1's rmse: 3.60588\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.585\tvalid_1's rmse: 3.81224\n",
      "[1000]\ttraining's rmse: 3.51645\tvalid_1's rmse: 3.7962\n",
      "[1500]\ttraining's rmse: 3.47288\tvalid_1's rmse: 3.79152\n",
      "[2000]\ttraining's rmse: 3.43823\tvalid_1's rmse: 3.79023\n",
      "[2500]\ttraining's rmse: 3.40755\tvalid_1's rmse: 3.78941\n",
      "Early stopping, best iteration is:\n",
      "[2381]\ttraining's rmse: 3.4148\tvalid_1's rmse: 3.7893\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62348\tvalid_1's rmse: 3.64617\n",
      "[1000]\ttraining's rmse: 3.55502\tvalid_1's rmse: 3.63072\n",
      "[1500]\ttraining's rmse: 3.51111\tvalid_1's rmse: 3.62495\n",
      "[2000]\ttraining's rmse: 3.47676\tvalid_1's rmse: 3.62271\n",
      "Early stopping, best iteration is:\n",
      "[2086]\ttraining's rmse: 3.47105\tvalid_1's rmse: 3.6224\n",
      "   61 | 04m25s |   -3.66520 |             0.9599 |        17.6965 |             0.5564 |             0.6667 |     13.8240 |             49.5344 |            44.3059 |            99.7540 |           0.6713 |      30.6079 |      5.5317 |       9.4025 |      0.1665 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00101068]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58049\tvalid_1's rmse: 3.70931\n",
      "[1000]\ttraining's rmse: 3.50047\tvalid_1's rmse: 3.69135\n",
      "[1500]\ttraining's rmse: 3.44557\tvalid_1's rmse: 3.68564\n",
      "[2000]\ttraining's rmse: 3.40215\tvalid_1's rmse: 3.68403\n",
      "Early stopping, best iteration is:\n",
      "[2158]\ttraining's rmse: 3.38947\tvalid_1's rmse: 3.68371\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59462\tvalid_1's rmse: 3.6518\n",
      "[1000]\ttraining's rmse: 3.51149\tvalid_1's rmse: 3.6338\n",
      "[1500]\ttraining's rmse: 3.45661\tvalid_1's rmse: 3.62927\n",
      "[2000]\ttraining's rmse: 3.41316\tvalid_1's rmse: 3.62837\n",
      "Early stopping, best iteration is:\n",
      "[1923]\ttraining's rmse: 3.41942\tvalid_1's rmse: 3.62825\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59683\tvalid_1's rmse: 3.62866\n",
      "[1000]\ttraining's rmse: 3.51452\tvalid_1's rmse: 3.61226\n",
      "[1500]\ttraining's rmse: 3.45904\tvalid_1's rmse: 3.60792\n",
      "[2000]\ttraining's rmse: 3.41529\tvalid_1's rmse: 3.60697\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's rmse: 3.42321\tvalid_1's rmse: 3.6068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55379\tvalid_1's rmse: 3.81074\n",
      "[1000]\ttraining's rmse: 3.46948\tvalid_1's rmse: 3.79388\n",
      "[1500]\ttraining's rmse: 3.41428\tvalid_1's rmse: 3.79\n",
      "[2000]\ttraining's rmse: 3.37126\tvalid_1's rmse: 3.78952\n",
      "Early stopping, best iteration is:\n",
      "[1810]\ttraining's rmse: 3.38631\tvalid_1's rmse: 3.78933\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59104\tvalid_1's rmse: 3.64783\n",
      "[1000]\ttraining's rmse: 3.50697\tvalid_1's rmse: 3.63245\n",
      "[1500]\ttraining's rmse: 3.45238\tvalid_1's rmse: 3.62787\n",
      "[2000]\ttraining's rmse: 3.4092\tvalid_1's rmse: 3.62638\n",
      "Early stopping, best iteration is:\n",
      "[2164]\ttraining's rmse: 3.39663\tvalid_1's rmse: 3.62614\n",
      "   62 | 03m56s |   -3.66745 |             0.4109 |         0.1631 |             0.5732 |             0.6969 |     10.0445 |              5.0529 |            44.3577 |            10.9664 |           0.0293 |      37.0298 |      0.4647 |       9.3024 |      0.1196 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65267\tvalid_1's rmse: 3.71584\n",
      "[1000]\ttraining's rmse: 3.61425\tvalid_1's rmse: 3.69749\n",
      "[1500]\ttraining's rmse: 3.58912\tvalid_1's rmse: 3.69145\n",
      "[2000]\ttraining's rmse: 3.56854\tvalid_1's rmse: 3.68992\n",
      "[2500]\ttraining's rmse: 3.5491\tvalid_1's rmse: 3.68744\n",
      "Early stopping, best iteration is:\n",
      "[2773]\ttraining's rmse: 3.54018\tvalid_1's rmse: 3.68699\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66525\tvalid_1's rmse: 3.65819\n",
      "[1000]\ttraining's rmse: 3.62491\tvalid_1's rmse: 3.64189\n",
      "[1500]\ttraining's rmse: 3.60112\tvalid_1's rmse: 3.63579\n",
      "[2000]\ttraining's rmse: 3.57954\tvalid_1's rmse: 3.63231\n",
      "[2500]\ttraining's rmse: 3.5603\tvalid_1's rmse: 3.63036\n",
      "[3000]\ttraining's rmse: 3.54265\tvalid_1's rmse: 3.62904\n",
      "[3500]\ttraining's rmse: 3.52588\tvalid_1's rmse: 3.62721\n",
      "Early stopping, best iteration is:\n",
      "[3347]\ttraining's rmse: 3.53102\tvalid_1's rmse: 3.627\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66961\tvalid_1's rmse: 3.63037\n",
      "[1000]\ttraining's rmse: 3.62936\tvalid_1's rmse: 3.61347\n",
      "[1500]\ttraining's rmse: 3.60251\tvalid_1's rmse: 3.609\n",
      "[2000]\ttraining's rmse: 3.58095\tvalid_1's rmse: 3.60638\n",
      "[2500]\ttraining's rmse: 3.56291\tvalid_1's rmse: 3.60551\n",
      "Early stopping, best iteration is:\n",
      "[2641]\ttraining's rmse: 3.55708\tvalid_1's rmse: 3.60502\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62351\tvalid_1's rmse: 3.81839\n",
      "[1000]\ttraining's rmse: 3.58009\tvalid_1's rmse: 3.80207\n",
      "[1500]\ttraining's rmse: 3.55425\tvalid_1's rmse: 3.79771\n",
      "[2000]\ttraining's rmse: 3.53358\tvalid_1's rmse: 3.79535\n",
      "Early stopping, best iteration is:\n",
      "[2128]\ttraining's rmse: 3.52918\tvalid_1's rmse: 3.79488\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66565\tvalid_1's rmse: 3.64774\n",
      "[1000]\ttraining's rmse: 3.62545\tvalid_1's rmse: 3.63222\n",
      "[1500]\ttraining's rmse: 3.59685\tvalid_1's rmse: 3.62606\n",
      "[2000]\ttraining's rmse: 3.57393\tvalid_1's rmse: 3.62403\n",
      "[2500]\ttraining's rmse: 3.55425\tvalid_1's rmse: 3.6234\n",
      "Early stopping, best iteration is:\n",
      "[2600]\ttraining's rmse: 3.5514\tvalid_1's rmse: 3.62292\n",
      "   63 | 04m30s |   -3.66802 |             0.8652 |        19.1996 |             0.5337 |             0.9419 |      5.5021 |              5.2308 |            41.7908 |            99.6356 |           0.8053 |      44.4120 |      7.0681 |       2.4606 |      0.6102 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64757\tvalid_1's rmse: 3.71588\n",
      "[1000]\ttraining's rmse: 3.60511\tvalid_1's rmse: 3.69675\n",
      "[1500]\ttraining's rmse: 3.57463\tvalid_1's rmse: 3.68923\n",
      "[2000]\ttraining's rmse: 3.54947\tvalid_1's rmse: 3.68662\n",
      "[2500]\ttraining's rmse: 3.52707\tvalid_1's rmse: 3.68526\n",
      "[3000]\ttraining's rmse: 3.50582\tvalid_1's rmse: 3.68468\n",
      "Early stopping, best iteration is:\n",
      "[2978]\ttraining's rmse: 3.5066\tvalid_1's rmse: 3.6846\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66086\tvalid_1's rmse: 3.65827\n",
      "[1000]\ttraining's rmse: 3.61567\tvalid_1's rmse: 3.6405\n",
      "[1500]\ttraining's rmse: 3.58702\tvalid_1's rmse: 3.63418\n",
      "[2000]\ttraining's rmse: 3.56118\tvalid_1's rmse: 3.63139\n",
      "[2500]\ttraining's rmse: 3.53913\tvalid_1's rmse: 3.63002\n",
      "[3000]\ttraining's rmse: 3.51733\tvalid_1's rmse: 3.62901\n",
      "[3500]\ttraining's rmse: 3.49733\tvalid_1's rmse: 3.62844\n",
      "[4000]\ttraining's rmse: 3.47809\tvalid_1's rmse: 3.62788\n",
      "Early stopping, best iteration is:\n",
      "[4093]\ttraining's rmse: 3.47478\tvalid_1's rmse: 3.6278\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6668\tvalid_1's rmse: 3.63056\n",
      "[1000]\ttraining's rmse: 3.62153\tvalid_1's rmse: 3.61281\n",
      "[1500]\ttraining's rmse: 3.59211\tvalid_1's rmse: 3.608\n",
      "[2000]\ttraining's rmse: 3.56768\tvalid_1's rmse: 3.60606\n",
      "[2500]\ttraining's rmse: 3.54474\tvalid_1's rmse: 3.60529\n",
      "[3000]\ttraining's rmse: 3.52347\tvalid_1's rmse: 3.60475\n",
      "Early stopping, best iteration is:\n",
      "[2943]\ttraining's rmse: 3.52575\tvalid_1's rmse: 3.60465\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61923\tvalid_1's rmse: 3.81786\n",
      "[1000]\ttraining's rmse: 3.57314\tvalid_1's rmse: 3.80191\n",
      "[1500]\ttraining's rmse: 3.54411\tvalid_1's rmse: 3.79644\n",
      "[2000]\ttraining's rmse: 3.52044\tvalid_1's rmse: 3.79442\n",
      "[2500]\ttraining's rmse: 3.49786\tvalid_1's rmse: 3.79341\n",
      "[3000]\ttraining's rmse: 3.47637\tvalid_1's rmse: 3.79238\n",
      "Early stopping, best iteration is:\n",
      "[3267]\ttraining's rmse: 3.46523\tvalid_1's rmse: 3.79223\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6624\tvalid_1's rmse: 3.64923\n",
      "[1000]\ttraining's rmse: 3.61634\tvalid_1's rmse: 3.63255\n",
      "[1500]\ttraining's rmse: 3.58501\tvalid_1's rmse: 3.62728\n",
      "[2000]\ttraining's rmse: 3.56043\tvalid_1's rmse: 3.62475\n",
      "[2500]\ttraining's rmse: 3.53763\tvalid_1's rmse: 3.62401\n",
      "Early stopping, best iteration is:\n",
      "[2527]\ttraining's rmse: 3.53638\tvalid_1's rmse: 3.62391\n",
      "   64 | 04m49s |   -3.66727 |             0.9409 |         1.0748 |             0.6550 |             0.8724 |      5.4363 |             48.7396 |            44.9476 |            11.9736 |           0.6795 |      30.3437 |      8.8873 |       9.4468 |      0.6351 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54967\tvalid_1's rmse: 3.71247\n",
      "[1000]\ttraining's rmse: 3.4455\tvalid_1's rmse: 3.69302\n",
      "[1500]\ttraining's rmse: 3.37341\tvalid_1's rmse: 3.68749\n",
      "[2000]\ttraining's rmse: 3.31677\tvalid_1's rmse: 3.68519\n",
      "Early stopping, best iteration is:\n",
      "[2008]\ttraining's rmse: 3.31598\tvalid_1's rmse: 3.68513\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56241\tvalid_1's rmse: 3.6528\n",
      "[1000]\ttraining's rmse: 3.45563\tvalid_1's rmse: 3.63544\n",
      "[1500]\ttraining's rmse: 3.38312\tvalid_1's rmse: 3.63027\n",
      "[2000]\ttraining's rmse: 3.32465\tvalid_1's rmse: 3.62899\n",
      "Early stopping, best iteration is:\n",
      "[2288]\ttraining's rmse: 3.29496\tvalid_1's rmse: 3.62853\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.56764\tvalid_1's rmse: 3.63027\n",
      "[1000]\ttraining's rmse: 3.46047\tvalid_1's rmse: 3.61287\n",
      "[1500]\ttraining's rmse: 3.3879\tvalid_1's rmse: 3.60911\n",
      "[2000]\ttraining's rmse: 3.33078\tvalid_1's rmse: 3.60846\n",
      "Early stopping, best iteration is:\n",
      "[1993]\ttraining's rmse: 3.33158\tvalid_1's rmse: 3.60835\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.52262\tvalid_1's rmse: 3.81077\n",
      "[1000]\ttraining's rmse: 3.41469\tvalid_1's rmse: 3.79472\n",
      "[1500]\ttraining's rmse: 3.34166\tvalid_1's rmse: 3.78942\n",
      "[2000]\ttraining's rmse: 3.28499\tvalid_1's rmse: 3.78762\n",
      "[2500]\ttraining's rmse: 3.2365\tvalid_1's rmse: 3.78751\n",
      "Early stopping, best iteration is:\n",
      "[2540]\ttraining's rmse: 3.23306\tvalid_1's rmse: 3.78743\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55949\tvalid_1's rmse: 3.65067\n",
      "[1000]\ttraining's rmse: 3.45341\tvalid_1's rmse: 3.63607\n",
      "[1500]\ttraining's rmse: 3.38129\tvalid_1's rmse: 3.63114\n",
      "[2000]\ttraining's rmse: 3.32537\tvalid_1's rmse: 3.62972\n",
      "Early stopping, best iteration is:\n",
      "[2135]\ttraining's rmse: 3.31119\tvalid_1's rmse: 3.62949\n",
      "   65 | 05m54s |   -3.66836 |             0.9533 |         2.8109 |             0.8116 |             0.8796 |     14.9796 |             43.8867 |            31.0466 |            12.7554 |           0.7021 |      42.8581 |      1.2317 |       9.2897 |      0.4262 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54804\tvalid_1's rmse: 3.71107\n",
      "[1000]\ttraining's rmse: 3.44664\tvalid_1's rmse: 3.6933\n",
      "[1500]\ttraining's rmse: 3.37851\tvalid_1's rmse: 3.68728\n",
      "[2000]\ttraining's rmse: 3.32531\tvalid_1's rmse: 3.68585\n",
      "Early stopping, best iteration is:\n",
      "[1900]\ttraining's rmse: 3.33499\tvalid_1's rmse: 3.68568\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55887\tvalid_1's rmse: 3.65399\n",
      "[1000]\ttraining's rmse: 3.45757\tvalid_1's rmse: 3.63754\n",
      "[1500]\ttraining's rmse: 3.3917\tvalid_1's rmse: 3.63494\n",
      "[2000]\ttraining's rmse: 3.33929\tvalid_1's rmse: 3.63451\n",
      "Early stopping, best iteration is:\n",
      "[1868]\ttraining's rmse: 3.35166\tvalid_1's rmse: 3.63427\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56573\tvalid_1's rmse: 3.62844\n",
      "[1000]\ttraining's rmse: 3.46493\tvalid_1's rmse: 3.61263\n",
      "[1500]\ttraining's rmse: 3.39675\tvalid_1's rmse: 3.60961\n",
      "Early stopping, best iteration is:\n",
      "[1377]\ttraining's rmse: 3.41124\tvalid_1's rmse: 3.60947\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.51991\tvalid_1's rmse: 3.80741\n",
      "[1000]\ttraining's rmse: 3.41696\tvalid_1's rmse: 3.79381\n",
      "[1500]\ttraining's rmse: 3.35023\tvalid_1's rmse: 3.79087\n",
      "Early stopping, best iteration is:\n",
      "[1421]\ttraining's rmse: 3.35936\tvalid_1's rmse: 3.79054\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55739\tvalid_1's rmse: 3.65309\n",
      "[1000]\ttraining's rmse: 3.45615\tvalid_1's rmse: 3.63961\n",
      "[1500]\ttraining's rmse: 3.38943\tvalid_1's rmse: 3.63634\n",
      "[2000]\ttraining's rmse: 3.33734\tvalid_1's rmse: 3.63584\n",
      "Early stopping, best iteration is:\n",
      "[2232]\ttraining's rmse: 3.31622\tvalid_1's rmse: 3.63573\n",
      "   66 | 04m37s |   -3.67171 |             0.7670 |         0.3186 |             0.2737 |             0.9482 |     14.7761 |             32.9690 |            44.8799 |            42.2451 |           0.9647 |      42.2383 |      8.7559 |       3.6818 |      0.8726 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64586\tvalid_1's rmse: 3.71545\n",
      "[1000]\ttraining's rmse: 3.60224\tvalid_1's rmse: 3.69643\n",
      "[1500]\ttraining's rmse: 3.57213\tvalid_1's rmse: 3.69016\n",
      "[2000]\ttraining's rmse: 3.54755\tvalid_1's rmse: 3.68677\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 3.5398\tvalid_1's rmse: 3.68581\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65922\tvalid_1's rmse: 3.65734\n",
      "[1000]\ttraining's rmse: 3.61412\tvalid_1's rmse: 3.63981\n",
      "[1500]\ttraining's rmse: 3.58523\tvalid_1's rmse: 3.63407\n",
      "[2000]\ttraining's rmse: 3.55954\tvalid_1's rmse: 3.63166\n",
      "[2500]\ttraining's rmse: 3.53656\tvalid_1's rmse: 3.6316\n",
      "Early stopping, best iteration is:\n",
      "[2318]\ttraining's rmse: 3.54549\tvalid_1's rmse: 3.63087\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66439\tvalid_1's rmse: 3.62922\n",
      "[1000]\ttraining's rmse: 3.61894\tvalid_1's rmse: 3.61268\n",
      "[1500]\ttraining's rmse: 3.58981\tvalid_1's rmse: 3.60846\n",
      "[2000]\ttraining's rmse: 3.56454\tvalid_1's rmse: 3.60682\n",
      "Early stopping, best iteration is:\n",
      "[2131]\ttraining's rmse: 3.55891\tvalid_1's rmse: 3.60626\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61701\tvalid_1's rmse: 3.81708\n",
      "[1000]\ttraining's rmse: 3.57206\tvalid_1's rmse: 3.80075\n",
      "[1500]\ttraining's rmse: 3.54303\tvalid_1's rmse: 3.79659\n",
      "[2000]\ttraining's rmse: 3.51813\tvalid_1's rmse: 3.79453\n",
      "[2500]\ttraining's rmse: 3.49528\tvalid_1's rmse: 3.79382\n",
      "[3000]\ttraining's rmse: 3.47485\tvalid_1's rmse: 3.79295\n",
      "[3500]\ttraining's rmse: 3.45248\tvalid_1's rmse: 3.79276\n",
      "Early stopping, best iteration is:\n",
      "[3311]\ttraining's rmse: 3.4607\tvalid_1's rmse: 3.79219\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66033\tvalid_1's rmse: 3.64816\n",
      "[1000]\ttraining's rmse: 3.61245\tvalid_1's rmse: 3.63239\n",
      "[1500]\ttraining's rmse: 3.58264\tvalid_1's rmse: 3.62624\n",
      "[2000]\ttraining's rmse: 3.55913\tvalid_1's rmse: 3.62487\n",
      "Early stopping, best iteration is:\n",
      "[2136]\ttraining's rmse: 3.55186\tvalid_1's rmse: 3.62445\n",
      "   67 | 04m12s |   -3.66854 |             0.9175 |        15.9986 |             0.2734 |             0.7515 |      5.1996 |              7.6624 |            31.7444 |            44.0210 |           0.8093 |      43.5450 |      2.8893 |       0.7135 |      0.9169 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60752\tvalid_1's rmse: 3.70552\n",
      "[1000]\ttraining's rmse: 3.55015\tvalid_1's rmse: 3.68868\n",
      "[1500]\ttraining's rmse: 3.50917\tvalid_1's rmse: 3.68371\n",
      "[2000]\ttraining's rmse: 3.47378\tvalid_1's rmse: 3.68192\n",
      "Early stopping, best iteration is:\n",
      "[2221]\ttraining's rmse: 3.45852\tvalid_1's rmse: 3.68137\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62103\tvalid_1's rmse: 3.64634\n",
      "[1000]\ttraining's rmse: 3.56318\tvalid_1's rmse: 3.6313\n",
      "[1500]\ttraining's rmse: 3.52226\tvalid_1's rmse: 3.6262\n",
      "[2000]\ttraining's rmse: 3.48703\tvalid_1's rmse: 3.62427\n",
      "[2500]\ttraining's rmse: 3.45295\tvalid_1's rmse: 3.6239\n",
      "Early stopping, best iteration is:\n",
      "[2307]\ttraining's rmse: 3.4657\tvalid_1's rmse: 3.62354\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62553\tvalid_1's rmse: 3.62254\n",
      "[1000]\ttraining's rmse: 3.56539\tvalid_1's rmse: 3.60721\n",
      "[1500]\ttraining's rmse: 3.52253\tvalid_1's rmse: 3.60434\n",
      "[2000]\ttraining's rmse: 3.48674\tvalid_1's rmse: 3.60383\n",
      "Early stopping, best iteration is:\n",
      "[2188]\ttraining's rmse: 3.47253\tvalid_1's rmse: 3.6037\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57973\tvalid_1's rmse: 3.81036\n",
      "[1000]\ttraining's rmse: 3.51904\tvalid_1's rmse: 3.79556\n",
      "[1500]\ttraining's rmse: 3.47615\tvalid_1's rmse: 3.79146\n",
      "[2000]\ttraining's rmse: 3.43975\tvalid_1's rmse: 3.7898\n",
      "[2500]\ttraining's rmse: 3.40671\tvalid_1's rmse: 3.78973\n",
      "Early stopping, best iteration is:\n",
      "[2356]\ttraining's rmse: 3.41634\tvalid_1's rmse: 3.78937\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62152\tvalid_1's rmse: 3.64119\n",
      "[1000]\ttraining's rmse: 3.55958\tvalid_1's rmse: 3.62862\n",
      "[1500]\ttraining's rmse: 3.5189\tvalid_1's rmse: 3.62556\n",
      "[2000]\ttraining's rmse: 3.48417\tvalid_1's rmse: 3.62476\n",
      "Early stopping, best iteration is:\n",
      "[1963]\ttraining's rmse: 3.48599\tvalid_1's rmse: 3.62463\n",
      "   68 | 04m35s |   -3.66515 |             0.7764 |         9.3881 |             0.3284 |             0.7771 |      7.7844 |             48.5856 |            44.1579 |            82.1116 |           0.8679 |      37.6794 |      9.2713 |       0.7401 |      0.5110 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.3658464e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57386\tvalid_1's rmse: 3.7026\n",
      "[1000]\ttraining's rmse: 3.4959\tvalid_1's rmse: 3.68591\n",
      "[1500]\ttraining's rmse: 3.4406\tvalid_1's rmse: 3.68128\n",
      "Early stopping, best iteration is:\n",
      "[1475]\ttraining's rmse: 3.44326\tvalid_1's rmse: 3.68115\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58531\tvalid_1's rmse: 3.64654\n",
      "[1000]\ttraining's rmse: 3.50585\tvalid_1's rmse: 3.63185\n",
      "[1500]\ttraining's rmse: 3.45133\tvalid_1's rmse: 3.62826\n",
      "[2000]\ttraining's rmse: 3.40505\tvalid_1's rmse: 3.62764\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's rmse: 3.40698\tvalid_1's rmse: 3.62713\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59205\tvalid_1's rmse: 3.6227\n",
      "[1000]\ttraining's rmse: 3.51146\tvalid_1's rmse: 3.60869\n",
      "[1500]\ttraining's rmse: 3.45509\tvalid_1's rmse: 3.60553\n",
      "Early stopping, best iteration is:\n",
      "[1617]\ttraining's rmse: 3.44338\tvalid_1's rmse: 3.60503\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54779\tvalid_1's rmse: 3.8051\n",
      "[1000]\ttraining's rmse: 3.46654\tvalid_1's rmse: 3.79118\n",
      "[1500]\ttraining's rmse: 3.41171\tvalid_1's rmse: 3.78825\n",
      "Early stopping, best iteration is:\n",
      "[1477]\ttraining's rmse: 3.4138\tvalid_1's rmse: 3.78813\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58509\tvalid_1's rmse: 3.64362\n",
      "[1000]\ttraining's rmse: 3.5057\tvalid_1's rmse: 3.63056\n",
      "[1500]\ttraining's rmse: 3.4502\tvalid_1's rmse: 3.62772\n",
      "Early stopping, best iteration is:\n",
      "[1368]\ttraining's rmse: 3.46371\tvalid_1's rmse: 3.62752\n",
      "   69 | 04m35s |   -3.66639 |             0.9282 |        18.6424 |             0.4679 |             0.8640 |     11.3200 |             40.1942 |            30.3070 |            99.5308 |           0.0571 |      44.9321 |      3.1965 |       1.5779 |      0.2737 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66344\tvalid_1's rmse: 3.7497\n",
      "[1000]\ttraining's rmse: 3.59104\tvalid_1's rmse: 3.71999\n",
      "[1500]\ttraining's rmse: 3.53978\tvalid_1's rmse: 3.70827\n",
      "[2000]\ttraining's rmse: 3.49682\tvalid_1's rmse: 3.70127\n",
      "[2500]\ttraining's rmse: 3.45898\tvalid_1's rmse: 3.69757\n",
      "[3000]\ttraining's rmse: 3.42305\tvalid_1's rmse: 3.69459\n",
      "Early stopping, best iteration is:\n",
      "[3180]\ttraining's rmse: 3.41007\tvalid_1's rmse: 3.69427\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67938\tvalid_1's rmse: 3.68411\n",
      "[1000]\ttraining's rmse: 3.60363\tvalid_1's rmse: 3.6589\n",
      "[1500]\ttraining's rmse: 3.55263\tvalid_1's rmse: 3.64799\n",
      "[2000]\ttraining's rmse: 3.50963\tvalid_1's rmse: 3.64241\n",
      "[2500]\ttraining's rmse: 3.47073\tvalid_1's rmse: 3.63969\n",
      "[3000]\ttraining's rmse: 3.43499\tvalid_1's rmse: 3.63835\n",
      "[3500]\ttraining's rmse: 3.40194\tvalid_1's rmse: 3.63771\n",
      "Early stopping, best iteration is:\n",
      "[3452]\ttraining's rmse: 3.40495\tvalid_1's rmse: 3.63751\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68348\tvalid_1's rmse: 3.65767\n",
      "[1000]\ttraining's rmse: 3.60785\tvalid_1's rmse: 3.63215\n",
      "[1500]\ttraining's rmse: 3.55619\tvalid_1's rmse: 3.62211\n",
      "[2000]\ttraining's rmse: 3.51286\tvalid_1's rmse: 3.61902\n",
      "[2500]\ttraining's rmse: 3.47376\tvalid_1's rmse: 3.61729\n",
      "Early stopping, best iteration is:\n",
      "[2354]\ttraining's rmse: 3.48534\tvalid_1's rmse: 3.6172\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63699\tvalid_1's rmse: 3.8597\n",
      "[1000]\ttraining's rmse: 3.56143\tvalid_1's rmse: 3.83011\n",
      "[1500]\ttraining's rmse: 3.50966\tvalid_1's rmse: 3.81916\n",
      "[2000]\ttraining's rmse: 3.46743\tvalid_1's rmse: 3.81409\n",
      "[2500]\ttraining's rmse: 3.42866\tvalid_1's rmse: 3.81057\n",
      "[3000]\ttraining's rmse: 3.39199\tvalid_1's rmse: 3.80872\n",
      "[3500]\ttraining's rmse: 3.35861\tvalid_1's rmse: 3.80701\n",
      "Early stopping, best iteration is:\n",
      "[3509]\ttraining's rmse: 3.35798\tvalid_1's rmse: 3.80687\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67896\tvalid_1's rmse: 3.67746\n",
      "[1000]\ttraining's rmse: 3.60244\tvalid_1's rmse: 3.65417\n",
      "[1500]\ttraining's rmse: 3.54867\tvalid_1's rmse: 3.64499\n",
      "[2000]\ttraining's rmse: 3.50641\tvalid_1's rmse: 3.64164\n",
      "[2500]\ttraining's rmse: 3.46694\tvalid_1's rmse: 3.63927\n",
      "[3000]\ttraining's rmse: 3.43187\tvalid_1's rmse: 3.63875\n",
      "Early stopping, best iteration is:\n",
      "[2803]\ttraining's rmse: 3.44553\tvalid_1's rmse: 3.63857\n",
      "   70 | 03m14s |   -3.67953 |             0.3329 |        18.9259 |             0.3976 |             0.1119 |     11.2784 |             47.8988 |            32.8353 |            11.7123 |           0.9492 |      44.0861 |      9.4117 |       9.6832 |      0.8479 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64962\tvalid_1's rmse: 3.71749\n",
      "[1000]\ttraining's rmse: 3.60727\tvalid_1's rmse: 3.69622\n",
      "[1500]\ttraining's rmse: 3.57808\tvalid_1's rmse: 3.68892\n",
      "[2000]\ttraining's rmse: 3.55457\tvalid_1's rmse: 3.68608\n",
      "[2500]\ttraining's rmse: 3.53292\tvalid_1's rmse: 3.68459\n",
      "[3000]\ttraining's rmse: 3.51248\tvalid_1's rmse: 3.68375\n",
      "Early stopping, best iteration is:\n",
      "[3057]\ttraining's rmse: 3.51025\tvalid_1's rmse: 3.68366\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66365\tvalid_1's rmse: 3.65996\n",
      "[1000]\ttraining's rmse: 3.61822\tvalid_1's rmse: 3.64169\n",
      "[1500]\ttraining's rmse: 3.59108\tvalid_1's rmse: 3.63531\n",
      "[2000]\ttraining's rmse: 3.56753\tvalid_1's rmse: 3.63248\n",
      "[2500]\ttraining's rmse: 3.54494\tvalid_1's rmse: 3.63106\n",
      "[3000]\ttraining's rmse: 3.52411\tvalid_1's rmse: 3.63011\n",
      "[3500]\ttraining's rmse: 3.5048\tvalid_1's rmse: 3.62947\n",
      "[4000]\ttraining's rmse: 3.48627\tvalid_1's rmse: 3.62903\n",
      "Early stopping, best iteration is:\n",
      "[3970]\ttraining's rmse: 3.48735\tvalid_1's rmse: 3.62897\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66994\tvalid_1's rmse: 3.63036\n",
      "[1000]\ttraining's rmse: 3.62502\tvalid_1's rmse: 3.6116\n",
      "[1500]\ttraining's rmse: 3.59744\tvalid_1's rmse: 3.60671\n",
      "[2000]\ttraining's rmse: 3.5743\tvalid_1's rmse: 3.60463\n",
      "[2500]\ttraining's rmse: 3.55235\tvalid_1's rmse: 3.60386\n",
      "Early stopping, best iteration is:\n",
      "[2724]\ttraining's rmse: 3.54261\tvalid_1's rmse: 3.60347\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62109\tvalid_1's rmse: 3.82321\n",
      "[1000]\ttraining's rmse: 3.57448\tvalid_1's rmse: 3.80527\n",
      "[1500]\ttraining's rmse: 3.54597\tvalid_1's rmse: 3.79947\n",
      "[2000]\ttraining's rmse: 3.52277\tvalid_1's rmse: 3.79732\n",
      "[2500]\ttraining's rmse: 3.50161\tvalid_1's rmse: 3.79601\n",
      "[3000]\ttraining's rmse: 3.4827\tvalid_1's rmse: 3.79541\n",
      "[3500]\ttraining's rmse: 3.46429\tvalid_1's rmse: 3.79527\n",
      "Early stopping, best iteration is:\n",
      "[3312]\ttraining's rmse: 3.47147\tvalid_1's rmse: 3.79517\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66384\tvalid_1's rmse: 3.64982\n",
      "[1000]\ttraining's rmse: 3.61598\tvalid_1's rmse: 3.63197\n",
      "[1500]\ttraining's rmse: 3.58743\tvalid_1's rmse: 3.62582\n",
      "[2000]\ttraining's rmse: 3.56364\tvalid_1's rmse: 3.62308\n",
      "[2500]\ttraining's rmse: 3.54121\tvalid_1's rmse: 3.62302\n",
      "Early stopping, best iteration is:\n",
      "[2313]\ttraining's rmse: 3.54958\tvalid_1's rmse: 3.62282\n",
      "   71 | 03m44s |   -3.66747 |             0.9823 |         0.5680 |             0.3330 |             0.4684 |      5.7173 |              5.3044 |            30.4644 |            12.1697 |           0.4439 |      32.3446 |      4.1613 |       2.5118 |      0.1482 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61388\tvalid_1's rmse: 3.70701\n",
      "[1000]\ttraining's rmse: 3.56143\tvalid_1's rmse: 3.69077\n",
      "[1500]\ttraining's rmse: 3.52133\tvalid_1's rmse: 3.68608\n",
      "[2000]\ttraining's rmse: 3.48622\tvalid_1's rmse: 3.68474\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.4916\tvalid_1's rmse: 3.68418\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62622\tvalid_1's rmse: 3.6482\n",
      "[1000]\ttraining's rmse: 3.57073\tvalid_1's rmse: 3.63466\n",
      "[1500]\ttraining's rmse: 3.53421\tvalid_1's rmse: 3.63099\n",
      "[2000]\ttraining's rmse: 3.49905\tvalid_1's rmse: 3.62867\n",
      "[2500]\ttraining's rmse: 3.47068\tvalid_1's rmse: 3.62733\n",
      "[3000]\ttraining's rmse: 3.4394\tvalid_1's rmse: 3.62577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500]\ttraining's rmse: 3.40814\tvalid_1's rmse: 3.62509\n",
      "Early stopping, best iteration is:\n",
      "[3453]\ttraining's rmse: 3.41097\tvalid_1's rmse: 3.62491\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63084\tvalid_1's rmse: 3.624\n",
      "[1000]\ttraining's rmse: 3.57305\tvalid_1's rmse: 3.61003\n",
      "[1500]\ttraining's rmse: 3.53432\tvalid_1's rmse: 3.60814\n",
      "Early stopping, best iteration is:\n",
      "[1470]\ttraining's rmse: 3.53631\tvalid_1's rmse: 3.60749\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58691\tvalid_1's rmse: 3.81136\n",
      "[1000]\ttraining's rmse: 3.53224\tvalid_1's rmse: 3.79827\n",
      "[1500]\ttraining's rmse: 3.49484\tvalid_1's rmse: 3.79481\n",
      "[2000]\ttraining's rmse: 3.45938\tvalid_1's rmse: 3.79272\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 3.45826\tvalid_1's rmse: 3.79253\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62634\tvalid_1's rmse: 3.64176\n",
      "[1000]\ttraining's rmse: 3.57144\tvalid_1's rmse: 3.62988\n",
      "[1500]\ttraining's rmse: 3.53263\tvalid_1's rmse: 3.62674\n",
      "Early stopping, best iteration is:\n",
      "[1649]\ttraining's rmse: 3.5214\tvalid_1's rmse: 3.62627\n",
      "   72 | 04m21s |   -3.66771 |             0.6666 |        19.2467 |             0.6548 |             0.8595 |      6.2049 |             48.5889 |            44.9028 |            31.3037 |           0.5732 |      44.8175 |      6.6143 |       8.4710 |      0.9570 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59179\tvalid_1's rmse: 3.71314\n",
      "[1000]\ttraining's rmse: 3.50958\tvalid_1's rmse: 3.69234\n",
      "[1500]\ttraining's rmse: 3.45188\tvalid_1's rmse: 3.68571\n",
      "[2000]\ttraining's rmse: 3.40212\tvalid_1's rmse: 3.68333\n",
      "Early stopping, best iteration is:\n",
      "[2270]\ttraining's rmse: 3.37757\tvalid_1's rmse: 3.68279\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60521\tvalid_1's rmse: 3.6547\n",
      "[1000]\ttraining's rmse: 3.52178\tvalid_1's rmse: 3.63719\n",
      "[1500]\ttraining's rmse: 3.4639\tvalid_1's rmse: 3.63103\n",
      "[2000]\ttraining's rmse: 3.41445\tvalid_1's rmse: 3.62911\n",
      "Early stopping, best iteration is:\n",
      "[2111]\ttraining's rmse: 3.40408\tvalid_1's rmse: 3.62866\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61068\tvalid_1's rmse: 3.6301\n",
      "[1000]\ttraining's rmse: 3.52702\tvalid_1's rmse: 3.61182\n",
      "[1500]\ttraining's rmse: 3.46808\tvalid_1's rmse: 3.60632\n",
      "[2000]\ttraining's rmse: 3.41883\tvalid_1's rmse: 3.60557\n",
      "[2500]\ttraining's rmse: 3.37197\tvalid_1's rmse: 3.60517\n",
      "Early stopping, best iteration is:\n",
      "[2383]\ttraining's rmse: 3.38282\tvalid_1's rmse: 3.60477\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56519\tvalid_1's rmse: 3.8156\n",
      "[1000]\ttraining's rmse: 3.4816\tvalid_1's rmse: 3.79965\n",
      "[1500]\ttraining's rmse: 3.42267\tvalid_1's rmse: 3.79657\n",
      "Early stopping, best iteration is:\n",
      "[1774]\ttraining's rmse: 3.3951\tvalid_1's rmse: 3.79554\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60484\tvalid_1's rmse: 3.65036\n",
      "[1000]\ttraining's rmse: 3.52067\tvalid_1's rmse: 3.63546\n",
      "[1500]\ttraining's rmse: 3.46277\tvalid_1's rmse: 3.63062\n",
      "[2000]\ttraining's rmse: 3.41227\tvalid_1's rmse: 3.62967\n",
      "Early stopping, best iteration is:\n",
      "[1858]\ttraining's rmse: 3.42602\tvalid_1's rmse: 3.62933\n",
      "   73 | 04m12s |   -3.66886 |             0.4935 |         2.3126 |             0.9708 |             0.8843 |     14.1713 |             49.6943 |            30.2848 |            19.1286 |           0.8151 |      32.3870 |      9.0879 |       8.2418 |      0.5735 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60417\tvalid_1's rmse: 3.70925\n",
      "[1000]\ttraining's rmse: 3.53509\tvalid_1's rmse: 3.68978\n",
      "[1500]\ttraining's rmse: 3.48845\tvalid_1's rmse: 3.68429\n",
      "[2000]\ttraining's rmse: 3.45006\tvalid_1's rmse: 3.68237\n",
      "Early stopping, best iteration is:\n",
      "[1942]\ttraining's rmse: 3.45448\tvalid_1's rmse: 3.68223\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61784\tvalid_1's rmse: 3.6522\n",
      "[1000]\ttraining's rmse: 3.5479\tvalid_1's rmse: 3.63485\n",
      "[1500]\ttraining's rmse: 3.50128\tvalid_1's rmse: 3.62917\n",
      "[2000]\ttraining's rmse: 3.46117\tvalid_1's rmse: 3.62717\n",
      "[2500]\ttraining's rmse: 3.4251\tvalid_1's rmse: 3.62637\n",
      "[3000]\ttraining's rmse: 3.39162\tvalid_1's rmse: 3.62603\n",
      "Early stopping, best iteration is:\n",
      "[2989]\ttraining's rmse: 3.39225\tvalid_1's rmse: 3.62593\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62311\tvalid_1's rmse: 3.62732\n",
      "[1000]\ttraining's rmse: 3.5538\tvalid_1's rmse: 3.6096\n",
      "[1500]\ttraining's rmse: 3.50671\tvalid_1's rmse: 3.60529\n",
      "[2000]\ttraining's rmse: 3.46782\tvalid_1's rmse: 3.60418\n",
      "Early stopping, best iteration is:\n",
      "[1993]\ttraining's rmse: 3.46839\tvalid_1's rmse: 3.6041\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57743\tvalid_1's rmse: 3.81074\n",
      "[1000]\ttraining's rmse: 3.50726\tvalid_1's rmse: 3.79471\n",
      "[1500]\ttraining's rmse: 3.46045\tvalid_1's rmse: 3.79096\n",
      "[2000]\ttraining's rmse: 3.42048\tvalid_1's rmse: 3.7897\n",
      "[2500]\ttraining's rmse: 3.38437\tvalid_1's rmse: 3.7893\n",
      "Early stopping, best iteration is:\n",
      "[2320]\ttraining's rmse: 3.39699\tvalid_1's rmse: 3.78912\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61679\tvalid_1's rmse: 3.6468\n",
      "[1000]\ttraining's rmse: 3.54853\tvalid_1's rmse: 3.63165\n",
      "[1500]\ttraining's rmse: 3.50117\tvalid_1's rmse: 3.62704\n",
      "[2000]\ttraining's rmse: 3.46209\tvalid_1's rmse: 3.62611\n",
      "Early stopping, best iteration is:\n",
      "[1876]\ttraining's rmse: 3.47147\tvalid_1's rmse: 3.62586\n",
      "   74 | 04m41s |   -3.66606 |             0.7894 |         2.9743 |             0.3524 |             0.7892 |     14.9954 |             46.3609 |            30.0216 |            85.8626 |           0.6690 |      30.3659 |      9.9287 |       1.7037 |      0.8804 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62637\tvalid_1's rmse: 3.71249\n",
      "[1000]\ttraining's rmse: 3.57469\tvalid_1's rmse: 3.6944\n",
      "[1500]\ttraining's rmse: 3.53822\tvalid_1's rmse: 3.68879\n",
      "[2000]\ttraining's rmse: 3.50701\tvalid_1's rmse: 3.68769\n",
      "Early stopping, best iteration is:\n",
      "[2150]\ttraining's rmse: 3.49877\tvalid_1's rmse: 3.68738\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63917\tvalid_1's rmse: 3.65395\n",
      "[1000]\ttraining's rmse: 3.58624\tvalid_1's rmse: 3.63695\n",
      "[1500]\ttraining's rmse: 3.54854\tvalid_1's rmse: 3.63147\n",
      "[2000]\ttraining's rmse: 3.51624\tvalid_1's rmse: 3.62935\n",
      "[2500]\ttraining's rmse: 3.48731\tvalid_1's rmse: 3.62919\n",
      "[3000]\ttraining's rmse: 3.45999\tvalid_1's rmse: 3.6285\n",
      "Early stopping, best iteration is:\n",
      "[3024]\ttraining's rmse: 3.45899\tvalid_1's rmse: 3.62847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64478\tvalid_1's rmse: 3.62748\n",
      "[1000]\ttraining's rmse: 3.59141\tvalid_1's rmse: 3.61134\n",
      "[1500]\ttraining's rmse: 3.55542\tvalid_1's rmse: 3.6073\n",
      "[2000]\ttraining's rmse: 3.52584\tvalid_1's rmse: 3.60639\n",
      "Early stopping, best iteration is:\n",
      "[1920]\ttraining's rmse: 3.53061\tvalid_1's rmse: 3.60623\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59833\tvalid_1's rmse: 3.81333\n",
      "[1000]\ttraining's rmse: 3.54447\tvalid_1's rmse: 3.79738\n",
      "[1500]\ttraining's rmse: 3.5078\tvalid_1's rmse: 3.79342\n",
      "Early stopping, best iteration is:\n",
      "[1746]\ttraining's rmse: 3.49175\tvalid_1's rmse: 3.793\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63984\tvalid_1's rmse: 3.64686\n",
      "[1000]\ttraining's rmse: 3.58461\tvalid_1's rmse: 3.63165\n",
      "[1500]\ttraining's rmse: 3.54677\tvalid_1's rmse: 3.62675\n",
      "[2000]\ttraining's rmse: 3.51651\tvalid_1's rmse: 3.62552\n",
      "[2500]\ttraining's rmse: 3.48759\tvalid_1's rmse: 3.62494\n",
      "Early stopping, best iteration is:\n",
      "[2501]\ttraining's rmse: 3.48753\tvalid_1's rmse: 3.62493\n",
      "   75 | 05m13s |   -3.66864 |             0.9817 |         6.6192 |             0.7941 |             0.8985 |      6.3849 |              9.1277 |            43.9093 |            11.4602 |           0.9636 |      30.7902 |      0.4104 |       9.7999 |      0.5211 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001959]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64649\tvalid_1's rmse: 3.71515\n",
      "[1000]\ttraining's rmse: 3.60344\tvalid_1's rmse: 3.69432\n",
      "[1500]\ttraining's rmse: 3.57458\tvalid_1's rmse: 3.68874\n",
      "[2000]\ttraining's rmse: 3.54953\tvalid_1's rmse: 3.68415\n",
      "Early stopping, best iteration is:\n",
      "[2237]\ttraining's rmse: 3.53809\tvalid_1's rmse: 3.68341\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66016\tvalid_1's rmse: 3.65626\n",
      "[1000]\ttraining's rmse: 3.61538\tvalid_1's rmse: 3.63927\n",
      "[1500]\ttraining's rmse: 3.58646\tvalid_1's rmse: 3.63392\n",
      "[2000]\ttraining's rmse: 3.56213\tvalid_1's rmse: 3.63045\n",
      "[2500]\ttraining's rmse: 3.53997\tvalid_1's rmse: 3.62822\n",
      "[3000]\ttraining's rmse: 3.51931\tvalid_1's rmse: 3.62777\n",
      "[3500]\ttraining's rmse: 3.49757\tvalid_1's rmse: 3.62683\n",
      "[4000]\ttraining's rmse: 3.47787\tvalid_1's rmse: 3.62573\n",
      "Early stopping, best iteration is:\n",
      "[4156]\ttraining's rmse: 3.47114\tvalid_1's rmse: 3.62518\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66649\tvalid_1's rmse: 3.63076\n",
      "[1000]\ttraining's rmse: 3.62075\tvalid_1's rmse: 3.6137\n",
      "[1500]\ttraining's rmse: 3.59272\tvalid_1's rmse: 3.60886\n",
      "[2000]\ttraining's rmse: 3.56855\tvalid_1's rmse: 3.60609\n",
      "Early stopping, best iteration is:\n",
      "[2016]\ttraining's rmse: 3.5677\tvalid_1's rmse: 3.60588\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6175\tvalid_1's rmse: 3.81804\n",
      "[1000]\ttraining's rmse: 3.57241\tvalid_1's rmse: 3.80419\n",
      "[1500]\ttraining's rmse: 3.5442\tvalid_1's rmse: 3.79912\n",
      "[2000]\ttraining's rmse: 3.52041\tvalid_1's rmse: 3.79687\n",
      "Early stopping, best iteration is:\n",
      "[2209]\ttraining's rmse: 3.50958\tvalid_1's rmse: 3.79611\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66068\tvalid_1's rmse: 3.64657\n",
      "[1000]\ttraining's rmse: 3.6158\tvalid_1's rmse: 3.63078\n",
      "[1500]\ttraining's rmse: 3.58453\tvalid_1's rmse: 3.62687\n",
      "[2000]\ttraining's rmse: 3.56053\tvalid_1's rmse: 3.62505\n",
      "Early stopping, best iteration is:\n",
      "[2144]\ttraining's rmse: 3.55289\tvalid_1's rmse: 3.62487\n",
      "   76 | 04m11s |   -3.66775 |             0.7806 |        16.8936 |             0.5071 |             0.7573 |      5.8512 |              6.1468 |            44.9963 |            10.8240 |           0.2663 |      43.6076 |      2.1098 |       1.6166 |      0.2448 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5951\tvalid_1's rmse: 3.71782\n",
      "[1000]\ttraining's rmse: 3.51411\tvalid_1's rmse: 3.6982\n",
      "[1500]\ttraining's rmse: 3.46113\tvalid_1's rmse: 3.69104\n",
      "[2000]\ttraining's rmse: 3.42089\tvalid_1's rmse: 3.6886\n",
      "Early stopping, best iteration is:\n",
      "[2243]\ttraining's rmse: 3.40381\tvalid_1's rmse: 3.68782\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60778\tvalid_1's rmse: 3.65568\n",
      "[1000]\ttraining's rmse: 3.52653\tvalid_1's rmse: 3.63797\n",
      "[1500]\ttraining's rmse: 3.47428\tvalid_1's rmse: 3.63324\n",
      "[2000]\ttraining's rmse: 3.43296\tvalid_1's rmse: 3.63151\n",
      "[2500]\ttraining's rmse: 3.39861\tvalid_1's rmse: 3.63105\n",
      "Early stopping, best iteration is:\n",
      "[2612]\ttraining's rmse: 3.39136\tvalid_1's rmse: 3.63073\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61399\tvalid_1's rmse: 3.63218\n",
      "[1000]\ttraining's rmse: 3.53244\tvalid_1's rmse: 3.61628\n",
      "[1500]\ttraining's rmse: 3.4789\tvalid_1's rmse: 3.61045\n",
      "[2000]\ttraining's rmse: 3.43778\tvalid_1's rmse: 3.60921\n",
      "Early stopping, best iteration is:\n",
      "[2028]\ttraining's rmse: 3.43589\tvalid_1's rmse: 3.60909\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56819\tvalid_1's rmse: 3.81279\n",
      "[1000]\ttraining's rmse: 3.48635\tvalid_1's rmse: 3.79647\n",
      "[1500]\ttraining's rmse: 3.43294\tvalid_1's rmse: 3.79241\n",
      "[2000]\ttraining's rmse: 3.39324\tvalid_1's rmse: 3.79107\n",
      "[2500]\ttraining's rmse: 3.35913\tvalid_1's rmse: 3.7902\n",
      "Early stopping, best iteration is:\n",
      "[2423]\ttraining's rmse: 3.36413\tvalid_1's rmse: 3.79013\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60627\tvalid_1's rmse: 3.65448\n",
      "[1000]\ttraining's rmse: 3.52387\tvalid_1's rmse: 3.63892\n",
      "[1500]\ttraining's rmse: 3.46957\tvalid_1's rmse: 3.63372\n",
      "[2000]\ttraining's rmse: 3.42819\tvalid_1's rmse: 3.63213\n",
      "[2500]\ttraining's rmse: 3.39486\tvalid_1's rmse: 3.63158\n",
      "Early stopping, best iteration is:\n",
      "[2346]\ttraining's rmse: 3.40453\tvalid_1's rmse: 3.6315\n",
      "   77 | 04m41s |   -3.67044 |             0.8282 |         0.8812 |             0.1343 |             0.9406 |     12.4725 |             49.3451 |            44.8828 |            44.8856 |           0.1659 |      30.5239 |      7.6438 |       9.3271 |      0.7185 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00114722]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64833\tvalid_1's rmse: 3.71631\n",
      "[1000]\ttraining's rmse: 3.60692\tvalid_1's rmse: 3.69639\n",
      "[1500]\ttraining's rmse: 3.57733\tvalid_1's rmse: 3.68925\n",
      "[2000]\ttraining's rmse: 3.55337\tvalid_1's rmse: 3.68687\n",
      "[2500]\ttraining's rmse: 3.5311\tvalid_1's rmse: 3.68549\n",
      "[3000]\ttraining's rmse: 3.51198\tvalid_1's rmse: 3.68486\n",
      "Early stopping, best iteration is:\n",
      "[3183]\ttraining's rmse: 3.50475\tvalid_1's rmse: 3.68458\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66179\tvalid_1's rmse: 3.65782\n",
      "[1000]\ttraining's rmse: 3.61768\tvalid_1's rmse: 3.63989\n",
      "[1500]\ttraining's rmse: 3.58978\tvalid_1's rmse: 3.63377\n",
      "[2000]\ttraining's rmse: 3.56497\tvalid_1's rmse: 3.63062\n",
      "[2500]\ttraining's rmse: 3.54278\tvalid_1's rmse: 3.62964\n",
      "[3000]\ttraining's rmse: 3.52222\tvalid_1's rmse: 3.6291\n",
      "[3500]\ttraining's rmse: 3.50265\tvalid_1's rmse: 3.62867\n",
      "Early stopping, best iteration is:\n",
      "[3449]\ttraining's rmse: 3.50442\tvalid_1's rmse: 3.62858\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66768\tvalid_1's rmse: 3.62858\n",
      "[1000]\ttraining's rmse: 3.62178\tvalid_1's rmse: 3.61048\n",
      "[1500]\ttraining's rmse: 3.59555\tvalid_1's rmse: 3.60548\n",
      "[2000]\ttraining's rmse: 3.57342\tvalid_1's rmse: 3.60386\n",
      "Early stopping, best iteration is:\n",
      "[2254]\ttraining's rmse: 3.56216\tvalid_1's rmse: 3.60351\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61933\tvalid_1's rmse: 3.81949\n",
      "[1000]\ttraining's rmse: 3.57393\tvalid_1's rmse: 3.80331\n",
      "[1500]\ttraining's rmse: 3.54597\tvalid_1's rmse: 3.79827\n",
      "[2000]\ttraining's rmse: 3.52279\tvalid_1's rmse: 3.79676\n",
      "[2500]\ttraining's rmse: 3.50182\tvalid_1's rmse: 3.79562\n",
      "[3000]\ttraining's rmse: 3.48229\tvalid_1's rmse: 3.79525\n",
      "[3500]\ttraining's rmse: 3.46315\tvalid_1's rmse: 3.79464\n",
      "[4000]\ttraining's rmse: 3.44516\tvalid_1's rmse: 3.79431\n",
      "[4500]\ttraining's rmse: 3.42707\tvalid_1's rmse: 3.7941\n",
      "Early stopping, best iteration is:\n",
      "[4757]\ttraining's rmse: 3.41799\tvalid_1's rmse: 3.79401\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66265\tvalid_1's rmse: 3.64904\n",
      "[1000]\ttraining's rmse: 3.61589\tvalid_1's rmse: 3.63149\n",
      "[1500]\ttraining's rmse: 3.58647\tvalid_1's rmse: 3.62556\n",
      "[2000]\ttraining's rmse: 3.56321\tvalid_1's rmse: 3.62348\n",
      "[2500]\ttraining's rmse: 3.5419\tvalid_1's rmse: 3.62293\n",
      "Early stopping, best iteration is:\n",
      "[2363]\ttraining's rmse: 3.54755\tvalid_1's rmse: 3.62287\n",
      "   78 | 04m28s |   -3.66736 |             0.6454 |         0.5457 |             0.2923 |             0.6453 |      5.6934 |              5.8154 |            31.9667 |            11.1700 |           0.2661 |      43.0659 |      2.1301 |       9.2713 |      0.4064 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56608\tvalid_1's rmse: 3.71008\n",
      "[1000]\ttraining's rmse: 3.47256\tvalid_1's rmse: 3.69065\n",
      "[1500]\ttraining's rmse: 3.40922\tvalid_1's rmse: 3.68468\n",
      "[2000]\ttraining's rmse: 3.35822\tvalid_1's rmse: 3.68301\n",
      "Early stopping, best iteration is:\n",
      "[2188]\ttraining's rmse: 3.34113\tvalid_1's rmse: 3.68252\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58005\tvalid_1's rmse: 3.6519\n",
      "[1000]\ttraining's rmse: 3.48469\tvalid_1's rmse: 3.63445\n",
      "[1500]\ttraining's rmse: 3.42078\tvalid_1's rmse: 3.62896\n",
      "[2000]\ttraining's rmse: 3.36986\tvalid_1's rmse: 3.62749\n",
      "[2500]\ttraining's rmse: 3.32414\tvalid_1's rmse: 3.62704\n",
      "Early stopping, best iteration is:\n",
      "[2532]\ttraining's rmse: 3.32139\tvalid_1's rmse: 3.627\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58441\tvalid_1's rmse: 3.62918\n",
      "[1000]\ttraining's rmse: 3.48924\tvalid_1's rmse: 3.61247\n",
      "[1500]\ttraining's rmse: 3.42437\tvalid_1's rmse: 3.60778\n",
      "[2000]\ttraining's rmse: 3.37433\tvalid_1's rmse: 3.60564\n",
      "Early stopping, best iteration is:\n",
      "[1993]\ttraining's rmse: 3.37507\tvalid_1's rmse: 3.60559\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.53963\tvalid_1's rmse: 3.81089\n",
      "[1000]\ttraining's rmse: 3.44234\tvalid_1's rmse: 3.79503\n",
      "[1500]\ttraining's rmse: 3.37877\tvalid_1's rmse: 3.7905\n",
      "[2000]\ttraining's rmse: 3.32875\tvalid_1's rmse: 3.78972\n",
      "Early stopping, best iteration is:\n",
      "[2073]\ttraining's rmse: 3.32175\tvalid_1's rmse: 3.78958\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57701\tvalid_1's rmse: 3.64989\n",
      "[1000]\ttraining's rmse: 3.48203\tvalid_1's rmse: 3.63477\n",
      "[1500]\ttraining's rmse: 3.41851\tvalid_1's rmse: 3.62955\n",
      "[2000]\ttraining's rmse: 3.3677\tvalid_1's rmse: 3.62818\n",
      "[2500]\ttraining's rmse: 3.32376\tvalid_1's rmse: 3.62785\n",
      "Early stopping, best iteration is:\n",
      "[2613]\ttraining's rmse: 3.31462\tvalid_1's rmse: 3.62752\n",
      "   79 | 05m34s |   -3.66705 |             0.9554 |         2.0211 |             0.3160 |             0.7213 |     14.7894 |             49.2189 |            42.2938 |            10.1376 |           0.0232 |      39.1746 |      1.0996 |       8.3339 |      0.6891 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60613\tvalid_1's rmse: 3.7084\n",
      "[1000]\ttraining's rmse: 3.54022\tvalid_1's rmse: 3.68962\n",
      "[1500]\ttraining's rmse: 3.49482\tvalid_1's rmse: 3.68404\n",
      "[2000]\ttraining's rmse: 3.45542\tvalid_1's rmse: 3.68154\n",
      "[2500]\ttraining's rmse: 3.42056\tvalid_1's rmse: 3.68044\n",
      "Early stopping, best iteration is:\n",
      "[2602]\ttraining's rmse: 3.41437\tvalid_1's rmse: 3.68005\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62023\tvalid_1's rmse: 3.65178\n",
      "[1000]\ttraining's rmse: 3.55189\tvalid_1's rmse: 3.6343\n",
      "[1500]\ttraining's rmse: 3.50569\tvalid_1's rmse: 3.6286\n",
      "[2000]\ttraining's rmse: 3.46778\tvalid_1's rmse: 3.62632\n",
      "Early stopping, best iteration is:\n",
      "[2084]\ttraining's rmse: 3.4613\tvalid_1's rmse: 3.62566\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62669\tvalid_1's rmse: 3.62595\n",
      "[1000]\ttraining's rmse: 3.55844\tvalid_1's rmse: 3.6104\n",
      "[1500]\ttraining's rmse: 3.51344\tvalid_1's rmse: 3.60726\n",
      "Early stopping, best iteration is:\n",
      "[1429]\ttraining's rmse: 3.5192\tvalid_1's rmse: 3.60715\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58081\tvalid_1's rmse: 3.81139\n",
      "[1000]\ttraining's rmse: 3.51362\tvalid_1's rmse: 3.79664\n",
      "[1500]\ttraining's rmse: 3.46906\tvalid_1's rmse: 3.79182\n",
      "Early stopping, best iteration is:\n",
      "[1503]\ttraining's rmse: 3.4688\tvalid_1's rmse: 3.79178\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62092\tvalid_1's rmse: 3.64585\n",
      "[1000]\ttraining's rmse: 3.55396\tvalid_1's rmse: 3.63138\n",
      "[1500]\ttraining's rmse: 3.51002\tvalid_1's rmse: 3.62675\n",
      "[2000]\ttraining's rmse: 3.46992\tvalid_1's rmse: 3.62582\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's rmse: 3.47334\tvalid_1's rmse: 3.62567\n",
      "   80 | 04m17s |   -3.66668 |             0.7374 |        16.7698 |             0.7580 |             0.8107 |     14.5674 |              5.9374 |            42.8342 |            97.3137 |           0.6114 |      31.5033 |      8.7731 |       2.2592 |      0.6983 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6056\tvalid_1's rmse: 3.70962\n",
      "[1000]\ttraining's rmse: 3.53687\tvalid_1's rmse: 3.68991\n",
      "[1500]\ttraining's rmse: 3.49143\tvalid_1's rmse: 3.68376\n",
      "[2000]\ttraining's rmse: 3.45378\tvalid_1's rmse: 3.6817\n",
      "[2500]\ttraining's rmse: 3.42114\tvalid_1's rmse: 3.6809\n",
      "Early stopping, best iteration is:\n",
      "[2778]\ttraining's rmse: 3.40412\tvalid_1's rmse: 3.68077\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62009\tvalid_1's rmse: 3.6509\n",
      "[1000]\ttraining's rmse: 3.55021\tvalid_1's rmse: 3.63282\n",
      "[1500]\ttraining's rmse: 3.50401\tvalid_1's rmse: 3.6266\n",
      "[2000]\ttraining's rmse: 3.46623\tvalid_1's rmse: 3.62442\n",
      "[2500]\ttraining's rmse: 3.43256\tvalid_1's rmse: 3.62395\n",
      "[3000]\ttraining's rmse: 3.40124\tvalid_1's rmse: 3.6236\n",
      "Early stopping, best iteration is:\n",
      "[2844]\ttraining's rmse: 3.41033\tvalid_1's rmse: 3.62343\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62456\tvalid_1's rmse: 3.62843\n",
      "[1000]\ttraining's rmse: 3.55433\tvalid_1's rmse: 3.61082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.50839\tvalid_1's rmse: 3.60629\n",
      "[2000]\ttraining's rmse: 3.47095\tvalid_1's rmse: 3.6046\n",
      "Early stopping, best iteration is:\n",
      "[2061]\ttraining's rmse: 3.46668\tvalid_1's rmse: 3.60441\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58016\tvalid_1's rmse: 3.80926\n",
      "[1000]\ttraining's rmse: 3.50947\tvalid_1's rmse: 3.79405\n",
      "[1500]\ttraining's rmse: 3.46292\tvalid_1's rmse: 3.78942\n",
      "[2000]\ttraining's rmse: 3.42564\tvalid_1's rmse: 3.78819\n",
      "Early stopping, best iteration is:\n",
      "[2042]\ttraining's rmse: 3.42305\tvalid_1's rmse: 3.78807\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61933\tvalid_1's rmse: 3.64685\n",
      "[1000]\ttraining's rmse: 3.54979\tvalid_1's rmse: 3.63136\n",
      "[1500]\ttraining's rmse: 3.50385\tvalid_1's rmse: 3.62557\n",
      "[2000]\ttraining's rmse: 3.46666\tvalid_1's rmse: 3.62458\n",
      "[2500]\ttraining's rmse: 3.43329\tvalid_1's rmse: 3.6234\n",
      "Early stopping, best iteration is:\n",
      "[2486]\ttraining's rmse: 3.43411\tvalid_1's rmse: 3.62338\n",
      "   81 | 05m26s |   -3.66463 |             0.9239 |         5.7273 |             0.4449 |             0.8127 |     14.2813 |             44.8872 |            34.1019 |            99.6389 |           0.7394 |      31.0721 |      0.7690 |       9.0405 |      0.8826 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00035474]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64646\tvalid_1's rmse: 3.71695\n",
      "[1000]\ttraining's rmse: 3.60391\tvalid_1's rmse: 3.69786\n",
      "[1500]\ttraining's rmse: 3.57256\tvalid_1's rmse: 3.69165\n",
      "[2000]\ttraining's rmse: 3.54845\tvalid_1's rmse: 3.6895\n",
      "[2500]\ttraining's rmse: 3.52782\tvalid_1's rmse: 3.68841\n",
      "[3000]\ttraining's rmse: 3.50964\tvalid_1's rmse: 3.68768\n",
      "Early stopping, best iteration is:\n",
      "[3004]\ttraining's rmse: 3.50945\tvalid_1's rmse: 3.68764\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65886\tvalid_1's rmse: 3.65765\n",
      "[1000]\ttraining's rmse: 3.61404\tvalid_1's rmse: 3.6401\n",
      "[1500]\ttraining's rmse: 3.58435\tvalid_1's rmse: 3.63437\n",
      "[2000]\ttraining's rmse: 3.55978\tvalid_1's rmse: 3.63227\n",
      "[2500]\ttraining's rmse: 3.53902\tvalid_1's rmse: 3.63191\n",
      "[3000]\ttraining's rmse: 3.51891\tvalid_1's rmse: 3.63106\n",
      "[3500]\ttraining's rmse: 3.49916\tvalid_1's rmse: 3.63029\n",
      "Early stopping, best iteration is:\n",
      "[3593]\ttraining's rmse: 3.49516\tvalid_1's rmse: 3.6302\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66467\tvalid_1's rmse: 3.63269\n",
      "[1000]\ttraining's rmse: 3.61879\tvalid_1's rmse: 3.61589\n",
      "[1500]\ttraining's rmse: 3.5909\tvalid_1's rmse: 3.61154\n",
      "Early stopping, best iteration is:\n",
      "[1731]\ttraining's rmse: 3.58001\tvalid_1's rmse: 3.61137\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61704\tvalid_1's rmse: 3.81682\n",
      "[1000]\ttraining's rmse: 3.57098\tvalid_1's rmse: 3.80156\n",
      "[1500]\ttraining's rmse: 3.5435\tvalid_1's rmse: 3.79709\n",
      "[2000]\ttraining's rmse: 3.52092\tvalid_1's rmse: 3.79614\n",
      "Early stopping, best iteration is:\n",
      "[2155]\ttraining's rmse: 3.51423\tvalid_1's rmse: 3.79584\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65921\tvalid_1's rmse: 3.64965\n",
      "[1000]\ttraining's rmse: 3.61256\tvalid_1's rmse: 3.63368\n",
      "[1500]\ttraining's rmse: 3.58182\tvalid_1's rmse: 3.62822\n",
      "[2000]\ttraining's rmse: 3.55726\tvalid_1's rmse: 3.62595\n",
      "[2500]\ttraining's rmse: 3.5351\tvalid_1's rmse: 3.62577\n",
      "Early stopping, best iteration is:\n",
      "[2301]\ttraining's rmse: 3.54374\tvalid_1's rmse: 3.62548\n",
      "   82 | 04m33s |   -3.67074 |             0.9891 |         0.2170 |             0.2417 |             0.8863 |      5.2547 |             20.9967 |            43.4741 |            10.9341 |           0.7800 |      43.1539 |      9.2257 |       2.0459 |      0.2607 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6467\tvalid_1's rmse: 3.71645\n",
      "[1000]\ttraining's rmse: 3.60341\tvalid_1's rmse: 3.69753\n",
      "[1500]\ttraining's rmse: 3.5747\tvalid_1's rmse: 3.69127\n",
      "[2000]\ttraining's rmse: 3.5494\tvalid_1's rmse: 3.68931\n",
      "[2500]\ttraining's rmse: 3.5271\tvalid_1's rmse: 3.68729\n",
      "Early stopping, best iteration is:\n",
      "[2724]\ttraining's rmse: 3.51826\tvalid_1's rmse: 3.68649\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66206\tvalid_1's rmse: 3.65842\n",
      "[1000]\ttraining's rmse: 3.61627\tvalid_1's rmse: 3.64098\n",
      "[1500]\ttraining's rmse: 3.5866\tvalid_1's rmse: 3.63436\n",
      "[2000]\ttraining's rmse: 3.56217\tvalid_1's rmse: 3.63119\n",
      "[2500]\ttraining's rmse: 3.54024\tvalid_1's rmse: 3.6299\n",
      "[3000]\ttraining's rmse: 3.51811\tvalid_1's rmse: 3.62876\n",
      "Early stopping, best iteration is:\n",
      "[3108]\ttraining's rmse: 3.51211\tvalid_1's rmse: 3.62825\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66561\tvalid_1's rmse: 3.62847\n",
      "[1000]\ttraining's rmse: 3.62113\tvalid_1's rmse: 3.61292\n",
      "[1500]\ttraining's rmse: 3.59191\tvalid_1's rmse: 3.6089\n",
      "[2000]\ttraining's rmse: 3.56879\tvalid_1's rmse: 3.60658\n",
      "Early stopping, best iteration is:\n",
      "[2127]\ttraining's rmse: 3.56238\tvalid_1's rmse: 3.60609\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61954\tvalid_1's rmse: 3.81857\n",
      "[1000]\ttraining's rmse: 3.57358\tvalid_1's rmse: 3.80253\n",
      "[1500]\ttraining's rmse: 3.54496\tvalid_1's rmse: 3.79777\n",
      "[2000]\ttraining's rmse: 3.52024\tvalid_1's rmse: 3.79639\n",
      "[2500]\ttraining's rmse: 3.50096\tvalid_1's rmse: 3.79537\n",
      "Early stopping, best iteration is:\n",
      "[2581]\ttraining's rmse: 3.49715\tvalid_1's rmse: 3.79524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66265\tvalid_1's rmse: 3.65021\n",
      "[1000]\ttraining's rmse: 3.61543\tvalid_1's rmse: 3.63412\n",
      "[1500]\ttraining's rmse: 3.58411\tvalid_1's rmse: 3.62913\n",
      "[2000]\ttraining's rmse: 3.55753\tvalid_1's rmse: 3.62661\n",
      "[2500]\ttraining's rmse: 3.53516\tvalid_1's rmse: 3.62673\n",
      "Early stopping, best iteration is:\n",
      "[2300]\ttraining's rmse: 3.54327\tvalid_1's rmse: 3.62629\n",
      "   83 | 05m06s |   -3.66912 |             0.9165 |        19.7856 |             0.4287 |             0.9261 |      5.8804 |             36.7514 |            44.8047 |            31.1665 |           0.8573 |      32.0364 |      1.0239 |       9.3571 |      0.4415 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58931\tvalid_1's rmse: 3.7137\n",
      "[1000]\ttraining's rmse: 3.50707\tvalid_1's rmse: 3.69447\n",
      "[1500]\ttraining's rmse: 3.45141\tvalid_1's rmse: 3.68804\n",
      "[2000]\ttraining's rmse: 3.40764\tvalid_1's rmse: 3.68558\n",
      "Early stopping, best iteration is:\n",
      "[2158]\ttraining's rmse: 3.39532\tvalid_1's rmse: 3.68516\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60334\tvalid_1's rmse: 3.6547\n",
      "[1000]\ttraining's rmse: 3.51879\tvalid_1's rmse: 3.6371\n",
      "[1500]\ttraining's rmse: 3.46358\tvalid_1's rmse: 3.63118\n",
      "[2000]\ttraining's rmse: 3.419\tvalid_1's rmse: 3.6294\n",
      "[2500]\ttraining's rmse: 3.37969\tvalid_1's rmse: 3.62838\n",
      "Early stopping, best iteration is:\n",
      "[2554]\ttraining's rmse: 3.37607\tvalid_1's rmse: 3.62822\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60833\tvalid_1's rmse: 3.62929\n",
      "[1000]\ttraining's rmse: 3.52411\tvalid_1's rmse: 3.61176\n",
      "[1500]\ttraining's rmse: 3.46814\tvalid_1's rmse: 3.60662\n",
      "[2000]\ttraining's rmse: 3.42495\tvalid_1's rmse: 3.60454\n",
      "Early stopping, best iteration is:\n",
      "[2121]\ttraining's rmse: 3.41565\tvalid_1's rmse: 3.60448\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56366\tvalid_1's rmse: 3.81161\n",
      "[1000]\ttraining's rmse: 3.47878\tvalid_1's rmse: 3.79503\n",
      "[1500]\ttraining's rmse: 3.422\tvalid_1's rmse: 3.78949\n",
      "[2000]\ttraining's rmse: 3.37833\tvalid_1's rmse: 3.78771\n",
      "Early stopping, best iteration is:\n",
      "[2191]\ttraining's rmse: 3.36358\tvalid_1's rmse: 3.78707\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6007\tvalid_1's rmse: 3.65027\n",
      "[1000]\ttraining's rmse: 3.51628\tvalid_1's rmse: 3.63497\n",
      "[1500]\ttraining's rmse: 3.46104\tvalid_1's rmse: 3.62939\n",
      "[2000]\ttraining's rmse: 3.41726\tvalid_1's rmse: 3.62712\n",
      "Early stopping, best iteration is:\n",
      "[2103]\ttraining's rmse: 3.40958\tvalid_1's rmse: 3.62703\n",
      "   84 | 05m07s |   -3.66699 |             0.9737 |         4.2236 |             0.9840 |             0.7047 |     14.6163 |              5.0361 |            30.2133 |            47.3667 |           0.6349 |      32.2192 |      0.2269 |       7.8935 |      0.5750 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68898\tvalid_1's rmse: 3.7435\n",
      "[1000]\ttraining's rmse: 3.64351\tvalid_1's rmse: 3.71364\n",
      "[1500]\ttraining's rmse: 3.61728\tvalid_1's rmse: 3.70133\n",
      "[2000]\ttraining's rmse: 3.59785\tvalid_1's rmse: 3.69521\n",
      "[2500]\ttraining's rmse: 3.58075\tvalid_1's rmse: 3.69108\n",
      "[3000]\ttraining's rmse: 3.56555\tvalid_1's rmse: 3.68882\n",
      "[3500]\ttraining's rmse: 3.5515\tvalid_1's rmse: 3.6871\n",
      "[4000]\ttraining's rmse: 3.53764\tvalid_1's rmse: 3.68628\n",
      "[4500]\ttraining's rmse: 3.5244\tvalid_1's rmse: 3.68573\n",
      "Early stopping, best iteration is:\n",
      "[4677]\ttraining's rmse: 3.51998\tvalid_1's rmse: 3.68558\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70349\tvalid_1's rmse: 3.67885\n",
      "[1000]\ttraining's rmse: 3.65667\tvalid_1's rmse: 3.65329\n",
      "[1500]\ttraining's rmse: 3.62999\tvalid_1's rmse: 3.64274\n",
      "[2000]\ttraining's rmse: 3.60939\tvalid_1's rmse: 3.63718\n",
      "[2500]\ttraining's rmse: 3.59229\tvalid_1's rmse: 3.63345\n",
      "[3000]\ttraining's rmse: 3.57674\tvalid_1's rmse: 3.63129\n",
      "[3500]\ttraining's rmse: 3.56264\tvalid_1's rmse: 3.62964\n",
      "[4000]\ttraining's rmse: 3.54902\tvalid_1's rmse: 3.62825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's rmse: 3.53648\tvalid_1's rmse: 3.6272\n",
      "[5000]\ttraining's rmse: 3.52358\tvalid_1's rmse: 3.62674\n",
      "[5500]\ttraining's rmse: 3.51126\tvalid_1's rmse: 3.6264\n",
      "Early stopping, best iteration is:\n",
      "[5680]\ttraining's rmse: 3.5068\tvalid_1's rmse: 3.62621\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70768\tvalid_1's rmse: 3.65278\n",
      "[1000]\ttraining's rmse: 3.66063\tvalid_1's rmse: 3.62682\n",
      "[1500]\ttraining's rmse: 3.63412\tvalid_1's rmse: 3.61742\n",
      "[2000]\ttraining's rmse: 3.61371\tvalid_1's rmse: 3.6124\n",
      "[2500]\ttraining's rmse: 3.59686\tvalid_1's rmse: 3.60985\n",
      "[3000]\ttraining's rmse: 3.58086\tvalid_1's rmse: 3.60816\n",
      "[3500]\ttraining's rmse: 3.56601\tvalid_1's rmse: 3.60761\n",
      "[4000]\ttraining's rmse: 3.5518\tvalid_1's rmse: 3.60724\n",
      "Early stopping, best iteration is:\n",
      "[3928]\ttraining's rmse: 3.55383\tvalid_1's rmse: 3.60701\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66049\tvalid_1's rmse: 3.85091\n",
      "[1000]\ttraining's rmse: 3.6132\tvalid_1's rmse: 3.82265\n",
      "[1500]\ttraining's rmse: 3.58712\tvalid_1's rmse: 3.81232\n",
      "[2000]\ttraining's rmse: 3.56753\tvalid_1's rmse: 3.80738\n",
      "[2500]\ttraining's rmse: 3.55051\tvalid_1's rmse: 3.80382\n",
      "[3000]\ttraining's rmse: 3.53437\tvalid_1's rmse: 3.80158\n",
      "[3500]\ttraining's rmse: 3.5199\tvalid_1's rmse: 3.80019\n",
      "[4000]\ttraining's rmse: 3.50572\tvalid_1's rmse: 3.79891\n",
      "[4500]\ttraining's rmse: 3.49222\tvalid_1's rmse: 3.79831\n",
      "[5000]\ttraining's rmse: 3.47925\tvalid_1's rmse: 3.79809\n",
      "Early stopping, best iteration is:\n",
      "[5128]\ttraining's rmse: 3.47583\tvalid_1's rmse: 3.79775\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70386\tvalid_1's rmse: 3.67128\n",
      "[1000]\ttraining's rmse: 3.65709\tvalid_1's rmse: 3.64623\n",
      "[1500]\ttraining's rmse: 3.62937\tvalid_1's rmse: 3.63662\n",
      "[2000]\ttraining's rmse: 3.60877\tvalid_1's rmse: 3.63214\n",
      "[2500]\ttraining's rmse: 3.59211\tvalid_1's rmse: 3.63008\n",
      "[3000]\ttraining's rmse: 3.57695\tvalid_1's rmse: 3.62893\n",
      "[3500]\ttraining's rmse: 3.56316\tvalid_1's rmse: 3.62828\n",
      "[4000]\ttraining's rmse: 3.54941\tvalid_1's rmse: 3.6278\n",
      "Early stopping, best iteration is:\n",
      "[4031]\ttraining's rmse: 3.54851\tvalid_1's rmse: 3.6277\n",
      "   85 | 04m22s |   -3.66951 |             0.8243 |        19.5797 |             0.9054 |             0.1544 |      5.0405 |             17.5502 |            30.9460 |            98.6232 |           0.3479 |      32.3464 |      0.7627 |       9.2280 |      0.9697 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021644]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66175\tvalid_1's rmse: 3.72188\n",
      "[1000]\ttraining's rmse: 3.62201\tvalid_1's rmse: 3.69822\n",
      "[1500]\ttraining's rmse: 3.59771\tvalid_1's rmse: 3.68956\n",
      "[2000]\ttraining's rmse: 3.57927\tvalid_1's rmse: 3.68617\n",
      "[2500]\ttraining's rmse: 3.56348\tvalid_1's rmse: 3.68431\n",
      "[3000]\ttraining's rmse: 3.54836\tvalid_1's rmse: 3.68345\n",
      "[3500]\ttraining's rmse: 3.53404\tvalid_1's rmse: 3.68258\n",
      "[4000]\ttraining's rmse: 3.51998\tvalid_1's rmse: 3.68221\n",
      "[4500]\ttraining's rmse: 3.5057\tvalid_1's rmse: 3.68204\n",
      "Early stopping, best iteration is:\n",
      "[4301]\ttraining's rmse: 3.51134\tvalid_1's rmse: 3.68191\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67603\tvalid_1's rmse: 3.66259\n",
      "[1000]\ttraining's rmse: 3.63398\tvalid_1's rmse: 3.6417\n",
      "[1500]\ttraining's rmse: 3.6105\tvalid_1's rmse: 3.63416\n",
      "[2000]\ttraining's rmse: 3.59163\tvalid_1's rmse: 3.63067\n",
      "[2500]\ttraining's rmse: 3.57449\tvalid_1's rmse: 3.62877\n",
      "[3000]\ttraining's rmse: 3.55842\tvalid_1's rmse: 3.62738\n",
      "[3500]\ttraining's rmse: 3.54324\tvalid_1's rmse: 3.62668\n",
      "[4000]\ttraining's rmse: 3.52863\tvalid_1's rmse: 3.62603\n",
      "[4500]\ttraining's rmse: 3.51469\tvalid_1's rmse: 3.62552\n",
      "Early stopping, best iteration is:\n",
      "[4789]\ttraining's rmse: 3.50674\tvalid_1's rmse: 3.62526\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68039\tvalid_1's rmse: 3.63491\n",
      "[1000]\ttraining's rmse: 3.63822\tvalid_1's rmse: 3.61379\n",
      "[1500]\ttraining's rmse: 3.61425\tvalid_1's rmse: 3.60745\n",
      "[2000]\ttraining's rmse: 3.59444\tvalid_1's rmse: 3.60424\n",
      "[2500]\ttraining's rmse: 3.57676\tvalid_1's rmse: 3.60318\n",
      "[3000]\ttraining's rmse: 3.55992\tvalid_1's rmse: 3.60278\n",
      "Early stopping, best iteration is:\n",
      "[2923]\ttraining's rmse: 3.56249\tvalid_1's rmse: 3.60265\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63281\tvalid_1's rmse: 3.82763\n",
      "[1000]\ttraining's rmse: 3.59013\tvalid_1's rmse: 3.80736\n",
      "[1500]\ttraining's rmse: 3.56598\tvalid_1's rmse: 3.80127\n",
      "[2000]\ttraining's rmse: 3.54766\tvalid_1's rmse: 3.79907\n",
      "[2500]\ttraining's rmse: 3.53096\tvalid_1's rmse: 3.79789\n",
      "[3000]\ttraining's rmse: 3.51567\tvalid_1's rmse: 3.79711\n",
      "[3500]\ttraining's rmse: 3.50091\tvalid_1's rmse: 3.79655\n",
      "[4000]\ttraining's rmse: 3.48598\tvalid_1's rmse: 3.79581\n",
      "[4500]\ttraining's rmse: 3.47159\tvalid_1's rmse: 3.79528\n",
      "Early stopping, best iteration is:\n",
      "[4532]\ttraining's rmse: 3.47081\tvalid_1's rmse: 3.79521\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67598\tvalid_1's rmse: 3.65262\n",
      "[1000]\ttraining's rmse: 3.63267\tvalid_1's rmse: 3.63267\n",
      "[1500]\ttraining's rmse: 3.60876\tvalid_1's rmse: 3.62645\n",
      "[2000]\ttraining's rmse: 3.58986\tvalid_1's rmse: 3.62319\n",
      "[2500]\ttraining's rmse: 3.57314\tvalid_1's rmse: 3.62213\n",
      "[3000]\ttraining's rmse: 3.55752\tvalid_1's rmse: 3.62173\n",
      "Early stopping, best iteration is:\n",
      "[3062]\ttraining's rmse: 3.55574\tvalid_1's rmse: 3.62166\n",
      "   86 | 04m15s |   -3.66601 |             0.6612 |         0.7375 |             0.7480 |             0.3595 |      5.3292 |             49.6616 |            44.7809 |            98.8146 |           0.3719 |      44.8353 |      9.7687 |       3.8526 |      0.7821 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00060778]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61556\tvalid_1's rmse: 3.70956\n",
      "[1000]\ttraining's rmse: 3.55225\tvalid_1's rmse: 3.68939\n",
      "[1500]\ttraining's rmse: 3.50802\tvalid_1's rmse: 3.68439\n",
      "[2000]\ttraining's rmse: 3.46951\tvalid_1's rmse: 3.68224\n",
      "[2500]\ttraining's rmse: 3.43446\tvalid_1's rmse: 3.68173\n",
      "[3000]\ttraining's rmse: 3.40118\tvalid_1's rmse: 3.68155\n",
      "Early stopping, best iteration is:\n",
      "[2827]\ttraining's rmse: 3.41253\tvalid_1's rmse: 3.68124\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62882\tvalid_1's rmse: 3.65117\n",
      "[1000]\ttraining's rmse: 3.56566\tvalid_1's rmse: 3.63391\n",
      "[1500]\ttraining's rmse: 3.52155\tvalid_1's rmse: 3.62845\n",
      "[2000]\ttraining's rmse: 3.48358\tvalid_1's rmse: 3.62699\n",
      "[2500]\ttraining's rmse: 3.44879\tvalid_1's rmse: 3.6261\n",
      "Early stopping, best iteration is:\n",
      "[2419]\ttraining's rmse: 3.45446\tvalid_1's rmse: 3.62606\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63433\tvalid_1's rmse: 3.62679\n",
      "[1000]\ttraining's rmse: 3.57016\tvalid_1's rmse: 3.61013\n",
      "[1500]\ttraining's rmse: 3.5253\tvalid_1's rmse: 3.60572\n",
      "[2000]\ttraining's rmse: 3.48696\tvalid_1's rmse: 3.60391\n",
      "Early stopping, best iteration is:\n",
      "[2007]\ttraining's rmse: 3.48653\tvalid_1's rmse: 3.60385\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58861\tvalid_1's rmse: 3.81211\n",
      "[1000]\ttraining's rmse: 3.52498\tvalid_1's rmse: 3.79725\n",
      "[1500]\ttraining's rmse: 3.48079\tvalid_1's rmse: 3.79346\n",
      "Early stopping, best iteration is:\n",
      "[1659]\ttraining's rmse: 3.46817\tvalid_1's rmse: 3.79293\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62894\tvalid_1's rmse: 3.64536\n",
      "[1000]\ttraining's rmse: 3.56549\tvalid_1's rmse: 3.63031\n",
      "[1500]\ttraining's rmse: 3.52146\tvalid_1's rmse: 3.62611\n",
      "[2000]\ttraining's rmse: 3.48303\tvalid_1's rmse: 3.62463\n",
      "Early stopping, best iteration is:\n",
      "[2042]\ttraining's rmse: 3.48003\tvalid_1's rmse: 3.62458\n",
      "   87 | 04m25s |   -3.66637 |             0.6012 |         1.0997 |             0.5796 |             0.8839 |     14.9676 |              7.3424 |            30.8459 |            94.7545 |           0.9648 |      30.2641 |      8.1948 |       9.8750 |      0.8236 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59755\tvalid_1's rmse: 3.71179\n",
      "[1000]\ttraining's rmse: 3.52171\tvalid_1's rmse: 3.69093\n",
      "[1500]\ttraining's rmse: 3.472\tvalid_1's rmse: 3.68441\n",
      "[2000]\ttraining's rmse: 3.43356\tvalid_1's rmse: 3.68241\n",
      "Early stopping, best iteration is:\n",
      "[2297]\ttraining's rmse: 3.41311\tvalid_1's rmse: 3.68176\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6111\tvalid_1's rmse: 3.6535\n",
      "[1000]\ttraining's rmse: 3.53342\tvalid_1's rmse: 3.63474\n",
      "[1500]\ttraining's rmse: 3.48293\tvalid_1's rmse: 3.6294\n",
      "[2000]\ttraining's rmse: 3.44344\tvalid_1's rmse: 3.62772\n",
      "[2500]\ttraining's rmse: 3.40923\tvalid_1's rmse: 3.62719\n",
      "Early stopping, best iteration is:\n",
      "[2639]\ttraining's rmse: 3.40081\tvalid_1's rmse: 3.62698\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61455\tvalid_1's rmse: 3.6288\n",
      "[1000]\ttraining's rmse: 3.53878\tvalid_1's rmse: 3.61098\n",
      "[1500]\ttraining's rmse: 3.48878\tvalid_1's rmse: 3.6055\n",
      "[2000]\ttraining's rmse: 3.44822\tvalid_1's rmse: 3.60365\n",
      "[2500]\ttraining's rmse: 3.41493\tvalid_1's rmse: 3.60309\n",
      "Early stopping, best iteration is:\n",
      "[2398]\ttraining's rmse: 3.42151\tvalid_1's rmse: 3.60295\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57085\tvalid_1's rmse: 3.8122\n",
      "[1000]\ttraining's rmse: 3.49265\tvalid_1's rmse: 3.79487\n",
      "[1500]\ttraining's rmse: 3.44173\tvalid_1's rmse: 3.78937\n",
      "[2000]\ttraining's rmse: 3.40321\tvalid_1's rmse: 3.78803\n",
      "Early stopping, best iteration is:\n",
      "[2244]\ttraining's rmse: 3.38705\tvalid_1's rmse: 3.7877\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60925\tvalid_1's rmse: 3.64944\n",
      "[1000]\ttraining's rmse: 3.53219\tvalid_1's rmse: 3.63283\n",
      "[1500]\ttraining's rmse: 3.48184\tvalid_1's rmse: 3.6268\n",
      "[2000]\ttraining's rmse: 3.44232\tvalid_1's rmse: 3.62427\n",
      "Early stopping, best iteration is:\n",
      "[2229]\ttraining's rmse: 3.42685\tvalid_1's rmse: 3.62359\n",
      "   88 | 04m06s |   -3.66521 |             0.8211 |         0.2969 |             0.2360 |             0.5402 |     14.0868 |             42.3683 |            43.7953 |            71.7214 |           0.7484 |      32.1984 |      8.7516 |       1.6754 |      0.7831 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65404\tvalid_1's rmse: 3.71622\n",
      "[1000]\ttraining's rmse: 3.61566\tvalid_1's rmse: 3.69622\n",
      "[1500]\ttraining's rmse: 3.58875\tvalid_1's rmse: 3.68915\n",
      "[2000]\ttraining's rmse: 3.56764\tvalid_1's rmse: 3.68556\n",
      "[2500]\ttraining's rmse: 3.54897\tvalid_1's rmse: 3.68444\n",
      "[3000]\ttraining's rmse: 3.5321\tvalid_1's rmse: 3.68381\n",
      "Early stopping, best iteration is:\n",
      "[3152]\ttraining's rmse: 3.52632\tvalid_1's rmse: 3.68337\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66818\tvalid_1's rmse: 3.65773\n",
      "[1000]\ttraining's rmse: 3.62823\tvalid_1's rmse: 3.64058\n",
      "[1500]\ttraining's rmse: 3.60246\tvalid_1's rmse: 3.63377\n",
      "[2000]\ttraining's rmse: 3.57991\tvalid_1's rmse: 3.6301\n",
      "[2500]\ttraining's rmse: 3.56041\tvalid_1's rmse: 3.62815\n",
      "[3000]\ttraining's rmse: 3.543\tvalid_1's rmse: 3.62694\n",
      "[3500]\ttraining's rmse: 3.52483\tvalid_1's rmse: 3.62619\n",
      "[4000]\ttraining's rmse: 3.50876\tvalid_1's rmse: 3.62553\n",
      "[4500]\ttraining's rmse: 3.49205\tvalid_1's rmse: 3.62505\n",
      "Early stopping, best iteration is:\n",
      "[4773]\ttraining's rmse: 3.48409\tvalid_1's rmse: 3.62488\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67223\tvalid_1's rmse: 3.6294\n",
      "[1000]\ttraining's rmse: 3.62984\tvalid_1's rmse: 3.61201\n",
      "[1500]\ttraining's rmse: 3.60411\tvalid_1's rmse: 3.60623\n",
      "[2000]\ttraining's rmse: 3.58304\tvalid_1's rmse: 3.60459\n",
      "[2500]\ttraining's rmse: 3.56147\tvalid_1's rmse: 3.6039\n",
      "Early stopping, best iteration is:\n",
      "[2580]\ttraining's rmse: 3.55842\tvalid_1's rmse: 3.6037\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62496\tvalid_1's rmse: 3.82018\n",
      "[1000]\ttraining's rmse: 3.58305\tvalid_1's rmse: 3.80379\n",
      "[1500]\ttraining's rmse: 3.55748\tvalid_1's rmse: 3.79842\n",
      "[2000]\ttraining's rmse: 3.53521\tvalid_1's rmse: 3.79579\n",
      "[2500]\ttraining's rmse: 3.51671\tvalid_1's rmse: 3.7941\n",
      "[3000]\ttraining's rmse: 3.49809\tvalid_1's rmse: 3.79322\n",
      "[3500]\ttraining's rmse: 3.48077\tvalid_1's rmse: 3.79262\n",
      "Early stopping, best iteration is:\n",
      "[3637]\ttraining's rmse: 3.47666\tvalid_1's rmse: 3.79247\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66858\tvalid_1's rmse: 3.64772\n",
      "[1000]\ttraining's rmse: 3.6267\tvalid_1's rmse: 3.63079\n",
      "[1500]\ttraining's rmse: 3.60135\tvalid_1's rmse: 3.62564\n",
      "[2000]\ttraining's rmse: 3.58066\tvalid_1's rmse: 3.62349\n",
      "[2500]\ttraining's rmse: 3.55971\tvalid_1's rmse: 3.62268\n",
      "Early stopping, best iteration is:\n",
      "[2534]\ttraining's rmse: 3.55848\tvalid_1's rmse: 3.62261\n",
      "   89 | 04m49s |   -3.66605 |             0.8111 |         4.9159 |             0.4543 |             0.5728 |      5.4692 |             49.3594 |            31.4875 |            91.4738 |           0.4405 |      44.9547 |      8.7527 |       0.2207 |      0.7070 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.000449]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00112186]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.703\tvalid_1's rmse: 3.7559\n",
      "[1000]\ttraining's rmse: 3.65678\tvalid_1's rmse: 3.72355\n",
      "[1500]\ttraining's rmse: 3.62905\tvalid_1's rmse: 3.70994\n",
      "[2000]\ttraining's rmse: 3.60746\tvalid_1's rmse: 3.702\n",
      "[2500]\ttraining's rmse: 3.59028\tvalid_1's rmse: 3.69726\n",
      "[3000]\ttraining's rmse: 3.57429\tvalid_1's rmse: 3.69456\n",
      "[3500]\ttraining's rmse: 3.55951\tvalid_1's rmse: 3.69237\n",
      "[4000]\ttraining's rmse: 3.54573\tvalid_1's rmse: 3.69114\n",
      "[4500]\ttraining's rmse: 3.5326\tvalid_1's rmse: 3.69063\n",
      "[5000]\ttraining's rmse: 3.52038\tvalid_1's rmse: 3.69021\n",
      "Early stopping, best iteration is:\n",
      "[4838]\ttraining's rmse: 3.52416\tvalid_1's rmse: 3.68999\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.71796\tvalid_1's rmse: 3.68962\n",
      "[1000]\ttraining's rmse: 3.6707\tvalid_1's rmse: 3.66202\n",
      "[1500]\ttraining's rmse: 3.64236\tvalid_1's rmse: 3.64986\n",
      "[2000]\ttraining's rmse: 3.62134\tvalid_1's rmse: 3.64272\n",
      "[2500]\ttraining's rmse: 3.60313\tvalid_1's rmse: 3.63834\n",
      "[3000]\ttraining's rmse: 3.58704\tvalid_1's rmse: 3.63489\n",
      "[3500]\ttraining's rmse: 3.57178\tvalid_1's rmse: 3.63272\n",
      "[4000]\ttraining's rmse: 3.55797\tvalid_1's rmse: 3.63166\n",
      "[4500]\ttraining's rmse: 3.54496\tvalid_1's rmse: 3.63048\n",
      "[5000]\ttraining's rmse: 3.53212\tvalid_1's rmse: 3.62982\n",
      "[5500]\ttraining's rmse: 3.51932\tvalid_1's rmse: 3.62896\n",
      "[6000]\ttraining's rmse: 3.50739\tvalid_1's rmse: 3.62824\n",
      "[6500]\ttraining's rmse: 3.49573\tvalid_1's rmse: 3.62761\n",
      "Early stopping, best iteration is:\n",
      "[6579]\ttraining's rmse: 3.4941\tvalid_1's rmse: 3.62745\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.72326\tvalid_1's rmse: 3.66303\n",
      "[1000]\ttraining's rmse: 3.67565\tvalid_1's rmse: 3.6367\n",
      "[1500]\ttraining's rmse: 3.64712\tvalid_1's rmse: 3.62548\n",
      "[2000]\ttraining's rmse: 3.62532\tvalid_1's rmse: 3.62005\n",
      "[2500]\ttraining's rmse: 3.60687\tvalid_1's rmse: 3.61681\n",
      "[3000]\ttraining's rmse: 3.59081\tvalid_1's rmse: 3.61394\n",
      "[3500]\ttraining's rmse: 3.57569\tvalid_1's rmse: 3.61241\n",
      "[4000]\ttraining's rmse: 3.56226\tvalid_1's rmse: 3.61125\n",
      "Early stopping, best iteration is:\n",
      "[4036]\ttraining's rmse: 3.56133\tvalid_1's rmse: 3.61119\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67415\tvalid_1's rmse: 3.86383\n",
      "[1000]\ttraining's rmse: 3.62763\tvalid_1's rmse: 3.83419\n",
      "[1500]\ttraining's rmse: 3.59869\tvalid_1's rmse: 3.82101\n",
      "[2000]\ttraining's rmse: 3.57796\tvalid_1's rmse: 3.81412\n",
      "[2500]\ttraining's rmse: 3.56045\tvalid_1's rmse: 3.81001\n",
      "[3000]\ttraining's rmse: 3.54484\tvalid_1's rmse: 3.80731\n",
      "[3500]\ttraining's rmse: 3.53025\tvalid_1's rmse: 3.80521\n",
      "[4000]\ttraining's rmse: 3.51605\tvalid_1's rmse: 3.8034\n",
      "[4500]\ttraining's rmse: 3.50249\tvalid_1's rmse: 3.80264\n",
      "[5000]\ttraining's rmse: 3.48947\tvalid_1's rmse: 3.80229\n",
      "[5500]\ttraining's rmse: 3.47634\tvalid_1's rmse: 3.80176\n",
      "[6000]\ttraining's rmse: 3.46457\tvalid_1's rmse: 3.80128\n",
      "[6500]\ttraining's rmse: 3.45279\tvalid_1's rmse: 3.80111\n",
      "Early stopping, best iteration is:\n",
      "[6424]\ttraining's rmse: 3.45453\tvalid_1's rmse: 3.80106\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.71893\tvalid_1's rmse: 3.68214\n",
      "[1000]\ttraining's rmse: 3.67023\tvalid_1's rmse: 3.65567\n",
      "[1500]\ttraining's rmse: 3.64132\tvalid_1's rmse: 3.64485\n",
      "[2000]\ttraining's rmse: 3.61926\tvalid_1's rmse: 3.63858\n",
      "[2500]\ttraining's rmse: 3.60153\tvalid_1's rmse: 3.6352\n",
      "[3000]\ttraining's rmse: 3.58533\tvalid_1's rmse: 3.63295\n",
      "[3500]\ttraining's rmse: 3.57107\tvalid_1's rmse: 3.63146\n",
      "[4000]\ttraining's rmse: 3.5577\tvalid_1's rmse: 3.63061\n",
      "Early stopping, best iteration is:\n",
      "[4001]\ttraining's rmse: 3.55768\tvalid_1's rmse: 3.63061\n",
      "   90 | 04m23s |   -3.67272 |             0.7383 |        15.4026 |             0.5543 |             0.1059 |      5.5251 |             49.2383 |            40.2972 |            83.8692 |           0.6234 |      44.2988 |      0.8994 |       0.0583 |      0.9221 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63082\tvalid_1's rmse: 3.7219\n",
      "[1000]\ttraining's rmse: 3.56254\tvalid_1's rmse: 3.69729\n",
      "[1500]\ttraining's rmse: 3.51922\tvalid_1's rmse: 3.68867\n",
      "[2000]\ttraining's rmse: 3.48375\tvalid_1's rmse: 3.68578\n",
      "[2500]\ttraining's rmse: 3.45337\tvalid_1's rmse: 3.68443\n",
      "[3000]\ttraining's rmse: 3.42711\tvalid_1's rmse: 3.68342\n",
      "Early stopping, best iteration is:\n",
      "[3071]\ttraining's rmse: 3.42357\tvalid_1's rmse: 3.6832\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64515\tvalid_1's rmse: 3.66029\n",
      "[1000]\ttraining's rmse: 3.57543\tvalid_1's rmse: 3.63928\n",
      "[1500]\ttraining's rmse: 3.53159\tvalid_1's rmse: 3.63176\n",
      "[2000]\ttraining's rmse: 3.49649\tvalid_1's rmse: 3.62815\n",
      "[2500]\ttraining's rmse: 3.46509\tvalid_1's rmse: 3.62684\n",
      "[3000]\ttraining's rmse: 3.43772\tvalid_1's rmse: 3.6259\n",
      "[3500]\ttraining's rmse: 3.41159\tvalid_1's rmse: 3.62518\n",
      "[4000]\ttraining's rmse: 3.38702\tvalid_1's rmse: 3.62482\n",
      "[4500]\ttraining's rmse: 3.36319\tvalid_1's rmse: 3.62456\n",
      "Early stopping, best iteration is:\n",
      "[4382]\ttraining's rmse: 3.36868\tvalid_1's rmse: 3.6244\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64977\tvalid_1's rmse: 3.63754\n",
      "[1000]\ttraining's rmse: 3.58002\tvalid_1's rmse: 3.61591\n",
      "[1500]\ttraining's rmse: 3.53623\tvalid_1's rmse: 3.60928\n",
      "[2000]\ttraining's rmse: 3.50024\tvalid_1's rmse: 3.60637\n",
      "[2500]\ttraining's rmse: 3.47003\tvalid_1's rmse: 3.60494\n",
      "[3000]\ttraining's rmse: 3.44262\tvalid_1's rmse: 3.60441\n",
      "[3500]\ttraining's rmse: 3.4166\tvalid_1's rmse: 3.60429\n",
      "Early stopping, best iteration is:\n",
      "[3437]\ttraining's rmse: 3.41965\tvalid_1's rmse: 3.60421\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60318\tvalid_1's rmse: 3.8254\n",
      "[1000]\ttraining's rmse: 3.53348\tvalid_1's rmse: 3.80416\n",
      "[1500]\ttraining's rmse: 3.49043\tvalid_1's rmse: 3.79737\n",
      "[2000]\ttraining's rmse: 3.45567\tvalid_1's rmse: 3.79363\n",
      "[2500]\ttraining's rmse: 3.42614\tvalid_1's rmse: 3.79233\n",
      "[3000]\ttraining's rmse: 3.39883\tvalid_1's rmse: 3.79177\n",
      "[3500]\ttraining's rmse: 3.37324\tvalid_1's rmse: 3.79156\n",
      "[4000]\ttraining's rmse: 3.34943\tvalid_1's rmse: 3.79121\n",
      "[4500]\ttraining's rmse: 3.32642\tvalid_1's rmse: 3.79086\n",
      "[5000]\ttraining's rmse: 3.30338\tvalid_1's rmse: 3.79077\n",
      "Early stopping, best iteration is:\n",
      "[4828]\ttraining's rmse: 3.31177\tvalid_1's rmse: 3.79064\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64434\tvalid_1's rmse: 3.65439\n",
      "[1000]\ttraining's rmse: 3.57379\tvalid_1's rmse: 3.63497\n",
      "[1500]\ttraining's rmse: 3.52952\tvalid_1's rmse: 3.62808\n",
      "[2000]\ttraining's rmse: 3.49452\tvalid_1's rmse: 3.62452\n",
      "[2500]\ttraining's rmse: 3.46479\tvalid_1's rmse: 3.62331\n",
      "[3000]\ttraining's rmse: 3.43793\tvalid_1's rmse: 3.62297\n",
      "Early stopping, best iteration is:\n",
      "[3009]\ttraining's rmse: 3.43747\tvalid_1's rmse: 3.6229\n",
      "   91 | 05m17s |   -3.66570 |             0.9749 |         3.7741 |             0.5405 |             0.2788 |     14.8713 |             48.5937 |            44.9055 |            84.8540 |           0.9949 |      30.9914 |      4.7807 |       8.4353 |      0.4390 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60029\tvalid_1's rmse: 3.70987\n",
      "[1000]\ttraining's rmse: 3.52774\tvalid_1's rmse: 3.69195\n",
      "[1500]\ttraining's rmse: 3.47764\tvalid_1's rmse: 3.68519\n",
      "[2000]\ttraining's rmse: 3.43905\tvalid_1's rmse: 3.68332\n",
      "Early stopping, best iteration is:\n",
      "[2058]\ttraining's rmse: 3.43494\tvalid_1's rmse: 3.68315\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61277\tvalid_1's rmse: 3.6525\n",
      "[1000]\ttraining's rmse: 3.53707\tvalid_1's rmse: 3.63603\n",
      "[1500]\ttraining's rmse: 3.48952\tvalid_1's rmse: 3.63083\n",
      "[2000]\ttraining's rmse: 3.44961\tvalid_1's rmse: 3.62977\n",
      "Early stopping, best iteration is:\n",
      "[2210]\ttraining's rmse: 3.43452\tvalid_1's rmse: 3.62939\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61841\tvalid_1's rmse: 3.62877\n",
      "[1000]\ttraining's rmse: 3.54405\tvalid_1's rmse: 3.61186\n",
      "[1500]\ttraining's rmse: 3.49578\tvalid_1's rmse: 3.60724\n",
      "[2000]\ttraining's rmse: 3.4578\tvalid_1's rmse: 3.60561\n",
      "Early stopping, best iteration is:\n",
      "[2010]\ttraining's rmse: 3.45713\tvalid_1's rmse: 3.60549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57442\tvalid_1's rmse: 3.81071\n",
      "[1000]\ttraining's rmse: 3.49874\tvalid_1's rmse: 3.79539\n",
      "[1500]\ttraining's rmse: 3.4509\tvalid_1's rmse: 3.79091\n",
      "Early stopping, best iteration is:\n",
      "[1659]\ttraining's rmse: 3.43775\tvalid_1's rmse: 3.79065\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61127\tvalid_1's rmse: 3.64793\n",
      "[1000]\ttraining's rmse: 3.53783\tvalid_1's rmse: 3.63312\n",
      "[1500]\ttraining's rmse: 3.48992\tvalid_1's rmse: 3.62841\n",
      "[2000]\ttraining's rmse: 3.45258\tvalid_1's rmse: 3.62628\n",
      "Early stopping, best iteration is:\n",
      "[2226]\ttraining's rmse: 3.43698\tvalid_1's rmse: 3.62583\n",
      "   92 | 05m19s |   -3.66751 |             0.9520 |        17.8856 |             0.5843 |             0.8999 |     14.3026 |             46.8617 |            36.5935 |            86.5718 |           0.9659 |      32.8194 |      8.9020 |       9.6016 |      0.9792 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00041233]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56718\tvalid_1's rmse: 3.70224\n",
      "[1000]\ttraining's rmse: 3.4872\tvalid_1's rmse: 3.68557\n",
      "[1500]\ttraining's rmse: 3.42872\tvalid_1's rmse: 3.68139\n",
      "[2000]\ttraining's rmse: 3.38015\tvalid_1's rmse: 3.68023\n",
      "Early stopping, best iteration is:\n",
      "[2044]\ttraining's rmse: 3.3756\tvalid_1's rmse: 3.68016\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57964\tvalid_1's rmse: 3.6462\n",
      "[1000]\ttraining's rmse: 3.49744\tvalid_1's rmse: 3.63068\n",
      "[1500]\ttraining's rmse: 3.43882\tvalid_1's rmse: 3.627\n",
      "[2000]\ttraining's rmse: 3.39034\tvalid_1's rmse: 3.62681\n",
      "Early stopping, best iteration is:\n",
      "[1935]\ttraining's rmse: 3.39642\tvalid_1's rmse: 3.62656\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58461\tvalid_1's rmse: 3.62566\n",
      "[1000]\ttraining's rmse: 3.49996\tvalid_1's rmse: 3.60984\n",
      "[1500]\ttraining's rmse: 3.44178\tvalid_1's rmse: 3.60684\n",
      "Early stopping, best iteration is:\n",
      "[1358]\ttraining's rmse: 3.4565\tvalid_1's rmse: 3.60662\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.53964\tvalid_1's rmse: 3.80656\n",
      "[1000]\ttraining's rmse: 3.45557\tvalid_1's rmse: 3.7945\n",
      "[1500]\ttraining's rmse: 3.3985\tvalid_1's rmse: 3.79193\n",
      "Early stopping, best iteration is:\n",
      "[1574]\ttraining's rmse: 3.3915\tvalid_1's rmse: 3.79152\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57756\tvalid_1's rmse: 3.64434\n",
      "[1000]\ttraining's rmse: 3.49538\tvalid_1's rmse: 3.63086\n",
      "[1500]\ttraining's rmse: 3.43825\tvalid_1's rmse: 3.62757\n",
      "Early stopping, best iteration is:\n",
      "[1602]\ttraining's rmse: 3.42769\tvalid_1's rmse: 3.62684\n",
      "   93 | 05m19s |   -3.66696 |             0.8920 |         9.8477 |             0.9782 |             0.9079 |     11.7118 |             37.4472 |            35.7198 |            83.0814 |           0.9344 |      44.5345 |      9.2825 |       0.6227 |      0.6658 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61616\tvalid_1's rmse: 3.70802\n",
      "[1000]\ttraining's rmse: 3.565\tvalid_1's rmse: 3.69016\n",
      "[1500]\ttraining's rmse: 3.52708\tvalid_1's rmse: 3.68517\n",
      "[2000]\ttraining's rmse: 3.49492\tvalid_1's rmse: 3.68425\n",
      "Early stopping, best iteration is:\n",
      "[2017]\ttraining's rmse: 3.49383\tvalid_1's rmse: 3.68419\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62918\tvalid_1's rmse: 3.65122\n",
      "[1000]\ttraining's rmse: 3.57576\tvalid_1's rmse: 3.6352\n",
      "[1500]\ttraining's rmse: 3.53668\tvalid_1's rmse: 3.63101\n",
      "[2000]\ttraining's rmse: 3.50607\tvalid_1's rmse: 3.62939\n",
      "[2500]\ttraining's rmse: 3.47651\tvalid_1's rmse: 3.62898\n",
      "Early stopping, best iteration is:\n",
      "[2545]\ttraining's rmse: 3.47369\tvalid_1's rmse: 3.6289\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63548\tvalid_1's rmse: 3.62366\n",
      "[1000]\ttraining's rmse: 3.58099\tvalid_1's rmse: 3.60905\n",
      "[1500]\ttraining's rmse: 3.54461\tvalid_1's rmse: 3.60582\n",
      "[2000]\ttraining's rmse: 3.51101\tvalid_1's rmse: 3.60519\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 3.50309\tvalid_1's rmse: 3.60495\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5878\tvalid_1's rmse: 3.80935\n",
      "[1000]\ttraining's rmse: 3.53231\tvalid_1's rmse: 3.79389\n",
      "[1500]\ttraining's rmse: 3.49311\tvalid_1's rmse: 3.79048\n",
      "[2000]\ttraining's rmse: 3.46119\tvalid_1's rmse: 3.78978\n",
      "Early stopping, best iteration is:\n",
      "[1969]\ttraining's rmse: 3.46298\tvalid_1's rmse: 3.78969\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62982\tvalid_1's rmse: 3.64213\n",
      "[1000]\ttraining's rmse: 3.57314\tvalid_1's rmse: 3.62764\n",
      "[1500]\ttraining's rmse: 3.53472\tvalid_1's rmse: 3.62374\n",
      "[2000]\ttraining's rmse: 3.50216\tvalid_1's rmse: 3.62273\n",
      "Early stopping, best iteration is:\n",
      "[2097]\ttraining's rmse: 3.49626\tvalid_1's rmse: 3.62261\n",
      "   94 | 04m28s |   -3.66669 |             0.5974 |         0.4777 |             0.8060 |             0.6799 |      6.5902 |              5.3970 |            44.2234 |            10.2329 |           0.0354 |      36.9250 |      9.9221 |       1.1888 |      0.6342 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60712\tvalid_1's rmse: 3.71525\n",
      "[1000]\ttraining's rmse: 3.53775\tvalid_1's rmse: 3.6935\n",
      "[1500]\ttraining's rmse: 3.49044\tvalid_1's rmse: 3.68687\n",
      "[2000]\ttraining's rmse: 3.45271\tvalid_1's rmse: 3.68455\n",
      "[2500]\ttraining's rmse: 3.41917\tvalid_1's rmse: 3.68342\n",
      "Early stopping, best iteration is:\n",
      "[2774]\ttraining's rmse: 3.40264\tvalid_1's rmse: 3.68288\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62043\tvalid_1's rmse: 3.65591\n",
      "[1000]\ttraining's rmse: 3.54936\tvalid_1's rmse: 3.63625\n",
      "[1500]\ttraining's rmse: 3.50278\tvalid_1's rmse: 3.62998\n",
      "[2000]\ttraining's rmse: 3.46332\tvalid_1's rmse: 3.62763\n",
      "[2500]\ttraining's rmse: 3.42968\tvalid_1's rmse: 3.62627\n",
      "Early stopping, best iteration is:\n",
      "[2791]\ttraining's rmse: 3.41119\tvalid_1's rmse: 3.62545\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62469\tvalid_1's rmse: 3.63199\n",
      "[1000]\ttraining's rmse: 3.55299\tvalid_1's rmse: 3.61295\n",
      "[1500]\ttraining's rmse: 3.50663\tvalid_1's rmse: 3.6081\n",
      "[2000]\ttraining's rmse: 3.46847\tvalid_1's rmse: 3.60586\n",
      "Early stopping, best iteration is:\n",
      "[2233]\ttraining's rmse: 3.45222\tvalid_1's rmse: 3.60557\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5797\tvalid_1's rmse: 3.81675\n",
      "[1000]\ttraining's rmse: 3.50708\tvalid_1's rmse: 3.79861\n",
      "[1500]\ttraining's rmse: 3.46011\tvalid_1's rmse: 3.79299\n",
      "[2000]\ttraining's rmse: 3.42249\tvalid_1's rmse: 3.79101\n",
      "[2500]\ttraining's rmse: 3.39006\tvalid_1's rmse: 3.79045\n",
      "[3000]\ttraining's rmse: 3.35985\tvalid_1's rmse: 3.79003\n",
      "Early stopping, best iteration is:\n",
      "[2944]\ttraining's rmse: 3.36311\tvalid_1's rmse: 3.78984\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61936\tvalid_1's rmse: 3.65028\n",
      "[1000]\ttraining's rmse: 3.54646\tvalid_1's rmse: 3.63271\n",
      "[1500]\ttraining's rmse: 3.499\tvalid_1's rmse: 3.6268\n",
      "[2000]\ttraining's rmse: 3.46164\tvalid_1's rmse: 3.62441\n",
      "[2500]\ttraining's rmse: 3.42826\tvalid_1's rmse: 3.62403\n",
      "[3000]\ttraining's rmse: 3.39738\tvalid_1's rmse: 3.6239\n",
      "Early stopping, best iteration is:\n",
      "[3042]\ttraining's rmse: 3.39488\tvalid_1's rmse: 3.62373\n",
      "   95 | 04m23s |   -3.66611 |             0.9685 |         1.4493 |             0.9046 |             0.4177 |      9.3628 |              9.6217 |            44.1023 |            12.4508 |           0.2284 |      30.0257 |      0.7582 |       0.4659 |      0.6128 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60598\tvalid_1's rmse: 3.70941\n",
      "[1000]\ttraining's rmse: 3.53755\tvalid_1's rmse: 3.68948\n",
      "[1500]\ttraining's rmse: 3.49237\tvalid_1's rmse: 3.6836\n",
      "[2000]\ttraining's rmse: 3.45579\tvalid_1's rmse: 3.68141\n",
      "[2500]\ttraining's rmse: 3.42499\tvalid_1's rmse: 3.68065\n",
      "[3000]\ttraining's rmse: 3.39529\tvalid_1's rmse: 3.68038\n",
      "Early stopping, best iteration is:\n",
      "[2899]\ttraining's rmse: 3.40104\tvalid_1's rmse: 3.68\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61903\tvalid_1's rmse: 3.65229\n",
      "[1000]\ttraining's rmse: 3.5499\tvalid_1's rmse: 3.63465\n",
      "[1500]\ttraining's rmse: 3.50447\tvalid_1's rmse: 3.62851\n",
      "[2000]\ttraining's rmse: 3.4679\tvalid_1's rmse: 3.6268\n",
      "[2500]\ttraining's rmse: 3.43548\tvalid_1's rmse: 3.62572\n",
      "[3000]\ttraining's rmse: 3.4062\tvalid_1's rmse: 3.62535\n",
      "Early stopping, best iteration is:\n",
      "[2917]\ttraining's rmse: 3.41086\tvalid_1's rmse: 3.62517\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62401\tvalid_1's rmse: 3.62789\n",
      "[1000]\ttraining's rmse: 3.5556\tvalid_1's rmse: 3.6106\n",
      "[1500]\ttraining's rmse: 3.5093\tvalid_1's rmse: 3.60595\n",
      "[2000]\ttraining's rmse: 3.47352\tvalid_1's rmse: 3.60504\n",
      "Early stopping, best iteration is:\n",
      "[2114]\ttraining's rmse: 3.46589\tvalid_1's rmse: 3.60469\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57988\tvalid_1's rmse: 3.81017\n",
      "[1000]\ttraining's rmse: 3.51013\tvalid_1's rmse: 3.79468\n",
      "[1500]\ttraining's rmse: 3.46493\tvalid_1's rmse: 3.79101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's rmse: 3.42826\tvalid_1's rmse: 3.78923\n",
      "[2500]\ttraining's rmse: 3.39595\tvalid_1's rmse: 3.78865\n",
      "Early stopping, best iteration is:\n",
      "[2418]\ttraining's rmse: 3.40141\tvalid_1's rmse: 3.78849\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61864\tvalid_1's rmse: 3.64692\n",
      "[1000]\ttraining's rmse: 3.54961\tvalid_1's rmse: 3.6308\n",
      "[1500]\ttraining's rmse: 3.50486\tvalid_1's rmse: 3.62539\n",
      "[2000]\ttraining's rmse: 3.46936\tvalid_1's rmse: 3.62352\n",
      "[2500]\ttraining's rmse: 3.43676\tvalid_1's rmse: 3.62286\n",
      "Early stopping, best iteration is:\n",
      "[2715]\ttraining's rmse: 3.4239\tvalid_1's rmse: 3.62267\n",
      "   96 | 05m32s |   -3.66482 |             0.9548 |         7.4288 |             0.9641 |             0.7210 |     14.1443 |             47.9897 |            44.4966 |            99.5247 |           0.9681 |      30.2837 |      2.7338 |       0.3818 |      0.6744 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64987\tvalid_1's rmse: 3.71738\n",
      "[1000]\ttraining's rmse: 3.60799\tvalid_1's rmse: 3.69732\n",
      "[1500]\ttraining's rmse: 3.58005\tvalid_1's rmse: 3.69048\n",
      "[2000]\ttraining's rmse: 3.55482\tvalid_1's rmse: 3.68719\n",
      "[2500]\ttraining's rmse: 3.5342\tvalid_1's rmse: 3.68555\n",
      "[3000]\ttraining's rmse: 3.51355\tvalid_1's rmse: 3.68469\n",
      "[3500]\ttraining's rmse: 3.49515\tvalid_1's rmse: 3.68452\n",
      "[4000]\ttraining's rmse: 3.47654\tvalid_1's rmse: 3.68391\n",
      "Early stopping, best iteration is:\n",
      "[4063]\ttraining's rmse: 3.47443\tvalid_1's rmse: 3.68383\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66454\tvalid_1's rmse: 3.65785\n",
      "[1000]\ttraining's rmse: 3.62105\tvalid_1's rmse: 3.64007\n",
      "[1500]\ttraining's rmse: 3.59243\tvalid_1's rmse: 3.63354\n",
      "[2000]\ttraining's rmse: 3.56985\tvalid_1's rmse: 3.63054\n",
      "[2500]\ttraining's rmse: 3.54619\tvalid_1's rmse: 3.62906\n",
      "[3000]\ttraining's rmse: 3.52614\tvalid_1's rmse: 3.6282\n",
      "[3500]\ttraining's rmse: 3.50668\tvalid_1's rmse: 3.62721\n",
      "[4000]\ttraining's rmse: 3.48827\tvalid_1's rmse: 3.62664\n",
      "[4500]\ttraining's rmse: 3.46979\tvalid_1's rmse: 3.62596\n",
      "Early stopping, best iteration is:\n",
      "[4484]\ttraining's rmse: 3.47033\tvalid_1's rmse: 3.62594\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67074\tvalid_1's rmse: 3.63007\n",
      "[1000]\ttraining's rmse: 3.62563\tvalid_1's rmse: 3.61138\n",
      "[1500]\ttraining's rmse: 3.59717\tvalid_1's rmse: 3.60611\n",
      "[2000]\ttraining's rmse: 3.57414\tvalid_1's rmse: 3.60443\n",
      "Early stopping, best iteration is:\n",
      "[2207]\ttraining's rmse: 3.56529\tvalid_1's rmse: 3.60407\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62184\tvalid_1's rmse: 3.82238\n",
      "[1000]\ttraining's rmse: 3.57695\tvalid_1's rmse: 3.80478\n",
      "[1500]\ttraining's rmse: 3.54945\tvalid_1's rmse: 3.79934\n",
      "[2000]\ttraining's rmse: 3.5258\tvalid_1's rmse: 3.79662\n",
      "[2500]\ttraining's rmse: 3.50492\tvalid_1's rmse: 3.79505\n",
      "[3000]\ttraining's rmse: 3.48546\tvalid_1's rmse: 3.79425\n",
      "[3500]\ttraining's rmse: 3.46721\tvalid_1's rmse: 3.79356\n",
      "[4000]\ttraining's rmse: 3.44927\tvalid_1's rmse: 3.79323\n",
      "Early stopping, best iteration is:\n",
      "[3855]\ttraining's rmse: 3.45435\tvalid_1's rmse: 3.79314\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66461\tvalid_1's rmse: 3.64921\n",
      "[1000]\ttraining's rmse: 3.61752\tvalid_1's rmse: 3.63096\n",
      "[1500]\ttraining's rmse: 3.58829\tvalid_1's rmse: 3.62493\n",
      "[2000]\ttraining's rmse: 3.56586\tvalid_1's rmse: 3.62307\n",
      "[2500]\ttraining's rmse: 3.54526\tvalid_1's rmse: 3.62225\n",
      "Early stopping, best iteration is:\n",
      "[2387]\ttraining's rmse: 3.54952\tvalid_1's rmse: 3.62204\n",
      "   97 | 05m26s |   -3.66645 |             0.9677 |        18.7340 |             0.7528 |             0.5496 |      5.8115 |             24.2364 |            32.2073 |            38.8899 |           0.9716 |      41.1699 |      2.6798 |       9.8133 |      0.1927 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00133305]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5955\tvalid_1's rmse: 3.71001\n",
      "[1000]\ttraining's rmse: 3.51706\tvalid_1's rmse: 3.6895\n",
      "[1500]\ttraining's rmse: 3.46513\tvalid_1's rmse: 3.68392\n",
      "[2000]\ttraining's rmse: 3.421\tvalid_1's rmse: 3.6813\n",
      "[2500]\ttraining's rmse: 3.38303\tvalid_1's rmse: 3.68034\n",
      "Early stopping, best iteration is:\n",
      "[2778]\ttraining's rmse: 3.36304\tvalid_1's rmse: 3.67993\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60887\tvalid_1's rmse: 3.65034\n",
      "[1000]\ttraining's rmse: 3.52876\tvalid_1's rmse: 3.63185\n",
      "[1500]\ttraining's rmse: 3.47543\tvalid_1's rmse: 3.62631\n",
      "[2000]\ttraining's rmse: 3.43064\tvalid_1's rmse: 3.62511\n",
      "[2500]\ttraining's rmse: 3.3925\tvalid_1's rmse: 3.62434\n",
      "[3000]\ttraining's rmse: 3.3564\tvalid_1's rmse: 3.62383\n",
      "Early stopping, best iteration is:\n",
      "[3070]\ttraining's rmse: 3.3513\tvalid_1's rmse: 3.62357\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61308\tvalid_1's rmse: 3.62747\n",
      "[1000]\ttraining's rmse: 3.53357\tvalid_1's rmse: 3.60949\n",
      "[1500]\ttraining's rmse: 3.48106\tvalid_1's rmse: 3.60479\n",
      "[2000]\ttraining's rmse: 3.43698\tvalid_1's rmse: 3.60348\n",
      "Early stopping, best iteration is:\n",
      "[2012]\ttraining's rmse: 3.43589\tvalid_1's rmse: 3.60346\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56774\tvalid_1's rmse: 3.81548\n",
      "[1000]\ttraining's rmse: 3.48799\tvalid_1's rmse: 3.79744\n",
      "[1500]\ttraining's rmse: 3.43519\tvalid_1's rmse: 3.79251\n",
      "[2000]\ttraining's rmse: 3.39176\tvalid_1's rmse: 3.79088\n",
      "[2500]\ttraining's rmse: 3.354\tvalid_1's rmse: 3.79043\n",
      "Early stopping, best iteration is:\n",
      "[2450]\ttraining's rmse: 3.35759\tvalid_1's rmse: 3.79028\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60775\tvalid_1's rmse: 3.64575\n",
      "[1000]\ttraining's rmse: 3.52848\tvalid_1's rmse: 3.63018\n",
      "[1500]\ttraining's rmse: 3.47521\tvalid_1's rmse: 3.62449\n",
      "[2000]\ttraining's rmse: 3.43122\tvalid_1's rmse: 3.62239\n",
      "[2500]\ttraining's rmse: 3.39324\tvalid_1's rmse: 3.62203\n",
      "Early stopping, best iteration is:\n",
      "[2304]\ttraining's rmse: 3.40802\tvalid_1's rmse: 3.62185\n",
      "   98 | 05m17s |   -3.66445 |             0.9483 |        16.5739 |             0.6834 |             0.4009 |     13.5769 |              7.3977 |            30.0028 |            99.8579 |           0.3001 |      43.7910 |      9.6116 |       9.4489 |      0.1379 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63954\tvalid_1's rmse: 3.74336\n",
      "[1000]\ttraining's rmse: 3.55294\tvalid_1's rmse: 3.71444\n",
      "[1500]\ttraining's rmse: 3.49409\tvalid_1's rmse: 3.70335\n",
      "[2000]\ttraining's rmse: 3.44862\tvalid_1's rmse: 3.6971\n",
      "[2500]\ttraining's rmse: 3.40857\tvalid_1's rmse: 3.69423\n",
      "[3000]\ttraining's rmse: 3.37407\tvalid_1's rmse: 3.69223\n",
      "[3500]\ttraining's rmse: 3.34175\tvalid_1's rmse: 3.69075\n",
      "[4000]\ttraining's rmse: 3.31267\tvalid_1's rmse: 3.69001\n",
      "Early stopping, best iteration is:\n",
      "[3823]\ttraining's rmse: 3.3223\tvalid_1's rmse: 3.68993\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65466\tvalid_1's rmse: 3.67924\n",
      "[1000]\ttraining's rmse: 3.56616\tvalid_1's rmse: 3.65425\n",
      "[1500]\ttraining's rmse: 3.50686\tvalid_1's rmse: 3.6439\n",
      "[2000]\ttraining's rmse: 3.46042\tvalid_1's rmse: 3.63873\n",
      "[2500]\ttraining's rmse: 3.42057\tvalid_1's rmse: 3.63589\n",
      "[3000]\ttraining's rmse: 3.38661\tvalid_1's rmse: 3.63388\n",
      "[3500]\ttraining's rmse: 3.35451\tvalid_1's rmse: 3.63241\n",
      "[4000]\ttraining's rmse: 3.325\tvalid_1's rmse: 3.63171\n",
      "[4500]\ttraining's rmse: 3.29686\tvalid_1's rmse: 3.6311\n",
      "[5000]\ttraining's rmse: 3.26882\tvalid_1's rmse: 3.63077\n",
      "Early stopping, best iteration is:\n",
      "[4956]\ttraining's rmse: 3.27122\tvalid_1's rmse: 3.63068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6583\tvalid_1's rmse: 3.65332\n",
      "[1000]\ttraining's rmse: 3.57029\tvalid_1's rmse: 3.63037\n",
      "[1500]\ttraining's rmse: 3.51124\tvalid_1's rmse: 3.6207\n",
      "[2000]\ttraining's rmse: 3.46512\tvalid_1's rmse: 3.61644\n",
      "[2500]\ttraining's rmse: 3.42493\tvalid_1's rmse: 3.61401\n",
      "[3000]\ttraining's rmse: 3.39053\tvalid_1's rmse: 3.61267\n",
      "[3500]\ttraining's rmse: 3.35891\tvalid_1's rmse: 3.61178\n",
      "[4000]\ttraining's rmse: 3.3284\tvalid_1's rmse: 3.6118\n",
      "Early stopping, best iteration is:\n",
      "[3808]\ttraining's rmse: 3.34011\tvalid_1's rmse: 3.61159\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61179\tvalid_1's rmse: 3.84723\n",
      "[1000]\ttraining's rmse: 3.52434\tvalid_1's rmse: 3.81934\n",
      "[1500]\ttraining's rmse: 3.46543\tvalid_1's rmse: 3.80854\n",
      "[2000]\ttraining's rmse: 3.42017\tvalid_1's rmse: 3.80348\n",
      "[2500]\ttraining's rmse: 3.38116\tvalid_1's rmse: 3.8006\n",
      "[3000]\ttraining's rmse: 3.34641\tvalid_1's rmse: 3.79899\n",
      "[3500]\ttraining's rmse: 3.31506\tvalid_1's rmse: 3.7978\n",
      "[4000]\ttraining's rmse: 3.28663\tvalid_1's rmse: 3.79689\n",
      "[4500]\ttraining's rmse: 3.25898\tvalid_1's rmse: 3.79649\n",
      "[5000]\ttraining's rmse: 3.23272\tvalid_1's rmse: 3.79591\n",
      "Early stopping, best iteration is:\n",
      "[5187]\ttraining's rmse: 3.22355\tvalid_1's rmse: 3.79579\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65321\tvalid_1's rmse: 3.67303\n",
      "[1000]\ttraining's rmse: 3.56455\tvalid_1's rmse: 3.65013\n",
      "[1500]\ttraining's rmse: 3.5056\tvalid_1's rmse: 3.64128\n",
      "[2000]\ttraining's rmse: 3.4594\tvalid_1's rmse: 3.63658\n",
      "[2500]\ttraining's rmse: 3.41943\tvalid_1's rmse: 3.6338\n",
      "[3000]\ttraining's rmse: 3.38535\tvalid_1's rmse: 3.63217\n",
      "[3500]\ttraining's rmse: 3.35303\tvalid_1's rmse: 3.63153\n",
      "Early stopping, best iteration is:\n",
      "[3724]\ttraining's rmse: 3.33929\tvalid_1's rmse: 3.63117\n",
      "   99 | 05m10s |   -3.67245 |             0.9649 |        19.9583 |             0.1357 |             0.1333 |     14.1360 |             49.3334 |            32.7745 |            18.9056 |           0.8665 |      34.6949 |      1.4099 |       1.3378 |      0.8169 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6446\tvalid_1's rmse: 3.72531\n",
      "[1000]\ttraining's rmse: 3.57957\tvalid_1's rmse: 3.69898\n",
      "[1500]\ttraining's rmse: 3.53741\tvalid_1's rmse: 3.68954\n",
      "[2000]\ttraining's rmse: 3.50255\tvalid_1's rmse: 3.6853\n",
      "[2500]\ttraining's rmse: 3.47106\tvalid_1's rmse: 3.68296\n",
      "[3000]\ttraining's rmse: 3.44167\tvalid_1's rmse: 3.68203\n",
      "[3500]\ttraining's rmse: 3.41433\tvalid_1's rmse: 3.6812\n",
      "Early stopping, best iteration is:\n",
      "[3313]\ttraining's rmse: 3.42411\tvalid_1's rmse: 3.68109\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6587\tvalid_1's rmse: 3.66438\n",
      "[1000]\ttraining's rmse: 3.59335\tvalid_1's rmse: 3.64224\n",
      "[1500]\ttraining's rmse: 3.55142\tvalid_1's rmse: 3.63403\n",
      "[2000]\ttraining's rmse: 3.51609\tvalid_1's rmse: 3.62966\n",
      "[2500]\ttraining's rmse: 3.48512\tvalid_1's rmse: 3.62819\n",
      "[3000]\ttraining's rmse: 3.45551\tvalid_1's rmse: 3.62706\n",
      "Early stopping, best iteration is:\n",
      "[3243]\ttraining's rmse: 3.44169\tvalid_1's rmse: 3.62645\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66291\tvalid_1's rmse: 3.63997\n",
      "[1000]\ttraining's rmse: 3.59743\tvalid_1's rmse: 3.61874\n",
      "[1500]\ttraining's rmse: 3.55459\tvalid_1's rmse: 3.61132\n",
      "[2000]\ttraining's rmse: 3.51967\tvalid_1's rmse: 3.60866\n",
      "[2500]\ttraining's rmse: 3.48842\tvalid_1's rmse: 3.60667\n",
      "Early stopping, best iteration is:\n",
      "[2509]\ttraining's rmse: 3.48792\tvalid_1's rmse: 3.60663\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61599\tvalid_1's rmse: 3.83199\n",
      "[1000]\ttraining's rmse: 3.55095\tvalid_1's rmse: 3.80924\n",
      "[1500]\ttraining's rmse: 3.50862\tvalid_1's rmse: 3.80222\n",
      "[2000]\ttraining's rmse: 3.47301\tvalid_1's rmse: 3.79861\n",
      "[2500]\ttraining's rmse: 3.44262\tvalid_1's rmse: 3.79722\n",
      "[3000]\ttraining's rmse: 3.41378\tvalid_1's rmse: 3.79645\n",
      "[3500]\ttraining's rmse: 3.38639\tvalid_1's rmse: 3.79587\n",
      "Early stopping, best iteration is:\n",
      "[3779]\ttraining's rmse: 3.37115\tvalid_1's rmse: 3.79555\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65809\tvalid_1's rmse: 3.65805\n",
      "[1000]\ttraining's rmse: 3.59197\tvalid_1's rmse: 3.63719\n",
      "[1500]\ttraining's rmse: 3.54998\tvalid_1's rmse: 3.63071\n",
      "[2000]\ttraining's rmse: 3.51442\tvalid_1's rmse: 3.62777\n",
      "[2500]\ttraining's rmse: 3.48352\tvalid_1's rmse: 3.6264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttraining's rmse: 3.45448\tvalid_1's rmse: 3.62605\n",
      "Early stopping, best iteration is:\n",
      "[2973]\ttraining's rmse: 3.45594\tvalid_1's rmse: 3.6259\n",
      "  100 | 04m33s |   -3.66777 |             0.7143 |        13.8257 |             0.1419 |             0.2297 |     13.3019 |              5.4176 |            41.5796 |            99.1255 |           0.0345 |      32.7823 |      0.3536 |       9.9490 |      0.6186 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64627\tvalid_1's rmse: 3.716\n",
      "[1000]\ttraining's rmse: 3.60264\tvalid_1's rmse: 3.69696\n",
      "[1500]\ttraining's rmse: 3.57133\tvalid_1's rmse: 3.69035\n",
      "[2000]\ttraining's rmse: 3.54553\tvalid_1's rmse: 3.68796\n",
      "[2500]\ttraining's rmse: 3.5217\tvalid_1's rmse: 3.68611\n",
      "[3000]\ttraining's rmse: 3.49896\tvalid_1's rmse: 3.6853\n",
      "Early stopping, best iteration is:\n",
      "[2995]\ttraining's rmse: 3.49931\tvalid_1's rmse: 3.68525\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66013\tvalid_1's rmse: 3.65778\n",
      "[1000]\ttraining's rmse: 3.6139\tvalid_1's rmse: 3.64026\n",
      "[1500]\ttraining's rmse: 3.58295\tvalid_1's rmse: 3.63433\n",
      "[2000]\ttraining's rmse: 3.55743\tvalid_1's rmse: 3.63181\n",
      "[2500]\ttraining's rmse: 3.53434\tvalid_1's rmse: 3.62996\n",
      "[3000]\ttraining's rmse: 3.51177\tvalid_1's rmse: 3.62905\n",
      "[3500]\ttraining's rmse: 3.49081\tvalid_1's rmse: 3.62808\n",
      "[4000]\ttraining's rmse: 3.47129\tvalid_1's rmse: 3.62797\n",
      "Early stopping, best iteration is:\n",
      "[3888]\ttraining's rmse: 3.47568\tvalid_1's rmse: 3.62771\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66538\tvalid_1's rmse: 3.63091\n",
      "[1000]\ttraining's rmse: 3.61805\tvalid_1's rmse: 3.61316\n",
      "[1500]\ttraining's rmse: 3.58885\tvalid_1's rmse: 3.60884\n",
      "[2000]\ttraining's rmse: 3.56426\tvalid_1's rmse: 3.60739\n",
      "Early stopping, best iteration is:\n",
      "[2212]\ttraining's rmse: 3.554\tvalid_1's rmse: 3.60677\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61759\tvalid_1's rmse: 3.81805\n",
      "[1000]\ttraining's rmse: 3.56957\tvalid_1's rmse: 3.80275\n",
      "[1500]\ttraining's rmse: 3.54043\tvalid_1's rmse: 3.79739\n",
      "[2000]\ttraining's rmse: 3.51608\tvalid_1's rmse: 3.7956\n",
      "[2500]\ttraining's rmse: 3.49376\tvalid_1's rmse: 3.79454\n",
      "[3000]\ttraining's rmse: 3.47257\tvalid_1's rmse: 3.79345\n",
      "Early stopping, best iteration is:\n",
      "[3149]\ttraining's rmse: 3.46602\tvalid_1's rmse: 3.79313\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66011\tvalid_1's rmse: 3.6489\n",
      "[1000]\ttraining's rmse: 3.61083\tvalid_1's rmse: 3.63161\n",
      "[1500]\ttraining's rmse: 3.57938\tvalid_1's rmse: 3.62722\n",
      "[2000]\ttraining's rmse: 3.5538\tvalid_1's rmse: 3.62475\n",
      "[2500]\ttraining's rmse: 3.53033\tvalid_1's rmse: 3.62451\n",
      "Early stopping, best iteration is:\n",
      "[2656]\ttraining's rmse: 3.52257\tvalid_1's rmse: 3.62399\n",
      "  101 | 06m17s |   -3.66801 |             0.9616 |         4.7517 |             0.3467 |             0.8418 |      5.3094 |             49.0095 |            31.1916 |            10.5367 |           0.5450 |      38.1379 |      4.0995 |       9.3595 |      0.8574 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.24987413e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65087\tvalid_1's rmse: 3.7154\n",
      "[1000]\ttraining's rmse: 3.61347\tvalid_1's rmse: 3.69744\n",
      "[1500]\ttraining's rmse: 3.58647\tvalid_1's rmse: 3.68986\n",
      "[2000]\ttraining's rmse: 3.56418\tvalid_1's rmse: 3.68743\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.56665\tvalid_1's rmse: 3.68705\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66341\tvalid_1's rmse: 3.65783\n",
      "[1000]\ttraining's rmse: 3.62046\tvalid_1's rmse: 3.64069\n",
      "[1500]\ttraining's rmse: 3.59523\tvalid_1's rmse: 3.63507\n",
      "[2000]\ttraining's rmse: 3.57369\tvalid_1's rmse: 3.63087\n",
      "[2500]\ttraining's rmse: 3.55389\tvalid_1's rmse: 3.62893\n",
      "[3000]\ttraining's rmse: 3.53493\tvalid_1's rmse: 3.62817\n",
      "[3500]\ttraining's rmse: 3.518\tvalid_1's rmse: 3.62608\n",
      "[4000]\ttraining's rmse: 3.50058\tvalid_1's rmse: 3.62535\n",
      "Early stopping, best iteration is:\n",
      "[4275]\ttraining's rmse: 3.4907\tvalid_1's rmse: 3.62443\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66898\tvalid_1's rmse: 3.63061\n",
      "[1000]\ttraining's rmse: 3.62711\tvalid_1's rmse: 3.61484\n",
      "[1500]\ttraining's rmse: 3.59905\tvalid_1's rmse: 3.6092\n",
      "[2000]\ttraining's rmse: 3.5762\tvalid_1's rmse: 3.60741\n",
      "Early stopping, best iteration is:\n",
      "[2087]\ttraining's rmse: 3.5722\tvalid_1's rmse: 3.60703\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62184\tvalid_1's rmse: 3.8181\n",
      "[1000]\ttraining's rmse: 3.57875\tvalid_1's rmse: 3.80117\n",
      "[1500]\ttraining's rmse: 3.55214\tvalid_1's rmse: 3.79713\n",
      "[2000]\ttraining's rmse: 3.53083\tvalid_1's rmse: 3.7958\n",
      "Early stopping, best iteration is:\n",
      "[2070]\ttraining's rmse: 3.52858\tvalid_1's rmse: 3.79575\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66527\tvalid_1's rmse: 3.64829\n",
      "[1000]\ttraining's rmse: 3.62235\tvalid_1's rmse: 3.63236\n",
      "[1500]\ttraining's rmse: 3.59448\tvalid_1's rmse: 3.62744\n",
      "[2000]\ttraining's rmse: 3.57108\tvalid_1's rmse: 3.62526\n",
      "Early stopping, best iteration is:\n",
      "[1930]\ttraining's rmse: 3.5743\tvalid_1's rmse: 3.62517\n",
      "  102 | 05m16s |   -3.66854 |             0.8824 |        19.0082 |             0.6702 |             0.8949 |      5.4491 |              5.0705 |            30.5578 |            81.4643 |           0.0368 |      34.1560 |      9.6951 |       1.5862 |      0.6346 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69294\tvalid_1's rmse: 3.75046\n",
      "[1000]\ttraining's rmse: 3.64412\tvalid_1's rmse: 3.7193\n",
      "[1500]\ttraining's rmse: 3.61406\tvalid_1's rmse: 3.70608\n",
      "[2000]\ttraining's rmse: 3.59213\tvalid_1's rmse: 3.69965\n",
      "[2500]\ttraining's rmse: 3.57193\tvalid_1's rmse: 3.69564\n",
      "[3000]\ttraining's rmse: 3.55433\tvalid_1's rmse: 3.69342\n",
      "[3500]\ttraining's rmse: 3.53766\tvalid_1's rmse: 3.69173\n",
      "[4000]\ttraining's rmse: 3.52209\tvalid_1's rmse: 3.6905\n",
      "Early stopping, best iteration is:\n",
      "[3972]\ttraining's rmse: 3.52285\tvalid_1's rmse: 3.69047\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70654\tvalid_1's rmse: 3.6843\n",
      "[1000]\ttraining's rmse: 3.65695\tvalid_1's rmse: 3.65773\n",
      "[1500]\ttraining's rmse: 3.62668\tvalid_1's rmse: 3.64614\n",
      "[2000]\ttraining's rmse: 3.60374\tvalid_1's rmse: 3.63964\n",
      "[2500]\ttraining's rmse: 3.58431\tvalid_1's rmse: 3.63574\n",
      "[3000]\ttraining's rmse: 3.56664\tvalid_1's rmse: 3.63363\n",
      "[3500]\ttraining's rmse: 3.54986\tvalid_1's rmse: 3.63207\n",
      "[4000]\ttraining's rmse: 3.53446\tvalid_1's rmse: 3.63078\n",
      "[4500]\ttraining's rmse: 3.51846\tvalid_1's rmse: 3.63004\n",
      "[5000]\ttraining's rmse: 3.50394\tvalid_1's rmse: 3.62914\n",
      "[5500]\ttraining's rmse: 3.49017\tvalid_1's rmse: 3.62828\n",
      "Early stopping, best iteration is:\n",
      "[5614]\ttraining's rmse: 3.48693\tvalid_1's rmse: 3.6281\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.71267\tvalid_1's rmse: 3.65787\n",
      "[1000]\ttraining's rmse: 3.66295\tvalid_1's rmse: 3.63241\n",
      "[1500]\ttraining's rmse: 3.63226\tvalid_1's rmse: 3.62199\n",
      "[2000]\ttraining's rmse: 3.60989\tvalid_1's rmse: 3.61693\n",
      "[2500]\ttraining's rmse: 3.58904\tvalid_1's rmse: 3.61381\n",
      "[3000]\ttraining's rmse: 3.57042\tvalid_1's rmse: 3.61218\n",
      "[3500]\ttraining's rmse: 3.55359\tvalid_1's rmse: 3.61132\n",
      "[4000]\ttraining's rmse: 3.53776\tvalid_1's rmse: 3.6107\n",
      "Early stopping, best iteration is:\n",
      "[4253]\ttraining's rmse: 3.52933\tvalid_1's rmse: 3.61036\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66357\tvalid_1's rmse: 3.8561\n",
      "[1000]\ttraining's rmse: 3.61478\tvalid_1's rmse: 3.82841\n",
      "[1500]\ttraining's rmse: 3.58519\tvalid_1's rmse: 3.81688\n",
      "[2000]\ttraining's rmse: 3.56242\tvalid_1's rmse: 3.81072\n",
      "[2500]\ttraining's rmse: 3.54325\tvalid_1's rmse: 3.8071\n",
      "[3000]\ttraining's rmse: 3.52554\tvalid_1's rmse: 3.80522\n",
      "[3500]\ttraining's rmse: 3.50774\tvalid_1's rmse: 3.80347\n",
      "[4000]\ttraining's rmse: 3.49223\tvalid_1's rmse: 3.80247\n",
      "[4500]\ttraining's rmse: 3.47646\tvalid_1's rmse: 3.80119\n",
      "[5000]\ttraining's rmse: 3.46131\tvalid_1's rmse: 3.80054\n",
      "[5500]\ttraining's rmse: 3.44781\tvalid_1's rmse: 3.80045\n",
      "Early stopping, best iteration is:\n",
      "[5319]\ttraining's rmse: 3.45274\tvalid_1's rmse: 3.80012\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.7077\tvalid_1's rmse: 3.67649\n",
      "[1000]\ttraining's rmse: 3.65795\tvalid_1's rmse: 3.65177\n",
      "[1500]\ttraining's rmse: 3.62759\tvalid_1's rmse: 3.64159\n",
      "[2000]\ttraining's rmse: 3.6043\tvalid_1's rmse: 3.63649\n",
      "[2500]\ttraining's rmse: 3.58405\tvalid_1's rmse: 3.63377\n",
      "[3000]\ttraining's rmse: 3.56645\tvalid_1's rmse: 3.63231\n",
      "[3500]\ttraining's rmse: 3.55026\tvalid_1's rmse: 3.63145\n",
      "[4000]\ttraining's rmse: 3.53413\tvalid_1's rmse: 3.63091\n",
      "Early stopping, best iteration is:\n",
      "[4239]\ttraining's rmse: 3.5271\tvalid_1's rmse: 3.63077\n",
      "  103 | 04m53s |   -3.67262 |             0.7317 |        14.1439 |             0.9024 |             0.1281 |      5.5608 |              7.0532 |            44.6759 |            38.7278 |           0.2422 |      41.2276 |      1.3083 |       0.7605 |      0.9224 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64633\tvalid_1's rmse: 3.71587\n",
      "[1000]\ttraining's rmse: 3.60303\tvalid_1's rmse: 3.69686\n",
      "[1500]\ttraining's rmse: 3.57288\tvalid_1's rmse: 3.68967\n",
      "[2000]\ttraining's rmse: 3.54644\tvalid_1's rmse: 3.68582\n",
      "[2500]\ttraining's rmse: 3.52439\tvalid_1's rmse: 3.68497\n",
      "Early stopping, best iteration is:\n",
      "[2754]\ttraining's rmse: 3.51342\tvalid_1's rmse: 3.68441\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6591\tvalid_1's rmse: 3.65649\n",
      "[1000]\ttraining's rmse: 3.61244\tvalid_1's rmse: 3.64003\n",
      "[1500]\ttraining's rmse: 3.58383\tvalid_1's rmse: 3.63501\n",
      "[2000]\ttraining's rmse: 3.55906\tvalid_1's rmse: 3.63196\n",
      "[2500]\ttraining's rmse: 3.53439\tvalid_1's rmse: 3.63075\n",
      "[3000]\ttraining's rmse: 3.51283\tvalid_1's rmse: 3.6301\n",
      "Early stopping, best iteration is:\n",
      "[3006]\ttraining's rmse: 3.51259\tvalid_1's rmse: 3.63007\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66505\tvalid_1's rmse: 3.6312\n",
      "[1000]\ttraining's rmse: 3.61814\tvalid_1's rmse: 3.61384\n",
      "[1500]\ttraining's rmse: 3.58858\tvalid_1's rmse: 3.60893\n",
      "[2000]\ttraining's rmse: 3.56516\tvalid_1's rmse: 3.60804\n",
      "Early stopping, best iteration is:\n",
      "[2154]\ttraining's rmse: 3.55665\tvalid_1's rmse: 3.6074\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61619\tvalid_1's rmse: 3.81755\n",
      "[1000]\ttraining's rmse: 3.5696\tvalid_1's rmse: 3.80175\n",
      "[1500]\ttraining's rmse: 3.5403\tvalid_1's rmse: 3.79752\n",
      "[2000]\ttraining's rmse: 3.5152\tvalid_1's rmse: 3.7955\n",
      "[2500]\ttraining's rmse: 3.49201\tvalid_1's rmse: 3.79457\n",
      "[3000]\ttraining's rmse: 3.47075\tvalid_1's rmse: 3.79348\n",
      "[3500]\ttraining's rmse: 3.45099\tvalid_1's rmse: 3.79257\n",
      "[4000]\ttraining's rmse: 3.43165\tvalid_1's rmse: 3.79172\n",
      "Early stopping, best iteration is:\n",
      "[3997]\ttraining's rmse: 3.43176\tvalid_1's rmse: 3.79169\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6603\tvalid_1's rmse: 3.64868\n",
      "[1000]\ttraining's rmse: 3.61146\tvalid_1's rmse: 3.63163\n",
      "[1500]\ttraining's rmse: 3.58014\tvalid_1's rmse: 3.62628\n",
      "[2000]\ttraining's rmse: 3.55625\tvalid_1's rmse: 3.62463\n",
      "[2500]\ttraining's rmse: 3.53369\tvalid_1's rmse: 3.62376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2447]\ttraining's rmse: 3.53545\tvalid_1's rmse: 3.62359\n",
      "  104 | 05m49s |   -3.66805 |             0.9511 |        18.4235 |             0.3263 |             0.7559 |      5.2864 |             48.9376 |            38.8321 |            12.3830 |           0.0518 |      32.9089 |      9.7073 |       1.1307 |      0.5057 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63894\tvalid_1's rmse: 3.72972\n",
      "[1000]\ttraining's rmse: 3.56419\tvalid_1's rmse: 3.70456\n",
      "[1500]\ttraining's rmse: 3.5149\tvalid_1's rmse: 3.694\n",
      "[2000]\ttraining's rmse: 3.477\tvalid_1's rmse: 3.68961\n",
      "[2500]\ttraining's rmse: 3.44253\tvalid_1's rmse: 3.68724\n",
      "[3000]\ttraining's rmse: 3.41228\tvalid_1's rmse: 3.68541\n",
      "[3500]\ttraining's rmse: 3.38411\tvalid_1's rmse: 3.68438\n",
      "[4000]\ttraining's rmse: 3.35729\tvalid_1's rmse: 3.68369\n",
      "[4500]\ttraining's rmse: 3.33258\tvalid_1's rmse: 3.68311\n",
      "Early stopping, best iteration is:\n",
      "[4580]\ttraining's rmse: 3.32867\tvalid_1's rmse: 3.68292\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65255\tvalid_1's rmse: 3.66686\n",
      "[1000]\ttraining's rmse: 3.57576\tvalid_1's rmse: 3.6448\n",
      "[1500]\ttraining's rmse: 3.52526\tvalid_1's rmse: 3.63642\n",
      "[2000]\ttraining's rmse: 3.48594\tvalid_1's rmse: 3.63194\n",
      "[2500]\ttraining's rmse: 3.45181\tvalid_1's rmse: 3.62951\n",
      "[3000]\ttraining's rmse: 3.42062\tvalid_1's rmse: 3.62821\n",
      "[3500]\ttraining's rmse: 3.39233\tvalid_1's rmse: 3.62714\n",
      "[4000]\ttraining's rmse: 3.36527\tvalid_1's rmse: 3.62643\n",
      "Early stopping, best iteration is:\n",
      "[4253]\ttraining's rmse: 3.35274\tvalid_1's rmse: 3.62605\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6572\tvalid_1's rmse: 3.64405\n",
      "[1000]\ttraining's rmse: 3.58097\tvalid_1's rmse: 3.62167\n",
      "[1500]\ttraining's rmse: 3.53143\tvalid_1's rmse: 3.61396\n",
      "[2000]\ttraining's rmse: 3.49291\tvalid_1's rmse: 3.61009\n",
      "[2500]\ttraining's rmse: 3.45924\tvalid_1's rmse: 3.60812\n",
      "[3000]\ttraining's rmse: 3.42855\tvalid_1's rmse: 3.60703\n",
      "Early stopping, best iteration is:\n",
      "[3185]\ttraining's rmse: 3.41767\tvalid_1's rmse: 3.60687\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61087\tvalid_1's rmse: 3.83611\n",
      "[1000]\ttraining's rmse: 3.53551\tvalid_1's rmse: 3.81255\n",
      "[1500]\ttraining's rmse: 3.48513\tvalid_1's rmse: 3.80379\n",
      "[2000]\ttraining's rmse: 3.4474\tvalid_1's rmse: 3.80027\n",
      "[2500]\ttraining's rmse: 3.41422\tvalid_1's rmse: 3.79812\n",
      "[3000]\ttraining's rmse: 3.38404\tvalid_1's rmse: 3.79682\n",
      "[3500]\ttraining's rmse: 3.35567\tvalid_1's rmse: 3.79634\n",
      "[4000]\ttraining's rmse: 3.32879\tvalid_1's rmse: 3.7958\n",
      "Early stopping, best iteration is:\n",
      "[4120]\ttraining's rmse: 3.32275\tvalid_1's rmse: 3.7956\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65209\tvalid_1's rmse: 3.66312\n",
      "[1000]\ttraining's rmse: 3.57514\tvalid_1's rmse: 3.64205\n",
      "[1500]\ttraining's rmse: 3.52382\tvalid_1's rmse: 3.63408\n",
      "[2000]\ttraining's rmse: 3.48496\tvalid_1's rmse: 3.6305\n",
      "[2500]\ttraining's rmse: 3.45181\tvalid_1's rmse: 3.62851\n",
      "[3000]\ttraining's rmse: 3.42116\tvalid_1's rmse: 3.62766\n",
      "[3500]\ttraining's rmse: 3.39299\tvalid_1's rmse: 3.62759\n",
      "Early stopping, best iteration is:\n",
      "[3362]\ttraining's rmse: 3.4007\tvalid_1's rmse: 3.62726\n",
      "  105 | 05m21s |   -3.66838 |             0.9434 |         5.4469 |             0.9406 |             0.2034 |     14.5880 |             24.0793 |            44.0234 |            43.3523 |           0.7556 |      30.2673 |      1.3683 |       9.1522 |      0.1405 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56773\tvalid_1's rmse: 3.7076\n",
      "[1000]\ttraining's rmse: 3.47727\tvalid_1's rmse: 3.68878\n",
      "[1500]\ttraining's rmse: 3.4145\tvalid_1's rmse: 3.68289\n",
      "[2000]\ttraining's rmse: 3.36665\tvalid_1's rmse: 3.68119\n",
      "[2500]\ttraining's rmse: 3.32432\tvalid_1's rmse: 3.68065\n",
      "Early stopping, best iteration is:\n",
      "[2330]\ttraining's rmse: 3.3384\tvalid_1's rmse: 3.68048\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58048\tvalid_1's rmse: 3.64912\n",
      "[1000]\ttraining's rmse: 3.48927\tvalid_1's rmse: 3.63229\n",
      "[1500]\ttraining's rmse: 3.4282\tvalid_1's rmse: 3.62809\n",
      "[2000]\ttraining's rmse: 3.37958\tvalid_1's rmse: 3.62693\n",
      "[2500]\ttraining's rmse: 3.33504\tvalid_1's rmse: 3.62612\n",
      "Early stopping, best iteration is:\n",
      "[2558]\ttraining's rmse: 3.32998\tvalid_1's rmse: 3.62571\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58525\tvalid_1's rmse: 3.62671\n",
      "[1000]\ttraining's rmse: 3.49242\tvalid_1's rmse: 3.61066\n",
      "[1500]\ttraining's rmse: 3.43121\tvalid_1's rmse: 3.60651\n",
      "Early stopping, best iteration is:\n",
      "[1792]\ttraining's rmse: 3.4012\tvalid_1's rmse: 3.60558\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54074\tvalid_1's rmse: 3.8084\n",
      "[1000]\ttraining's rmse: 3.44767\tvalid_1's rmse: 3.79164\n",
      "[1500]\ttraining's rmse: 3.38549\tvalid_1's rmse: 3.78818\n",
      "Early stopping, best iteration is:\n",
      "[1432]\ttraining's rmse: 3.39248\tvalid_1's rmse: 3.78814\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57878\tvalid_1's rmse: 3.64596\n",
      "[1000]\ttraining's rmse: 3.48642\tvalid_1's rmse: 3.63042\n",
      "[1500]\ttraining's rmse: 3.42528\tvalid_1's rmse: 3.62565\n",
      "Early stopping, best iteration is:\n",
      "[1770]\ttraining's rmse: 3.3977\tvalid_1's rmse: 3.62472\n",
      "  106 | 05m49s |   -3.66553 |             0.9652 |        13.1769 |             0.6670 |             0.7340 |     14.6180 |             48.4441 |            41.9397 |            63.3229 |           0.1691 |      42.1714 |      4.0034 |       8.7252 |      0.7046 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00076808]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57658\tvalid_1's rmse: 3.70397\n",
      "[1000]\ttraining's rmse: 3.49477\tvalid_1's rmse: 3.68574\n",
      "[1500]\ttraining's rmse: 3.43788\tvalid_1's rmse: 3.68125\n",
      "Early stopping, best iteration is:\n",
      "[1720]\ttraining's rmse: 3.41546\tvalid_1's rmse: 3.68056\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58851\tvalid_1's rmse: 3.64684\n",
      "[1000]\ttraining's rmse: 3.50723\tvalid_1's rmse: 3.63155\n",
      "[1500]\ttraining's rmse: 3.44913\tvalid_1's rmse: 3.62775\n",
      "[2000]\ttraining's rmse: 3.39889\tvalid_1's rmse: 3.62635\n",
      "Early stopping, best iteration is:\n",
      "[2256]\ttraining's rmse: 3.37569\tvalid_1's rmse: 3.62572\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59556\tvalid_1's rmse: 3.62297\n",
      "[1000]\ttraining's rmse: 3.51275\tvalid_1's rmse: 3.60911\n",
      "[1500]\ttraining's rmse: 3.45382\tvalid_1's rmse: 3.60658\n",
      "[2000]\ttraining's rmse: 3.40425\tvalid_1's rmse: 3.60563\n",
      "Early stopping, best iteration is:\n",
      "[1871]\ttraining's rmse: 3.41623\tvalid_1's rmse: 3.60548\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54943\tvalid_1's rmse: 3.80681\n",
      "[1000]\ttraining's rmse: 3.46669\tvalid_1's rmse: 3.79286\n",
      "[1500]\ttraining's rmse: 3.40889\tvalid_1's rmse: 3.79015\n",
      "[2000]\ttraining's rmse: 3.35902\tvalid_1's rmse: 3.78948\n",
      "Early stopping, best iteration is:\n",
      "[1930]\ttraining's rmse: 3.36597\tvalid_1's rmse: 3.78948\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58902\tvalid_1's rmse: 3.64177\n",
      "[1000]\ttraining's rmse: 3.50733\tvalid_1's rmse: 3.62853\n",
      "[1500]\ttraining's rmse: 3.4494\tvalid_1's rmse: 3.62571\n",
      "[2000]\ttraining's rmse: 3.39942\tvalid_1's rmse: 3.62512\n",
      "Early stopping, best iteration is:\n",
      "[1806]\ttraining's rmse: 3.41791\tvalid_1's rmse: 3.62469\n",
      "  107 | 05m38s |   -3.66580 |             0.8215 |         1.3809 |             0.2690 |             0.9319 |     14.9121 |              5.2007 |            30.1429 |            95.9660 |           0.2236 |      43.0862 |      2.9373 |       6.5482 |      0.6042 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00080843]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 65, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60813\tvalid_1's rmse: 3.7103\n",
      "[1000]\ttraining's rmse: 3.54129\tvalid_1's rmse: 3.68992\n",
      "[1500]\ttraining's rmse: 3.49763\tvalid_1's rmse: 3.68456\n",
      "[2000]\ttraining's rmse: 3.46089\tvalid_1's rmse: 3.68245\n",
      "[2500]\ttraining's rmse: 3.42796\tvalid_1's rmse: 3.682\n",
      "[3000]\ttraining's rmse: 3.39727\tvalid_1's rmse: 3.68132\n",
      "Early stopping, best iteration is:\n",
      "[3272]\ttraining's rmse: 3.38217\tvalid_1's rmse: 3.6809\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62188\tvalid_1's rmse: 3.65189\n",
      "[1000]\ttraining's rmse: 3.55443\tvalid_1's rmse: 3.63345\n",
      "[1500]\ttraining's rmse: 3.50984\tvalid_1's rmse: 3.62907\n",
      "[2000]\ttraining's rmse: 3.47233\tvalid_1's rmse: 3.6275\n",
      "[2500]\ttraining's rmse: 3.43898\tvalid_1's rmse: 3.62629\n",
      "[3000]\ttraining's rmse: 3.40891\tvalid_1's rmse: 3.62578\n",
      "Early stopping, best iteration is:\n",
      "[3118]\ttraining's rmse: 3.40207\tvalid_1's rmse: 3.62555\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62669\tvalid_1's rmse: 3.62704\n",
      "[1000]\ttraining's rmse: 3.55882\tvalid_1's rmse: 3.60968\n",
      "[1500]\ttraining's rmse: 3.51382\tvalid_1's rmse: 3.60545\n",
      "[2000]\ttraining's rmse: 3.47609\tvalid_1's rmse: 3.60514\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's rmse: 3.48687\tvalid_1's rmse: 3.60475\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58201\tvalid_1's rmse: 3.81188\n",
      "[1000]\ttraining's rmse: 3.5133\tvalid_1's rmse: 3.79683\n",
      "[1500]\ttraining's rmse: 3.46817\tvalid_1's rmse: 3.79145\n",
      "[2000]\ttraining's rmse: 3.43108\tvalid_1's rmse: 3.7904\n",
      "Early stopping, best iteration is:\n",
      "[1885]\ttraining's rmse: 3.43929\tvalid_1's rmse: 3.79009\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62125\tvalid_1's rmse: 3.64736\n",
      "[1000]\ttraining's rmse: 3.55284\tvalid_1's rmse: 3.63156\n",
      "[1500]\ttraining's rmse: 3.50812\tvalid_1's rmse: 3.62696\n",
      "[2000]\ttraining's rmse: 3.47128\tvalid_1's rmse: 3.62479\n",
      "[2500]\ttraining's rmse: 3.43869\tvalid_1's rmse: 3.62432\n",
      "Early stopping, best iteration is:\n",
      "[2363]\ttraining's rmse: 3.44696\tvalid_1's rmse: 3.62424\n",
      "  108 | 05m39s |   -3.66573 |             0.8973 |        12.3918 |             0.6641 |             0.6661 |     13.6469 |             36.2244 |            44.7069 |            99.2424 |           0.0109 |      30.4174 |      8.5568 |       1.1546 |      0.9701 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00039794]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60144\tvalid_1's rmse: 3.70988\n",
      "[1000]\ttraining's rmse: 3.52747\tvalid_1's rmse: 3.68919\n",
      "[1500]\ttraining's rmse: 3.47731\tvalid_1's rmse: 3.68289\n",
      "[2000]\ttraining's rmse: 3.43764\tvalid_1's rmse: 3.68107\n",
      "[2500]\ttraining's rmse: 3.40157\tvalid_1's rmse: 3.68051\n",
      "[3000]\ttraining's rmse: 3.36968\tvalid_1's rmse: 3.68005\n",
      "Early stopping, best iteration is:\n",
      "[2881]\ttraining's rmse: 3.37755\tvalid_1's rmse: 3.67997\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61531\tvalid_1's rmse: 3.65211\n",
      "[1000]\ttraining's rmse: 3.54027\tvalid_1's rmse: 3.63327\n",
      "[1500]\ttraining's rmse: 3.49028\tvalid_1's rmse: 3.62786\n",
      "[2000]\ttraining's rmse: 3.44936\tvalid_1's rmse: 3.62573\n",
      "[2500]\ttraining's rmse: 3.41279\tvalid_1's rmse: 3.62485\n",
      "[3000]\ttraining's rmse: 3.37986\tvalid_1's rmse: 3.62455\n",
      "Early stopping, best iteration is:\n",
      "[2935]\ttraining's rmse: 3.38401\tvalid_1's rmse: 3.62445\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61942\tvalid_1's rmse: 3.62751\n",
      "[1000]\ttraining's rmse: 3.54508\tvalid_1's rmse: 3.61005\n",
      "[1500]\ttraining's rmse: 3.49549\tvalid_1's rmse: 3.6052\n",
      "[2000]\ttraining's rmse: 3.45522\tvalid_1's rmse: 3.60316\n",
      "[2500]\ttraining's rmse: 3.41828\tvalid_1's rmse: 3.60271\n",
      "Early stopping, best iteration is:\n",
      "[2491]\ttraining's rmse: 3.41891\tvalid_1's rmse: 3.60269\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57425\tvalid_1's rmse: 3.81409\n",
      "[1000]\ttraining's rmse: 3.49923\tvalid_1's rmse: 3.7968\n",
      "[1500]\ttraining's rmse: 3.45062\tvalid_1's rmse: 3.79189\n",
      "[2000]\ttraining's rmse: 3.4103\tvalid_1's rmse: 3.79058\n",
      "[2500]\ttraining's rmse: 3.37538\tvalid_1's rmse: 3.79024\n",
      "Early stopping, best iteration is:\n",
      "[2629]\ttraining's rmse: 3.3668\tvalid_1's rmse: 3.79006\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61366\tvalid_1's rmse: 3.64542\n",
      "[1000]\ttraining's rmse: 3.53745\tvalid_1's rmse: 3.62887\n",
      "[1500]\ttraining's rmse: 3.48851\tvalid_1's rmse: 3.62307\n",
      "[2000]\ttraining's rmse: 3.44906\tvalid_1's rmse: 3.62143\n",
      "Early stopping, best iteration is:\n",
      "[2127]\ttraining's rmse: 3.43965\tvalid_1's rmse: 3.62104\n",
      "  109 | 05m36s |   -3.66428 |             0.9591 |        15.5203 |             0.8907 |             0.4663 |     14.4852 |             48.3671 |            30.6148 |            96.4644 |           0.2048 |      37.4443 |      0.8735 |       9.4056 |      0.9682 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60286\tvalid_1's rmse: 3.7105\n",
      "[1000]\ttraining's rmse: 3.5331\tvalid_1's rmse: 3.69087\n",
      "[1500]\ttraining's rmse: 3.48597\tvalid_1's rmse: 3.68438\n",
      "[2000]\ttraining's rmse: 3.44975\tvalid_1's rmse: 3.68299\n",
      "[2500]\ttraining's rmse: 3.41746\tvalid_1's rmse: 3.68212\n",
      "Early stopping, best iteration is:\n",
      "[2554]\ttraining's rmse: 3.41401\tvalid_1's rmse: 3.68191\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61676\tvalid_1's rmse: 3.65176\n",
      "[1000]\ttraining's rmse: 3.54422\tvalid_1's rmse: 3.63393\n",
      "[1500]\ttraining's rmse: 3.49757\tvalid_1's rmse: 3.62894\n",
      "[2000]\ttraining's rmse: 3.45955\tvalid_1's rmse: 3.62744\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's rmse: 3.46597\tvalid_1's rmse: 3.62737\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62189\tvalid_1's rmse: 3.62745\n",
      "[1000]\ttraining's rmse: 3.55153\tvalid_1's rmse: 3.61135\n",
      "[1500]\ttraining's rmse: 3.50425\tvalid_1's rmse: 3.60634\n",
      "Early stopping, best iteration is:\n",
      "[1742]\ttraining's rmse: 3.48595\tvalid_1's rmse: 3.60566\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57753\tvalid_1's rmse: 3.81027\n",
      "[1000]\ttraining's rmse: 3.5044\tvalid_1's rmse: 3.79404\n",
      "[1500]\ttraining's rmse: 3.45587\tvalid_1's rmse: 3.78931\n",
      "[2000]\ttraining's rmse: 3.42046\tvalid_1's rmse: 3.78822\n",
      "Early stopping, best iteration is:\n",
      "[2214]\ttraining's rmse: 3.40603\tvalid_1's rmse: 3.78774\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61639\tvalid_1's rmse: 3.64727\n",
      "[1000]\ttraining's rmse: 3.54366\tvalid_1's rmse: 3.63201\n",
      "[1500]\ttraining's rmse: 3.49739\tvalid_1's rmse: 3.62691\n",
      "[2000]\ttraining's rmse: 3.45992\tvalid_1's rmse: 3.62471\n",
      "[2500]\ttraining's rmse: 3.42822\tvalid_1's rmse: 3.6236\n",
      "Early stopping, best iteration is:\n",
      "[2449]\ttraining's rmse: 3.43146\tvalid_1's rmse: 3.62345\n",
      "  110 | 06m04s |   -3.66583 |             0.9739 |        10.8945 |             0.3361 |             0.8518 |     14.9241 |              5.4734 |            31.3176 |            92.0840 |           0.0323 |      31.9968 |      9.2208 |       8.0874 |      0.5620 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57498\tvalid_1's rmse: 3.70197\n",
      "[1000]\ttraining's rmse: 3.49773\tvalid_1's rmse: 3.68654\n",
      "[1500]\ttraining's rmse: 3.43964\tvalid_1's rmse: 3.68222\n",
      "Early stopping, best iteration is:\n",
      "[1618]\ttraining's rmse: 3.42773\tvalid_1's rmse: 3.6817\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59043\tvalid_1's rmse: 3.64612\n",
      "[1000]\ttraining's rmse: 3.50985\tvalid_1's rmse: 3.63219\n",
      "[1500]\ttraining's rmse: 3.45049\tvalid_1's rmse: 3.62791\n",
      "[2000]\ttraining's rmse: 3.40139\tvalid_1's rmse: 3.62717\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's rmse: 3.41619\tvalid_1's rmse: 3.62647\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59342\tvalid_1's rmse: 3.62223\n",
      "[1000]\ttraining's rmse: 3.51407\tvalid_1's rmse: 3.60848\n",
      "[1500]\ttraining's rmse: 3.456\tvalid_1's rmse: 3.60544\n",
      "[2000]\ttraining's rmse: 3.40567\tvalid_1's rmse: 3.60441\n",
      "Early stopping, best iteration is:\n",
      "[2051]\ttraining's rmse: 3.40103\tvalid_1's rmse: 3.60424\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55075\tvalid_1's rmse: 3.80724\n",
      "[1000]\ttraining's rmse: 3.46727\tvalid_1's rmse: 3.79312\n",
      "Early stopping, best iteration is:\n",
      "[1275]\ttraining's rmse: 3.43465\tvalid_1's rmse: 3.7916\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58892\tvalid_1's rmse: 3.64021\n",
      "[1000]\ttraining's rmse: 3.50789\tvalid_1's rmse: 3.62765\n",
      "[1500]\ttraining's rmse: 3.451\tvalid_1's rmse: 3.62453\n",
      "[2000]\ttraining's rmse: 3.40071\tvalid_1's rmse: 3.62401\n",
      "Early stopping, best iteration is:\n",
      "[1808]\ttraining's rmse: 3.41899\tvalid_1's rmse: 3.62323\n",
      "  111 | 05m35s |   -3.66608 |             0.7792 |        18.2645 |             0.8852 |             0.8328 |     14.2627 |             11.0270 |            30.8629 |            99.5174 |           0.8007 |      44.5249 |      1.1066 |       0.0530 |      0.6404 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59033\tvalid_1's rmse: 3.70893\n",
      "[1000]\ttraining's rmse: 3.51134\tvalid_1's rmse: 3.68832\n",
      "[1500]\ttraining's rmse: 3.45811\tvalid_1's rmse: 3.68254\n",
      "[2000]\ttraining's rmse: 3.41444\tvalid_1's rmse: 3.68095\n",
      "Early stopping, best iteration is:\n",
      "[2049]\ttraining's rmse: 3.41063\tvalid_1's rmse: 3.68085\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60395\tvalid_1's rmse: 3.64939\n",
      "[1000]\ttraining's rmse: 3.52236\tvalid_1's rmse: 3.6313\n",
      "[1500]\ttraining's rmse: 3.46855\tvalid_1's rmse: 3.62611\n",
      "[2000]\ttraining's rmse: 3.42503\tvalid_1's rmse: 3.62434\n",
      "[2500]\ttraining's rmse: 3.38617\tvalid_1's rmse: 3.6241\n",
      "Early stopping, best iteration is:\n",
      "[2382]\ttraining's rmse: 3.39507\tvalid_1's rmse: 3.62398\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60794\tvalid_1's rmse: 3.62566\n",
      "[1000]\ttraining's rmse: 3.52677\tvalid_1's rmse: 3.60874\n",
      "[1500]\ttraining's rmse: 3.4736\tvalid_1's rmse: 3.60469\n",
      "[2000]\ttraining's rmse: 3.42888\tvalid_1's rmse: 3.60381\n",
      "Early stopping, best iteration is:\n",
      "[1849]\ttraining's rmse: 3.44165\tvalid_1's rmse: 3.60362\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56243\tvalid_1's rmse: 3.81259\n",
      "[1000]\ttraining's rmse: 3.48149\tvalid_1's rmse: 3.7952\n",
      "[1500]\ttraining's rmse: 3.42807\tvalid_1's rmse: 3.79073\n",
      "[2000]\ttraining's rmse: 3.38493\tvalid_1's rmse: 3.7897\n",
      "Early stopping, best iteration is:\n",
      "[2203]\ttraining's rmse: 3.36888\tvalid_1's rmse: 3.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60345\tvalid_1's rmse: 3.64464\n",
      "[1000]\ttraining's rmse: 3.52157\tvalid_1's rmse: 3.62846\n",
      "[1500]\ttraining's rmse: 3.46786\tvalid_1's rmse: 3.6232\n",
      "[2000]\ttraining's rmse: 3.42454\tvalid_1's rmse: 3.6214\n",
      "Early stopping, best iteration is:\n",
      "[2278]\ttraining's rmse: 3.40316\tvalid_1's rmse: 3.62085\n",
      "  112 | 05m20s |   -3.66441 |             0.9850 |        18.3911 |             0.3474 |             0.4465 |     14.0154 |             32.8280 |            40.9500 |            99.6065 |           0.1613 |      43.1068 |      1.3208 |       9.6798 |      0.7632 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59416\tvalid_1's rmse: 3.71293\n",
      "[1000]\ttraining's rmse: 3.51938\tvalid_1's rmse: 3.69335\n",
      "[1500]\ttraining's rmse: 3.46896\tvalid_1's rmse: 3.68768\n",
      "[2000]\ttraining's rmse: 3.42748\tvalid_1's rmse: 3.68685\n",
      "Early stopping, best iteration is:\n",
      "[1884]\ttraining's rmse: 3.43689\tvalid_1's rmse: 3.68669\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60714\tvalid_1's rmse: 3.65264\n",
      "[1000]\ttraining's rmse: 3.53029\tvalid_1's rmse: 3.63458\n",
      "[1500]\ttraining's rmse: 3.47981\tvalid_1's rmse: 3.62914\n",
      "[2000]\ttraining's rmse: 3.43817\tvalid_1's rmse: 3.62724\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's rmse: 3.44284\tvalid_1's rmse: 3.62698\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61138\tvalid_1's rmse: 3.62848\n",
      "[1000]\ttraining's rmse: 3.53429\tvalid_1's rmse: 3.61103\n",
      "[1500]\ttraining's rmse: 3.48151\tvalid_1's rmse: 3.60697\n",
      "[2000]\ttraining's rmse: 3.44072\tvalid_1's rmse: 3.6061\n",
      "Early stopping, best iteration is:\n",
      "[1971]\ttraining's rmse: 3.44244\tvalid_1's rmse: 3.60605\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56644\tvalid_1's rmse: 3.81159\n",
      "[1000]\ttraining's rmse: 3.48944\tvalid_1's rmse: 3.79537\n",
      "[1500]\ttraining's rmse: 3.43812\tvalid_1's rmse: 3.79107\n",
      "Early stopping, best iteration is:\n",
      "[1768]\ttraining's rmse: 3.41503\tvalid_1's rmse: 3.79068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60513\tvalid_1's rmse: 3.6497\n",
      "[1000]\ttraining's rmse: 3.52835\tvalid_1's rmse: 3.63524\n",
      "[1500]\ttraining's rmse: 3.47657\tvalid_1's rmse: 3.6299\n",
      "[2000]\ttraining's rmse: 3.43571\tvalid_1's rmse: 3.62846\n",
      "Early stopping, best iteration is:\n",
      "[2047]\ttraining's rmse: 3.43182\tvalid_1's rmse: 3.62835\n",
      "  113 | 05m34s |   -3.66836 |             0.9669 |        19.6113 |             0.9893 |             0.8173 |      9.1996 |             49.7783 |            38.1027 |            33.8200 |           0.5630 |      32.8707 |      8.5261 |       8.5412 |      0.7859 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59892\tvalid_1's rmse: 3.70868\n",
      "[1000]\ttraining's rmse: 3.52703\tvalid_1's rmse: 3.68879\n",
      "[1500]\ttraining's rmse: 3.48003\tvalid_1's rmse: 3.6838\n",
      "[2000]\ttraining's rmse: 3.44254\tvalid_1's rmse: 3.68298\n",
      "Early stopping, best iteration is:\n",
      "[2084]\ttraining's rmse: 3.43708\tvalid_1's rmse: 3.68277\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61116\tvalid_1's rmse: 3.65124\n",
      "[1000]\ttraining's rmse: 3.53886\tvalid_1's rmse: 3.63624\n",
      "[1500]\ttraining's rmse: 3.4917\tvalid_1's rmse: 3.63133\n",
      "[2000]\ttraining's rmse: 3.45303\tvalid_1's rmse: 3.62896\n",
      "Early stopping, best iteration is:\n",
      "[2001]\ttraining's rmse: 3.45299\tvalid_1's rmse: 3.62894\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61567\tvalid_1's rmse: 3.62702\n",
      "[1000]\ttraining's rmse: 3.54405\tvalid_1's rmse: 3.61073\n",
      "[1500]\ttraining's rmse: 3.496\tvalid_1's rmse: 3.60694\n",
      "[2000]\ttraining's rmse: 3.45684\tvalid_1's rmse: 3.606\n",
      "Early stopping, best iteration is:\n",
      "[2247]\ttraining's rmse: 3.43943\tvalid_1's rmse: 3.6057\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57113\tvalid_1's rmse: 3.80795\n",
      "[1000]\ttraining's rmse: 3.49923\tvalid_1's rmse: 3.79389\n",
      "[1500]\ttraining's rmse: 3.45203\tvalid_1's rmse: 3.79021\n",
      "[2000]\ttraining's rmse: 3.41484\tvalid_1's rmse: 3.78899\n",
      "Early stopping, best iteration is:\n",
      "[1937]\ttraining's rmse: 3.41916\tvalid_1's rmse: 3.78878\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61072\tvalid_1's rmse: 3.6453\n",
      "[1000]\ttraining's rmse: 3.53924\tvalid_1's rmse: 3.63076\n",
      "[1500]\ttraining's rmse: 3.49208\tvalid_1's rmse: 3.62607\n",
      "[2000]\ttraining's rmse: 3.45365\tvalid_1's rmse: 3.62338\n",
      "Early stopping, best iteration is:\n",
      "[2299]\ttraining's rmse: 3.43307\tvalid_1's rmse: 3.62251\n",
      "  114 | 06m01s |   -3.66635 |             0.9442 |        19.5705 |             0.1469 |             0.8751 |     14.7091 |              9.2965 |            30.8241 |            98.8505 |           0.3125 |      32.3322 |      6.2401 |       0.1862 |      0.7012 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64723\tvalid_1's rmse: 3.71623\n",
      "[1000]\ttraining's rmse: 3.60561\tvalid_1's rmse: 3.69674\n",
      "[1500]\ttraining's rmse: 3.57546\tvalid_1's rmse: 3.68897\n",
      "[2000]\ttraining's rmse: 3.54949\tvalid_1's rmse: 3.68625\n",
      "[2500]\ttraining's rmse: 3.52881\tvalid_1's rmse: 3.68541\n",
      "[3000]\ttraining's rmse: 3.50971\tvalid_1's rmse: 3.68494\n",
      "Early stopping, best iteration is:\n",
      "[3029]\ttraining's rmse: 3.50837\tvalid_1's rmse: 3.68484\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65942\tvalid_1's rmse: 3.6571\n",
      "[1000]\ttraining's rmse: 3.61512\tvalid_1's rmse: 3.63969\n",
      "[1500]\ttraining's rmse: 3.58636\tvalid_1's rmse: 3.63434\n",
      "[2000]\ttraining's rmse: 3.56222\tvalid_1's rmse: 3.63188\n",
      "[2500]\ttraining's rmse: 3.54049\tvalid_1's rmse: 3.63071\n",
      "[3000]\ttraining's rmse: 3.52053\tvalid_1's rmse: 3.63032\n",
      "[3500]\ttraining's rmse: 3.50242\tvalid_1's rmse: 3.62964\n",
      "Early stopping, best iteration is:\n",
      "[3613]\ttraining's rmse: 3.49775\tvalid_1's rmse: 3.62948\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66577\tvalid_1's rmse: 3.63032\n",
      "[1000]\ttraining's rmse: 3.62175\tvalid_1's rmse: 3.61294\n",
      "[1500]\ttraining's rmse: 3.594\tvalid_1's rmse: 3.60853\n",
      "[2000]\ttraining's rmse: 3.56998\tvalid_1's rmse: 3.60716\n",
      "[2500]\ttraining's rmse: 3.54806\tvalid_1's rmse: 3.60613\n",
      "Early stopping, best iteration is:\n",
      "[2631]\ttraining's rmse: 3.54228\tvalid_1's rmse: 3.60596\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61811\tvalid_1's rmse: 3.81713\n",
      "[1000]\ttraining's rmse: 3.57347\tvalid_1's rmse: 3.80215\n",
      "[1500]\ttraining's rmse: 3.5451\tvalid_1's rmse: 3.79751\n",
      "[2000]\ttraining's rmse: 3.52273\tvalid_1's rmse: 3.79631\n",
      "Early stopping, best iteration is:\n",
      "[2145]\ttraining's rmse: 3.51581\tvalid_1's rmse: 3.7958\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6614\tvalid_1's rmse: 3.64886\n",
      "[1000]\ttraining's rmse: 3.61623\tvalid_1's rmse: 3.63197\n",
      "[1500]\ttraining's rmse: 3.58511\tvalid_1's rmse: 3.6262\n",
      "[2000]\ttraining's rmse: 3.56117\tvalid_1's rmse: 3.62365\n",
      "Early stopping, best iteration is:\n",
      "[2255]\ttraining's rmse: 3.54975\tvalid_1's rmse: 3.6232\n",
      "  115 | 05m41s |   -3.66851 |             0.9882 |        13.8743 |             0.2416 |             0.7551 |      5.0106 |             14.8987 |            39.0501 |            47.4186 |           0.9369 |      34.1588 |      8.8397 |       1.6446 |      0.6507 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59265\tvalid_1's rmse: 3.71462\n",
      "[1000]\ttraining's rmse: 3.51939\tvalid_1's rmse: 3.6968\n",
      "[1500]\ttraining's rmse: 3.46827\tvalid_1's rmse: 3.69012\n",
      "[2000]\ttraining's rmse: 3.4288\tvalid_1's rmse: 3.68875\n",
      "Early stopping, best iteration is:\n",
      "[1972]\ttraining's rmse: 3.43088\tvalid_1's rmse: 3.68863\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6057\tvalid_1's rmse: 3.65419\n",
      "[1000]\ttraining's rmse: 3.5315\tvalid_1's rmse: 3.63525\n",
      "[1500]\ttraining's rmse: 3.48215\tvalid_1's rmse: 3.6318\n",
      "[2000]\ttraining's rmse: 3.44245\tvalid_1's rmse: 3.63106\n",
      "[2500]\ttraining's rmse: 3.40741\tvalid_1's rmse: 3.63048\n",
      "Early stopping, best iteration is:\n",
      "[2585]\ttraining's rmse: 3.40129\tvalid_1's rmse: 3.63028\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.61121\tvalid_1's rmse: 3.63022\n",
      "[1000]\ttraining's rmse: 3.53616\tvalid_1's rmse: 3.61393\n",
      "[1500]\ttraining's rmse: 3.48611\tvalid_1's rmse: 3.61062\n",
      "[2000]\ttraining's rmse: 3.44625\tvalid_1's rmse: 3.60966\n",
      "Early stopping, best iteration is:\n",
      "[1886]\ttraining's rmse: 3.45453\tvalid_1's rmse: 3.60954\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56545\tvalid_1's rmse: 3.81091\n",
      "[1000]\ttraining's rmse: 3.48979\tvalid_1's rmse: 3.79564\n",
      "[1500]\ttraining's rmse: 3.44016\tvalid_1's rmse: 3.79089\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttraining's rmse: 3.41984\tvalid_1's rmse: 3.79031\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60364\tvalid_1's rmse: 3.65042\n",
      "[1000]\ttraining's rmse: 3.52694\tvalid_1's rmse: 3.63523\n",
      "[1500]\ttraining's rmse: 3.47703\tvalid_1's rmse: 3.63129\n",
      "[2000]\ttraining's rmse: 3.43721\tvalid_1's rmse: 3.63039\n",
      "Early stopping, best iteration is:\n",
      "[2123]\ttraining's rmse: 3.42842\tvalid_1's rmse: 3.63013\n",
      "  116 | 05m21s |   -3.67037 |             0.9601 |         0.0887 |             0.7843 |             0.8827 |      9.7843 |             48.7927 |            37.9690 |            10.4566 |           0.8396 |      30.8213 |      3.0660 |       2.9525 |      0.3541 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.37106578e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.554\tvalid_1's rmse: 3.71513\n",
      "[1000]\ttraining's rmse: 3.45064\tvalid_1's rmse: 3.6964\n",
      "[1500]\ttraining's rmse: 3.38047\tvalid_1's rmse: 3.69026\n",
      "[2000]\ttraining's rmse: 3.3249\tvalid_1's rmse: 3.68821\n",
      "[2500]\ttraining's rmse: 3.27988\tvalid_1's rmse: 3.688\n",
      "Early stopping, best iteration is:\n",
      "[2633]\ttraining's rmse: 3.26892\tvalid_1's rmse: 3.68771\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56485\tvalid_1's rmse: 3.65517\n",
      "[1000]\ttraining's rmse: 3.4602\tvalid_1's rmse: 3.63882\n",
      "[1500]\ttraining's rmse: 3.39168\tvalid_1's rmse: 3.6348\n",
      "Early stopping, best iteration is:\n",
      "[1741]\ttraining's rmse: 3.36383\tvalid_1's rmse: 3.634\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57218\tvalid_1's rmse: 3.63016\n",
      "[1000]\ttraining's rmse: 3.469\tvalid_1's rmse: 3.61485\n",
      "[1500]\ttraining's rmse: 3.39978\tvalid_1's rmse: 3.61084\n",
      "[2000]\ttraining's rmse: 3.34818\tvalid_1's rmse: 3.61005\n",
      "Early stopping, best iteration is:\n",
      "[1945]\ttraining's rmse: 3.3533\tvalid_1's rmse: 3.60998\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5258\tvalid_1's rmse: 3.81205\n",
      "[1000]\ttraining's rmse: 3.42005\tvalid_1's rmse: 3.79714\n",
      "[1500]\ttraining's rmse: 3.3506\tvalid_1's rmse: 3.79285\n",
      "[2000]\ttraining's rmse: 3.2983\tvalid_1's rmse: 3.79208\n",
      "Early stopping, best iteration is:\n",
      "[1905]\ttraining's rmse: 3.30725\tvalid_1's rmse: 3.79196\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5642\tvalid_1's rmse: 3.65397\n",
      "[1000]\ttraining's rmse: 3.45882\tvalid_1's rmse: 3.63926\n",
      "[1500]\ttraining's rmse: 3.39013\tvalid_1's rmse: 3.63476\n",
      "[2000]\ttraining's rmse: 3.33654\tvalid_1's rmse: 3.63396\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's rmse: 3.33524\tvalid_1's rmse: 3.63392\n",
      "  117 | 05m58s |   -3.67210 |             0.6921 |         0.0278 |             0.1328 |             0.9437 |     14.5305 |             49.3553 |            34.1286 |            10.8213 |           0.1295 |      41.1891 |      8.7801 |       8.9183 |      0.7563 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63677\tvalid_1's rmse: 3.72199\n",
      "[1000]\ttraining's rmse: 3.57198\tvalid_1's rmse: 3.69703\n",
      "[1500]\ttraining's rmse: 3.53101\tvalid_1's rmse: 3.6889\n",
      "[2000]\ttraining's rmse: 3.4981\tvalid_1's rmse: 3.68561\n",
      "[2500]\ttraining's rmse: 3.47037\tvalid_1's rmse: 3.68415\n",
      "[3000]\ttraining's rmse: 3.44548\tvalid_1's rmse: 3.68326\n",
      "[3500]\ttraining's rmse: 3.42279\tvalid_1's rmse: 3.68252\n",
      "Early stopping, best iteration is:\n",
      "[3795]\ttraining's rmse: 3.41016\tvalid_1's rmse: 3.68212\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65006\tvalid_1's rmse: 3.66044\n",
      "[1000]\ttraining's rmse: 3.58351\tvalid_1's rmse: 3.63906\n",
      "[1500]\ttraining's rmse: 3.54199\tvalid_1's rmse: 3.63095\n",
      "[2000]\ttraining's rmse: 3.50897\tvalid_1's rmse: 3.62788\n",
      "[2500]\ttraining's rmse: 3.48039\tvalid_1's rmse: 3.62596\n",
      "[3000]\ttraining's rmse: 3.45504\tvalid_1's rmse: 3.62516\n",
      "[3500]\ttraining's rmse: 3.43115\tvalid_1's rmse: 3.62466\n",
      "Early stopping, best iteration is:\n",
      "[3467]\ttraining's rmse: 3.43279\tvalid_1's rmse: 3.62459\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65458\tvalid_1's rmse: 3.63746\n",
      "[1000]\ttraining's rmse: 3.58804\tvalid_1's rmse: 3.61619\n",
      "[1500]\ttraining's rmse: 3.54688\tvalid_1's rmse: 3.60956\n",
      "[2000]\ttraining's rmse: 3.51379\tvalid_1's rmse: 3.60663\n",
      "[2500]\ttraining's rmse: 3.48563\tvalid_1's rmse: 3.60516\n",
      "[3000]\ttraining's rmse: 3.45982\tvalid_1's rmse: 3.60497\n",
      "Early stopping, best iteration is:\n",
      "[2813]\ttraining's rmse: 3.46933\tvalid_1's rmse: 3.60474\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60854\tvalid_1's rmse: 3.82721\n",
      "[1000]\ttraining's rmse: 3.54195\tvalid_1's rmse: 3.80468\n",
      "[1500]\ttraining's rmse: 3.50128\tvalid_1's rmse: 3.79782\n",
      "[2000]\ttraining's rmse: 3.46927\tvalid_1's rmse: 3.79492\n",
      "[2500]\ttraining's rmse: 3.44157\tvalid_1's rmse: 3.79361\n",
      "[3000]\ttraining's rmse: 3.41642\tvalid_1's rmse: 3.79287\n",
      "[3500]\ttraining's rmse: 3.39329\tvalid_1's rmse: 3.79249\n",
      "[4000]\ttraining's rmse: 3.37101\tvalid_1's rmse: 3.7921\n",
      "[4500]\ttraining's rmse: 3.34995\tvalid_1's rmse: 3.79173\n",
      "[5000]\ttraining's rmse: 3.3297\tvalid_1's rmse: 3.79145\n",
      "Early stopping, best iteration is:\n",
      "[5076]\ttraining's rmse: 3.32673\tvalid_1's rmse: 3.79141\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64966\tvalid_1's rmse: 3.65459\n",
      "[1000]\ttraining's rmse: 3.58219\tvalid_1's rmse: 3.63459\n",
      "[1500]\ttraining's rmse: 3.54114\tvalid_1's rmse: 3.62766\n",
      "[2000]\ttraining's rmse: 3.50868\tvalid_1's rmse: 3.62415\n",
      "[2500]\ttraining's rmse: 3.48081\tvalid_1's rmse: 3.6228\n",
      "[3000]\ttraining's rmse: 3.45537\tvalid_1's rmse: 3.62259\n",
      "[3500]\ttraining's rmse: 3.43235\tvalid_1's rmse: 3.62245\n",
      "Early stopping, best iteration is:\n",
      "[3423]\ttraining's rmse: 3.43593\tvalid_1's rmse: 3.62227\n",
      "  118 | 05m01s |   -3.66566 |             0.1460 |         0.8398 |             0.1488 |             0.2678 |     11.3343 |              5.2178 |            43.6511 |            98.0017 |           0.2167 |      30.0331 |      8.1729 |       9.5522 |      0.9296 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00384943]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60653\tvalid_1's rmse: 3.70445\n",
      "[1000]\ttraining's rmse: 3.55165\tvalid_1's rmse: 3.68774\n",
      "[1500]\ttraining's rmse: 3.51129\tvalid_1's rmse: 3.6837\n",
      "[2000]\ttraining's rmse: 3.47615\tvalid_1's rmse: 3.68248\n",
      "Early stopping, best iteration is:\n",
      "[1989]\ttraining's rmse: 3.47704\tvalid_1's rmse: 3.68242\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62152\tvalid_1's rmse: 3.64815\n",
      "[1000]\ttraining's rmse: 3.56252\tvalid_1's rmse: 3.6325\n",
      "[1500]\ttraining's rmse: 3.52191\tvalid_1's rmse: 3.62854\n",
      "[2000]\ttraining's rmse: 3.484\tvalid_1's rmse: 3.62625\n",
      "Early stopping, best iteration is:\n",
      "[2278]\ttraining's rmse: 3.46706\tvalid_1's rmse: 3.62552\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62529\tvalid_1's rmse: 3.6235\n",
      "[1000]\ttraining's rmse: 3.56678\tvalid_1's rmse: 3.60933\n",
      "[1500]\ttraining's rmse: 3.52517\tvalid_1's rmse: 3.60513\n",
      "Early stopping, best iteration is:\n",
      "[1717]\ttraining's rmse: 3.51014\tvalid_1's rmse: 3.60471\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57941\tvalid_1's rmse: 3.80886\n",
      "[1000]\ttraining's rmse: 3.52003\tvalid_1's rmse: 3.79557\n",
      "[1500]\ttraining's rmse: 3.4793\tvalid_1's rmse: 3.7921\n",
      "Early stopping, best iteration is:\n",
      "[1560]\ttraining's rmse: 3.4745\tvalid_1's rmse: 3.79184\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62104\tvalid_1's rmse: 3.63997\n",
      "[1000]\ttraining's rmse: 3.56176\tvalid_1's rmse: 3.62709\n",
      "[1500]\ttraining's rmse: 3.5239\tvalid_1's rmse: 3.62355\n",
      "Early stopping, best iteration is:\n",
      "[1751]\ttraining's rmse: 3.50407\tvalid_1's rmse: 3.62227\n",
      "  119 | 05m55s |   -3.66599 |             0.8973 |        17.2880 |             0.1586 |             0.8846 |      7.5202 |              6.2600 |            43.6438 |            99.9469 |           0.8911 |      40.2002 |      9.8073 |       7.9657 |      0.9685 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59791\tvalid_1's rmse: 3.70599\n",
      "[1000]\ttraining's rmse: 3.52427\tvalid_1's rmse: 3.68653\n",
      "[1500]\ttraining's rmse: 3.47341\tvalid_1's rmse: 3.68061\n",
      "[2000]\ttraining's rmse: 3.43024\tvalid_1's rmse: 3.67894\n",
      "Early stopping, best iteration is:\n",
      "[2194]\ttraining's rmse: 3.41446\tvalid_1's rmse: 3.67836\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61016\tvalid_1's rmse: 3.64874\n",
      "[1000]\ttraining's rmse: 3.53554\tvalid_1's rmse: 3.63127\n",
      "[1500]\ttraining's rmse: 3.48408\tvalid_1's rmse: 3.62598\n",
      "[2000]\ttraining's rmse: 3.44025\tvalid_1's rmse: 3.62457\n",
      "[2500]\ttraining's rmse: 3.40046\tvalid_1's rmse: 3.62336\n",
      "Early stopping, best iteration is:\n",
      "[2663]\ttraining's rmse: 3.3885\tvalid_1's rmse: 3.62316\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61475\tvalid_1's rmse: 3.62527\n",
      "[1000]\ttraining's rmse: 3.54126\tvalid_1's rmse: 3.60778\n",
      "[1500]\ttraining's rmse: 3.48939\tvalid_1's rmse: 3.60422\n",
      "[2000]\ttraining's rmse: 3.44437\tvalid_1's rmse: 3.60318\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's rmse: 3.42156\tvalid_1's rmse: 3.60307\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56961\tvalid_1's rmse: 3.81152\n",
      "[1000]\ttraining's rmse: 3.49558\tvalid_1's rmse: 3.79602\n",
      "[1500]\ttraining's rmse: 3.44384\tvalid_1's rmse: 3.79248\n",
      "[2000]\ttraining's rmse: 3.4001\tvalid_1's rmse: 3.7912\n",
      "Early stopping, best iteration is:\n",
      "[2248]\ttraining's rmse: 3.37922\tvalid_1's rmse: 3.7907\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60968\tvalid_1's rmse: 3.64351\n",
      "[1000]\ttraining's rmse: 3.53443\tvalid_1's rmse: 3.62806\n",
      "[1500]\ttraining's rmse: 3.48345\tvalid_1's rmse: 3.62351\n",
      "[2000]\ttraining's rmse: 3.4404\tvalid_1's rmse: 3.62291\n",
      "Early stopping, best iteration is:\n",
      "[1954]\ttraining's rmse: 3.44388\tvalid_1's rmse: 3.62284\n",
      "  120 | 05m40s |   -3.66426 |             0.7987 |         3.9726 |             0.1270 |             0.5413 |     13.6936 |             49.5967 |            31.5304 |            98.7807 |           0.5885 |      39.3322 |      8.9444 |       5.7247 |      0.7321 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54498\tvalid_1's rmse: 3.70723\n",
      "[1000]\ttraining's rmse: 3.44557\tvalid_1's rmse: 3.68883\n",
      "[1500]\ttraining's rmse: 3.37803\tvalid_1's rmse: 3.68384\n",
      "Early stopping, best iteration is:\n",
      "[1585]\ttraining's rmse: 3.36748\tvalid_1's rmse: 3.68344\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55405\tvalid_1's rmse: 3.65049\n",
      "[1000]\ttraining's rmse: 3.45424\tvalid_1's rmse: 3.63644\n",
      "[1500]\ttraining's rmse: 3.38674\tvalid_1's rmse: 3.63194\n",
      "[2000]\ttraining's rmse: 3.33246\tvalid_1's rmse: 3.63059\n",
      "Early stopping, best iteration is:\n",
      "[1995]\ttraining's rmse: 3.33309\tvalid_1's rmse: 3.63056\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56061\tvalid_1's rmse: 3.62658\n",
      "[1000]\ttraining's rmse: 3.46211\tvalid_1's rmse: 3.61309\n",
      "[1500]\ttraining's rmse: 3.39268\tvalid_1's rmse: 3.60961\n",
      "Early stopping, best iteration is:\n",
      "[1673]\ttraining's rmse: 3.3728\tvalid_1's rmse: 3.60924\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5149\tvalid_1's rmse: 3.80473\n",
      "[1000]\ttraining's rmse: 3.4162\tvalid_1's rmse: 3.79162\n",
      "[1500]\ttraining's rmse: 3.34895\tvalid_1's rmse: 3.78882\n",
      "Early stopping, best iteration is:\n",
      "[1622]\ttraining's rmse: 3.33532\tvalid_1's rmse: 3.78849\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55448\tvalid_1's rmse: 3.64843\n",
      "[1000]\ttraining's rmse: 3.4556\tvalid_1's rmse: 3.63423\n",
      "[1500]\ttraining's rmse: 3.38824\tvalid_1's rmse: 3.63137\n",
      "Early stopping, best iteration is:\n",
      "[1657]\ttraining's rmse: 3.37169\tvalid_1's rmse: 3.63055\n",
      "  121 | 05m58s |   -3.66903 |             0.9530 |        19.0587 |             0.5374 |             0.9462 |     14.7752 |              5.3765 |            44.4280 |            53.2411 |           0.7720 |      44.9180 |      4.7931 |       0.1381 |      0.9932 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00041869]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65355\tvalid_1's rmse: 3.71651\n",
      "[1000]\ttraining's rmse: 3.61513\tvalid_1's rmse: 3.69799\n",
      "[1500]\ttraining's rmse: 3.58992\tvalid_1's rmse: 3.69128\n",
      "[2000]\ttraining's rmse: 3.56952\tvalid_1's rmse: 3.68903\n",
      "[2500]\ttraining's rmse: 3.54961\tvalid_1's rmse: 3.68679\n",
      "Early stopping, best iteration is:\n",
      "[2413]\ttraining's rmse: 3.55299\tvalid_1's rmse: 3.68667\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66644\tvalid_1's rmse: 3.65733\n",
      "[1000]\ttraining's rmse: 3.62548\tvalid_1's rmse: 3.64089\n",
      "[1500]\ttraining's rmse: 3.6016\tvalid_1's rmse: 3.6343\n",
      "[2000]\ttraining's rmse: 3.57951\tvalid_1's rmse: 3.63038\n",
      "[2500]\ttraining's rmse: 3.55983\tvalid_1's rmse: 3.6291\n",
      "[3000]\ttraining's rmse: 3.54254\tvalid_1's rmse: 3.62848\n",
      "[3500]\ttraining's rmse: 3.52569\tvalid_1's rmse: 3.62711\n",
      "Early stopping, best iteration is:\n",
      "[3344]\ttraining's rmse: 3.53093\tvalid_1's rmse: 3.62688\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67142\tvalid_1's rmse: 3.6297\n",
      "[1000]\ttraining's rmse: 3.63113\tvalid_1's rmse: 3.61258\n",
      "[1500]\ttraining's rmse: 3.60332\tvalid_1's rmse: 3.60756\n",
      "[2000]\ttraining's rmse: 3.58249\tvalid_1's rmse: 3.60552\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 3.5877\tvalid_1's rmse: 3.60543\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62421\tvalid_1's rmse: 3.81903\n",
      "[1000]\ttraining's rmse: 3.58152\tvalid_1's rmse: 3.80245\n",
      "[1500]\ttraining's rmse: 3.55648\tvalid_1's rmse: 3.79792\n",
      "[2000]\ttraining's rmse: 3.53543\tvalid_1's rmse: 3.79584\n",
      "[2500]\ttraining's rmse: 3.51884\tvalid_1's rmse: 3.79498\n",
      "[3000]\ttraining's rmse: 3.50181\tvalid_1's rmse: 3.79434\n",
      "Early stopping, best iteration is:\n",
      "[3101]\ttraining's rmse: 3.49884\tvalid_1's rmse: 3.79402\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66722\tvalid_1's rmse: 3.64854\n",
      "[1000]\ttraining's rmse: 3.62707\tvalid_1's rmse: 3.63323\n",
      "[1500]\ttraining's rmse: 3.5998\tvalid_1's rmse: 3.62656\n",
      "[2000]\ttraining's rmse: 3.57676\tvalid_1's rmse: 3.62403\n",
      "[2500]\ttraining's rmse: 3.55687\tvalid_1's rmse: 3.62352\n",
      "Early stopping, best iteration is:\n",
      "[2357]\ttraining's rmse: 3.5624\tvalid_1's rmse: 3.62324\n",
      "  122 | 05m43s |   -3.66790 |             0.8656 |        19.4743 |             0.4757 |             0.8570 |      5.3311 |             44.2495 |            32.6642 |            98.5750 |           0.1555 |      44.2249 |      9.7090 |       9.7917 |      0.9936 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54287\tvalid_1's rmse: 3.70863\n",
      "[1000]\ttraining's rmse: 3.44229\tvalid_1's rmse: 3.69059\n",
      "[1500]\ttraining's rmse: 3.37445\tvalid_1's rmse: 3.68601\n",
      "[2000]\ttraining's rmse: 3.31991\tvalid_1's rmse: 3.68408\n",
      "Early stopping, best iteration is:\n",
      "[2148]\ttraining's rmse: 3.30499\tvalid_1's rmse: 3.68376\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55475\tvalid_1's rmse: 3.65021\n",
      "[1000]\ttraining's rmse: 3.45392\tvalid_1's rmse: 3.63321\n",
      "[1500]\ttraining's rmse: 3.38546\tvalid_1's rmse: 3.62851\n",
      "[2000]\ttraining's rmse: 3.32897\tvalid_1's rmse: 3.62774\n",
      "[2500]\ttraining's rmse: 3.28173\tvalid_1's rmse: 3.62771\n",
      "Early stopping, best iteration is:\n",
      "[2440]\ttraining's rmse: 3.28682\tvalid_1's rmse: 3.62749\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55944\tvalid_1's rmse: 3.62686\n",
      "[1000]\ttraining's rmse: 3.45773\tvalid_1's rmse: 3.61105\n",
      "[1500]\ttraining's rmse: 3.39001\tvalid_1's rmse: 3.60791\n",
      "Early stopping, best iteration is:\n",
      "[1588]\ttraining's rmse: 3.37938\tvalid_1's rmse: 3.60741\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.51462\tvalid_1's rmse: 3.80691\n",
      "[1000]\ttraining's rmse: 3.41204\tvalid_1's rmse: 3.7924\n",
      "[1500]\ttraining's rmse: 3.34316\tvalid_1's rmse: 3.78829\n",
      "Early stopping, best iteration is:\n",
      "[1497]\ttraining's rmse: 3.34359\tvalid_1's rmse: 3.78823\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55292\tvalid_1's rmse: 3.64724\n",
      "[1000]\ttraining's rmse: 3.45128\tvalid_1's rmse: 3.63305\n",
      "[1500]\ttraining's rmse: 3.3834\tvalid_1's rmse: 3.62871\n",
      "Early stopping, best iteration is:\n",
      "[1655]\ttraining's rmse: 3.36617\tvalid_1's rmse: 3.62836\n",
      "  123 | 05m48s |   -3.66764 |             0.9644 |        16.4731 |             0.7878 |             0.7005 |     13.5026 |             49.7532 |            44.1441 |            30.5028 |           0.9656 |      44.2433 |      0.9391 |       0.2789 |      0.1102 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60194\tvalid_1's rmse: 3.71085\n",
      "[1000]\ttraining's rmse: 3.53194\tvalid_1's rmse: 3.69116\n",
      "[1500]\ttraining's rmse: 3.48466\tvalid_1's rmse: 3.68409\n",
      "[2000]\ttraining's rmse: 3.4488\tvalid_1's rmse: 3.6818\n",
      "Early stopping, best iteration is:\n",
      "[1985]\ttraining's rmse: 3.45015\tvalid_1's rmse: 3.68176\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6148\tvalid_1's rmse: 3.65312\n",
      "[1000]\ttraining's rmse: 3.54238\tvalid_1's rmse: 3.63568\n",
      "[1500]\ttraining's rmse: 3.4961\tvalid_1's rmse: 3.63013\n",
      "[2000]\ttraining's rmse: 3.4598\tvalid_1's rmse: 3.62802\n",
      "Early stopping, best iteration is:\n",
      "[2279]\ttraining's rmse: 3.44119\tvalid_1's rmse: 3.62727\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61995\tvalid_1's rmse: 3.62892\n",
      "[1000]\ttraining's rmse: 3.54913\tvalid_1's rmse: 3.61248\n",
      "[1500]\ttraining's rmse: 3.50194\tvalid_1's rmse: 3.60835\n",
      "[2000]\ttraining's rmse: 3.46618\tvalid_1's rmse: 3.60721\n",
      "Early stopping, best iteration is:\n",
      "[2112]\ttraining's rmse: 3.4577\tvalid_1's rmse: 3.60682\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57613\tvalid_1's rmse: 3.80941\n",
      "[1000]\ttraining's rmse: 3.50306\tvalid_1's rmse: 3.7938\n",
      "[1500]\ttraining's rmse: 3.45633\tvalid_1's rmse: 3.78884\n",
      "[2000]\ttraining's rmse: 3.42078\tvalid_1's rmse: 3.78797\n",
      "[2500]\ttraining's rmse: 3.38932\tvalid_1's rmse: 3.78756\n",
      "[3000]\ttraining's rmse: 3.36016\tvalid_1's rmse: 3.78756\n",
      "Early stopping, best iteration is:\n",
      "[2941]\ttraining's rmse: 3.36345\tvalid_1's rmse: 3.78719\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61436\tvalid_1's rmse: 3.64691\n",
      "[1000]\ttraining's rmse: 3.54215\tvalid_1's rmse: 3.63184\n",
      "[1500]\ttraining's rmse: 3.49667\tvalid_1's rmse: 3.62646\n",
      "[2000]\ttraining's rmse: 3.46043\tvalid_1's rmse: 3.62475\n",
      "[2500]\ttraining's rmse: 3.42803\tvalid_1's rmse: 3.62406\n",
      "Early stopping, best iteration is:\n",
      "[2470]\ttraining's rmse: 3.42983\tvalid_1's rmse: 3.62405\n",
      "  124 | 06m12s |   -3.66601 |             0.9870 |        12.9433 |             0.4484 |             0.7962 |     14.5118 |             35.9706 |            37.1302 |            89.0875 |           0.7639 |      30.0893 |      0.2613 |       1.6526 |      0.9346 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61569\tvalid_1's rmse: 3.7072\n",
      "[1000]\ttraining's rmse: 3.56298\tvalid_1's rmse: 3.68914\n",
      "[1500]\ttraining's rmse: 3.52442\tvalid_1's rmse: 3.68408\n",
      "[2000]\ttraining's rmse: 3.49283\tvalid_1's rmse: 3.68297\n",
      "[2500]\ttraining's rmse: 3.46327\tvalid_1's rmse: 3.68272\n",
      "Early stopping, best iteration is:\n",
      "[2416]\ttraining's rmse: 3.46803\tvalid_1's rmse: 3.68265\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62903\tvalid_1's rmse: 3.65128\n",
      "[1000]\ttraining's rmse: 3.57357\tvalid_1's rmse: 3.63386\n",
      "[1500]\ttraining's rmse: 3.5362\tvalid_1's rmse: 3.62996\n",
      "[2000]\ttraining's rmse: 3.50518\tvalid_1's rmse: 3.62835\n",
      "[2500]\ttraining's rmse: 3.47247\tvalid_1's rmse: 3.62767\n",
      "Early stopping, best iteration is:\n",
      "[2501]\ttraining's rmse: 3.47241\tvalid_1's rmse: 3.62765\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63488\tvalid_1's rmse: 3.62291\n",
      "[1000]\ttraining's rmse: 3.57905\tvalid_1's rmse: 3.60786\n",
      "[1500]\ttraining's rmse: 3.54111\tvalid_1's rmse: 3.60403\n",
      "[2000]\ttraining's rmse: 3.50626\tvalid_1's rmse: 3.60358\n",
      "Early stopping, best iteration is:\n",
      "[1879]\ttraining's rmse: 3.51426\tvalid_1's rmse: 3.6034\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58682\tvalid_1's rmse: 3.81146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.53077\tvalid_1's rmse: 3.79568\n",
      "[1500]\ttraining's rmse: 3.49193\tvalid_1's rmse: 3.79226\n",
      "[2000]\ttraining's rmse: 3.4585\tvalid_1's rmse: 3.79142\n",
      "Early stopping, best iteration is:\n",
      "[2193]\ttraining's rmse: 3.44661\tvalid_1's rmse: 3.79129\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62849\tvalid_1's rmse: 3.64183\n",
      "[1000]\ttraining's rmse: 3.57077\tvalid_1's rmse: 3.62696\n",
      "[1500]\ttraining's rmse: 3.53178\tvalid_1's rmse: 3.62239\n",
      "[2000]\ttraining's rmse: 3.49943\tvalid_1's rmse: 3.62157\n",
      "Early stopping, best iteration is:\n",
      "[1908]\ttraining's rmse: 3.50552\tvalid_1's rmse: 3.62144\n",
      "  125 | 05m04s |   -3.66592 |             0.8443 |         0.8115 |             0.3614 |             0.5957 |      6.1899 |              7.0147 |            42.2714 |            12.7725 |           0.0006 |      38.3884 |      0.9436 |       0.3709 |      0.3884 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.2832066e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56809\tvalid_1's rmse: 3.70989\n",
      "[1000]\ttraining's rmse: 3.47628\tvalid_1's rmse: 3.69143\n",
      "[1500]\ttraining's rmse: 3.41366\tvalid_1's rmse: 3.68517\n",
      "[2000]\ttraining's rmse: 3.36404\tvalid_1's rmse: 3.68379\n",
      "Early stopping, best iteration is:\n",
      "[2243]\ttraining's rmse: 3.34365\tvalid_1's rmse: 3.68354\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58117\tvalid_1's rmse: 3.65191\n",
      "[1000]\ttraining's rmse: 3.48828\tvalid_1's rmse: 3.63543\n",
      "[1500]\ttraining's rmse: 3.4267\tvalid_1's rmse: 3.63079\n",
      "[2000]\ttraining's rmse: 3.3783\tvalid_1's rmse: 3.6297\n",
      "Early stopping, best iteration is:\n",
      "[2270]\ttraining's rmse: 3.35445\tvalid_1's rmse: 3.62925\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5866\tvalid_1's rmse: 3.62606\n",
      "[1000]\ttraining's rmse: 3.49396\tvalid_1's rmse: 3.60968\n",
      "[1500]\ttraining's rmse: 3.43035\tvalid_1's rmse: 3.60515\n",
      "[2000]\ttraining's rmse: 3.3825\tvalid_1's rmse: 3.60445\n",
      "Early stopping, best iteration is:\n",
      "[2012]\ttraining's rmse: 3.38135\tvalid_1's rmse: 3.60432\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54163\tvalid_1's rmse: 3.80832\n",
      "[1000]\ttraining's rmse: 3.44638\tvalid_1's rmse: 3.79277\n",
      "[1500]\ttraining's rmse: 3.38347\tvalid_1's rmse: 3.7887\n",
      "[2000]\ttraining's rmse: 3.33619\tvalid_1's rmse: 3.78784\n",
      "[2500]\ttraining's rmse: 3.29426\tvalid_1's rmse: 3.78752\n",
      "Early stopping, best iteration is:\n",
      "[2348]\ttraining's rmse: 3.30621\tvalid_1's rmse: 3.78737\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57853\tvalid_1's rmse: 3.64907\n",
      "[1000]\ttraining's rmse: 3.48548\tvalid_1's rmse: 3.63512\n",
      "[1500]\ttraining's rmse: 3.4247\tvalid_1's rmse: 3.62972\n",
      "[2000]\ttraining's rmse: 3.37634\tvalid_1's rmse: 3.62848\n",
      "Early stopping, best iteration is:\n",
      "[2114]\ttraining's rmse: 3.36648\tvalid_1's rmse: 3.62834\n",
      "  126 | 06m47s |   -3.66715 |             0.9831 |         3.5912 |             0.2014 |             0.8381 |     14.8434 |             11.8728 |            38.7642 |            55.0119 |           0.0773 |      40.8609 |      0.0094 |       9.7848 |      0.9088 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00046497]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58513\tvalid_1's rmse: 3.71055\n",
      "[1000]\ttraining's rmse: 3.51274\tvalid_1's rmse: 3.69477\n",
      "[1500]\ttraining's rmse: 3.46013\tvalid_1's rmse: 3.69066\n",
      "[2000]\ttraining's rmse: 3.41372\tvalid_1's rmse: 3.68874\n",
      "Early stopping, best iteration is:\n",
      "[1998]\ttraining's rmse: 3.41387\tvalid_1's rmse: 3.68871\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.598\tvalid_1's rmse: 3.65049\n",
      "[1000]\ttraining's rmse: 3.52606\tvalid_1's rmse: 3.63715\n",
      "[1500]\ttraining's rmse: 3.47358\tvalid_1's rmse: 3.63355\n",
      "Early stopping, best iteration is:\n",
      "[1708]\ttraining's rmse: 3.45409\tvalid_1's rmse: 3.63225\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60379\tvalid_1's rmse: 3.62666\n",
      "[1000]\ttraining's rmse: 3.52965\tvalid_1's rmse: 3.61452\n",
      "Early stopping, best iteration is:\n",
      "[905]\ttraining's rmse: 3.54151\tvalid_1's rmse: 3.61359\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55808\tvalid_1's rmse: 3.80874\n",
      "[1000]\ttraining's rmse: 3.48296\tvalid_1's rmse: 3.79554\n",
      "[1500]\ttraining's rmse: 3.42964\tvalid_1's rmse: 3.79356\n",
      "Early stopping, best iteration is:\n",
      "[1521]\ttraining's rmse: 3.42726\tvalid_1's rmse: 3.79322\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59538\tvalid_1's rmse: 3.6455\n",
      "[1000]\ttraining's rmse: 3.51862\tvalid_1's rmse: 3.63479\n",
      "Early stopping, best iteration is:\n",
      "[934]\ttraining's rmse: 3.52654\tvalid_1's rmse: 3.63434\n",
      "  127 | 04m46s |   -3.67300 |             0.5118 |        18.9386 |             0.2148 |             0.9352 |      9.6158 |             46.0511 |            44.9775 |            11.6959 |           0.9780 |      37.5511 |      7.3563 |       0.0964 |      0.8970 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00109325]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58862\tvalid_1's rmse: 3.71097\n",
      "[1000]\ttraining's rmse: 3.50556\tvalid_1's rmse: 3.69016\n",
      "[1500]\ttraining's rmse: 3.44862\tvalid_1's rmse: 3.68411\n",
      "[2000]\ttraining's rmse: 3.40029\tvalid_1's rmse: 3.68149\n",
      "[2500]\ttraining's rmse: 3.35816\tvalid_1's rmse: 3.68037\n",
      "Early stopping, best iteration is:\n",
      "[2463]\ttraining's rmse: 3.36103\tvalid_1's rmse: 3.68033\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60166\tvalid_1's rmse: 3.65292\n",
      "[1000]\ttraining's rmse: 3.51643\tvalid_1's rmse: 3.63451\n",
      "[1500]\ttraining's rmse: 3.45925\tvalid_1's rmse: 3.62852\n",
      "[2000]\ttraining's rmse: 3.41094\tvalid_1's rmse: 3.62614\n",
      "[2500]\ttraining's rmse: 3.36858\tvalid_1's rmse: 3.62492\n",
      "Early stopping, best iteration is:\n",
      "[2362]\ttraining's rmse: 3.37985\tvalid_1's rmse: 3.62484\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60595\tvalid_1's rmse: 3.62917\n",
      "[1000]\ttraining's rmse: 3.52139\tvalid_1's rmse: 3.61156\n",
      "[1500]\ttraining's rmse: 3.46382\tvalid_1's rmse: 3.60618\n",
      "[2000]\ttraining's rmse: 3.41547\tvalid_1's rmse: 3.6049\n",
      "[2500]\ttraining's rmse: 3.3722\tvalid_1's rmse: 3.60411\n",
      "Early stopping, best iteration is:\n",
      "[2657]\ttraining's rmse: 3.35901\tvalid_1's rmse: 3.60395\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56091\tvalid_1's rmse: 3.81674\n",
      "[1000]\ttraining's rmse: 3.47598\tvalid_1's rmse: 3.79873\n",
      "[1500]\ttraining's rmse: 3.41944\tvalid_1's rmse: 3.79379\n",
      "[2000]\ttraining's rmse: 3.37174\tvalid_1's rmse: 3.79173\n",
      "Early stopping, best iteration is:\n",
      "[2146]\ttraining's rmse: 3.359\tvalid_1's rmse: 3.79101\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60107\tvalid_1's rmse: 3.64734\n",
      "[1000]\ttraining's rmse: 3.51506\tvalid_1's rmse: 3.63058\n",
      "[1500]\ttraining's rmse: 3.45707\tvalid_1's rmse: 3.62511\n",
      "[2000]\ttraining's rmse: 3.40903\tvalid_1's rmse: 3.62374\n",
      "[2500]\ttraining's rmse: 3.36659\tvalid_1's rmse: 3.62324\n",
      "Early stopping, best iteration is:\n",
      "[2458]\ttraining's rmse: 3.36997\tvalid_1's rmse: 3.62316\n",
      "  128 | 05m27s |   -3.66529 |             0.8838 |         3.7782 |             0.1310 |             0.3416 |     14.2399 |             49.6659 |            42.5234 |            75.6164 |           0.3638 |      43.2686 |      9.4367 |       0.1479 |      0.8214 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62615\tvalid_1's rmse: 3.70964\n",
      "[1000]\ttraining's rmse: 3.58074\tvalid_1's rmse: 3.69198\n",
      "[1500]\ttraining's rmse: 3.54582\tvalid_1's rmse: 3.68687\n",
      "[2000]\ttraining's rmse: 3.51855\tvalid_1's rmse: 3.6861\n",
      "Early stopping, best iteration is:\n",
      "[2090]\ttraining's rmse: 3.5134\tvalid_1's rmse: 3.6857\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63808\tvalid_1's rmse: 3.65171\n",
      "[1000]\ttraining's rmse: 3.58725\tvalid_1's rmse: 3.63717\n",
      "[1500]\ttraining's rmse: 3.55409\tvalid_1's rmse: 3.63251\n",
      "[2000]\ttraining's rmse: 3.52516\tvalid_1's rmse: 3.62979\n",
      "[2500]\ttraining's rmse: 3.50162\tvalid_1's rmse: 3.62868\n",
      "[3000]\ttraining's rmse: 3.47725\tvalid_1's rmse: 3.62839\n",
      "Early stopping, best iteration is:\n",
      "[2970]\ttraining's rmse: 3.47909\tvalid_1's rmse: 3.62823\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64322\tvalid_1's rmse: 3.62728\n",
      "[1000]\ttraining's rmse: 3.59225\tvalid_1's rmse: 3.61118\n",
      "[1500]\ttraining's rmse: 3.55795\tvalid_1's rmse: 3.60785\n",
      "[2000]\ttraining's rmse: 3.5299\tvalid_1's rmse: 3.60588\n",
      "Early stopping, best iteration is:\n",
      "[2110]\ttraining's rmse: 3.52335\tvalid_1's rmse: 3.60573\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59768\tvalid_1's rmse: 3.8116\n",
      "[1000]\ttraining's rmse: 3.54606\tvalid_1's rmse: 3.79626\n",
      "[1500]\ttraining's rmse: 3.51295\tvalid_1's rmse: 3.79282\n",
      "[2000]\ttraining's rmse: 3.4856\tvalid_1's rmse: 3.79114\n",
      "Early stopping, best iteration is:\n",
      "[2247]\ttraining's rmse: 3.47247\tvalid_1's rmse: 3.79046\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64059\tvalid_1's rmse: 3.64336\n",
      "[1000]\ttraining's rmse: 3.5895\tvalid_1's rmse: 3.62904\n",
      "[1500]\ttraining's rmse: 3.55588\tvalid_1's rmse: 3.62525\n",
      "[2000]\ttraining's rmse: 3.52713\tvalid_1's rmse: 3.62329\n",
      "Early stopping, best iteration is:\n",
      "[1980]\ttraining's rmse: 3.52791\tvalid_1's rmse: 3.62314\n",
      "  129 | 06m34s |   -3.66727 |             0.9491 |        10.1912 |             0.1221 |             0.9452 |      6.3394 |             48.8728 |            38.5261 |            98.8997 |           0.9474 |      34.7567 |      6.7952 |       1.5773 |      0.8070 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58942\tvalid_1's rmse: 3.70685\n",
      "[1000]\ttraining's rmse: 3.52078\tvalid_1's rmse: 3.68927\n",
      "[1500]\ttraining's rmse: 3.47182\tvalid_1's rmse: 3.68497\n",
      "[2000]\ttraining's rmse: 3.42892\tvalid_1's rmse: 3.68475\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's rmse: 3.44439\tvalid_1's rmse: 3.68449\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6049\tvalid_1's rmse: 3.64864\n",
      "[1000]\ttraining's rmse: 3.534\tvalid_1's rmse: 3.63274\n",
      "[1500]\ttraining's rmse: 3.48374\tvalid_1's rmse: 3.62882\n",
      "[2000]\ttraining's rmse: 3.44243\tvalid_1's rmse: 3.6273\n",
      "Early stopping, best iteration is:\n",
      "[1916]\ttraining's rmse: 3.44969\tvalid_1's rmse: 3.62707\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60808\tvalid_1's rmse: 3.62359\n",
      "[1000]\ttraining's rmse: 3.53669\tvalid_1's rmse: 3.60919\n",
      "[1500]\ttraining's rmse: 3.48546\tvalid_1's rmse: 3.60711\n",
      "Early stopping, best iteration is:\n",
      "[1577]\ttraining's rmse: 3.47769\tvalid_1's rmse: 3.6068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56249\tvalid_1's rmse: 3.80972\n",
      "[1000]\ttraining's rmse: 3.49073\tvalid_1's rmse: 3.7943\n",
      "[1500]\ttraining's rmse: 3.44224\tvalid_1's rmse: 3.79151\n",
      "Early stopping, best iteration is:\n",
      "[1484]\ttraining's rmse: 3.443\tvalid_1's rmse: 3.79144\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60313\tvalid_1's rmse: 3.64309\n",
      "[1000]\ttraining's rmse: 3.5327\tvalid_1's rmse: 3.63079\n",
      "[1500]\ttraining's rmse: 3.48245\tvalid_1's rmse: 3.627\n",
      "Early stopping, best iteration is:\n",
      "[1600]\ttraining's rmse: 3.47438\tvalid_1's rmse: 3.62648\n",
      "  130 | 05m40s |   -3.66787 |             0.8765 |        19.9734 |             0.7592 |             0.8395 |      7.3443 |             48.8783 |            36.6976 |            29.3646 |           0.7564 |      41.6457 |      0.0235 |       9.2205 |      0.6720 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64958\tvalid_1's rmse: 3.71621\n",
      "[1000]\ttraining's rmse: 3.60928\tvalid_1's rmse: 3.69842\n",
      "[1500]\ttraining's rmse: 3.58163\tvalid_1's rmse: 3.69192\n",
      "[2000]\ttraining's rmse: 3.55818\tvalid_1's rmse: 3.68978\n",
      "[2500]\ttraining's rmse: 3.53462\tvalid_1's rmse: 3.6877\n",
      "Early stopping, best iteration is:\n",
      "[2572]\ttraining's rmse: 3.53216\tvalid_1's rmse: 3.68725\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66247\tvalid_1's rmse: 3.65823\n",
      "[1000]\ttraining's rmse: 3.61807\tvalid_1's rmse: 3.6406\n",
      "[1500]\ttraining's rmse: 3.5913\tvalid_1's rmse: 3.6345\n",
      "[2000]\ttraining's rmse: 3.56915\tvalid_1's rmse: 3.63083\n",
      "[2500]\ttraining's rmse: 3.54837\tvalid_1's rmse: 3.62926\n",
      "Early stopping, best iteration is:\n",
      "[2677]\ttraining's rmse: 3.54077\tvalid_1's rmse: 3.62888\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66715\tvalid_1's rmse: 3.63049\n",
      "[1000]\ttraining's rmse: 3.62392\tvalid_1's rmse: 3.61467\n",
      "[1500]\ttraining's rmse: 3.59548\tvalid_1's rmse: 3.60907\n",
      "[2000]\ttraining's rmse: 3.57075\tvalid_1's rmse: 3.60686\n",
      "Early stopping, best iteration is:\n",
      "[2185]\ttraining's rmse: 3.56198\tvalid_1's rmse: 3.60625\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62076\tvalid_1's rmse: 3.81829\n",
      "[1000]\ttraining's rmse: 3.57454\tvalid_1's rmse: 3.80053\n",
      "[1500]\ttraining's rmse: 3.5463\tvalid_1's rmse: 3.79637\n",
      "[2000]\ttraining's rmse: 3.52328\tvalid_1's rmse: 3.79528\n",
      "[2500]\ttraining's rmse: 3.50363\tvalid_1's rmse: 3.79404\n",
      "Early stopping, best iteration is:\n",
      "[2508]\ttraining's rmse: 3.50317\tvalid_1's rmse: 3.79394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66413\tvalid_1's rmse: 3.64919\n",
      "[1000]\ttraining's rmse: 3.61961\tvalid_1's rmse: 3.63372\n",
      "[1500]\ttraining's rmse: 3.5893\tvalid_1's rmse: 3.62837\n",
      "[2000]\ttraining's rmse: 3.56439\tvalid_1's rmse: 3.62674\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.56765\tvalid_1's rmse: 3.62665\n",
      "  131 | 05m40s |   -3.66923 |             0.8832 |        19.8485 |             0.3121 |             0.9159 |      5.1087 |              5.5584 |            30.2268 |            58.6896 |           0.7115 |      34.6987 |      0.1649 |       6.7364 |      0.1617 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003886]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62402\tvalid_1's rmse: 3.72458\n",
      "[1000]\ttraining's rmse: 3.54596\tvalid_1's rmse: 3.70008\n",
      "[1500]\ttraining's rmse: 3.4926\tvalid_1's rmse: 3.69159\n",
      "[2000]\ttraining's rmse: 3.44854\tvalid_1's rmse: 3.68787\n",
      "[2500]\ttraining's rmse: 3.40956\tvalid_1's rmse: 3.68601\n",
      "[3000]\ttraining's rmse: 3.37369\tvalid_1's rmse: 3.68493\n",
      "[3500]\ttraining's rmse: 3.33978\tvalid_1's rmse: 3.6845\n",
      "[4000]\ttraining's rmse: 3.30721\tvalid_1's rmse: 3.68444\n",
      "Early stopping, best iteration is:\n",
      "[3854]\ttraining's rmse: 3.31603\tvalid_1's rmse: 3.68403\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63702\tvalid_1's rmse: 3.66099\n",
      "[1000]\ttraining's rmse: 3.55794\tvalid_1's rmse: 3.64109\n",
      "[1500]\ttraining's rmse: 3.50416\tvalid_1's rmse: 3.63349\n",
      "[2000]\ttraining's rmse: 3.46035\tvalid_1's rmse: 3.63085\n",
      "[2500]\ttraining's rmse: 3.42106\tvalid_1's rmse: 3.62903\n",
      "[3000]\ttraining's rmse: 3.38485\tvalid_1's rmse: 3.62855\n",
      "Early stopping, best iteration is:\n",
      "[3135]\ttraining's rmse: 3.37545\tvalid_1's rmse: 3.62846\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64192\tvalid_1's rmse: 3.63775\n",
      "[1000]\ttraining's rmse: 3.5631\tvalid_1's rmse: 3.61752\n",
      "[1500]\ttraining's rmse: 3.50949\tvalid_1's rmse: 3.61115\n",
      "[2000]\ttraining's rmse: 3.46551\tvalid_1's rmse: 3.60834\n",
      "[2500]\ttraining's rmse: 3.42631\tvalid_1's rmse: 3.60686\n",
      "Early stopping, best iteration is:\n",
      "[2465]\ttraining's rmse: 3.42891\tvalid_1's rmse: 3.60676\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59437\tvalid_1's rmse: 3.8308\n",
      "[1000]\ttraining's rmse: 3.51537\tvalid_1's rmse: 3.80801\n",
      "[1500]\ttraining's rmse: 3.46295\tvalid_1's rmse: 3.80097\n",
      "[2000]\ttraining's rmse: 3.41917\tvalid_1's rmse: 3.79769\n",
      "[2500]\ttraining's rmse: 3.37994\tvalid_1's rmse: 3.79623\n",
      "[3000]\ttraining's rmse: 3.34404\tvalid_1's rmse: 3.79525\n",
      "[3500]\ttraining's rmse: 3.31005\tvalid_1's rmse: 3.79485\n",
      "Early stopping, best iteration is:\n",
      "[3464]\ttraining's rmse: 3.31238\tvalid_1's rmse: 3.79472\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63639\tvalid_1's rmse: 3.65595\n",
      "[1000]\ttraining's rmse: 3.55691\tvalid_1's rmse: 3.63725\n",
      "[1500]\ttraining's rmse: 3.50338\tvalid_1's rmse: 3.63087\n",
      "[2000]\ttraining's rmse: 3.45953\tvalid_1's rmse: 3.62738\n",
      "[2500]\ttraining's rmse: 3.41996\tvalid_1's rmse: 3.62637\n",
      "Early stopping, best iteration is:\n",
      "[2541]\ttraining's rmse: 3.41681\tvalid_1's rmse: 3.6263\n",
      "  132 | 05m06s |   -3.66869 |             0.8265 |         1.5228 |             0.6946 |             0.1908 |     14.9046 |             39.0436 |            30.7535 |            96.5747 |           0.0531 |      44.6818 |      5.4108 |       1.4644 |      0.5882 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00011778]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00350479]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6028\tvalid_1's rmse: 3.70789\n",
      "[1000]\ttraining's rmse: 3.5317\tvalid_1's rmse: 3.68853\n",
      "[1500]\ttraining's rmse: 3.48544\tvalid_1's rmse: 3.68342\n",
      "[2000]\ttraining's rmse: 3.44497\tvalid_1's rmse: 3.68181\n",
      "Early stopping, best iteration is:\n",
      "[2207]\ttraining's rmse: 3.42882\tvalid_1's rmse: 3.68117\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61565\tvalid_1's rmse: 3.65366\n",
      "[1000]\ttraining's rmse: 3.54418\tvalid_1's rmse: 3.63644\n",
      "[1500]\ttraining's rmse: 3.49658\tvalid_1's rmse: 3.63216\n",
      "[2000]\ttraining's rmse: 3.45621\tvalid_1's rmse: 3.62972\n",
      "[2500]\ttraining's rmse: 3.42101\tvalid_1's rmse: 3.62821\n",
      "Early stopping, best iteration is:\n",
      "[2516]\ttraining's rmse: 3.41985\tvalid_1's rmse: 3.62814\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6211\tvalid_1's rmse: 3.62706\n",
      "[1000]\ttraining's rmse: 3.55068\tvalid_1's rmse: 3.6097\n",
      "[1500]\ttraining's rmse: 3.50316\tvalid_1's rmse: 3.60528\n",
      "[2000]\ttraining's rmse: 3.46205\tvalid_1's rmse: 3.6051\n",
      "Early stopping, best iteration is:\n",
      "[1859]\ttraining's rmse: 3.47229\tvalid_1's rmse: 3.60459\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5778\tvalid_1's rmse: 3.81148\n",
      "[1000]\ttraining's rmse: 3.50519\tvalid_1's rmse: 3.7955\n",
      "[1500]\ttraining's rmse: 3.45808\tvalid_1's rmse: 3.79198\n",
      "Early stopping, best iteration is:\n",
      "[1615]\ttraining's rmse: 3.44889\tvalid_1's rmse: 3.79151\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61456\tvalid_1's rmse: 3.64443\n",
      "[1000]\ttraining's rmse: 3.54422\tvalid_1's rmse: 3.63075\n",
      "[1500]\ttraining's rmse: 3.49876\tvalid_1's rmse: 3.62588\n",
      "[2000]\ttraining's rmse: 3.45793\tvalid_1's rmse: 3.62392\n",
      "Early stopping, best iteration is:\n",
      "[1992]\ttraining's rmse: 3.45842\tvalid_1's rmse: 3.62391\n",
      "  133 | 06m02s |   -3.66649 |             0.8660 |        16.2398 |             0.3631 |             0.8763 |     14.3702 |             26.9133 |            30.0659 |            99.1767 |           0.8065 |      33.2032 |      3.3467 |       9.8631 |      0.1750 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58769\tvalid_1's rmse: 3.71263\n",
      "[1000]\ttraining's rmse: 3.50499\tvalid_1's rmse: 3.69255\n",
      "[1500]\ttraining's rmse: 3.44967\tvalid_1's rmse: 3.68594\n",
      "[2000]\ttraining's rmse: 3.4061\tvalid_1's rmse: 3.68317\n",
      "[2500]\ttraining's rmse: 3.36777\tvalid_1's rmse: 3.68257\n",
      "[3000]\ttraining's rmse: 3.33317\tvalid_1's rmse: 3.68212\n",
      "Early stopping, best iteration is:\n",
      "[3175]\ttraining's rmse: 3.3207\tvalid_1's rmse: 3.68158\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60165\tvalid_1's rmse: 3.65371\n",
      "[1000]\ttraining's rmse: 3.51723\tvalid_1's rmse: 3.63415\n",
      "[1500]\ttraining's rmse: 3.46167\tvalid_1's rmse: 3.62802\n",
      "[2000]\ttraining's rmse: 3.41769\tvalid_1's rmse: 3.62611\n",
      "[2500]\ttraining's rmse: 3.37724\tvalid_1's rmse: 3.6254\n",
      "Early stopping, best iteration is:\n",
      "[2436]\ttraining's rmse: 3.38204\tvalid_1's rmse: 3.62522\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60561\tvalid_1's rmse: 3.63082\n",
      "[1000]\ttraining's rmse: 3.5215\tvalid_1's rmse: 3.61195\n",
      "[1500]\ttraining's rmse: 3.46595\tvalid_1's rmse: 3.60658\n",
      "[2000]\ttraining's rmse: 3.42257\tvalid_1's rmse: 3.60551\n",
      "Early stopping, best iteration is:\n",
      "[1856]\ttraining's rmse: 3.43448\tvalid_1's rmse: 3.60533\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56128\tvalid_1's rmse: 3.81277\n",
      "[1000]\ttraining's rmse: 3.4756\tvalid_1's rmse: 3.79511\n",
      "[1500]\ttraining's rmse: 3.41897\tvalid_1's rmse: 3.79001\n",
      "[2000]\ttraining's rmse: 3.37489\tvalid_1's rmse: 3.78803\n",
      "Early stopping, best iteration is:\n",
      "[2018]\ttraining's rmse: 3.37355\tvalid_1's rmse: 3.78793\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59869\tvalid_1's rmse: 3.65113\n",
      "[1000]\ttraining's rmse: 3.51304\tvalid_1's rmse: 3.63457\n",
      "[1500]\ttraining's rmse: 3.45875\tvalid_1's rmse: 3.62903\n",
      "[2000]\ttraining's rmse: 3.41474\tvalid_1's rmse: 3.62696\n",
      "[2500]\ttraining's rmse: 3.3752\tvalid_1's rmse: 3.62691\n",
      "Early stopping, best iteration is:\n",
      "[2360]\ttraining's rmse: 3.38574\tvalid_1's rmse: 3.62649\n",
      "  134 | 05m35s |   -3.66591 |             0.9252 |        18.0733 |             0.5217 |             0.5283 |     13.2714 |             48.6526 |            44.7170 |            48.0289 |           0.6322 |      33.8074 |      4.9147 |       1.9671 |      0.9051 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00014295]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65787\tvalid_1's rmse: 3.72203\n",
      "[1000]\ttraining's rmse: 3.61545\tvalid_1's rmse: 3.69944\n",
      "[1500]\ttraining's rmse: 3.58751\tvalid_1's rmse: 3.69124\n",
      "[2000]\ttraining's rmse: 3.56395\tvalid_1's rmse: 3.68778\n",
      "[2500]\ttraining's rmse: 3.54375\tvalid_1's rmse: 3.68584\n",
      "[3000]\ttraining's rmse: 3.52445\tvalid_1's rmse: 3.68458\n",
      "[3500]\ttraining's rmse: 3.50595\tvalid_1's rmse: 3.68403\n",
      "[4000]\ttraining's rmse: 3.48794\tvalid_1's rmse: 3.68315\n",
      "[4500]\ttraining's rmse: 3.4703\tvalid_1's rmse: 3.68252\n",
      "Early stopping, best iteration is:\n",
      "[4547]\ttraining's rmse: 3.46859\tvalid_1's rmse: 3.68249\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67179\tvalid_1's rmse: 3.66148\n",
      "[1000]\ttraining's rmse: 3.62714\tvalid_1's rmse: 3.64193\n",
      "[1500]\ttraining's rmse: 3.60002\tvalid_1's rmse: 3.63513\n",
      "[2000]\ttraining's rmse: 3.57588\tvalid_1's rmse: 3.63138\n",
      "[2500]\ttraining's rmse: 3.55562\tvalid_1's rmse: 3.62926\n",
      "[3000]\ttraining's rmse: 3.53647\tvalid_1's rmse: 3.62793\n",
      "[3500]\ttraining's rmse: 3.51833\tvalid_1's rmse: 3.62717\n",
      "[4000]\ttraining's rmse: 3.50007\tvalid_1's rmse: 3.62673\n",
      "[4500]\ttraining's rmse: 3.48181\tvalid_1's rmse: 3.62638\n",
      "[5000]\ttraining's rmse: 3.46539\tvalid_1's rmse: 3.62587\n",
      "[5500]\ttraining's rmse: 3.44888\tvalid_1's rmse: 3.62565\n",
      "Early stopping, best iteration is:\n",
      "[5455]\ttraining's rmse: 3.45026\tvalid_1's rmse: 3.6256\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67737\tvalid_1's rmse: 3.63435\n",
      "[1000]\ttraining's rmse: 3.63174\tvalid_1's rmse: 3.61418\n",
      "[1500]\ttraining's rmse: 3.60395\tvalid_1's rmse: 3.6077\n",
      "[2000]\ttraining's rmse: 3.58156\tvalid_1's rmse: 3.60519\n",
      "[2500]\ttraining's rmse: 3.56102\tvalid_1's rmse: 3.60432\n",
      "[3000]\ttraining's rmse: 3.54133\tvalid_1's rmse: 3.60381\n",
      "[3500]\ttraining's rmse: 3.52169\tvalid_1's rmse: 3.60376\n",
      "Early stopping, best iteration is:\n",
      "[3366]\ttraining's rmse: 3.52669\tvalid_1's rmse: 3.60355\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62999\tvalid_1's rmse: 3.8266\n",
      "[1000]\ttraining's rmse: 3.58497\tvalid_1's rmse: 3.80691\n",
      "[1500]\ttraining's rmse: 3.55724\tvalid_1's rmse: 3.80067\n",
      "[2000]\ttraining's rmse: 3.53467\tvalid_1's rmse: 3.79744\n",
      "[2500]\ttraining's rmse: 3.51399\tvalid_1's rmse: 3.79588\n",
      "[3000]\ttraining's rmse: 3.49432\tvalid_1's rmse: 3.79484\n",
      "[3500]\ttraining's rmse: 3.47517\tvalid_1's rmse: 3.79414\n",
      "[4000]\ttraining's rmse: 3.45695\tvalid_1's rmse: 3.79358\n",
      "Early stopping, best iteration is:\n",
      "[4269]\ttraining's rmse: 3.44728\tvalid_1's rmse: 3.79317\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67212\tvalid_1's rmse: 3.6527\n",
      "[1000]\ttraining's rmse: 3.6258\tvalid_1's rmse: 3.63333\n",
      "[1500]\ttraining's rmse: 3.59702\tvalid_1's rmse: 3.62663\n",
      "[2000]\ttraining's rmse: 3.574\tvalid_1's rmse: 3.62341\n",
      "[2500]\ttraining's rmse: 3.55281\tvalid_1's rmse: 3.62231\n",
      "[3000]\ttraining's rmse: 3.53302\tvalid_1's rmse: 3.62199\n",
      "Early stopping, best iteration is:\n",
      "[2840]\ttraining's rmse: 3.53905\tvalid_1's rmse: 3.62193\n",
      "  135 | 05m38s |   -3.66600 |             0.9166 |         1.0523 |             0.5148 |             0.3768 |      5.1017 |              5.0422 |            43.1611 |            10.8615 |           0.0035 |      44.4052 |      6.8874 |       9.2227 |      0.4195 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00013053]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54304\tvalid_1's rmse: 3.70857\n",
      "[1000]\ttraining's rmse: 3.44158\tvalid_1's rmse: 3.68966\n",
      "[1500]\ttraining's rmse: 3.3715\tvalid_1's rmse: 3.68402\n",
      "[2000]\ttraining's rmse: 3.31704\tvalid_1's rmse: 3.68249\n",
      "[2500]\ttraining's rmse: 3.2702\tvalid_1's rmse: 3.68205\n",
      "Early stopping, best iteration is:\n",
      "[2676]\ttraining's rmse: 3.25439\tvalid_1's rmse: 3.68189\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55526\tvalid_1's rmse: 3.65177\n",
      "[1000]\ttraining's rmse: 3.452\tvalid_1's rmse: 3.63539\n",
      "[1500]\ttraining's rmse: 3.3834\tvalid_1's rmse: 3.63049\n",
      "[2000]\ttraining's rmse: 3.32954\tvalid_1's rmse: 3.62883\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's rmse: 3.31395\tvalid_1's rmse: 3.6285\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55939\tvalid_1's rmse: 3.62786\n",
      "[1000]\ttraining's rmse: 3.4558\tvalid_1's rmse: 3.61228\n",
      "[1500]\ttraining's rmse: 3.38595\tvalid_1's rmse: 3.60889\n",
      "Early stopping, best iteration is:\n",
      "[1538]\ttraining's rmse: 3.38146\tvalid_1's rmse: 3.60872\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.51487\tvalid_1's rmse: 3.80591\n",
      "[1000]\ttraining's rmse: 3.4102\tvalid_1's rmse: 3.79125\n",
      "[1500]\ttraining's rmse: 3.3395\tvalid_1's rmse: 3.78778\n",
      "[2000]\ttraining's rmse: 3.28585\tvalid_1's rmse: 3.78669\n",
      "Early stopping, best iteration is:\n",
      "[1919]\ttraining's rmse: 3.29313\tvalid_1's rmse: 3.78652\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5524\tvalid_1's rmse: 3.64873\n",
      "[1000]\ttraining's rmse: 3.44944\tvalid_1's rmse: 3.63384\n",
      "[1500]\ttraining's rmse: 3.37991\tvalid_1's rmse: 3.63004\n",
      "Early stopping, best iteration is:\n",
      "[1688]\ttraining's rmse: 3.35886\tvalid_1's rmse: 3.62961\n",
      "  136 | 06m31s |   -3.66761 |             0.9626 |         5.0026 |             0.4730 |             0.7210 |     14.8587 |              5.1388 |            39.1550 |            10.5577 |           0.9761 |      42.5230 |      5.1818 |       0.2338 |      0.9177 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58721\tvalid_1's rmse: 3.70689\n",
      "[1000]\ttraining's rmse: 3.50928\tvalid_1's rmse: 3.68789\n",
      "[1500]\ttraining's rmse: 3.45622\tvalid_1's rmse: 3.68245\n",
      "[2000]\ttraining's rmse: 3.41465\tvalid_1's rmse: 3.68107\n",
      "[2500]\ttraining's rmse: 3.37801\tvalid_1's rmse: 3.6808\n",
      "[3000]\ttraining's rmse: 3.34432\tvalid_1's rmse: 3.68055\n",
      "Early stopping, best iteration is:\n",
      "[2883]\ttraining's rmse: 3.35177\tvalid_1's rmse: 3.68029\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59937\tvalid_1's rmse: 3.65038\n",
      "[1000]\ttraining's rmse: 3.52093\tvalid_1's rmse: 3.63403\n",
      "[1500]\ttraining's rmse: 3.46838\tvalid_1's rmse: 3.6305\n",
      "[2000]\ttraining's rmse: 3.42647\tvalid_1's rmse: 3.62976\n",
      "Early stopping, best iteration is:\n",
      "[2268]\ttraining's rmse: 3.40593\tvalid_1's rmse: 3.62913\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60556\tvalid_1's rmse: 3.62537\n",
      "[1000]\ttraining's rmse: 3.52783\tvalid_1's rmse: 3.60916\n",
      "[1500]\ttraining's rmse: 3.47418\tvalid_1's rmse: 3.60507\n",
      "Early stopping, best iteration is:\n",
      "[1795]\ttraining's rmse: 3.44851\tvalid_1's rmse: 3.60426\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56065\tvalid_1's rmse: 3.80868\n",
      "[1000]\ttraining's rmse: 3.48049\tvalid_1's rmse: 3.79381\n",
      "[1500]\ttraining's rmse: 3.42901\tvalid_1's rmse: 3.79034\n",
      "[2000]\ttraining's rmse: 3.38768\tvalid_1's rmse: 3.78945\n",
      "Early stopping, best iteration is:\n",
      "[2112]\ttraining's rmse: 3.37873\tvalid_1's rmse: 3.78929\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59969\tvalid_1's rmse: 3.64591\n",
      "[1000]\ttraining's rmse: 3.51995\tvalid_1's rmse: 3.6309\n",
      "[1500]\ttraining's rmse: 3.46812\tvalid_1's rmse: 3.62636\n",
      "[2000]\ttraining's rmse: 3.42625\tvalid_1's rmse: 3.62529\n",
      "Early stopping, best iteration is:\n",
      "[2052]\ttraining's rmse: 3.4221\tvalid_1's rmse: 3.62503\n",
      "  137 | 06m34s |   -3.66621 |             0.9777 |         1.3934 |             0.1142 |             0.8692 |     14.8359 |             13.1600 |            44.9664 |            99.3637 |           0.4309 |      38.6293 |      5.6195 |       8.2532 |      0.6026 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68657\tvalid_1's rmse: 3.74414\n",
      "[1000]\ttraining's rmse: 3.6391\tvalid_1's rmse: 3.71445\n",
      "[1500]\ttraining's rmse: 3.60983\tvalid_1's rmse: 3.70191\n",
      "[2000]\ttraining's rmse: 3.58857\tvalid_1's rmse: 3.696\n",
      "[2500]\ttraining's rmse: 3.56941\tvalid_1's rmse: 3.69213\n",
      "[3000]\ttraining's rmse: 3.55187\tvalid_1's rmse: 3.69006\n",
      "[3500]\ttraining's rmse: 3.53506\tvalid_1's rmse: 3.68884\n",
      "[4000]\ttraining's rmse: 3.51976\tvalid_1's rmse: 3.68765\n",
      "[4500]\ttraining's rmse: 3.50467\tvalid_1's rmse: 3.68682\n",
      "Early stopping, best iteration is:\n",
      "[4523]\ttraining's rmse: 3.50403\tvalid_1's rmse: 3.68679\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70072\tvalid_1's rmse: 3.67905\n",
      "[1000]\ttraining's rmse: 3.65102\tvalid_1's rmse: 3.65358\n",
      "[1500]\ttraining's rmse: 3.6215\tvalid_1's rmse: 3.64289\n",
      "[2000]\ttraining's rmse: 3.59914\tvalid_1's rmse: 3.63729\n",
      "[2500]\ttraining's rmse: 3.57996\tvalid_1's rmse: 3.63355\n",
      "[3000]\ttraining's rmse: 3.56278\tvalid_1's rmse: 3.63128\n",
      "[3500]\ttraining's rmse: 3.5464\tvalid_1's rmse: 3.62958\n",
      "[4000]\ttraining's rmse: 3.53075\tvalid_1's rmse: 3.62856\n",
      "[4500]\ttraining's rmse: 3.5155\tvalid_1's rmse: 3.62764\n",
      "[5000]\ttraining's rmse: 3.50105\tvalid_1's rmse: 3.62718\n",
      "[5500]\ttraining's rmse: 3.48661\tvalid_1's rmse: 3.62655\n",
      "[6000]\ttraining's rmse: 3.47209\tvalid_1's rmse: 3.62623\n",
      "[6500]\ttraining's rmse: 3.45818\tvalid_1's rmse: 3.62572\n",
      "[7000]\ttraining's rmse: 3.44455\tvalid_1's rmse: 3.6254\n",
      "[7500]\ttraining's rmse: 3.43125\tvalid_1's rmse: 3.62529\n",
      "Early stopping, best iteration is:\n",
      "[7440]\ttraining's rmse: 3.4328\tvalid_1's rmse: 3.62524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70668\tvalid_1's rmse: 3.65386\n",
      "[1000]\ttraining's rmse: 3.65703\tvalid_1's rmse: 3.62786\n",
      "[1500]\ttraining's rmse: 3.62735\tvalid_1's rmse: 3.6173\n",
      "[2000]\ttraining's rmse: 3.60522\tvalid_1's rmse: 3.6123\n",
      "[2500]\ttraining's rmse: 3.58573\tvalid_1's rmse: 3.60981\n",
      "[3000]\ttraining's rmse: 3.56834\tvalid_1's rmse: 3.60797\n",
      "[3500]\ttraining's rmse: 3.55222\tvalid_1's rmse: 3.60724\n",
      "[4000]\ttraining's rmse: 3.53655\tvalid_1's rmse: 3.60674\n",
      "Early stopping, best iteration is:\n",
      "[3897]\ttraining's rmse: 3.53973\tvalid_1's rmse: 3.60665\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65841\tvalid_1's rmse: 3.85118\n",
      "[1000]\ttraining's rmse: 3.60963\tvalid_1's rmse: 3.82335\n",
      "[1500]\ttraining's rmse: 3.58038\tvalid_1's rmse: 3.81211\n",
      "[2000]\ttraining's rmse: 3.55853\tvalid_1's rmse: 3.80692\n",
      "[2500]\ttraining's rmse: 3.53916\tvalid_1's rmse: 3.80358\n",
      "[3000]\ttraining's rmse: 3.5219\tvalid_1's rmse: 3.8019\n",
      "[3500]\ttraining's rmse: 3.5056\tvalid_1's rmse: 3.80027\n",
      "[4000]\ttraining's rmse: 3.4901\tvalid_1's rmse: 3.79936\n",
      "[4500]\ttraining's rmse: 3.47492\tvalid_1's rmse: 3.7987\n",
      "[5000]\ttraining's rmse: 3.46028\tvalid_1's rmse: 3.79805\n",
      "[5500]\ttraining's rmse: 3.44586\tvalid_1's rmse: 3.7978\n",
      "[6000]\ttraining's rmse: 3.43209\tvalid_1's rmse: 3.79751\n",
      "[6500]\ttraining's rmse: 3.41801\tvalid_1's rmse: 3.79718\n",
      "Early stopping, best iteration is:\n",
      "[6335]\ttraining's rmse: 3.42281\tvalid_1's rmse: 3.79704\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.7015\tvalid_1's rmse: 3.6718\n",
      "[1000]\ttraining's rmse: 3.65166\tvalid_1's rmse: 3.64712\n",
      "[1500]\ttraining's rmse: 3.62176\tvalid_1's rmse: 3.63697\n",
      "[2000]\ttraining's rmse: 3.59941\tvalid_1's rmse: 3.63215\n",
      "[2500]\ttraining's rmse: 3.58056\tvalid_1's rmse: 3.62952\n",
      "[3000]\ttraining's rmse: 3.56284\tvalid_1's rmse: 3.62802\n",
      "[3500]\ttraining's rmse: 3.54635\tvalid_1's rmse: 3.62713\n",
      "[4000]\ttraining's rmse: 3.53062\tvalid_1's rmse: 3.6269\n",
      "[4500]\ttraining's rmse: 3.51561\tvalid_1's rmse: 3.6266\n",
      "Early stopping, best iteration is:\n",
      "[4355]\ttraining's rmse: 3.51964\tvalid_1's rmse: 3.62643\n",
      "  138 | 06m43s |   -3.66909 |             0.9110 |         2.7970 |             0.2857 |             0.1518 |      5.1572 |             49.1720 |            44.0103 |            10.2603 |           0.8746 |      44.4915 |      6.2835 |       9.4179 |      0.3086 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60177\tvalid_1's rmse: 3.7163\n",
      "[1000]\ttraining's rmse: 3.51842\tvalid_1's rmse: 3.69455\n",
      "[1500]\ttraining's rmse: 3.46104\tvalid_1's rmse: 3.68662\n",
      "[2000]\ttraining's rmse: 3.41708\tvalid_1's rmse: 3.68351\n",
      "[2500]\ttraining's rmse: 3.38036\tvalid_1's rmse: 3.6824\n",
      "Early stopping, best iteration is:\n",
      "[2626]\ttraining's rmse: 3.37168\tvalid_1's rmse: 3.68226\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61561\tvalid_1's rmse: 3.65718\n",
      "[1000]\ttraining's rmse: 3.5308\tvalid_1's rmse: 3.63688\n",
      "[1500]\ttraining's rmse: 3.4737\tvalid_1's rmse: 3.63044\n",
      "[2000]\ttraining's rmse: 3.43043\tvalid_1's rmse: 3.62703\n",
      "[2500]\ttraining's rmse: 3.39311\tvalid_1's rmse: 3.62562\n",
      "[3000]\ttraining's rmse: 3.35933\tvalid_1's rmse: 3.62497\n",
      "Early stopping, best iteration is:\n",
      "[2951]\ttraining's rmse: 3.36234\tvalid_1's rmse: 3.62491\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61905\tvalid_1's rmse: 3.63363\n",
      "[1000]\ttraining's rmse: 3.53449\tvalid_1's rmse: 3.61377\n",
      "[1500]\ttraining's rmse: 3.47865\tvalid_1's rmse: 3.60789\n",
      "[2000]\ttraining's rmse: 3.43435\tvalid_1's rmse: 3.60519\n",
      "[2500]\ttraining's rmse: 3.39778\tvalid_1's rmse: 3.60398\n",
      "[3000]\ttraining's rmse: 3.36424\tvalid_1's rmse: 3.60394\n",
      "Early stopping, best iteration is:\n",
      "[2838]\ttraining's rmse: 3.37449\tvalid_1's rmse: 3.60366\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57483\tvalid_1's rmse: 3.81822\n",
      "[1000]\ttraining's rmse: 3.48914\tvalid_1's rmse: 3.79898\n",
      "[1500]\ttraining's rmse: 3.43197\tvalid_1's rmse: 3.79183\n",
      "[2000]\ttraining's rmse: 3.38645\tvalid_1's rmse: 3.78882\n",
      "[2500]\ttraining's rmse: 3.35052\tvalid_1's rmse: 3.78757\n",
      "Early stopping, best iteration is:\n",
      "[2698]\ttraining's rmse: 3.33756\tvalid_1's rmse: 3.78719\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61381\tvalid_1's rmse: 3.65283\n",
      "[1000]\ttraining's rmse: 3.52844\tvalid_1's rmse: 3.63499\n",
      "[1500]\ttraining's rmse: 3.47202\tvalid_1's rmse: 3.62871\n",
      "[2000]\ttraining's rmse: 3.42741\tvalid_1's rmse: 3.62615\n",
      "[2500]\ttraining's rmse: 3.39015\tvalid_1's rmse: 3.62525\n",
      "Early stopping, best iteration is:\n",
      "[2622]\ttraining's rmse: 3.3821\tvalid_1's rmse: 3.62514\n",
      "  139 | 05m31s |   -3.66524 |             0.9193 |         0.2993 |             0.1614 |             0.4426 |     14.7515 |             19.4977 |            30.1928 |            10.4531 |           0.4347 |      31.8237 |      0.2407 |       9.7961 |      0.5251 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62858\tvalid_1's rmse: 3.71737\n",
      "[1000]\ttraining's rmse: 3.56367\tvalid_1's rmse: 3.6941\n",
      "[1500]\ttraining's rmse: 3.52125\tvalid_1's rmse: 3.68701\n",
      "[2000]\ttraining's rmse: 3.48479\tvalid_1's rmse: 3.68355\n",
      "[2500]\ttraining's rmse: 3.45297\tvalid_1's rmse: 3.68255\n",
      "[3000]\ttraining's rmse: 3.42238\tvalid_1's rmse: 3.68184\n",
      "Early stopping, best iteration is:\n",
      "[3235]\ttraining's rmse: 3.40895\tvalid_1's rmse: 3.68154\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6423\tvalid_1's rmse: 3.65706\n",
      "[1000]\ttraining's rmse: 3.57672\tvalid_1's rmse: 3.63678\n",
      "[1500]\ttraining's rmse: 3.53299\tvalid_1's rmse: 3.62965\n",
      "[2000]\ttraining's rmse: 3.49585\tvalid_1's rmse: 3.6258\n",
      "[2500]\ttraining's rmse: 3.46329\tvalid_1's rmse: 3.62421\n",
      "[3000]\ttraining's rmse: 3.43263\tvalid_1's rmse: 3.62365\n",
      "Early stopping, best iteration is:\n",
      "[3174]\ttraining's rmse: 3.4221\tvalid_1's rmse: 3.62321\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64684\tvalid_1's rmse: 3.6332\n",
      "[1000]\ttraining's rmse: 3.58106\tvalid_1's rmse: 3.61306\n",
      "[1500]\ttraining's rmse: 3.53769\tvalid_1's rmse: 3.6071\n",
      "[2000]\ttraining's rmse: 3.50121\tvalid_1's rmse: 3.60533\n",
      "[2500]\ttraining's rmse: 3.46844\tvalid_1's rmse: 3.60422\n",
      "[3000]\ttraining's rmse: 3.43739\tvalid_1's rmse: 3.60379\n",
      "Early stopping, best iteration is:\n",
      "[2963]\ttraining's rmse: 3.43955\tvalid_1's rmse: 3.6037\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60019\tvalid_1's rmse: 3.822\n",
      "[1000]\ttraining's rmse: 3.53452\tvalid_1's rmse: 3.80245\n",
      "[1500]\ttraining's rmse: 3.49099\tvalid_1's rmse: 3.796\n",
      "[2000]\ttraining's rmse: 3.45494\tvalid_1's rmse: 3.79416\n",
      "[2500]\ttraining's rmse: 3.42237\tvalid_1's rmse: 3.79298\n",
      "[3000]\ttraining's rmse: 3.39181\tvalid_1's rmse: 3.79243\n",
      "Early stopping, best iteration is:\n",
      "[3033]\ttraining's rmse: 3.3898\tvalid_1's rmse: 3.79238\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64301\tvalid_1's rmse: 3.65108\n",
      "[1000]\ttraining's rmse: 3.57691\tvalid_1's rmse: 3.63266\n",
      "[1500]\ttraining's rmse: 3.53373\tvalid_1's rmse: 3.62705\n",
      "[2000]\ttraining's rmse: 3.49729\tvalid_1's rmse: 3.62417\n",
      "[2500]\ttraining's rmse: 3.46489\tvalid_1's rmse: 3.62352\n",
      "Early stopping, best iteration is:\n",
      "[2390]\ttraining's rmse: 3.47179\tvalid_1's rmse: 3.62341\n",
      "  140 | 05m16s |   -3.66550 |             0.7687 |         1.7723 |             0.3116 |             0.3319 |     12.6854 |             49.8971 |            41.8543 |            99.5815 |           0.2710 |      32.3310 |      6.6210 |       9.5415 |      0.8062 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64687\tvalid_1's rmse: 3.71641\n",
      "[1000]\ttraining's rmse: 3.60361\tvalid_1's rmse: 3.6967\n",
      "[1500]\ttraining's rmse: 3.57252\tvalid_1's rmse: 3.68928\n",
      "[2000]\ttraining's rmse: 3.54612\tvalid_1's rmse: 3.6865\n",
      "[2500]\ttraining's rmse: 3.52094\tvalid_1's rmse: 3.68492\n",
      "[3000]\ttraining's rmse: 3.50028\tvalid_1's rmse: 3.68431\n",
      "Early stopping, best iteration is:\n",
      "[3139]\ttraining's rmse: 3.49365\tvalid_1's rmse: 3.68401\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66194\tvalid_1's rmse: 3.65914\n",
      "[1000]\ttraining's rmse: 3.61449\tvalid_1's rmse: 3.64017\n",
      "[1500]\ttraining's rmse: 3.5858\tvalid_1's rmse: 3.63453\n",
      "[2000]\ttraining's rmse: 3.55873\tvalid_1's rmse: 3.6304\n",
      "[2500]\ttraining's rmse: 3.53484\tvalid_1's rmse: 3.62876\n",
      "[3000]\ttraining's rmse: 3.51221\tvalid_1's rmse: 3.62759\n",
      "[3500]\ttraining's rmse: 3.49117\tvalid_1's rmse: 3.62724\n",
      "Early stopping, best iteration is:\n",
      "[3372]\ttraining's rmse: 3.49669\tvalid_1's rmse: 3.62712\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66768\tvalid_1's rmse: 3.62921\n",
      "[1000]\ttraining's rmse: 3.6202\tvalid_1's rmse: 3.61105\n",
      "[1500]\ttraining's rmse: 3.59094\tvalid_1's rmse: 3.60729\n",
      "[2000]\ttraining's rmse: 3.56483\tvalid_1's rmse: 3.60515\n",
      "[2500]\ttraining's rmse: 3.54015\tvalid_1's rmse: 3.60402\n",
      "Early stopping, best iteration is:\n",
      "[2639]\ttraining's rmse: 3.53344\tvalid_1's rmse: 3.60371\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62038\tvalid_1's rmse: 3.82112\n",
      "[1000]\ttraining's rmse: 3.57279\tvalid_1's rmse: 3.80286\n",
      "[1500]\ttraining's rmse: 3.54321\tvalid_1's rmse: 3.79785\n",
      "[2000]\ttraining's rmse: 3.51581\tvalid_1's rmse: 3.79554\n",
      "[2500]\ttraining's rmse: 3.49297\tvalid_1's rmse: 3.79489\n",
      "[3000]\ttraining's rmse: 3.47042\tvalid_1's rmse: 3.79375\n",
      "Early stopping, best iteration is:\n",
      "[3210]\ttraining's rmse: 3.46057\tvalid_1's rmse: 3.79331\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66169\tvalid_1's rmse: 3.64949\n",
      "[1000]\ttraining's rmse: 3.61358\tvalid_1's rmse: 3.63253\n",
      "[1500]\ttraining's rmse: 3.58146\tvalid_1's rmse: 3.62706\n",
      "[2000]\ttraining's rmse: 3.55582\tvalid_1's rmse: 3.62561\n",
      "[2500]\ttraining's rmse: 3.53027\tvalid_1's rmse: 3.62439\n",
      "Early stopping, best iteration is:\n",
      "[2571]\ttraining's rmse: 3.52755\tvalid_1's rmse: 3.6242\n",
      "  141 | 05m45s |   -3.66712 |             0.8319 |        19.0389 |             0.9228 |             0.5516 |      5.8028 |              6.2361 |            31.0307 |            11.8065 |           0.9467 |      43.1914 |      7.6748 |       1.7606 |      0.2043 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66374\tvalid_1's rmse: 3.73398\n",
      "[1000]\ttraining's rmse: 3.60739\tvalid_1's rmse: 3.70567\n",
      "[1500]\ttraining's rmse: 3.57274\tvalid_1's rmse: 3.69468\n",
      "[2000]\ttraining's rmse: 3.54552\tvalid_1's rmse: 3.68988\n",
      "[2500]\ttraining's rmse: 3.52026\tvalid_1's rmse: 3.68748\n",
      "[3000]\ttraining's rmse: 3.49653\tvalid_1's rmse: 3.68582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500]\ttraining's rmse: 3.47538\tvalid_1's rmse: 3.68496\n",
      "[4000]\ttraining's rmse: 3.45639\tvalid_1's rmse: 3.68458\n",
      "Early stopping, best iteration is:\n",
      "[4254]\ttraining's rmse: 3.44623\tvalid_1's rmse: 3.68421\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67758\tvalid_1's rmse: 3.67176\n",
      "[1000]\ttraining's rmse: 3.61883\tvalid_1's rmse: 3.6472\n",
      "[1500]\ttraining's rmse: 3.58351\tvalid_1's rmse: 3.63772\n",
      "[2000]\ttraining's rmse: 3.55521\tvalid_1's rmse: 3.63316\n",
      "[2500]\ttraining's rmse: 3.53028\tvalid_1's rmse: 3.63034\n",
      "[3000]\ttraining's rmse: 3.50783\tvalid_1's rmse: 3.62854\n",
      "[3500]\ttraining's rmse: 3.48604\tvalid_1's rmse: 3.62748\n",
      "[4000]\ttraining's rmse: 3.46601\tvalid_1's rmse: 3.62668\n",
      "[4500]\ttraining's rmse: 3.44593\tvalid_1's rmse: 3.62574\n",
      "Early stopping, best iteration is:\n",
      "[4789]\ttraining's rmse: 3.43473\tvalid_1's rmse: 3.62528\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68329\tvalid_1's rmse: 3.64591\n",
      "[1000]\ttraining's rmse: 3.6252\tvalid_1's rmse: 3.62215\n",
      "[1500]\ttraining's rmse: 3.58953\tvalid_1's rmse: 3.61357\n",
      "[2000]\ttraining's rmse: 3.56144\tvalid_1's rmse: 3.60928\n",
      "[2500]\ttraining's rmse: 3.53744\tvalid_1's rmse: 3.60775\n",
      "[3000]\ttraining's rmse: 3.51396\tvalid_1's rmse: 3.60663\n",
      "[3500]\ttraining's rmse: 3.49238\tvalid_1's rmse: 3.60636\n",
      "Early stopping, best iteration is:\n",
      "[3428]\ttraining's rmse: 3.49518\tvalid_1's rmse: 3.6062\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63494\tvalid_1's rmse: 3.84212\n",
      "[1000]\ttraining's rmse: 3.57646\tvalid_1's rmse: 3.81615\n",
      "[1500]\ttraining's rmse: 3.54162\tvalid_1's rmse: 3.80692\n",
      "[2000]\ttraining's rmse: 3.51326\tvalid_1's rmse: 3.80208\n",
      "[2500]\ttraining's rmse: 3.48877\tvalid_1's rmse: 3.79974\n",
      "[3000]\ttraining's rmse: 3.46571\tvalid_1's rmse: 3.79851\n",
      "[3500]\ttraining's rmse: 3.44437\tvalid_1's rmse: 3.79759\n",
      "[4000]\ttraining's rmse: 3.42452\tvalid_1's rmse: 3.79708\n",
      "[4500]\ttraining's rmse: 3.4043\tvalid_1's rmse: 3.79665\n",
      "Early stopping, best iteration is:\n",
      "[4405]\ttraining's rmse: 3.40785\tvalid_1's rmse: 3.79654\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67784\tvalid_1's rmse: 3.66449\n",
      "[1000]\ttraining's rmse: 3.61843\tvalid_1's rmse: 3.64141\n",
      "[1500]\ttraining's rmse: 3.5821\tvalid_1's rmse: 3.63299\n",
      "[2000]\ttraining's rmse: 3.55398\tvalid_1's rmse: 3.62927\n",
      "[2500]\ttraining's rmse: 3.52913\tvalid_1's rmse: 3.62758\n",
      "[3000]\ttraining's rmse: 3.50612\tvalid_1's rmse: 3.62642\n",
      "Early stopping, best iteration is:\n",
      "[2919]\ttraining's rmse: 3.50985\tvalid_1's rmse: 3.62639\n",
      "  142 | 05m59s |   -3.66838 |             0.9853 |        19.9670 |             0.9210 |             0.1700 |      6.7698 |             49.6760 |            41.5005 |            11.5374 |           0.7082 |      32.7153 |      1.1549 |       9.0019 |      0.2179 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59976\tvalid_1's rmse: 3.71769\n",
      "[1000]\ttraining's rmse: 3.51941\tvalid_1's rmse: 3.69646\n",
      "[1500]\ttraining's rmse: 3.46477\tvalid_1's rmse: 3.68981\n",
      "[2000]\ttraining's rmse: 3.42074\tvalid_1's rmse: 3.68701\n",
      "[2500]\ttraining's rmse: 3.37928\tvalid_1's rmse: 3.68622\n",
      "Early stopping, best iteration is:\n",
      "[2726]\ttraining's rmse: 3.36238\tvalid_1's rmse: 3.68566\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61206\tvalid_1's rmse: 3.66015\n",
      "[1000]\ttraining's rmse: 3.5309\tvalid_1's rmse: 3.64024\n",
      "[1500]\ttraining's rmse: 3.47684\tvalid_1's rmse: 3.63382\n",
      "[2000]\ttraining's rmse: 3.43137\tvalid_1's rmse: 3.63098\n",
      "[2500]\ttraining's rmse: 3.39038\tvalid_1's rmse: 3.62926\n",
      "Early stopping, best iteration is:\n",
      "[2691]\ttraining's rmse: 3.37584\tvalid_1's rmse: 3.62885\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61612\tvalid_1's rmse: 3.63451\n",
      "[1000]\ttraining's rmse: 3.53583\tvalid_1's rmse: 3.61551\n",
      "[1500]\ttraining's rmse: 3.48208\tvalid_1's rmse: 3.61003\n",
      "[2000]\ttraining's rmse: 3.43578\tvalid_1's rmse: 3.60841\n",
      "Early stopping, best iteration is:\n",
      "[2176]\ttraining's rmse: 3.42123\tvalid_1's rmse: 3.60796\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57075\tvalid_1's rmse: 3.81671\n",
      "[1000]\ttraining's rmse: 3.48934\tvalid_1's rmse: 3.79921\n",
      "[1500]\ttraining's rmse: 3.4343\tvalid_1's rmse: 3.79307\n",
      "[2000]\ttraining's rmse: 3.38962\tvalid_1's rmse: 3.79088\n",
      "[2500]\ttraining's rmse: 3.34866\tvalid_1's rmse: 3.78942\n",
      "[3000]\ttraining's rmse: 3.30869\tvalid_1's rmse: 3.78759\n",
      "Early stopping, best iteration is:\n",
      "[3122]\ttraining's rmse: 3.29983\tvalid_1's rmse: 3.7875\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61089\tvalid_1's rmse: 3.65197\n",
      "[1000]\ttraining's rmse: 3.52969\tvalid_1's rmse: 3.63347\n",
      "[1500]\ttraining's rmse: 3.47668\tvalid_1's rmse: 3.62811\n",
      "[2000]\ttraining's rmse: 3.43141\tvalid_1's rmse: 3.62561\n",
      "[2500]\ttraining's rmse: 3.38997\tvalid_1's rmse: 3.62451\n",
      "Early stopping, best iteration is:\n",
      "[2371]\ttraining's rmse: 3.39987\tvalid_1's rmse: 3.62425\n",
      "  143 | 05m16s |   -3.66743 |             0.7006 |        17.9821 |             0.5872 |             0.4483 |     11.1128 |              5.1994 |            31.2485 |            10.5212 |           0.5498 |      30.1699 |      2.7701 |       0.3886 |      0.8758 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59644\tvalid_1's rmse: 3.71614\n",
      "[1000]\ttraining's rmse: 3.51784\tvalid_1's rmse: 3.69553\n",
      "[1500]\ttraining's rmse: 3.46282\tvalid_1's rmse: 3.6894\n",
      "[2000]\ttraining's rmse: 3.41737\tvalid_1's rmse: 3.68653\n",
      "Early stopping, best iteration is:\n",
      "[2044]\ttraining's rmse: 3.41314\tvalid_1's rmse: 3.68593\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61122\tvalid_1's rmse: 3.65486\n",
      "[1000]\ttraining's rmse: 3.52999\tvalid_1's rmse: 3.63705\n",
      "[1500]\ttraining's rmse: 3.4757\tvalid_1's rmse: 3.63131\n",
      "[2000]\ttraining's rmse: 3.42823\tvalid_1's rmse: 3.62915\n",
      "Early stopping, best iteration is:\n",
      "[2274]\ttraining's rmse: 3.40525\tvalid_1's rmse: 3.62779\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6173\tvalid_1's rmse: 3.63173\n",
      "[1000]\ttraining's rmse: 3.53595\tvalid_1's rmse: 3.61267\n",
      "[1500]\ttraining's rmse: 3.48053\tvalid_1's rmse: 3.60806\n",
      "[2000]\ttraining's rmse: 3.43332\tvalid_1's rmse: 3.60698\n",
      "Early stopping, best iteration is:\n",
      "[2226]\ttraining's rmse: 3.41429\tvalid_1's rmse: 3.60639\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57056\tvalid_1's rmse: 3.81707\n",
      "[1000]\ttraining's rmse: 3.48731\tvalid_1's rmse: 3.79898\n",
      "[1500]\ttraining's rmse: 3.43219\tvalid_1's rmse: 3.79513\n",
      "[2000]\ttraining's rmse: 3.38729\tvalid_1's rmse: 3.79243\n",
      "Early stopping, best iteration is:\n",
      "[2228]\ttraining's rmse: 3.3669\tvalid_1's rmse: 3.79185\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60859\tvalid_1's rmse: 3.65228\n",
      "[1000]\ttraining's rmse: 3.52678\tvalid_1's rmse: 3.63706\n",
      "[1500]\ttraining's rmse: 3.47115\tvalid_1's rmse: 3.6319\n",
      "[2000]\ttraining's rmse: 3.42438\tvalid_1's rmse: 3.63033\n",
      "Early stopping, best iteration is:\n",
      "[2007]\ttraining's rmse: 3.42369\tvalid_1's rmse: 3.63031\n",
      "  144 | 05m59s |   -3.66907 |             0.6651 |         6.0649 |             0.7460 |             0.8822 |     13.8259 |             49.9441 |            35.9464 |            10.0529 |           0.7452 |      30.8567 |      5.6625 |       9.6039 |      0.2804 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65122\tvalid_1's rmse: 3.71806\n",
      "[1000]\ttraining's rmse: 3.61004\tvalid_1's rmse: 3.69712\n",
      "[1500]\ttraining's rmse: 3.58178\tvalid_1's rmse: 3.68971\n",
      "[2000]\ttraining's rmse: 3.55853\tvalid_1's rmse: 3.6865\n",
      "[2500]\ttraining's rmse: 3.53818\tvalid_1's rmse: 3.68486\n",
      "[3000]\ttraining's rmse: 3.51913\tvalid_1's rmse: 3.68383\n",
      "[3500]\ttraining's rmse: 3.5007\tvalid_1's rmse: 3.68358\n",
      "Early stopping, best iteration is:\n",
      "[3769]\ttraining's rmse: 3.49122\tvalid_1's rmse: 3.68344\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66508\tvalid_1's rmse: 3.659\n",
      "[1000]\ttraining's rmse: 3.62036\tvalid_1's rmse: 3.64039\n",
      "[1500]\ttraining's rmse: 3.59379\tvalid_1's rmse: 3.63445\n",
      "[2000]\ttraining's rmse: 3.57046\tvalid_1's rmse: 3.63158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\ttraining's rmse: 3.54854\tvalid_1's rmse: 3.63021\n",
      "[3000]\ttraining's rmse: 3.52834\tvalid_1's rmse: 3.6289\n",
      "[3500]\ttraining's rmse: 3.50964\tvalid_1's rmse: 3.62787\n",
      "[4000]\ttraining's rmse: 3.49118\tvalid_1's rmse: 3.62733\n",
      "[4500]\ttraining's rmse: 3.47363\tvalid_1's rmse: 3.62706\n",
      "[5000]\ttraining's rmse: 3.45698\tvalid_1's rmse: 3.62703\n",
      "Early stopping, best iteration is:\n",
      "[4808]\ttraining's rmse: 3.46334\tvalid_1's rmse: 3.6269\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67081\tvalid_1's rmse: 3.63045\n",
      "[1000]\ttraining's rmse: 3.62606\tvalid_1's rmse: 3.61173\n",
      "[1500]\ttraining's rmse: 3.60005\tvalid_1's rmse: 3.60699\n",
      "[2000]\ttraining's rmse: 3.57836\tvalid_1's rmse: 3.60499\n",
      "[2500]\ttraining's rmse: 3.55726\tvalid_1's rmse: 3.60422\n",
      "[3000]\ttraining's rmse: 3.53667\tvalid_1's rmse: 3.60401\n",
      "Early stopping, best iteration is:\n",
      "[2807]\ttraining's rmse: 3.54414\tvalid_1's rmse: 3.60393\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62242\tvalid_1's rmse: 3.82367\n",
      "[1000]\ttraining's rmse: 3.57639\tvalid_1's rmse: 3.80586\n",
      "[1500]\ttraining's rmse: 3.54863\tvalid_1's rmse: 3.80035\n",
      "[2000]\ttraining's rmse: 3.52668\tvalid_1's rmse: 3.79858\n",
      "[2500]\ttraining's rmse: 3.50602\tvalid_1's rmse: 3.79723\n",
      "[3000]\ttraining's rmse: 3.48763\tvalid_1's rmse: 3.79675\n",
      "[3500]\ttraining's rmse: 3.4689\tvalid_1's rmse: 3.79598\n",
      "[4000]\ttraining's rmse: 3.45165\tvalid_1's rmse: 3.79558\n",
      "Early stopping, best iteration is:\n",
      "[4227]\ttraining's rmse: 3.44366\tvalid_1's rmse: 3.79544\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66557\tvalid_1's rmse: 3.65\n",
      "[1000]\ttraining's rmse: 3.61883\tvalid_1's rmse: 3.63198\n",
      "[1500]\ttraining's rmse: 3.59071\tvalid_1's rmse: 3.62583\n",
      "[2000]\ttraining's rmse: 3.5686\tvalid_1's rmse: 3.62401\n",
      "[2500]\ttraining's rmse: 3.5476\tvalid_1's rmse: 3.62364\n",
      "Early stopping, best iteration is:\n",
      "[2432]\ttraining's rmse: 3.55046\tvalid_1's rmse: 3.62358\n",
      "  145 | 05m48s |   -3.66732 |             0.9481 |         0.5325 |             0.6984 |             0.4952 |      5.0055 |             24.9529 |            31.2587 |            15.9949 |           0.8456 |      37.9690 |      0.0249 |       8.7013 |      0.9164 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61833\tvalid_1's rmse: 3.71101\n",
      "[1000]\ttraining's rmse: 3.55717\tvalid_1's rmse: 3.68922\n",
      "[1500]\ttraining's rmse: 3.51544\tvalid_1's rmse: 3.6829\n",
      "[2000]\ttraining's rmse: 3.48013\tvalid_1's rmse: 3.68073\n",
      "[2500]\ttraining's rmse: 3.44841\tvalid_1's rmse: 3.67964\n",
      "[3000]\ttraining's rmse: 3.41977\tvalid_1's rmse: 3.67905\n",
      "Early stopping, best iteration is:\n",
      "[2881]\ttraining's rmse: 3.42625\tvalid_1's rmse: 3.67887\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63145\tvalid_1's rmse: 3.65238\n",
      "[1000]\ttraining's rmse: 3.56807\tvalid_1's rmse: 3.63354\n",
      "[1500]\ttraining's rmse: 3.52628\tvalid_1's rmse: 3.62806\n",
      "[2000]\ttraining's rmse: 3.49019\tvalid_1's rmse: 3.62565\n",
      "[2500]\ttraining's rmse: 3.45838\tvalid_1's rmse: 3.6244\n",
      "[3000]\ttraining's rmse: 3.42921\tvalid_1's rmse: 3.6238\n",
      "[3500]\ttraining's rmse: 3.40153\tvalid_1's rmse: 3.6233\n",
      "[4000]\ttraining's rmse: 3.37525\tvalid_1's rmse: 3.62325\n",
      "Early stopping, best iteration is:\n",
      "[3800]\ttraining's rmse: 3.38614\tvalid_1's rmse: 3.62314\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6357\tvalid_1's rmse: 3.62806\n",
      "[1000]\ttraining's rmse: 3.57249\tvalid_1's rmse: 3.60952\n",
      "[1500]\ttraining's rmse: 3.53044\tvalid_1's rmse: 3.60464\n",
      "[2000]\ttraining's rmse: 3.49485\tvalid_1's rmse: 3.60326\n",
      "Early stopping, best iteration is:\n",
      "[1941]\ttraining's rmse: 3.49871\tvalid_1's rmse: 3.60318\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59039\tvalid_1's rmse: 3.81544\n",
      "[1000]\ttraining's rmse: 3.52635\tvalid_1's rmse: 3.79745\n",
      "[1500]\ttraining's rmse: 3.48474\tvalid_1's rmse: 3.79228\n",
      "[2000]\ttraining's rmse: 3.44947\tvalid_1's rmse: 3.79029\n",
      "[2500]\ttraining's rmse: 3.41782\tvalid_1's rmse: 3.78933\n",
      "[3000]\ttraining's rmse: 3.38878\tvalid_1's rmse: 3.78885\n",
      "Early stopping, best iteration is:\n",
      "[3137]\ttraining's rmse: 3.38104\tvalid_1's rmse: 3.78863\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63128\tvalid_1's rmse: 3.64646\n",
      "[1000]\ttraining's rmse: 3.56704\tvalid_1's rmse: 3.62892\n",
      "[1500]\ttraining's rmse: 3.52554\tvalid_1's rmse: 3.62308\n",
      "[2000]\ttraining's rmse: 3.49137\tvalid_1's rmse: 3.62102\n",
      "Early stopping, best iteration is:\n",
      "[2287]\ttraining's rmse: 3.4733\tvalid_1's rmse: 3.62045\n",
      "  146 | 06m40s | \u001b[35m  -3.66348\u001b[0m | \u001b[32m            0.9079\u001b[0m | \u001b[32m        2.8461\u001b[0m | \u001b[32m            0.9488\u001b[0m | \u001b[32m            0.4400\u001b[0m | \u001b[32m     9.7723\u001b[0m | \u001b[32m             6.4956\u001b[0m | \u001b[32m           32.7641\u001b[0m | \u001b[32m           99.5720\u001b[0m | \u001b[32m          0.1308\u001b[0m | \u001b[32m     33.7567\u001b[0m | \u001b[32m     4.2712\u001b[0m | \u001b[32m      9.9681\u001b[0m | \u001b[32m     0.9249\u001b[0m | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59046\tvalid_1's rmse: 3.71353\n",
      "[1000]\ttraining's rmse: 3.50692\tvalid_1's rmse: 3.69346\n",
      "[1500]\ttraining's rmse: 3.45043\tvalid_1's rmse: 3.68626\n",
      "[2000]\ttraining's rmse: 3.40781\tvalid_1's rmse: 3.68365\n",
      "[2500]\ttraining's rmse: 3.37122\tvalid_1's rmse: 3.68295\n",
      "Early stopping, best iteration is:\n",
      "[2409]\ttraining's rmse: 3.37753\tvalid_1's rmse: 3.68286\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60387\tvalid_1's rmse: 3.65406\n",
      "[1000]\ttraining's rmse: 3.51853\tvalid_1's rmse: 3.63576\n",
      "[1500]\ttraining's rmse: 3.46262\tvalid_1's rmse: 3.63007\n",
      "[2000]\ttraining's rmse: 3.4191\tvalid_1's rmse: 3.62825\n",
      "[2500]\ttraining's rmse: 3.38222\tvalid_1's rmse: 3.62758\n",
      "[3000]\ttraining's rmse: 3.34853\tvalid_1's rmse: 3.62732\n",
      "Early stopping, best iteration is:\n",
      "[3189]\ttraining's rmse: 3.33594\tvalid_1's rmse: 3.62725\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60796\tvalid_1's rmse: 3.62994\n",
      "[1000]\ttraining's rmse: 3.52338\tvalid_1's rmse: 3.61266\n",
      "[1500]\ttraining's rmse: 3.46646\tvalid_1's rmse: 3.60779\n",
      "[2000]\ttraining's rmse: 3.42233\tvalid_1's rmse: 3.60595\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's rmse: 3.40535\tvalid_1's rmse: 3.60565\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56404\tvalid_1's rmse: 3.81409\n",
      "[1000]\ttraining's rmse: 3.47703\tvalid_1's rmse: 3.79615\n",
      "[1500]\ttraining's rmse: 3.41976\tvalid_1's rmse: 3.79074\n",
      "[2000]\ttraining's rmse: 3.37709\tvalid_1's rmse: 3.78909\n",
      "[2500]\ttraining's rmse: 3.34248\tvalid_1's rmse: 3.78852\n",
      "Early stopping, best iteration is:\n",
      "[2513]\ttraining's rmse: 3.34178\tvalid_1's rmse: 3.78851\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60131\tvalid_1's rmse: 3.65042\n",
      "[1000]\ttraining's rmse: 3.51595\tvalid_1's rmse: 3.63375\n",
      "[1500]\ttraining's rmse: 3.46038\tvalid_1's rmse: 3.62852\n",
      "[2000]\ttraining's rmse: 3.41673\tvalid_1's rmse: 3.62645\n",
      "Early stopping, best iteration is:\n",
      "[2178]\ttraining's rmse: 3.40335\tvalid_1's rmse: 3.62608\n",
      "  147 | 06m01s |   -3.66667 |             0.9502 |         0.6670 |             0.9650 |             0.6245 |     14.4800 |             46.3810 |            44.2817 |            33.1290 |           0.9512 |      33.9407 |      2.9014 |       9.9157 |      0.9494 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59094\tvalid_1's rmse: 3.71169\n",
      "[1000]\ttraining's rmse: 3.51079\tvalid_1's rmse: 3.69167\n",
      "[1500]\ttraining's rmse: 3.45734\tvalid_1's rmse: 3.68523\n",
      "[2000]\ttraining's rmse: 3.41339\tvalid_1's rmse: 3.68334\n",
      "Early stopping, best iteration is:\n",
      "[2073]\ttraining's rmse: 3.40733\tvalid_1's rmse: 3.68324\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60344\tvalid_1's rmse: 3.65214\n",
      "[1000]\ttraining's rmse: 3.52212\tvalid_1's rmse: 3.63446\n",
      "[1500]\ttraining's rmse: 3.46812\tvalid_1's rmse: 3.62833\n",
      "[2000]\ttraining's rmse: 3.42443\tvalid_1's rmse: 3.6263\n",
      "[2500]\ttraining's rmse: 3.38554\tvalid_1's rmse: 3.6251\n",
      "Early stopping, best iteration is:\n",
      "[2465]\ttraining's rmse: 3.38803\tvalid_1's rmse: 3.62505\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60854\tvalid_1's rmse: 3.62885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.52692\tvalid_1's rmse: 3.61146\n",
      "[1500]\ttraining's rmse: 3.47334\tvalid_1's rmse: 3.60654\n",
      "[2000]\ttraining's rmse: 3.43038\tvalid_1's rmse: 3.60505\n",
      "Early stopping, best iteration is:\n",
      "[2125]\ttraining's rmse: 3.42076\tvalid_1's rmse: 3.60494\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56356\tvalid_1's rmse: 3.81023\n",
      "[1000]\ttraining's rmse: 3.48017\tvalid_1's rmse: 3.79336\n",
      "[1500]\ttraining's rmse: 3.42608\tvalid_1's rmse: 3.78851\n",
      "[2000]\ttraining's rmse: 3.38307\tvalid_1's rmse: 3.78669\n",
      "[2500]\ttraining's rmse: 3.34548\tvalid_1's rmse: 3.78597\n",
      "[3000]\ttraining's rmse: 3.31108\tvalid_1's rmse: 3.78589\n",
      "Early stopping, best iteration is:\n",
      "[2934]\ttraining's rmse: 3.31515\tvalid_1's rmse: 3.78569\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60156\tvalid_1's rmse: 3.64948\n",
      "[1000]\ttraining's rmse: 3.51922\tvalid_1's rmse: 3.63366\n",
      "[1500]\ttraining's rmse: 3.46521\tvalid_1's rmse: 3.62782\n",
      "[2000]\ttraining's rmse: 3.42294\tvalid_1's rmse: 3.62611\n",
      "[2500]\ttraining's rmse: 3.38556\tvalid_1's rmse: 3.6258\n",
      "Early stopping, best iteration is:\n",
      "[2529]\ttraining's rmse: 3.38334\tvalid_1's rmse: 3.62566\n",
      "  148 | 07m01s |   -3.66551 |             0.9435 |         2.4861 |             0.6540 |             0.7352 |     14.5581 |             25.2729 |            31.0923 |            58.5126 |           0.9508 |      33.2849 |      9.5099 |       8.3002 |      0.9942 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00524822]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62825\tvalid_1's rmse: 3.70827\n",
      "[1000]\ttraining's rmse: 3.58037\tvalid_1's rmse: 3.68975\n",
      "[1500]\ttraining's rmse: 3.54763\tvalid_1's rmse: 3.68375\n",
      "[2000]\ttraining's rmse: 3.51902\tvalid_1's rmse: 3.68187\n",
      "[2500]\ttraining's rmse: 3.49303\tvalid_1's rmse: 3.6808\n",
      "Early stopping, best iteration is:\n",
      "[2461]\ttraining's rmse: 3.49453\tvalid_1's rmse: 3.68062\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64195\tvalid_1's rmse: 3.65092\n",
      "[1000]\ttraining's rmse: 3.59028\tvalid_1's rmse: 3.63402\n",
      "[1500]\ttraining's rmse: 3.5585\tvalid_1's rmse: 3.62823\n",
      "[2000]\ttraining's rmse: 3.52923\tvalid_1's rmse: 3.62473\n",
      "[2500]\ttraining's rmse: 3.5033\tvalid_1's rmse: 3.6235\n",
      "Early stopping, best iteration is:\n",
      "[2694]\ttraining's rmse: 3.494\tvalid_1's rmse: 3.62294\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64547\tvalid_1's rmse: 3.62349\n",
      "[1000]\ttraining's rmse: 3.59332\tvalid_1's rmse: 3.60725\n",
      "[1500]\ttraining's rmse: 3.55932\tvalid_1's rmse: 3.60376\n",
      "[2000]\ttraining's rmse: 3.53128\tvalid_1's rmse: 3.60254\n",
      "Early stopping, best iteration is:\n",
      "[2127]\ttraining's rmse: 3.52454\tvalid_1's rmse: 3.60231\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59972\tvalid_1's rmse: 3.81458\n",
      "[1000]\ttraining's rmse: 3.54815\tvalid_1's rmse: 3.79777\n",
      "[1500]\ttraining's rmse: 3.51531\tvalid_1's rmse: 3.79338\n",
      "[2000]\ttraining's rmse: 3.48507\tvalid_1's rmse: 3.79134\n",
      "[2500]\ttraining's rmse: 3.45865\tvalid_1's rmse: 3.79065\n",
      "Early stopping, best iteration is:\n",
      "[2583]\ttraining's rmse: 3.45458\tvalid_1's rmse: 3.79035\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64129\tvalid_1's rmse: 3.64158\n",
      "[1000]\ttraining's rmse: 3.58945\tvalid_1's rmse: 3.62627\n",
      "[1500]\ttraining's rmse: 3.55505\tvalid_1's rmse: 3.62141\n",
      "[2000]\ttraining's rmse: 3.52644\tvalid_1's rmse: 3.62103\n",
      "Early stopping, best iteration is:\n",
      "[1822]\ttraining's rmse: 3.53585\tvalid_1's rmse: 3.62079\n",
      "  149 | 05m50s |   -3.66405 |             0.8232 |        19.5833 |             0.2718 |             0.4804 |      6.1835 |              7.1559 |            30.9110 |            97.8158 |           0.7632 |      44.3750 |      6.7441 |       1.5847 |      0.8542 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00029624]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59595\tvalid_1's rmse: 3.71052\n",
      "[1000]\ttraining's rmse: 3.5221\tvalid_1's rmse: 3.69119\n",
      "[1500]\ttraining's rmse: 3.47166\tvalid_1's rmse: 3.68425\n",
      "[2000]\ttraining's rmse: 3.43131\tvalid_1's rmse: 3.68266\n",
      "[2500]\ttraining's rmse: 3.39137\tvalid_1's rmse: 3.68224\n",
      "Early stopping, best iteration is:\n",
      "[2414]\ttraining's rmse: 3.39874\tvalid_1's rmse: 3.6818\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60786\tvalid_1's rmse: 3.65416\n",
      "[1000]\ttraining's rmse: 3.53168\tvalid_1's rmse: 3.63651\n",
      "[1500]\ttraining's rmse: 3.4819\tvalid_1's rmse: 3.63125\n",
      "[2000]\ttraining's rmse: 3.44143\tvalid_1's rmse: 3.62995\n",
      "Early stopping, best iteration is:\n",
      "[1861]\ttraining's rmse: 3.45259\tvalid_1's rmse: 3.62955\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61391\tvalid_1's rmse: 3.6297\n",
      "[1000]\ttraining's rmse: 3.53924\tvalid_1's rmse: 3.6133\n",
      "[1500]\ttraining's rmse: 3.48714\tvalid_1's rmse: 3.60923\n",
      "Early stopping, best iteration is:\n",
      "[1422]\ttraining's rmse: 3.49468\tvalid_1's rmse: 3.60907\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56906\tvalid_1's rmse: 3.81053\n",
      "[1000]\ttraining's rmse: 3.49071\tvalid_1's rmse: 3.79613\n",
      "[1500]\ttraining's rmse: 3.44053\tvalid_1's rmse: 3.79234\n",
      "Early stopping, best iteration is:\n",
      "[1483]\ttraining's rmse: 3.44231\tvalid_1's rmse: 3.79215\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60849\tvalid_1's rmse: 3.64879\n",
      "[1000]\ttraining's rmse: 3.53298\tvalid_1's rmse: 3.63316\n",
      "[1500]\ttraining's rmse: 3.48215\tvalid_1's rmse: 3.62795\n",
      "[2000]\ttraining's rmse: 3.4393\tvalid_1's rmse: 3.62572\n",
      "Early stopping, best iteration is:\n",
      "[1975]\ttraining's rmse: 3.44118\tvalid_1's rmse: 3.62547\n",
      "  150 | 05m51s |   -3.66822 |             0.8072 |        19.9099 |             0.2156 |             0.8599 |     13.6208 |              6.7550 |            30.1478 |            62.6255 |           0.3856 |      30.3729 |      2.8600 |       0.4361 |      0.6273 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64627\tvalid_1's rmse: 3.71586\n",
      "[1000]\ttraining's rmse: 3.60302\tvalid_1's rmse: 3.69566\n",
      "[1500]\ttraining's rmse: 3.57191\tvalid_1's rmse: 3.68862\n",
      "[2000]\ttraining's rmse: 3.54643\tvalid_1's rmse: 3.68587\n",
      "Early stopping, best iteration is:\n",
      "[2073]\ttraining's rmse: 3.54312\tvalid_1's rmse: 3.68565\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66035\tvalid_1's rmse: 3.65734\n",
      "[1000]\ttraining's rmse: 3.61408\tvalid_1's rmse: 3.63936\n",
      "[1500]\ttraining's rmse: 3.58476\tvalid_1's rmse: 3.6334\n",
      "[2000]\ttraining's rmse: 3.5597\tvalid_1's rmse: 3.63052\n",
      "[2500]\ttraining's rmse: 3.53563\tvalid_1's rmse: 3.6299\n",
      "[3000]\ttraining's rmse: 3.5136\tvalid_1's rmse: 3.62898\n",
      "Early stopping, best iteration is:\n",
      "[2935]\ttraining's rmse: 3.51641\tvalid_1's rmse: 3.62883\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66658\tvalid_1's rmse: 3.63003\n",
      "[1000]\ttraining's rmse: 3.61972\tvalid_1's rmse: 3.61298\n",
      "[1500]\ttraining's rmse: 3.59081\tvalid_1's rmse: 3.60901\n",
      "[2000]\ttraining's rmse: 3.56634\tvalid_1's rmse: 3.60724\n",
      "[2500]\ttraining's rmse: 3.54175\tvalid_1's rmse: 3.60698\n",
      "Early stopping, best iteration is:\n",
      "[2402]\ttraining's rmse: 3.54677\tvalid_1's rmse: 3.60673\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6177\tvalid_1's rmse: 3.81942\n",
      "[1000]\ttraining's rmse: 3.5712\tvalid_1's rmse: 3.80309\n",
      "[1500]\ttraining's rmse: 3.54313\tvalid_1's rmse: 3.7986\n",
      "[2000]\ttraining's rmse: 3.51794\tvalid_1's rmse: 3.79663\n",
      "[2500]\ttraining's rmse: 3.49484\tvalid_1's rmse: 3.79549\n",
      "[3000]\ttraining's rmse: 3.47494\tvalid_1's rmse: 3.79503\n",
      "Early stopping, best iteration is:\n",
      "[3245]\ttraining's rmse: 3.46474\tvalid_1's rmse: 3.79438\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66021\tvalid_1's rmse: 3.64864\n",
      "[1000]\ttraining's rmse: 3.61235\tvalid_1's rmse: 3.63179\n",
      "[1500]\ttraining's rmse: 3.5811\tvalid_1's rmse: 3.62587\n",
      "[2000]\ttraining's rmse: 3.55644\tvalid_1's rmse: 3.62386\n",
      "Early stopping, best iteration is:\n",
      "[2295]\ttraining's rmse: 3.54248\tvalid_1's rmse: 3.62308\n",
      "  151 | 06m03s |   -3.66838 |             0.9881 |        18.7841 |             0.4870 |             0.5987 |      5.4882 |              6.2362 |            30.1554 |            23.1854 |           0.1865 |      30.8667 |      2.9205 |       0.5394 |      0.1001 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59263\tvalid_1's rmse: 3.71469\n",
      "[1000]\ttraining's rmse: 3.50939\tvalid_1's rmse: 3.69374\n",
      "[1500]\ttraining's rmse: 3.45399\tvalid_1's rmse: 3.68683\n",
      "[2000]\ttraining's rmse: 3.4091\tvalid_1's rmse: 3.68378\n",
      "[2500]\ttraining's rmse: 3.37074\tvalid_1's rmse: 3.68355\n",
      "[3000]\ttraining's rmse: 3.33553\tvalid_1's rmse: 3.68283\n",
      "Early stopping, best iteration is:\n",
      "[3096]\ttraining's rmse: 3.32813\tvalid_1's rmse: 3.68253\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60594\tvalid_1's rmse: 3.65423\n",
      "[1000]\ttraining's rmse: 3.52156\tvalid_1's rmse: 3.63509\n",
      "[1500]\ttraining's rmse: 3.46639\tvalid_1's rmse: 3.62837\n",
      "[2000]\ttraining's rmse: 3.42136\tvalid_1's rmse: 3.62603\n",
      "[2500]\ttraining's rmse: 3.3813\tvalid_1's rmse: 3.62464\n",
      "Early stopping, best iteration is:\n",
      "[2682]\ttraining's rmse: 3.368\tvalid_1's rmse: 3.62411\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61023\tvalid_1's rmse: 3.63045\n",
      "[1000]\ttraining's rmse: 3.5257\tvalid_1's rmse: 3.61231\n",
      "[1500]\ttraining's rmse: 3.47002\tvalid_1's rmse: 3.6067\n",
      "[2000]\ttraining's rmse: 3.42623\tvalid_1's rmse: 3.60515\n",
      "Early stopping, best iteration is:\n",
      "[2227]\ttraining's rmse: 3.40681\tvalid_1's rmse: 3.60459\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56592\tvalid_1's rmse: 3.8148\n",
      "[1000]\ttraining's rmse: 3.47962\tvalid_1's rmse: 3.79661\n",
      "[1500]\ttraining's rmse: 3.42274\tvalid_1's rmse: 3.79088\n",
      "[2000]\ttraining's rmse: 3.37739\tvalid_1's rmse: 3.78907\n",
      "[2500]\ttraining's rmse: 3.33828\tvalid_1's rmse: 3.78853\n",
      "Early stopping, best iteration is:\n",
      "[2329]\ttraining's rmse: 3.35107\tvalid_1's rmse: 3.78851\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60317\tvalid_1's rmse: 3.65103\n",
      "[1000]\ttraining's rmse: 3.51704\tvalid_1's rmse: 3.63418\n",
      "[1500]\ttraining's rmse: 3.46143\tvalid_1's rmse: 3.62824\n",
      "[2000]\ttraining's rmse: 3.41743\tvalid_1's rmse: 3.62635\n",
      "[2500]\ttraining's rmse: 3.37793\tvalid_1's rmse: 3.62598\n",
      "Early stopping, best iteration is:\n",
      "[2361]\ttraining's rmse: 3.38821\tvalid_1's rmse: 3.62565\n",
      "  152 | 06m16s |   -3.66569 |             0.9235 |        18.8098 |             0.6515 |             0.5220 |     13.9400 |              5.8109 |            37.5577 |            43.9420 |           0.2123 |      33.0218 |      1.0899 |       6.8107 |      0.7512 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64657\tvalid_1's rmse: 3.71389\n",
      "[1000]\ttraining's rmse: 3.6042\tvalid_1's rmse: 3.69578\n",
      "[1500]\ttraining's rmse: 3.57172\tvalid_1's rmse: 3.69109\n",
      "Early stopping, best iteration is:\n",
      "[1710]\ttraining's rmse: 3.55933\tvalid_1's rmse: 3.68855\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66077\tvalid_1's rmse: 3.65816\n",
      "[1000]\ttraining's rmse: 3.61598\tvalid_1's rmse: 3.6409\n",
      "[1500]\ttraining's rmse: 3.58526\tvalid_1's rmse: 3.63448\n",
      "[2000]\ttraining's rmse: 3.56007\tvalid_1's rmse: 3.63156\n",
      "Early stopping, best iteration is:\n",
      "[1945]\ttraining's rmse: 3.56254\tvalid_1's rmse: 3.63115\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66211\tvalid_1's rmse: 3.6284\n",
      "[1000]\ttraining's rmse: 3.61529\tvalid_1's rmse: 3.61167\n",
      "[1500]\ttraining's rmse: 3.58575\tvalid_1's rmse: 3.60816\n",
      "Early stopping, best iteration is:\n",
      "[1552]\ttraining's rmse: 3.5828\tvalid_1's rmse: 3.60754\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61735\tvalid_1's rmse: 3.81926\n",
      "[1000]\ttraining's rmse: 3.56983\tvalid_1's rmse: 3.80416\n",
      "[1500]\ttraining's rmse: 3.53711\tvalid_1's rmse: 3.79947\n",
      "[2000]\ttraining's rmse: 3.51158\tvalid_1's rmse: 3.79767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2148]\ttraining's rmse: 3.50312\tvalid_1's rmse: 3.79753\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65885\tvalid_1's rmse: 3.65096\n",
      "[1000]\ttraining's rmse: 3.61158\tvalid_1's rmse: 3.6368\n",
      "[1500]\ttraining's rmse: 3.58081\tvalid_1's rmse: 3.63315\n",
      "[2000]\ttraining's rmse: 3.55357\tvalid_1's rmse: 3.6316\n",
      "[2500]\ttraining's rmse: 3.53256\tvalid_1's rmse: 3.63023\n",
      "Early stopping, best iteration is:\n",
      "[2318]\ttraining's rmse: 3.53873\tvalid_1's rmse: 3.62965\n",
      "  153 | 05m35s |   -3.67153 |             0.7013 |        19.9590 |             0.4656 |             0.9136 |      5.5915 |              5.0371 |            31.1464 |            10.3115 |           0.1547 |      41.7395 |      0.2426 |       3.2189 |      0.7978 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00077663]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58291\tvalid_1's rmse: 3.71645\n",
      "[1000]\ttraining's rmse: 3.49416\tvalid_1's rmse: 3.69706\n",
      "[1500]\ttraining's rmse: 3.4322\tvalid_1's rmse: 3.68956\n",
      "[2000]\ttraining's rmse: 3.386\tvalid_1's rmse: 3.68799\n",
      "Early stopping, best iteration is:\n",
      "[2253]\ttraining's rmse: 3.36456\tvalid_1's rmse: 3.68725\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59655\tvalid_1's rmse: 3.65528\n",
      "[1000]\ttraining's rmse: 3.50535\tvalid_1's rmse: 3.63858\n",
      "[1500]\ttraining's rmse: 3.44477\tvalid_1's rmse: 3.63289\n",
      "[2000]\ttraining's rmse: 3.3981\tvalid_1's rmse: 3.6313\n",
      "[2500]\ttraining's rmse: 3.35769\tvalid_1's rmse: 3.63027\n",
      "[3000]\ttraining's rmse: 3.32146\tvalid_1's rmse: 3.63002\n",
      "Early stopping, best iteration is:\n",
      "[2866]\ttraining's rmse: 3.33073\tvalid_1's rmse: 3.62998\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60084\tvalid_1's rmse: 3.63185\n",
      "[1000]\ttraining's rmse: 3.50965\tvalid_1's rmse: 3.61463\n",
      "[1500]\ttraining's rmse: 3.4483\tvalid_1's rmse: 3.60944\n",
      "[2000]\ttraining's rmse: 3.40132\tvalid_1's rmse: 3.60768\n",
      "[2500]\ttraining's rmse: 3.36121\tvalid_1's rmse: 3.60718\n",
      "Early stopping, best iteration is:\n",
      "[2393]\ttraining's rmse: 3.36925\tvalid_1's rmse: 3.60707\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55745\tvalid_1's rmse: 3.81409\n",
      "[1000]\ttraining's rmse: 3.46496\tvalid_1's rmse: 3.79736\n",
      "[1500]\ttraining's rmse: 3.40202\tvalid_1's rmse: 3.79202\n",
      "[2000]\ttraining's rmse: 3.35476\tvalid_1's rmse: 3.78988\n",
      "[2500]\ttraining's rmse: 3.31768\tvalid_1's rmse: 3.78962\n",
      "Early stopping, best iteration is:\n",
      "[2361]\ttraining's rmse: 3.32723\tvalid_1's rmse: 3.78931\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59437\tvalid_1's rmse: 3.65353\n",
      "[1000]\ttraining's rmse: 3.50242\tvalid_1's rmse: 3.63827\n",
      "[1500]\ttraining's rmse: 3.43979\tvalid_1's rmse: 3.63315\n",
      "[2000]\ttraining's rmse: 3.39392\tvalid_1's rmse: 3.632\n",
      "[2500]\ttraining's rmse: 3.35476\tvalid_1's rmse: 3.63126\n",
      "Early stopping, best iteration is:\n",
      "[2480]\ttraining's rmse: 3.3563\tvalid_1's rmse: 3.63122\n",
      "  154 | 06m42s |   -3.66955 |             0.8210 |         0.3319 |             0.9734 |             0.8174 |     14.5555 |              8.6029 |            30.7604 |            14.4915 |           0.6529 |      32.0816 |      9.6043 |       8.7646 |      0.3963 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00340193]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65956\tvalid_1's rmse: 3.73534\n",
      "[1000]\ttraining's rmse: 3.59637\tvalid_1's rmse: 3.70743\n",
      "[1500]\ttraining's rmse: 3.55534\tvalid_1's rmse: 3.69678\n",
      "[2000]\ttraining's rmse: 3.52219\tvalid_1's rmse: 3.69128\n",
      "[2500]\ttraining's rmse: 3.49301\tvalid_1's rmse: 3.68888\n",
      "[3000]\ttraining's rmse: 3.46675\tvalid_1's rmse: 3.68723\n",
      "[3500]\ttraining's rmse: 3.44205\tvalid_1's rmse: 3.68578\n",
      "[4000]\ttraining's rmse: 3.41893\tvalid_1's rmse: 3.68513\n",
      "Early stopping, best iteration is:\n",
      "[4182]\ttraining's rmse: 3.41071\tvalid_1's rmse: 3.68496\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67392\tvalid_1's rmse: 3.67253\n",
      "[1000]\ttraining's rmse: 3.60859\tvalid_1's rmse: 3.64821\n",
      "[1500]\ttraining's rmse: 3.56635\tvalid_1's rmse: 3.63897\n",
      "[2000]\ttraining's rmse: 3.53316\tvalid_1's rmse: 3.63386\n",
      "[2500]\ttraining's rmse: 3.50448\tvalid_1's rmse: 3.63117\n",
      "[3000]\ttraining's rmse: 3.47773\tvalid_1's rmse: 3.62946\n",
      "[3500]\ttraining's rmse: 3.45271\tvalid_1's rmse: 3.62888\n",
      "[4000]\ttraining's rmse: 3.42939\tvalid_1's rmse: 3.62836\n",
      "Early stopping, best iteration is:\n",
      "[3921]\ttraining's rmse: 3.43303\tvalid_1's rmse: 3.62815\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67808\tvalid_1's rmse: 3.64767\n",
      "[1000]\ttraining's rmse: 3.61333\tvalid_1's rmse: 3.6243\n",
      "[1500]\ttraining's rmse: 3.572\tvalid_1's rmse: 3.61539\n",
      "[2000]\ttraining's rmse: 3.53875\tvalid_1's rmse: 3.61144\n",
      "[2500]\ttraining's rmse: 3.51009\tvalid_1's rmse: 3.60933\n",
      "[3000]\ttraining's rmse: 3.48303\tvalid_1's rmse: 3.60829\n",
      "[3500]\ttraining's rmse: 3.45817\tvalid_1's rmse: 3.60778\n",
      "[4000]\ttraining's rmse: 3.43464\tvalid_1's rmse: 3.60736\n",
      "Early stopping, best iteration is:\n",
      "[4044]\ttraining's rmse: 3.43258\tvalid_1's rmse: 3.60731\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63095\tvalid_1's rmse: 3.84282\n",
      "[1000]\ttraining's rmse: 3.56651\tvalid_1's rmse: 3.81686\n",
      "[1500]\ttraining's rmse: 3.52506\tvalid_1's rmse: 3.80766\n",
      "[2000]\ttraining's rmse: 3.49196\tvalid_1's rmse: 3.80312\n",
      "[2500]\ttraining's rmse: 3.46345\tvalid_1's rmse: 3.80089\n",
      "[3000]\ttraining's rmse: 3.43657\tvalid_1's rmse: 3.79973\n",
      "[3500]\ttraining's rmse: 3.41208\tvalid_1's rmse: 3.79849\n",
      "Early stopping, best iteration is:\n",
      "[3456]\ttraining's rmse: 3.41418\tvalid_1's rmse: 3.79843\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67328\tvalid_1's rmse: 3.66712\n",
      "[1000]\ttraining's rmse: 3.6084\tvalid_1's rmse: 3.6452\n",
      "[1500]\ttraining's rmse: 3.56639\tvalid_1's rmse: 3.63685\n",
      "[2000]\ttraining's rmse: 3.53306\tvalid_1's rmse: 3.63246\n",
      "[2500]\ttraining's rmse: 3.50407\tvalid_1's rmse: 3.62995\n",
      "[3000]\ttraining's rmse: 3.47729\tvalid_1's rmse: 3.62862\n",
      "[3500]\ttraining's rmse: 3.45283\tvalid_1's rmse: 3.62796\n",
      "Early stopping, best iteration is:\n",
      "[3587]\ttraining's rmse: 3.44876\tvalid_1's rmse: 3.62773\n",
      "  155 | 05m43s |   -3.66997 |             0.8285 |         1.2027 |             0.2626 |             0.1570 |     12.9289 |              5.3476 |            43.3856 |            99.6474 |           0.2469 |      30.6683 |      7.9112 |       4.0828 |      0.9300 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57662\tvalid_1's rmse: 3.70563\n",
      "[1000]\ttraining's rmse: 3.49545\tvalid_1's rmse: 3.68731\n",
      "[1500]\ttraining's rmse: 3.43967\tvalid_1's rmse: 3.68225\n",
      "[2000]\ttraining's rmse: 3.39603\tvalid_1's rmse: 3.68043\n",
      "[2500]\ttraining's rmse: 3.35788\tvalid_1's rmse: 3.68002\n",
      "Early stopping, best iteration is:\n",
      "[2472]\ttraining's rmse: 3.35973\tvalid_1's rmse: 3.67991\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58837\tvalid_1's rmse: 3.65062\n",
      "[1000]\ttraining's rmse: 3.50556\tvalid_1's rmse: 3.63432\n",
      "[1500]\ttraining's rmse: 3.45092\tvalid_1's rmse: 3.63008\n",
      "[2000]\ttraining's rmse: 3.40412\tvalid_1's rmse: 3.62866\n",
      "[2500]\ttraining's rmse: 3.36434\tvalid_1's rmse: 3.62814\n",
      "Early stopping, best iteration is:\n",
      "[2673]\ttraining's rmse: 3.35082\tvalid_1's rmse: 3.62796\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59366\tvalid_1's rmse: 3.62447\n",
      "[1000]\ttraining's rmse: 3.51116\tvalid_1's rmse: 3.60997\n",
      "[1500]\ttraining's rmse: 3.45553\tvalid_1's rmse: 3.60692\n",
      "[2000]\ttraining's rmse: 3.40935\tvalid_1's rmse: 3.60619\n",
      "Early stopping, best iteration is:\n",
      "[1866]\ttraining's rmse: 3.42071\tvalid_1's rmse: 3.60583\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54935\tvalid_1's rmse: 3.80607\n",
      "[1000]\ttraining's rmse: 3.46543\tvalid_1's rmse: 3.79113\n",
      "[1500]\ttraining's rmse: 3.40959\tvalid_1's rmse: 3.78816\n",
      "Early stopping, best iteration is:\n",
      "[1783]\ttraining's rmse: 3.38347\tvalid_1's rmse: 3.78734\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58742\tvalid_1's rmse: 3.6445\n",
      "[1000]\ttraining's rmse: 3.50525\tvalid_1's rmse: 3.63043\n",
      "[1500]\ttraining's rmse: 3.4505\tvalid_1's rmse: 3.62551\n",
      "[2000]\ttraining's rmse: 3.40582\tvalid_1's rmse: 3.62459\n",
      "Early stopping, best iteration is:\n",
      "[2055]\ttraining's rmse: 3.40147\tvalid_1's rmse: 3.62448\n",
      "  156 | 07m23s |   -3.66570 |             0.9613 |         8.2259 |             0.3989 |             0.8701 |     14.4784 |             27.7743 |            43.5753 |            87.3669 |           0.2263 |      39.5996 |      4.3221 |       0.5708 |      0.9157 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68452\tvalid_1's rmse: 3.74895\n",
      "[1000]\ttraining's rmse: 3.63011\tvalid_1's rmse: 3.72094\n",
      "[1500]\ttraining's rmse: 3.59314\tvalid_1's rmse: 3.71001\n",
      "[2000]\ttraining's rmse: 3.56167\tvalid_1's rmse: 3.70534\n",
      "[2500]\ttraining's rmse: 3.53421\tvalid_1's rmse: 3.70152\n",
      "[3000]\ttraining's rmse: 3.50766\tvalid_1's rmse: 3.7002\n",
      "[3500]\ttraining's rmse: 3.48291\tvalid_1's rmse: 3.69908\n",
      "Early stopping, best iteration is:\n",
      "[3468]\ttraining's rmse: 3.48438\tvalid_1's rmse: 3.69884\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69988\tvalid_1's rmse: 3.68047\n",
      "[1000]\ttraining's rmse: 3.64402\tvalid_1's rmse: 3.65583\n",
      "[1500]\ttraining's rmse: 3.6067\tvalid_1's rmse: 3.646\n",
      "[2000]\ttraining's rmse: 3.57569\tvalid_1's rmse: 3.64168\n",
      "[2500]\ttraining's rmse: 3.54777\tvalid_1's rmse: 3.63872\n",
      "Early stopping, best iteration is:\n",
      "[2781]\ttraining's rmse: 3.53238\tvalid_1's rmse: 3.63755\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70395\tvalid_1's rmse: 3.6557\n",
      "[1000]\ttraining's rmse: 3.64781\tvalid_1's rmse: 3.63259\n",
      "[1500]\ttraining's rmse: 3.61134\tvalid_1's rmse: 3.62459\n",
      "[2000]\ttraining's rmse: 3.5794\tvalid_1's rmse: 3.62173\n",
      "[2500]\ttraining's rmse: 3.55166\tvalid_1's rmse: 3.62017\n",
      "[3000]\ttraining's rmse: 3.52458\tvalid_1's rmse: 3.6188\n",
      "Early stopping, best iteration is:\n",
      "[2935]\ttraining's rmse: 3.52811\tvalid_1's rmse: 3.61848\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6571\tvalid_1's rmse: 3.85884\n",
      "[1000]\ttraining's rmse: 3.60114\tvalid_1's rmse: 3.83191\n",
      "[1500]\ttraining's rmse: 3.56381\tvalid_1's rmse: 3.8223\n",
      "[2000]\ttraining's rmse: 3.53223\tvalid_1's rmse: 3.81708\n",
      "[2500]\ttraining's rmse: 3.50533\tvalid_1's rmse: 3.81401\n",
      "[3000]\ttraining's rmse: 3.47842\tvalid_1's rmse: 3.81232\n",
      "[3500]\ttraining's rmse: 3.45343\tvalid_1's rmse: 3.81107\n",
      "[4000]\ttraining's rmse: 3.42962\tvalid_1's rmse: 3.81056\n",
      "[4500]\ttraining's rmse: 3.40631\tvalid_1's rmse: 3.80963\n",
      "Early stopping, best iteration is:\n",
      "[4347]\ttraining's rmse: 3.41329\tvalid_1's rmse: 3.80944\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.7006\tvalid_1's rmse: 3.67424\n",
      "[1000]\ttraining's rmse: 3.64364\tvalid_1's rmse: 3.6522\n",
      "[1500]\ttraining's rmse: 3.60611\tvalid_1's rmse: 3.64431\n",
      "[2000]\ttraining's rmse: 3.57506\tvalid_1's rmse: 3.64121\n",
      "[2500]\ttraining's rmse: 3.54642\tvalid_1's rmse: 3.63945\n",
      "[3000]\ttraining's rmse: 3.52\tvalid_1's rmse: 3.63796\n",
      "[3500]\ttraining's rmse: 3.49575\tvalid_1's rmse: 3.63754\n",
      "Early stopping, best iteration is:\n",
      "[3311]\ttraining's rmse: 3.50501\tvalid_1's rmse: 3.63729\n",
      "  157 | 05m32s |   -3.68099 |             0.2167 |         9.9610 |             0.3485 |             0.1231 |     13.8467 |              9.3429 |            44.0345 |            99.9860 |           0.8779 |      44.6683 |      3.3574 |       8.1430 |      0.8988 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6027\tvalid_1's rmse: 3.71077\n",
      "[1000]\ttraining's rmse: 3.5309\tvalid_1's rmse: 3.69131\n",
      "[1500]\ttraining's rmse: 3.48135\tvalid_1's rmse: 3.68556\n",
      "[2000]\ttraining's rmse: 3.44266\tvalid_1's rmse: 3.68366\n",
      "Early stopping, best iteration is:\n",
      "[2297]\ttraining's rmse: 3.42254\tvalid_1's rmse: 3.68332\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61638\tvalid_1's rmse: 3.65332\n",
      "[1000]\ttraining's rmse: 3.54162\tvalid_1's rmse: 3.63601\n",
      "[1500]\ttraining's rmse: 3.49298\tvalid_1's rmse: 3.63046\n",
      "[2000]\ttraining's rmse: 3.45363\tvalid_1's rmse: 3.62824\n",
      "[2500]\ttraining's rmse: 3.41772\tvalid_1's rmse: 3.62727\n",
      "Early stopping, best iteration is:\n",
      "[2448]\ttraining's rmse: 3.42089\tvalid_1's rmse: 3.62703\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62136\tvalid_1's rmse: 3.62917\n",
      "[1000]\ttraining's rmse: 3.547\tvalid_1's rmse: 3.61222\n",
      "[1500]\ttraining's rmse: 3.49847\tvalid_1's rmse: 3.60714\n",
      "[2000]\ttraining's rmse: 3.4588\tvalid_1's rmse: 3.60627\n",
      "Early stopping, best iteration is:\n",
      "[1971]\ttraining's rmse: 3.461\tvalid_1's rmse: 3.6062\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57599\tvalid_1's rmse: 3.81078\n",
      "[1000]\ttraining's rmse: 3.50178\tvalid_1's rmse: 3.79531\n",
      "[1500]\ttraining's rmse: 3.45189\tvalid_1's rmse: 3.79196\n",
      "[2000]\ttraining's rmse: 3.41412\tvalid_1's rmse: 3.79142\n",
      "Early stopping, best iteration is:\n",
      "[2278]\ttraining's rmse: 3.3936\tvalid_1's rmse: 3.79066\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61403\tvalid_1's rmse: 3.64785\n",
      "[1000]\ttraining's rmse: 3.5397\tvalid_1's rmse: 3.63215\n",
      "[1500]\ttraining's rmse: 3.49255\tvalid_1's rmse: 3.62657\n",
      "[2000]\ttraining's rmse: 3.45409\tvalid_1's rmse: 3.62522\n",
      "[2500]\ttraining's rmse: 3.41953\tvalid_1's rmse: 3.62429\n",
      "Early stopping, best iteration is:\n",
      "[2396]\ttraining's rmse: 3.42596\tvalid_1's rmse: 3.62412\n",
      "  158 | 06m55s |   -3.66688 |             0.9160 |        17.8922 |             0.9568 |             0.8633 |     14.9539 |              7.7907 |            43.8053 |            73.7002 |           0.0881 |      30.5036 |      6.0728 |       7.9493 |      0.1906 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00097774]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59998\tvalid_1's rmse: 3.70909\n",
      "[1000]\ttraining's rmse: 3.52958\tvalid_1's rmse: 3.69016\n",
      "[1500]\ttraining's rmse: 3.48294\tvalid_1's rmse: 3.6832\n",
      "[2000]\ttraining's rmse: 3.44737\tvalid_1's rmse: 3.6812\n",
      "[2500]\ttraining's rmse: 3.41568\tvalid_1's rmse: 3.68053\n",
      "Early stopping, best iteration is:\n",
      "[2543]\ttraining's rmse: 3.41319\tvalid_1's rmse: 3.68048\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61257\tvalid_1's rmse: 3.65109\n",
      "[1000]\ttraining's rmse: 3.54013\tvalid_1's rmse: 3.63476\n",
      "[1500]\ttraining's rmse: 3.49331\tvalid_1's rmse: 3.63081\n",
      "[2000]\ttraining's rmse: 3.4554\tvalid_1's rmse: 3.62938\n",
      "[2500]\ttraining's rmse: 3.42289\tvalid_1's rmse: 3.62824\n",
      "[3000]\ttraining's rmse: 3.39305\tvalid_1's rmse: 3.62803\n",
      "Early stopping, best iteration is:\n",
      "[2841]\ttraining's rmse: 3.40227\tvalid_1's rmse: 3.62789\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61768\tvalid_1's rmse: 3.62676\n",
      "[1000]\ttraining's rmse: 3.54646\tvalid_1's rmse: 3.61096\n",
      "[1500]\ttraining's rmse: 3.49942\tvalid_1's rmse: 3.60619\n",
      "[2000]\ttraining's rmse: 3.46217\tvalid_1's rmse: 3.60455\n",
      "Early stopping, best iteration is:\n",
      "[1876]\ttraining's rmse: 3.47062\tvalid_1's rmse: 3.60447\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57259\tvalid_1's rmse: 3.80995\n",
      "[1000]\ttraining's rmse: 3.49956\tvalid_1's rmse: 3.79505\n",
      "[1500]\ttraining's rmse: 3.45342\tvalid_1's rmse: 3.79143\n",
      "Early stopping, best iteration is:\n",
      "[1661]\ttraining's rmse: 3.44111\tvalid_1's rmse: 3.79123\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61196\tvalid_1's rmse: 3.6457\n",
      "[1000]\ttraining's rmse: 3.53893\tvalid_1's rmse: 3.63109\n",
      "[1500]\ttraining's rmse: 3.49328\tvalid_1's rmse: 3.62599\n",
      "[2000]\ttraining's rmse: 3.45642\tvalid_1's rmse: 3.62356\n",
      "[2500]\ttraining's rmse: 3.42543\tvalid_1's rmse: 3.62326\n",
      "Early stopping, best iteration is:\n",
      "[2323]\ttraining's rmse: 3.43672\tvalid_1's rmse: 3.62283\n",
      "  159 | 06m50s |   -3.66601 |             0.7837 |         0.1161 |             0.8723 |             0.8708 |     12.2840 |             30.7107 |            43.9475 |            96.4427 |           0.6644 |      33.6135 |      2.0859 |       8.5619 |      0.4811 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59548\tvalid_1's rmse: 3.70918\n",
      "[1000]\ttraining's rmse: 3.52291\tvalid_1's rmse: 3.68962\n",
      "[1500]\ttraining's rmse: 3.4747\tvalid_1's rmse: 3.68427\n",
      "[2000]\ttraining's rmse: 3.43785\tvalid_1's rmse: 3.68222\n",
      "Early stopping, best iteration is:\n",
      "[2233]\ttraining's rmse: 3.42219\tvalid_1's rmse: 3.68207\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60801\tvalid_1's rmse: 3.65099\n",
      "[1000]\ttraining's rmse: 3.53383\tvalid_1's rmse: 3.63479\n",
      "[1500]\ttraining's rmse: 3.48564\tvalid_1's rmse: 3.63038\n",
      "[2000]\ttraining's rmse: 3.44789\tvalid_1's rmse: 3.62867\n",
      "[2500]\ttraining's rmse: 3.41454\tvalid_1's rmse: 3.62808\n",
      "Early stopping, best iteration is:\n",
      "[2599]\ttraining's rmse: 3.40838\tvalid_1's rmse: 3.62792\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61355\tvalid_1's rmse: 3.62742\n",
      "[1000]\ttraining's rmse: 3.54007\tvalid_1's rmse: 3.61109\n",
      "[1500]\ttraining's rmse: 3.49145\tvalid_1's rmse: 3.60733\n",
      "[2000]\ttraining's rmse: 3.45282\tvalid_1's rmse: 3.60638\n",
      "Early stopping, best iteration is:\n",
      "[1939]\ttraining's rmse: 3.45747\tvalid_1's rmse: 3.60622\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56835\tvalid_1's rmse: 3.80912\n",
      "[1000]\ttraining's rmse: 3.49372\tvalid_1's rmse: 3.7938\n",
      "[1500]\ttraining's rmse: 3.44647\tvalid_1's rmse: 3.79001\n",
      "[2000]\ttraining's rmse: 3.41\tvalid_1's rmse: 3.78938\n",
      "[2500]\ttraining's rmse: 3.37802\tvalid_1's rmse: 3.78887\n",
      "[3000]\ttraining's rmse: 3.34764\tvalid_1's rmse: 3.78843\n",
      "Early stopping, best iteration is:\n",
      "[2839]\ttraining's rmse: 3.35728\tvalid_1's rmse: 3.78835\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60677\tvalid_1's rmse: 3.64522\n",
      "[1000]\ttraining's rmse: 3.53258\tvalid_1's rmse: 3.63025\n",
      "[1500]\ttraining's rmse: 3.4846\tvalid_1's rmse: 3.6256\n",
      "[2000]\ttraining's rmse: 3.44774\tvalid_1's rmse: 3.62295\n",
      "[2500]\ttraining's rmse: 3.41561\tvalid_1's rmse: 3.62225\n",
      "Early stopping, best iteration is:\n",
      "[2436]\ttraining's rmse: 3.41977\tvalid_1's rmse: 3.62218\n",
      "  160 | 06m36s |   -3.66595 |             0.9175 |         0.5477 |             0.2309 |             0.7625 |     14.7682 |             48.1987 |            31.4877 |            95.8979 |           0.7328 |      33.5848 |      2.8891 |       0.6784 |      0.8882 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65791\tvalid_1's rmse: 3.72118\n",
      "[1000]\ttraining's rmse: 3.61803\tvalid_1's rmse: 3.70134\n",
      "[1500]\ttraining's rmse: 3.59049\tvalid_1's rmse: 3.69387\n",
      "[2000]\ttraining's rmse: 3.5681\tvalid_1's rmse: 3.69038\n",
      "[2500]\ttraining's rmse: 3.54969\tvalid_1's rmse: 3.68906\n",
      "Early stopping, best iteration is:\n",
      "[2410]\ttraining's rmse: 3.55312\tvalid_1's rmse: 3.68852\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6715\tvalid_1's rmse: 3.65682\n",
      "[1000]\ttraining's rmse: 3.6283\tvalid_1's rmse: 3.63932\n",
      "[1500]\ttraining's rmse: 3.60337\tvalid_1's rmse: 3.63353\n",
      "[2000]\ttraining's rmse: 3.58282\tvalid_1's rmse: 3.63189\n",
      "[2500]\ttraining's rmse: 3.56345\tvalid_1's rmse: 3.63141\n",
      "Early stopping, best iteration is:\n",
      "[2324]\ttraining's rmse: 3.57031\tvalid_1's rmse: 3.63112\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67549\tvalid_1's rmse: 3.63178\n",
      "[1000]\ttraining's rmse: 3.63219\tvalid_1's rmse: 3.61539\n",
      "[1500]\ttraining's rmse: 3.60626\tvalid_1's rmse: 3.61024\n",
      "[2000]\ttraining's rmse: 3.58221\tvalid_1's rmse: 3.6098\n",
      "Early stopping, best iteration is:\n",
      "[2189]\ttraining's rmse: 3.57329\tvalid_1's rmse: 3.60881\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62968\tvalid_1's rmse: 3.82767\n",
      "[1000]\ttraining's rmse: 3.5873\tvalid_1's rmse: 3.81085\n",
      "[1500]\ttraining's rmse: 3.55824\tvalid_1's rmse: 3.80563\n",
      "[2000]\ttraining's rmse: 3.53795\tvalid_1's rmse: 3.80392\n",
      "[2500]\ttraining's rmse: 3.51772\tvalid_1's rmse: 3.80259\n",
      "Early stopping, best iteration is:\n",
      "[2448]\ttraining's rmse: 3.52018\tvalid_1's rmse: 3.802\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67186\tvalid_1's rmse: 3.65129\n",
      "[1000]\ttraining's rmse: 3.62841\tvalid_1's rmse: 3.63516\n",
      "[1500]\ttraining's rmse: 3.60267\tvalid_1's rmse: 3.63023\n",
      "Early stopping, best iteration is:\n",
      "[1643]\ttraining's rmse: 3.59523\tvalid_1's rmse: 3.62898\n",
      "  161 | 04m45s |   -3.67256 |             0.3617 |        18.9817 |             0.4844 |             0.5682 |      5.2090 |              5.2975 |            30.9553 |            10.1965 |           0.1119 |      30.1485 |      7.7167 |       7.8113 |      0.7802 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5686\tvalid_1's rmse: 3.7065\n",
      "[1000]\ttraining's rmse: 3.4806\tvalid_1's rmse: 3.68759\n",
      "[1500]\ttraining's rmse: 3.41989\tvalid_1's rmse: 3.68277\n",
      "[2000]\ttraining's rmse: 3.37052\tvalid_1's rmse: 3.68199\n",
      "Early stopping, best iteration is:\n",
      "[2267]\ttraining's rmse: 3.34522\tvalid_1's rmse: 3.68092\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57977\tvalid_1's rmse: 3.65132\n",
      "[1000]\ttraining's rmse: 3.49031\tvalid_1's rmse: 3.6351\n",
      "[1500]\ttraining's rmse: 3.42972\tvalid_1's rmse: 3.62983\n",
      "[2000]\ttraining's rmse: 3.37931\tvalid_1's rmse: 3.62697\n",
      "Early stopping, best iteration is:\n",
      "[2070]\ttraining's rmse: 3.37345\tvalid_1's rmse: 3.62686\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58444\tvalid_1's rmse: 3.62618\n",
      "[1000]\ttraining's rmse: 3.49642\tvalid_1's rmse: 3.61062\n",
      "[1500]\ttraining's rmse: 3.43279\tvalid_1's rmse: 3.607\n",
      "Early stopping, best iteration is:\n",
      "[1476]\ttraining's rmse: 3.43532\tvalid_1's rmse: 3.60685\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54027\tvalid_1's rmse: 3.80802\n",
      "[1000]\ttraining's rmse: 3.44931\tvalid_1's rmse: 3.79383\n",
      "[1500]\ttraining's rmse: 3.38984\tvalid_1's rmse: 3.79084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1654]\ttraining's rmse: 3.3742\tvalid_1's rmse: 3.79069\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5788\tvalid_1's rmse: 3.64751\n",
      "[1000]\ttraining's rmse: 3.49123\tvalid_1's rmse: 3.63233\n",
      "[1500]\ttraining's rmse: 3.43084\tvalid_1's rmse: 3.62824\n",
      "Early stopping, best iteration is:\n",
      "[1729]\ttraining's rmse: 3.40771\tvalid_1's rmse: 3.62716\n",
      "  162 | 06m50s |   -3.66710 |             0.8734 |        19.4769 |             0.2403 |             0.9038 |     13.6524 |              6.1978 |            32.5475 |            63.6173 |           0.0467 |      41.5209 |      9.1781 |       5.7880 |      0.9463 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65534\tvalid_1's rmse: 3.73827\n",
      "[1000]\ttraining's rmse: 3.58771\tvalid_1's rmse: 3.70905\n",
      "[1500]\ttraining's rmse: 3.54261\tvalid_1's rmse: 3.69732\n",
      "[2000]\ttraining's rmse: 3.50622\tvalid_1's rmse: 3.69186\n",
      "[2500]\ttraining's rmse: 3.47418\tvalid_1's rmse: 3.68875\n",
      "[3000]\ttraining's rmse: 3.44454\tvalid_1's rmse: 3.68688\n",
      "[3500]\ttraining's rmse: 3.41713\tvalid_1's rmse: 3.68586\n",
      "[4000]\ttraining's rmse: 3.39086\tvalid_1's rmse: 3.68529\n",
      "Early stopping, best iteration is:\n",
      "[4034]\ttraining's rmse: 3.38923\tvalid_1's rmse: 3.68522\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66858\tvalid_1's rmse: 3.67525\n",
      "[1000]\ttraining's rmse: 3.59914\tvalid_1's rmse: 3.64982\n",
      "[1500]\ttraining's rmse: 3.55308\tvalid_1's rmse: 3.63947\n",
      "[2000]\ttraining's rmse: 3.51587\tvalid_1's rmse: 3.63385\n",
      "[2500]\ttraining's rmse: 3.48262\tvalid_1's rmse: 3.63074\n",
      "[3000]\ttraining's rmse: 3.45274\tvalid_1's rmse: 3.62905\n",
      "[3500]\ttraining's rmse: 3.42454\tvalid_1's rmse: 3.62773\n",
      "[4000]\ttraining's rmse: 3.39774\tvalid_1's rmse: 3.62719\n",
      "Early stopping, best iteration is:\n",
      "[3814]\ttraining's rmse: 3.40804\tvalid_1's rmse: 3.62709\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67455\tvalid_1's rmse: 3.64882\n",
      "[1000]\ttraining's rmse: 3.60452\tvalid_1's rmse: 3.62444\n",
      "[1500]\ttraining's rmse: 3.5589\tvalid_1's rmse: 3.61536\n",
      "[2000]\ttraining's rmse: 3.52223\tvalid_1's rmse: 3.61179\n",
      "[2500]\ttraining's rmse: 3.48893\tvalid_1's rmse: 3.60994\n",
      "[3000]\ttraining's rmse: 3.45854\tvalid_1's rmse: 3.60876\n",
      "Early stopping, best iteration is:\n",
      "[3097]\ttraining's rmse: 3.45304\tvalid_1's rmse: 3.60852\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62618\tvalid_1's rmse: 3.84656\n",
      "[1000]\ttraining's rmse: 3.55709\tvalid_1's rmse: 3.81911\n",
      "[1500]\ttraining's rmse: 3.51183\tvalid_1's rmse: 3.80817\n",
      "[2000]\ttraining's rmse: 3.47555\tvalid_1's rmse: 3.80298\n",
      "[2500]\ttraining's rmse: 3.44356\tvalid_1's rmse: 3.80042\n",
      "[3000]\ttraining's rmse: 3.4137\tvalid_1's rmse: 3.79912\n",
      "[3500]\ttraining's rmse: 3.38586\tvalid_1's rmse: 3.79814\n",
      "[4000]\ttraining's rmse: 3.35874\tvalid_1's rmse: 3.79776\n",
      "Early stopping, best iteration is:\n",
      "[3836]\ttraining's rmse: 3.36726\tvalid_1's rmse: 3.79764\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6685\tvalid_1's rmse: 3.66737\n",
      "[1000]\ttraining's rmse: 3.59811\tvalid_1's rmse: 3.64471\n",
      "[1500]\ttraining's rmse: 3.55135\tvalid_1's rmse: 3.63568\n",
      "[2000]\ttraining's rmse: 3.51435\tvalid_1's rmse: 3.63118\n",
      "[2500]\ttraining's rmse: 3.48189\tvalid_1's rmse: 3.62944\n",
      "[3000]\ttraining's rmse: 3.45308\tvalid_1's rmse: 3.62819\n",
      "[3500]\ttraining's rmse: 3.42492\tvalid_1's rmse: 3.62783\n",
      "Early stopping, best iteration is:\n",
      "[3563]\ttraining's rmse: 3.42161\tvalid_1's rmse: 3.62772\n",
      "  163 | 06m43s |   -3.66989 |             0.8425 |         2.4312 |             0.6935 |             0.1312 |      7.4965 |             48.9636 |            44.0556 |            59.7669 |           0.5949 |      44.9305 |      9.0709 |       0.4645 |      0.7430 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57603\tvalid_1's rmse: 3.70392\n",
      "[1000]\ttraining's rmse: 3.49443\tvalid_1's rmse: 3.68628\n",
      "[1500]\ttraining's rmse: 3.43763\tvalid_1's rmse: 3.68077\n",
      "[2000]\ttraining's rmse: 3.39147\tvalid_1's rmse: 3.67974\n",
      "Early stopping, best iteration is:\n",
      "[2010]\ttraining's rmse: 3.3905\tvalid_1's rmse: 3.67965\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58937\tvalid_1's rmse: 3.64857\n",
      "[1000]\ttraining's rmse: 3.5064\tvalid_1's rmse: 3.63275\n",
      "[1500]\ttraining's rmse: 3.44978\tvalid_1's rmse: 3.629\n",
      "[2000]\ttraining's rmse: 3.40329\tvalid_1's rmse: 3.62798\n",
      "Early stopping, best iteration is:\n",
      "[2091]\ttraining's rmse: 3.39496\tvalid_1's rmse: 3.62784\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59438\tvalid_1's rmse: 3.62349\n",
      "[1000]\ttraining's rmse: 3.5108\tvalid_1's rmse: 3.60855\n",
      "[1500]\ttraining's rmse: 3.45381\tvalid_1's rmse: 3.60498\n",
      "[2000]\ttraining's rmse: 3.40702\tvalid_1's rmse: 3.60451\n",
      "Early stopping, best iteration is:\n",
      "[1847]\ttraining's rmse: 3.4206\tvalid_1's rmse: 3.60418\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54962\tvalid_1's rmse: 3.80763\n",
      "[1000]\ttraining's rmse: 3.46461\tvalid_1's rmse: 3.79239\n",
      "[1500]\ttraining's rmse: 3.40914\tvalid_1's rmse: 3.78933\n",
      "Early stopping, best iteration is:\n",
      "[1579]\ttraining's rmse: 3.40147\tvalid_1's rmse: 3.78902\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.588\tvalid_1's rmse: 3.6426\n",
      "[1000]\ttraining's rmse: 3.50482\tvalid_1's rmse: 3.62941\n",
      "[1500]\ttraining's rmse: 3.44952\tvalid_1's rmse: 3.62533\n",
      "[2000]\ttraining's rmse: 3.4032\tvalid_1's rmse: 3.62427\n",
      "Early stopping, best iteration is:\n",
      "[2125]\ttraining's rmse: 3.39272\tvalid_1's rmse: 3.62381\n",
      "  164 | 07m17s |   -3.66551 |             0.9752 |         6.5389 |             0.6093 |             0.7906 |     13.0550 |             47.4283 |            44.2609 |            99.7514 |           0.3613 |      44.4064 |      4.0590 |       9.6090 |      0.9178 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0003076]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60066\tvalid_1's rmse: 3.70839\n",
      "[1000]\ttraining's rmse: 3.53103\tvalid_1's rmse: 3.68899\n",
      "[1500]\ttraining's rmse: 3.48442\tvalid_1's rmse: 3.68395\n",
      "[2000]\ttraining's rmse: 3.44371\tvalid_1's rmse: 3.68305\n",
      "Early stopping, best iteration is:\n",
      "[1906]\ttraining's rmse: 3.45097\tvalid_1's rmse: 3.68242\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61364\tvalid_1's rmse: 3.65103\n",
      "[1000]\ttraining's rmse: 3.54258\tvalid_1's rmse: 3.63518\n",
      "[1500]\ttraining's rmse: 3.49524\tvalid_1's rmse: 3.62955\n",
      "[2000]\ttraining's rmse: 3.45573\tvalid_1's rmse: 3.62724\n",
      "[2500]\ttraining's rmse: 3.41983\tvalid_1's rmse: 3.62654\n",
      "Early stopping, best iteration is:\n",
      "[2777]\ttraining's rmse: 3.40152\tvalid_1's rmse: 3.62587\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6184\tvalid_1's rmse: 3.6273\n",
      "[1000]\ttraining's rmse: 3.54815\tvalid_1's rmse: 3.61064\n",
      "[1500]\ttraining's rmse: 3.49971\tvalid_1's rmse: 3.60699\n",
      "Early stopping, best iteration is:\n",
      "[1448]\ttraining's rmse: 3.50435\tvalid_1's rmse: 3.60679\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57358\tvalid_1's rmse: 3.80921\n",
      "[1000]\ttraining's rmse: 3.50237\tvalid_1's rmse: 3.79412\n",
      "[1500]\ttraining's rmse: 3.45567\tvalid_1's rmse: 3.7905\n",
      "Early stopping, best iteration is:\n",
      "[1654]\ttraining's rmse: 3.4431\tvalid_1's rmse: 3.78985\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61343\tvalid_1's rmse: 3.64513\n",
      "[1000]\ttraining's rmse: 3.54359\tvalid_1's rmse: 3.62898\n",
      "[1500]\ttraining's rmse: 3.49655\tvalid_1's rmse: 3.62513\n",
      "[2000]\ttraining's rmse: 3.45712\tvalid_1's rmse: 3.62414\n",
      "Early stopping, best iteration is:\n",
      "[1893]\ttraining's rmse: 3.46462\tvalid_1's rmse: 3.62396\n",
      "  165 | 06m37s |   -3.66639 |             0.8453 |        19.8903 |             0.1724 |             0.8843 |     11.3601 |             17.1943 |            44.1895 |            94.8250 |           0.2379 |      34.3128 |      7.4438 |       9.8470 |      0.5821 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6175\tvalid_1's rmse: 3.70733\n",
      "[1000]\ttraining's rmse: 3.56395\tvalid_1's rmse: 3.68934\n",
      "[1500]\ttraining's rmse: 3.52639\tvalid_1's rmse: 3.68424\n",
      "[2000]\ttraining's rmse: 3.49492\tvalid_1's rmse: 3.68302\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's rmse: 3.48803\tvalid_1's rmse: 3.68267\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62978\tvalid_1's rmse: 3.65007\n",
      "[1000]\ttraining's rmse: 3.57455\tvalid_1's rmse: 3.63431\n",
      "[1500]\ttraining's rmse: 3.53638\tvalid_1's rmse: 3.6306\n",
      "[2000]\ttraining's rmse: 3.50305\tvalid_1's rmse: 3.62828\n",
      "Early stopping, best iteration is:\n",
      "[2129]\ttraining's rmse: 3.49493\tvalid_1's rmse: 3.62776\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6351\tvalid_1's rmse: 3.62803\n",
      "[1000]\ttraining's rmse: 3.57961\tvalid_1's rmse: 3.61204\n",
      "[1500]\ttraining's rmse: 3.54085\tvalid_1's rmse: 3.60864\n",
      "[2000]\ttraining's rmse: 3.50756\tvalid_1's rmse: 3.60797\n",
      "Early stopping, best iteration is:\n",
      "[1853]\ttraining's rmse: 3.51785\tvalid_1's rmse: 3.60759\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58846\tvalid_1's rmse: 3.80895\n",
      "[1000]\ttraining's rmse: 3.53125\tvalid_1's rmse: 3.79421\n",
      "[1500]\ttraining's rmse: 3.49395\tvalid_1's rmse: 3.79062\n",
      "Early stopping, best iteration is:\n",
      "[1742]\ttraining's rmse: 3.47787\tvalid_1's rmse: 3.78915\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63072\tvalid_1's rmse: 3.64405\n",
      "[1000]\ttraining's rmse: 3.57312\tvalid_1's rmse: 3.62995\n",
      "[1500]\ttraining's rmse: 3.53475\tvalid_1's rmse: 3.62517\n",
      "Early stopping, best iteration is:\n",
      "[1611]\ttraining's rmse: 3.52735\tvalid_1's rmse: 3.62468\n",
      "  166 | 06m42s |   -3.66697 |             0.9281 |        13.5637 |             0.8778 |             0.9382 |      7.9277 |              6.1652 |            35.4432 |            99.9876 |           0.3106 |      33.1893 |      9.6263 |       9.6307 |      0.3526 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00018892]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59258\tvalid_1's rmse: 3.70413\n",
      "[1000]\ttraining's rmse: 3.52782\tvalid_1's rmse: 3.68621\n",
      "[1500]\ttraining's rmse: 3.48385\tvalid_1's rmse: 3.6827\n",
      "Early stopping, best iteration is:\n",
      "[1558]\ttraining's rmse: 3.47878\tvalid_1's rmse: 3.68233\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60682\tvalid_1's rmse: 3.64602\n",
      "[1000]\ttraining's rmse: 3.54115\tvalid_1's rmse: 3.63145\n",
      "[1500]\ttraining's rmse: 3.49386\tvalid_1's rmse: 3.62683\n",
      "[2000]\ttraining's rmse: 3.45239\tvalid_1's rmse: 3.62526\n",
      "Early stopping, best iteration is:\n",
      "[2120]\ttraining's rmse: 3.44295\tvalid_1's rmse: 3.62522\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60912\tvalid_1's rmse: 3.62314\n",
      "[1000]\ttraining's rmse: 3.5429\tvalid_1's rmse: 3.60839\n",
      "[1500]\ttraining's rmse: 3.49779\tvalid_1's rmse: 3.60573\n",
      "[2000]\ttraining's rmse: 3.4554\tvalid_1's rmse: 3.60443\n",
      "Early stopping, best iteration is:\n",
      "[1834]\ttraining's rmse: 3.46916\tvalid_1's rmse: 3.60416\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56522\tvalid_1's rmse: 3.80733\n",
      "[1000]\ttraining's rmse: 3.49881\tvalid_1's rmse: 3.79272\n",
      "[1500]\ttraining's rmse: 3.45468\tvalid_1's rmse: 3.78943\n",
      "Early stopping, best iteration is:\n",
      "[1596]\ttraining's rmse: 3.44711\tvalid_1's rmse: 3.7891\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60625\tvalid_1's rmse: 3.63985\n",
      "[1000]\ttraining's rmse: 3.53939\tvalid_1's rmse: 3.62713\n",
      "[1500]\ttraining's rmse: 3.49381\tvalid_1's rmse: 3.62364\n",
      "[2000]\ttraining's rmse: 3.45497\tvalid_1's rmse: 3.62355\n",
      "Early stopping, best iteration is:\n",
      "[1844]\ttraining's rmse: 3.46738\tvalid_1's rmse: 3.62292\n",
      "  167 | 06m30s |   -3.66537 |             0.9286 |        19.9776 |             0.8279 |             0.8051 |      8.8852 |             33.1272 |            44.1748 |            99.7403 |           0.3627 |      41.0965 |      7.1816 |       2.1124 |      0.9065 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59227\tvalid_1's rmse: 3.71387\n",
      "[1000]\ttraining's rmse: 3.51832\tvalid_1's rmse: 3.69525\n",
      "[1500]\ttraining's rmse: 3.46807\tvalid_1's rmse: 3.68829\n",
      "[2000]\ttraining's rmse: 3.42823\tvalid_1's rmse: 3.68753\n",
      "Early stopping, best iteration is:\n",
      "[2002]\ttraining's rmse: 3.42808\tvalid_1's rmse: 3.68749\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60491\tvalid_1's rmse: 3.65302\n",
      "[1000]\ttraining's rmse: 3.5296\tvalid_1's rmse: 3.63565\n",
      "[1500]\ttraining's rmse: 3.48007\tvalid_1's rmse: 3.63231\n",
      "[2000]\ttraining's rmse: 3.44048\tvalid_1's rmse: 3.63145\n",
      "[2500]\ttraining's rmse: 3.40507\tvalid_1's rmse: 3.63056\n",
      "Early stopping, best iteration is:\n",
      "[2504]\ttraining's rmse: 3.40481\tvalid_1's rmse: 3.63056\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6103\tvalid_1's rmse: 3.62823\n",
      "[1000]\ttraining's rmse: 3.53507\tvalid_1's rmse: 3.61313\n",
      "[1500]\ttraining's rmse: 3.48483\tvalid_1's rmse: 3.60852\n",
      "[2000]\ttraining's rmse: 3.44548\tvalid_1's rmse: 3.60793\n",
      "Early stopping, best iteration is:\n",
      "[1921]\ttraining's rmse: 3.45113\tvalid_1's rmse: 3.60772\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56547\tvalid_1's rmse: 3.81142\n",
      "[1000]\ttraining's rmse: 3.49111\tvalid_1's rmse: 3.79618\n",
      "[1500]\ttraining's rmse: 3.44191\tvalid_1's rmse: 3.79237\n",
      "[2000]\ttraining's rmse: 3.40353\tvalid_1's rmse: 3.79132\n",
      "Early stopping, best iteration is:\n",
      "[1970]\ttraining's rmse: 3.40567\tvalid_1's rmse: 3.7912\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60365\tvalid_1's rmse: 3.64896\n",
      "[1000]\ttraining's rmse: 3.52623\tvalid_1's rmse: 3.63358\n",
      "[1500]\ttraining's rmse: 3.47607\tvalid_1's rmse: 3.62869\n",
      "[2000]\ttraining's rmse: 3.43674\tvalid_1's rmse: 3.62778\n",
      "Early stopping, best iteration is:\n",
      "[2116]\ttraining's rmse: 3.4287\tvalid_1's rmse: 3.62752\n",
      "  168 | 06m35s |   -3.66950 |             0.7847 |         0.6354 |             0.1804 |             0.8921 |      9.2020 |              6.5861 |            43.5522 |            31.9785 |           0.2950 |      33.8776 |      0.1116 |       9.4248 |      0.9873 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58518\tvalid_1's rmse: 3.70437\n",
      "[1000]\ttraining's rmse: 3.5078\tvalid_1's rmse: 3.68632\n",
      "[1500]\ttraining's rmse: 3.45484\tvalid_1's rmse: 3.68217\n",
      "Early stopping, best iteration is:\n",
      "[1792]\ttraining's rmse: 3.42778\tvalid_1's rmse: 3.68101\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59674\tvalid_1's rmse: 3.64896\n",
      "[1000]\ttraining's rmse: 3.5187\tvalid_1's rmse: 3.63398\n",
      "[1500]\ttraining's rmse: 3.46622\tvalid_1's rmse: 3.6305\n",
      "[2000]\ttraining's rmse: 3.42086\tvalid_1's rmse: 3.62859\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's rmse: 3.43277\tvalid_1's rmse: 3.62812\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60248\tvalid_1's rmse: 3.62386\n",
      "[1000]\ttraining's rmse: 3.52518\tvalid_1's rmse: 3.60873\n",
      "[1500]\ttraining's rmse: 3.47025\tvalid_1's rmse: 3.607\n",
      "Early stopping, best iteration is:\n",
      "[1440]\ttraining's rmse: 3.47615\tvalid_1's rmse: 3.60652\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55837\tvalid_1's rmse: 3.80845\n",
      "[1000]\ttraining's rmse: 3.47854\tvalid_1's rmse: 3.79473\n",
      "[1500]\ttraining's rmse: 3.42507\tvalid_1's rmse: 3.79122\n",
      "[2000]\ttraining's rmse: 3.37851\tvalid_1's rmse: 3.79118\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's rmse: 3.38766\tvalid_1's rmse: 3.7907\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59739\tvalid_1's rmse: 3.64509\n",
      "[1000]\ttraining's rmse: 3.51924\tvalid_1's rmse: 3.63072\n",
      "[1500]\ttraining's rmse: 3.46548\tvalid_1's rmse: 3.62721\n",
      "[2000]\ttraining's rmse: 3.41782\tvalid_1's rmse: 3.62667\n",
      "Early stopping, best iteration is:\n",
      "[1865]\ttraining's rmse: 3.42966\tvalid_1's rmse: 3.62633\n",
      "  169 | 06m31s |   -3.66714 |             0.8099 |        19.5954 |             0.1155 |             0.8904 |     13.4743 |             17.3500 |            31.5361 |            92.2291 |           0.1287 |      39.6520 |      8.0141 |       2.4957 |      0.4056 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61881\tvalid_1's rmse: 3.71157\n",
      "[1000]\ttraining's rmse: 3.56503\tvalid_1's rmse: 3.69312\n",
      "[1500]\ttraining's rmse: 3.52726\tvalid_1's rmse: 3.68835\n",
      "Early stopping, best iteration is:\n",
      "[1786]\ttraining's rmse: 3.50808\tvalid_1's rmse: 3.6874\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63375\tvalid_1's rmse: 3.65346\n",
      "[1000]\ttraining's rmse: 3.57855\tvalid_1's rmse: 3.6382\n",
      "[1500]\ttraining's rmse: 3.54121\tvalid_1's rmse: 3.63356\n",
      "[2000]\ttraining's rmse: 3.50917\tvalid_1's rmse: 3.63126\n",
      "Early stopping, best iteration is:\n",
      "[2143]\ttraining's rmse: 3.49915\tvalid_1's rmse: 3.63084\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6365\tvalid_1's rmse: 3.62828\n",
      "[1000]\ttraining's rmse: 3.58011\tvalid_1's rmse: 3.61357\n",
      "[1500]\ttraining's rmse: 3.54315\tvalid_1's rmse: 3.61021\n",
      "[2000]\ttraining's rmse: 3.50861\tvalid_1's rmse: 3.60883\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's rmse: 3.50244\tvalid_1's rmse: 3.60833\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59207\tvalid_1's rmse: 3.81092\n",
      "[1000]\ttraining's rmse: 3.53466\tvalid_1's rmse: 3.79643\n",
      "[1500]\ttraining's rmse: 3.49649\tvalid_1's rmse: 3.79262\n",
      "[2000]\ttraining's rmse: 3.46392\tvalid_1's rmse: 3.79159\n",
      "[2500]\ttraining's rmse: 3.43479\tvalid_1's rmse: 3.79087\n",
      "Early stopping, best iteration is:\n",
      "[2305]\ttraining's rmse: 3.4456\tvalid_1's rmse: 3.7906\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63342\tvalid_1's rmse: 3.64545\n",
      "[1000]\ttraining's rmse: 3.57581\tvalid_1's rmse: 3.63096\n",
      "[1500]\ttraining's rmse: 3.53493\tvalid_1's rmse: 3.62631\n",
      "[2000]\ttraining's rmse: 3.49965\tvalid_1's rmse: 3.62526\n",
      "Early stopping, best iteration is:\n",
      "[2230]\ttraining's rmse: 3.48476\tvalid_1's rmse: 3.62442\n",
      "  170 | 06m41s |   -3.66892 |             0.9478 |        19.4690 |             0.2617 |             0.9068 |      6.4253 |              6.1887 |            42.0374 |            12.7966 |           0.5166 |      31.3965 |      8.7119 |       0.3802 |      0.1517 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65217\tvalid_1's rmse: 3.71646\n",
      "[1000]\ttraining's rmse: 3.61377\tvalid_1's rmse: 3.69727\n",
      "[1500]\ttraining's rmse: 3.58781\tvalid_1's rmse: 3.69023\n",
      "[2000]\ttraining's rmse: 3.56612\tvalid_1's rmse: 3.6874\n",
      "[2500]\ttraining's rmse: 3.54864\tvalid_1's rmse: 3.68622\n",
      "[3000]\ttraining's rmse: 3.53052\tvalid_1's rmse: 3.68598\n",
      "Early stopping, best iteration is:\n",
      "[2952]\ttraining's rmse: 3.53211\tvalid_1's rmse: 3.68584\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66522\tvalid_1's rmse: 3.65761\n",
      "[1000]\ttraining's rmse: 3.62456\tvalid_1's rmse: 3.64083\n",
      "[1500]\ttraining's rmse: 3.60018\tvalid_1's rmse: 3.63452\n",
      "[2000]\ttraining's rmse: 3.5778\tvalid_1's rmse: 3.63106\n",
      "[2500]\ttraining's rmse: 3.55927\tvalid_1's rmse: 3.62917\n",
      "[3000]\ttraining's rmse: 3.54267\tvalid_1's rmse: 3.62802\n",
      "[3500]\ttraining's rmse: 3.52601\tvalid_1's rmse: 3.62752\n",
      "Early stopping, best iteration is:\n",
      "[3457]\ttraining's rmse: 3.52716\tvalid_1's rmse: 3.62743\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67072\tvalid_1's rmse: 3.62926\n",
      "[1000]\ttraining's rmse: 3.6294\tvalid_1's rmse: 3.61187\n",
      "[1500]\ttraining's rmse: 3.60345\tvalid_1's rmse: 3.60746\n",
      "[2000]\ttraining's rmse: 3.58283\tvalid_1's rmse: 3.60551\n",
      "[2500]\ttraining's rmse: 3.56309\tvalid_1's rmse: 3.60431\n",
      "[3000]\ttraining's rmse: 3.54611\tvalid_1's rmse: 3.60364\n",
      "Early stopping, best iteration is:\n",
      "[2889]\ttraining's rmse: 3.55027\tvalid_1's rmse: 3.60339\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62256\tvalid_1's rmse: 3.81857\n",
      "[1000]\ttraining's rmse: 3.58065\tvalid_1's rmse: 3.80341\n",
      "[1500]\ttraining's rmse: 3.5548\tvalid_1's rmse: 3.7987\n",
      "[2000]\ttraining's rmse: 3.53539\tvalid_1's rmse: 3.79683\n",
      "[2500]\ttraining's rmse: 3.5155\tvalid_1's rmse: 3.7951\n",
      "[3000]\ttraining's rmse: 3.4979\tvalid_1's rmse: 3.7941\n",
      "Early stopping, best iteration is:\n",
      "[2985]\ttraining's rmse: 3.49829\tvalid_1's rmse: 3.79405\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66629\tvalid_1's rmse: 3.64711\n",
      "[1000]\ttraining's rmse: 3.62596\tvalid_1's rmse: 3.63075\n",
      "[1500]\ttraining's rmse: 3.59839\tvalid_1's rmse: 3.62464\n",
      "[2000]\ttraining's rmse: 3.57867\tvalid_1's rmse: 3.62202\n",
      "[2500]\ttraining's rmse: 3.55899\tvalid_1's rmse: 3.62111\n",
      "Early stopping, best iteration is:\n",
      "[2476]\ttraining's rmse: 3.56013\tvalid_1's rmse: 3.62102\n",
      "  171 | 06m51s |   -3.66701 |             0.9465 |        14.0440 |             0.1803 |             0.7312 |      5.6312 |              6.9215 |            30.9138 |            99.4523 |           0.5456 |      40.1598 |      0.7498 |       1.6424 |      0.8732 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.593\tvalid_1's rmse: 3.71205\n",
      "[1000]\ttraining's rmse: 3.51569\tvalid_1's rmse: 3.69317\n",
      "[1500]\ttraining's rmse: 3.46472\tvalid_1's rmse: 3.68776\n",
      "[2000]\ttraining's rmse: 3.42343\tvalid_1's rmse: 3.68536\n",
      "[2500]\ttraining's rmse: 3.38705\tvalid_1's rmse: 3.68465\n",
      "Early stopping, best iteration is:\n",
      "[2799]\ttraining's rmse: 3.36671\tvalid_1's rmse: 3.68387\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60698\tvalid_1's rmse: 3.65271\n",
      "[1000]\ttraining's rmse: 3.52817\tvalid_1's rmse: 3.63499\n",
      "[1500]\ttraining's rmse: 3.47655\tvalid_1's rmse: 3.62923\n",
      "[2000]\ttraining's rmse: 3.43419\tvalid_1's rmse: 3.62738\n",
      "[2500]\ttraining's rmse: 3.39615\tvalid_1's rmse: 3.6263\n",
      "[3000]\ttraining's rmse: 3.36173\tvalid_1's rmse: 3.6258\n",
      "[3500]\ttraining's rmse: 3.3293\tvalid_1's rmse: 3.62514\n",
      "Early stopping, best iteration is:\n",
      "[3531]\ttraining's rmse: 3.32753\tvalid_1's rmse: 3.62506\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61067\tvalid_1's rmse: 3.62838\n",
      "[1000]\ttraining's rmse: 3.53262\tvalid_1's rmse: 3.6115\n",
      "[1500]\ttraining's rmse: 3.48094\tvalid_1's rmse: 3.6066\n",
      "[2000]\ttraining's rmse: 3.44015\tvalid_1's rmse: 3.60518\n",
      "Early stopping, best iteration is:\n",
      "[1854]\ttraining's rmse: 3.45124\tvalid_1's rmse: 3.60496\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56556\tvalid_1's rmse: 3.81056\n",
      "[1000]\ttraining's rmse: 3.48533\tvalid_1's rmse: 3.7933\n",
      "[1500]\ttraining's rmse: 3.43353\tvalid_1's rmse: 3.78881\n",
      "Early stopping, best iteration is:\n",
      "[1584]\ttraining's rmse: 3.42635\tvalid_1's rmse: 3.78825\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60423\tvalid_1's rmse: 3.64891\n",
      "[1000]\ttraining's rmse: 3.52522\tvalid_1's rmse: 3.6328\n",
      "[1500]\ttraining's rmse: 3.47353\tvalid_1's rmse: 3.62725\n",
      "[2000]\ttraining's rmse: 3.43296\tvalid_1's rmse: 3.62497\n",
      "Early stopping, best iteration is:\n",
      "[2296]\ttraining's rmse: 3.41087\tvalid_1's rmse: 3.62428\n",
      "  172 | 06m32s |   -3.66590 |             0.9321 |        18.2938 |             0.4845 |             0.5669 |     13.7202 |             48.8439 |            44.5678 |            65.3047 |           0.9519 |      33.0141 |      2.2959 |       1.9890 |      0.9884 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59408\tvalid_1's rmse: 3.70891\n",
      "[1000]\ttraining's rmse: 3.52031\tvalid_1's rmse: 3.68955\n",
      "[1500]\ttraining's rmse: 3.46947\tvalid_1's rmse: 3.6832\n",
      "[2000]\ttraining's rmse: 3.42881\tvalid_1's rmse: 3.68144\n",
      "Early stopping, best iteration is:\n",
      "[1976]\ttraining's rmse: 3.43081\tvalid_1's rmse: 3.68119\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6071\tvalid_1's rmse: 3.65248\n",
      "[1000]\ttraining's rmse: 3.53198\tvalid_1's rmse: 3.63625\n",
      "[1500]\ttraining's rmse: 3.48319\tvalid_1's rmse: 3.63122\n",
      "[2000]\ttraining's rmse: 3.44293\tvalid_1's rmse: 3.62948\n",
      "[2500]\ttraining's rmse: 3.40621\tvalid_1's rmse: 3.62835\n",
      "[3000]\ttraining's rmse: 3.37384\tvalid_1's rmse: 3.62778\n",
      "Early stopping, best iteration is:\n",
      "[2996]\ttraining's rmse: 3.37407\tvalid_1's rmse: 3.62775\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6124\tvalid_1's rmse: 3.62618\n",
      "[1000]\ttraining's rmse: 3.53817\tvalid_1's rmse: 3.6102\n",
      "[1500]\ttraining's rmse: 3.48799\tvalid_1's rmse: 3.60641\n",
      "Early stopping, best iteration is:\n",
      "[1695]\ttraining's rmse: 3.47107\tvalid_1's rmse: 3.6058\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56758\tvalid_1's rmse: 3.80856\n",
      "[1000]\ttraining's rmse: 3.49114\tvalid_1's rmse: 3.79327\n",
      "[1500]\ttraining's rmse: 3.44181\tvalid_1's rmse: 3.78997\n",
      "[2000]\ttraining's rmse: 3.40175\tvalid_1's rmse: 3.78904\n",
      "Early stopping, best iteration is:\n",
      "[2068]\ttraining's rmse: 3.39659\tvalid_1's rmse: 3.78887\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.607\tvalid_1's rmse: 3.64623\n",
      "[1000]\ttraining's rmse: 3.53185\tvalid_1's rmse: 3.63248\n",
      "[1500]\ttraining's rmse: 3.48357\tvalid_1's rmse: 3.62776\n",
      "[2000]\ttraining's rmse: 3.44281\tvalid_1's rmse: 3.62662\n",
      "[2500]\ttraining's rmse: 3.4086\tvalid_1's rmse: 3.62578\n",
      "Early stopping, best iteration is:\n",
      "[2522]\ttraining's rmse: 3.40662\tvalid_1's rmse: 3.62564\n",
      "  173 | 07m40s |   -3.66645 |             0.9764 |        13.6700 |             0.3934 |             0.8979 |     14.1103 |             39.4881 |            44.6845 |            99.5616 |           0.7190 |      35.1094 |      3.8832 |       8.1611 |      0.8512 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([8.94014374e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60341\tvalid_1's rmse: 3.71168\n",
      "[1000]\ttraining's rmse: 3.53\tvalid_1's rmse: 3.69187\n",
      "[1500]\ttraining's rmse: 3.48146\tvalid_1's rmse: 3.6842\n",
      "[2000]\ttraining's rmse: 3.44593\tvalid_1's rmse: 3.6821\n",
      "[2500]\ttraining's rmse: 3.41442\tvalid_1's rmse: 3.68135\n",
      "Early stopping, best iteration is:\n",
      "[2495]\ttraining's rmse: 3.41469\tvalid_1's rmse: 3.68133\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61558\tvalid_1's rmse: 3.65309\n",
      "[1000]\ttraining's rmse: 3.54041\tvalid_1's rmse: 3.63589\n",
      "[1500]\ttraining's rmse: 3.4933\tvalid_1's rmse: 3.63108\n",
      "[2000]\ttraining's rmse: 3.45623\tvalid_1's rmse: 3.62935\n",
      "[2500]\ttraining's rmse: 3.42392\tvalid_1's rmse: 3.62863\n",
      "[3000]\ttraining's rmse: 3.39381\tvalid_1's rmse: 3.62816\n",
      "Early stopping, best iteration is:\n",
      "[2879]\ttraining's rmse: 3.40066\tvalid_1's rmse: 3.6281\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6218\tvalid_1's rmse: 3.6297\n",
      "[1000]\ttraining's rmse: 3.54787\tvalid_1's rmse: 3.6127\n",
      "[1500]\ttraining's rmse: 3.49916\tvalid_1's rmse: 3.60796\n",
      "[2000]\ttraining's rmse: 3.4624\tvalid_1's rmse: 3.606\n",
      "Early stopping, best iteration is:\n",
      "[2102]\ttraining's rmse: 3.45569\tvalid_1's rmse: 3.60568\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57527\tvalid_1's rmse: 3.81\n",
      "[1000]\ttraining's rmse: 3.49969\tvalid_1's rmse: 3.79348\n",
      "[1500]\ttraining's rmse: 3.45158\tvalid_1's rmse: 3.78908\n",
      "[2000]\ttraining's rmse: 3.41555\tvalid_1's rmse: 3.78826\n",
      "[2500]\ttraining's rmse: 3.38503\tvalid_1's rmse: 3.78707\n",
      "Early stopping, best iteration is:\n",
      "[2619]\ttraining's rmse: 3.37816\tvalid_1's rmse: 3.78695\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61443\tvalid_1's rmse: 3.64885\n",
      "[1000]\ttraining's rmse: 3.53918\tvalid_1's rmse: 3.63351\n",
      "[1500]\ttraining's rmse: 3.49136\tvalid_1's rmse: 3.62813\n",
      "[2000]\ttraining's rmse: 3.45467\tvalid_1's rmse: 3.62598\n",
      "[2500]\ttraining's rmse: 3.42314\tvalid_1's rmse: 3.62546\n",
      "Early stopping, best iteration is:\n",
      "[2591]\ttraining's rmse: 3.41797\tvalid_1's rmse: 3.62534\n",
      "  174 | 07m05s |   -3.66607 |             0.9845 |         0.8061 |             0.1977 |             0.9021 |     14.3586 |             23.2463 |            38.5484 |            75.6837 |           0.7347 |      30.5344 |      5.1013 |       9.2110 |      0.5797 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58365\tvalid_1's rmse: 3.70496\n",
      "[1000]\ttraining's rmse: 3.50462\tvalid_1's rmse: 3.68597\n",
      "[1500]\ttraining's rmse: 3.45112\tvalid_1's rmse: 3.68145\n",
      "[2000]\ttraining's rmse: 3.40552\tvalid_1's rmse: 3.67967\n",
      "[2500]\ttraining's rmse: 3.36453\tvalid_1's rmse: 3.67982\n",
      "Early stopping, best iteration is:\n",
      "[2318]\ttraining's rmse: 3.37898\tvalid_1's rmse: 3.67951\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59618\tvalid_1's rmse: 3.64896\n",
      "[1000]\ttraining's rmse: 3.51679\tvalid_1's rmse: 3.63257\n",
      "[1500]\ttraining's rmse: 3.46151\tvalid_1's rmse: 3.62814\n",
      "[2000]\ttraining's rmse: 3.41532\tvalid_1's rmse: 3.62675\n",
      "[2500]\ttraining's rmse: 3.37378\tvalid_1's rmse: 3.62657\n",
      "Early stopping, best iteration is:\n",
      "[2336]\ttraining's rmse: 3.38718\tvalid_1's rmse: 3.6264\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60236\tvalid_1's rmse: 3.62527\n",
      "[1000]\ttraining's rmse: 3.52209\tvalid_1's rmse: 3.60971\n",
      "[1500]\ttraining's rmse: 3.46677\tvalid_1's rmse: 3.60645\n",
      "[2000]\ttraining's rmse: 3.42061\tvalid_1's rmse: 3.60595\n",
      "Early stopping, best iteration is:\n",
      "[1917]\ttraining's rmse: 3.42755\tvalid_1's rmse: 3.60569\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55591\tvalid_1's rmse: 3.80874\n",
      "[1000]\ttraining's rmse: 3.47601\tvalid_1's rmse: 3.79405\n",
      "[1500]\ttraining's rmse: 3.4216\tvalid_1's rmse: 3.79138\n",
      "[2000]\ttraining's rmse: 3.37637\tvalid_1's rmse: 3.79051\n",
      "Early stopping, best iteration is:\n",
      "[1946]\ttraining's rmse: 3.38085\tvalid_1's rmse: 3.79031\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59543\tvalid_1's rmse: 3.64389\n",
      "[1000]\ttraining's rmse: 3.51625\tvalid_1's rmse: 3.6298\n",
      "[1500]\ttraining's rmse: 3.46263\tvalid_1's rmse: 3.62603\n",
      "[2000]\ttraining's rmse: 3.41672\tvalid_1's rmse: 3.62552\n",
      "Early stopping, best iteration is:\n",
      "[1842]\ttraining's rmse: 3.43078\tvalid_1's rmse: 3.62538\n",
      "  175 | 07m03s |   -3.66607 |             0.8970 |         1.4173 |             0.5748 |             0.9337 |     13.5748 |             17.6060 |            30.3325 |            97.0788 |           0.0094 |      40.1605 |      0.4537 |       9.3976 |      0.6804 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57664\tvalid_1's rmse: 3.7143\n",
      "[1000]\ttraining's rmse: 3.48995\tvalid_1's rmse: 3.69589\n",
      "[1500]\ttraining's rmse: 3.43291\tvalid_1's rmse: 3.68966\n",
      "[2000]\ttraining's rmse: 3.38806\tvalid_1's rmse: 3.6877\n",
      "Early stopping, best iteration is:\n",
      "[2032]\ttraining's rmse: 3.38541\tvalid_1's rmse: 3.68765\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59053\tvalid_1's rmse: 3.65401\n",
      "[1000]\ttraining's rmse: 3.50261\tvalid_1's rmse: 3.63624\n",
      "[1500]\ttraining's rmse: 3.44597\tvalid_1's rmse: 3.63094\n",
      "[2000]\ttraining's rmse: 3.401\tvalid_1's rmse: 3.62868\n",
      "[2500]\ttraining's rmse: 3.36156\tvalid_1's rmse: 3.62837\n",
      "Early stopping, best iteration is:\n",
      "[2448]\ttraining's rmse: 3.36514\tvalid_1's rmse: 3.62806\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59494\tvalid_1's rmse: 3.63058\n",
      "[1000]\ttraining's rmse: 3.50777\tvalid_1's rmse: 3.61461\n",
      "[1500]\ttraining's rmse: 3.44876\tvalid_1's rmse: 3.61019\n",
      "[2000]\ttraining's rmse: 3.40369\tvalid_1's rmse: 3.60986\n",
      "Early stopping, best iteration is:\n",
      "[1920]\ttraining's rmse: 3.41023\tvalid_1's rmse: 3.60949\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55077\tvalid_1's rmse: 3.80788\n",
      "[1000]\ttraining's rmse: 3.46096\tvalid_1's rmse: 3.79358\n",
      "[1500]\ttraining's rmse: 3.40194\tvalid_1's rmse: 3.78895\n",
      "[2000]\ttraining's rmse: 3.35641\tvalid_1's rmse: 3.78787\n",
      "Early stopping, best iteration is:\n",
      "[2015]\ttraining's rmse: 3.35507\tvalid_1's rmse: 3.78774\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58761\tvalid_1's rmse: 3.65148\n",
      "[1000]\ttraining's rmse: 3.49981\tvalid_1's rmse: 3.63559\n",
      "[1500]\ttraining's rmse: 3.44229\tvalid_1's rmse: 3.63125\n",
      "[2000]\ttraining's rmse: 3.39796\tvalid_1's rmse: 3.62984\n",
      "Early stopping, best iteration is:\n",
      "[2062]\ttraining's rmse: 3.39248\tvalid_1's rmse: 3.62951\n",
      "  176 | 07m02s |   -3.66907 |             0.9869 |        16.1708 |             0.8636 |             0.8382 |     13.5535 |             15.1359 |            32.1386 |            44.5379 |           0.8011 |      32.8021 |      0.6549 |       0.4739 |      0.9846 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6321\tvalid_1's rmse: 3.72889\n",
      "[1000]\ttraining's rmse: 3.55477\tvalid_1's rmse: 3.70284\n",
      "[1500]\ttraining's rmse: 3.50291\tvalid_1's rmse: 3.69309\n",
      "[2000]\ttraining's rmse: 3.46182\tvalid_1's rmse: 3.68891\n",
      "[2500]\ttraining's rmse: 3.42641\tvalid_1's rmse: 3.68723\n",
      "[3000]\ttraining's rmse: 3.39505\tvalid_1's rmse: 3.68628\n",
      "[3500]\ttraining's rmse: 3.3659\tvalid_1's rmse: 3.68549\n",
      "Early stopping, best iteration is:\n",
      "[3703]\ttraining's rmse: 3.35513\tvalid_1's rmse: 3.68524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64599\tvalid_1's rmse: 3.667\n",
      "[1000]\ttraining's rmse: 3.56663\tvalid_1's rmse: 3.64521\n",
      "[1500]\ttraining's rmse: 3.51459\tvalid_1's rmse: 3.63683\n",
      "[2000]\ttraining's rmse: 3.47325\tvalid_1's rmse: 3.63247\n",
      "[2500]\ttraining's rmse: 3.43735\tvalid_1's rmse: 3.63007\n",
      "[3000]\ttraining's rmse: 3.40483\tvalid_1's rmse: 3.62836\n",
      "[3500]\ttraining's rmse: 3.37495\tvalid_1's rmse: 3.62721\n",
      "[4000]\ttraining's rmse: 3.34694\tvalid_1's rmse: 3.62678\n",
      "Early stopping, best iteration is:\n",
      "[3889]\ttraining's rmse: 3.35319\tvalid_1's rmse: 3.62672\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65086\tvalid_1's rmse: 3.64357\n",
      "[1000]\ttraining's rmse: 3.57225\tvalid_1's rmse: 3.62208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.52068\tvalid_1's rmse: 3.61441\n",
      "[2000]\ttraining's rmse: 3.47956\tvalid_1's rmse: 3.61098\n",
      "[2500]\ttraining's rmse: 3.444\tvalid_1's rmse: 3.60931\n",
      "[3000]\ttraining's rmse: 3.4122\tvalid_1's rmse: 3.60876\n",
      "Early stopping, best iteration is:\n",
      "[3242]\ttraining's rmse: 3.39745\tvalid_1's rmse: 3.60837\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60405\tvalid_1's rmse: 3.83518\n",
      "[1000]\ttraining's rmse: 3.52621\tvalid_1's rmse: 3.81113\n",
      "[1500]\ttraining's rmse: 3.47517\tvalid_1's rmse: 3.80227\n",
      "[2000]\ttraining's rmse: 3.43444\tvalid_1's rmse: 3.79822\n",
      "[2500]\ttraining's rmse: 3.39932\tvalid_1's rmse: 3.79618\n",
      "[3000]\ttraining's rmse: 3.36767\tvalid_1's rmse: 3.79501\n",
      "[3500]\ttraining's rmse: 3.3384\tvalid_1's rmse: 3.79389\n",
      "[4000]\ttraining's rmse: 3.31092\tvalid_1's rmse: 3.79298\n",
      "[4500]\ttraining's rmse: 3.28562\tvalid_1's rmse: 3.79267\n",
      "Early stopping, best iteration is:\n",
      "[4460]\ttraining's rmse: 3.28768\tvalid_1's rmse: 3.79263\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64535\tvalid_1's rmse: 3.66193\n",
      "[1000]\ttraining's rmse: 3.56622\tvalid_1's rmse: 3.6421\n",
      "[1500]\ttraining's rmse: 3.51435\tvalid_1's rmse: 3.63412\n",
      "[2000]\ttraining's rmse: 3.47333\tvalid_1's rmse: 3.63023\n",
      "[2500]\ttraining's rmse: 3.43801\tvalid_1's rmse: 3.62832\n",
      "[3000]\ttraining's rmse: 3.40615\tvalid_1's rmse: 3.62755\n",
      "[3500]\ttraining's rmse: 3.37726\tvalid_1's rmse: 3.62718\n",
      "Early stopping, best iteration is:\n",
      "[3442]\ttraining's rmse: 3.38028\tvalid_1's rmse: 3.62707\n",
      "  177 | 06m39s |   -3.66863 |             0.9521 |         4.7365 |             0.1304 |             0.1844 |     14.2685 |             47.6135 |            44.2999 |            62.5608 |           0.9438 |      35.7008 |      9.2248 |       6.4195 |      0.7157 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58092\tvalid_1's rmse: 3.70834\n",
      "[1000]\ttraining's rmse: 3.50454\tvalid_1's rmse: 3.68945\n",
      "[1500]\ttraining's rmse: 3.45413\tvalid_1's rmse: 3.68392\n",
      "[2000]\ttraining's rmse: 3.41305\tvalid_1's rmse: 3.68293\n",
      "Early stopping, best iteration is:\n",
      "[1855]\ttraining's rmse: 3.4241\tvalid_1's rmse: 3.68278\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59367\tvalid_1's rmse: 3.64879\n",
      "[1000]\ttraining's rmse: 3.51472\tvalid_1's rmse: 3.63165\n",
      "[1500]\ttraining's rmse: 3.4642\tvalid_1's rmse: 3.62759\n",
      "[2000]\ttraining's rmse: 3.42271\tvalid_1's rmse: 3.6268\n",
      "Early stopping, best iteration is:\n",
      "[1856]\ttraining's rmse: 3.434\tvalid_1's rmse: 3.62666\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59897\tvalid_1's rmse: 3.62674\n",
      "[1000]\ttraining's rmse: 3.51997\tvalid_1's rmse: 3.6127\n",
      "[1500]\ttraining's rmse: 3.46799\tvalid_1's rmse: 3.60894\n",
      "[2000]\ttraining's rmse: 3.42659\tvalid_1's rmse: 3.6085\n",
      "Early stopping, best iteration is:\n",
      "[1941]\ttraining's rmse: 3.43138\tvalid_1's rmse: 3.60837\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55325\tvalid_1's rmse: 3.80668\n",
      "[1000]\ttraining's rmse: 3.47425\tvalid_1's rmse: 3.79184\n",
      "[1500]\ttraining's rmse: 3.4235\tvalid_1's rmse: 3.78914\n",
      "[2000]\ttraining's rmse: 3.38345\tvalid_1's rmse: 3.78888\n",
      "Early stopping, best iteration is:\n",
      "[1904]\ttraining's rmse: 3.39079\tvalid_1's rmse: 3.78877\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5915\tvalid_1's rmse: 3.64512\n",
      "[1000]\ttraining's rmse: 3.51369\tvalid_1's rmse: 3.6312\n",
      "[1500]\ttraining's rmse: 3.46274\tvalid_1's rmse: 3.6263\n",
      "[2000]\ttraining's rmse: 3.421\tvalid_1's rmse: 3.62454\n",
      "Early stopping, best iteration is:\n",
      "[2033]\ttraining's rmse: 3.41864\tvalid_1's rmse: 3.6244\n",
      "  178 | 06m25s |   -3.66680 |             0.9595 |         0.3032 |             0.1534 |             0.8147 |     11.8582 |             47.1710 |            39.9842 |            80.9034 |           0.3159 |      37.0658 |      4.6169 |       0.2897 |      0.3765 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58881\tvalid_1's rmse: 3.7152\n",
      "[1000]\ttraining's rmse: 3.5076\tvalid_1's rmse: 3.69455\n",
      "[1500]\ttraining's rmse: 3.45325\tvalid_1's rmse: 3.68729\n",
      "[2000]\ttraining's rmse: 3.41051\tvalid_1's rmse: 3.68532\n",
      "[2500]\ttraining's rmse: 3.37246\tvalid_1's rmse: 3.68392\n",
      "Early stopping, best iteration is:\n",
      "[2647]\ttraining's rmse: 3.36191\tvalid_1's rmse: 3.68346\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60144\tvalid_1's rmse: 3.6558\n",
      "[1000]\ttraining's rmse: 3.51778\tvalid_1's rmse: 3.63811\n",
      "[1500]\ttraining's rmse: 3.46472\tvalid_1's rmse: 3.63137\n",
      "[2000]\ttraining's rmse: 3.42103\tvalid_1's rmse: 3.62821\n",
      "Early stopping, best iteration is:\n",
      "[2135]\ttraining's rmse: 3.40939\tvalid_1's rmse: 3.62812\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60506\tvalid_1's rmse: 3.63132\n",
      "[1000]\ttraining's rmse: 3.52363\tvalid_1's rmse: 3.61448\n",
      "[1500]\ttraining's rmse: 3.46702\tvalid_1's rmse: 3.6105\n",
      "[2000]\ttraining's rmse: 3.42373\tvalid_1's rmse: 3.60925\n",
      "Early stopping, best iteration is:\n",
      "[2044]\ttraining's rmse: 3.4207\tvalid_1's rmse: 3.60916\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5612\tvalid_1's rmse: 3.81054\n",
      "[1000]\ttraining's rmse: 3.47708\tvalid_1's rmse: 3.7957\n",
      "[1500]\ttraining's rmse: 3.42097\tvalid_1's rmse: 3.79076\n",
      "[2000]\ttraining's rmse: 3.3779\tvalid_1's rmse: 3.78913\n",
      "Early stopping, best iteration is:\n",
      "[2244]\ttraining's rmse: 3.36006\tvalid_1's rmse: 3.78847\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5997\tvalid_1's rmse: 3.65215\n",
      "[1000]\ttraining's rmse: 3.51818\tvalid_1's rmse: 3.63636\n",
      "[1500]\ttraining's rmse: 3.46273\tvalid_1's rmse: 3.63211\n",
      "[2000]\ttraining's rmse: 3.41985\tvalid_1's rmse: 3.62946\n",
      "[2500]\ttraining's rmse: 3.38256\tvalid_1's rmse: 3.6298\n",
      "Early stopping, best iteration is:\n",
      "[2350]\ttraining's rmse: 3.39313\tvalid_1's rmse: 3.62904\n",
      "  179 | 06m59s |   -3.66823 |             0.9469 |        19.0455 |             0.8028 |             0.7716 |     13.6589 |             48.9612 |            44.3757 |            19.1743 |           0.0798 |      30.1478 |      0.3300 |       1.9717 |      0.3685 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65016\tvalid_1's rmse: 3.71773\n",
      "[1000]\ttraining's rmse: 3.60811\tvalid_1's rmse: 3.69691\n",
      "[1500]\ttraining's rmse: 3.57827\tvalid_1's rmse: 3.69001\n",
      "[2000]\ttraining's rmse: 3.55387\tvalid_1's rmse: 3.68664\n",
      "[2500]\ttraining's rmse: 3.53186\tvalid_1's rmse: 3.6854\n",
      "[3000]\ttraining's rmse: 3.51062\tvalid_1's rmse: 3.68475\n",
      "[3500]\ttraining's rmse: 3.49145\tvalid_1's rmse: 3.68418\n",
      "Early stopping, best iteration is:\n",
      "[3641]\ttraining's rmse: 3.48577\tvalid_1's rmse: 3.68384\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6633\tvalid_1's rmse: 3.65883\n",
      "[1000]\ttraining's rmse: 3.61862\tvalid_1's rmse: 3.64032\n",
      "[1500]\ttraining's rmse: 3.58931\tvalid_1's rmse: 3.63429\n",
      "[2000]\ttraining's rmse: 3.56405\tvalid_1's rmse: 3.63062\n",
      "[2500]\ttraining's rmse: 3.54145\tvalid_1's rmse: 3.62894\n",
      "[3000]\ttraining's rmse: 3.52164\tvalid_1's rmse: 3.62745\n",
      "[3500]\ttraining's rmse: 3.50126\tvalid_1's rmse: 3.62675\n",
      "[4000]\ttraining's rmse: 3.48257\tvalid_1's rmse: 3.62597\n",
      "[4500]\ttraining's rmse: 3.46335\tvalid_1's rmse: 3.6258\n",
      "Early stopping, best iteration is:\n",
      "[4364]\ttraining's rmse: 3.46859\tvalid_1's rmse: 3.62561\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66913\tvalid_1's rmse: 3.63096\n",
      "[1000]\ttraining's rmse: 3.62345\tvalid_1's rmse: 3.61261\n",
      "[1500]\ttraining's rmse: 3.5945\tvalid_1's rmse: 3.60808\n",
      "[2000]\ttraining's rmse: 3.56998\tvalid_1's rmse: 3.60631\n",
      "[2500]\ttraining's rmse: 3.54693\tvalid_1's rmse: 3.60554\n",
      "Early stopping, best iteration is:\n",
      "[2323]\ttraining's rmse: 3.55461\tvalid_1's rmse: 3.6054\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62323\tvalid_1's rmse: 3.82249\n",
      "[1000]\ttraining's rmse: 3.57678\tvalid_1's rmse: 3.80438\n",
      "[1500]\ttraining's rmse: 3.54893\tvalid_1's rmse: 3.79895\n",
      "[2000]\ttraining's rmse: 3.5255\tvalid_1's rmse: 3.79635\n",
      "[2500]\ttraining's rmse: 3.50368\tvalid_1's rmse: 3.79501\n",
      "[3000]\ttraining's rmse: 3.48236\tvalid_1's rmse: 3.79389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500]\ttraining's rmse: 3.46244\tvalid_1's rmse: 3.79319\n",
      "[4000]\ttraining's rmse: 3.44225\tvalid_1's rmse: 3.79284\n",
      "Early stopping, best iteration is:\n",
      "[3952]\ttraining's rmse: 3.44423\tvalid_1's rmse: 3.79264\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66348\tvalid_1's rmse: 3.64923\n",
      "[1000]\ttraining's rmse: 3.61703\tvalid_1's rmse: 3.63138\n",
      "[1500]\ttraining's rmse: 3.58784\tvalid_1's rmse: 3.62528\n",
      "[2000]\ttraining's rmse: 3.56356\tvalid_1's rmse: 3.62316\n",
      "[2500]\ttraining's rmse: 3.54064\tvalid_1's rmse: 3.62226\n",
      "Early stopping, best iteration is:\n",
      "[2542]\ttraining's rmse: 3.53872\tvalid_1's rmse: 3.62216\n",
      "  180 | 06m59s |   -3.66657 |             0.8717 |         8.2669 |             0.2895 |             0.5182 |      5.4687 |             49.2892 |            44.4535 |            15.7566 |           0.3903 |      44.9527 |      9.3457 |       0.4887 |      0.8402 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00269942]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65172\tvalid_1's rmse: 3.71614\n",
      "[1000]\ttraining's rmse: 3.6126\tvalid_1's rmse: 3.6973\n",
      "[1500]\ttraining's rmse: 3.58642\tvalid_1's rmse: 3.69065\n",
      "[2000]\ttraining's rmse: 3.56476\tvalid_1's rmse: 3.68711\n",
      "[2500]\ttraining's rmse: 3.54617\tvalid_1's rmse: 3.68611\n",
      "[3000]\ttraining's rmse: 3.52707\tvalid_1's rmse: 3.68567\n",
      "Early stopping, best iteration is:\n",
      "[2869]\ttraining's rmse: 3.53265\tvalid_1's rmse: 3.68537\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6657\tvalid_1's rmse: 3.65777\n",
      "[1000]\ttraining's rmse: 3.62383\tvalid_1's rmse: 3.64041\n",
      "[1500]\ttraining's rmse: 3.59688\tvalid_1's rmse: 3.63445\n",
      "[2000]\ttraining's rmse: 3.57465\tvalid_1's rmse: 3.63\n",
      "[2500]\ttraining's rmse: 3.55491\tvalid_1's rmse: 3.62816\n",
      "[3000]\ttraining's rmse: 3.53617\tvalid_1's rmse: 3.62726\n",
      "[3500]\ttraining's rmse: 3.51913\tvalid_1's rmse: 3.62605\n",
      "Early stopping, best iteration is:\n",
      "[3411]\ttraining's rmse: 3.52129\tvalid_1's rmse: 3.62593\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67069\tvalid_1's rmse: 3.63002\n",
      "[1000]\ttraining's rmse: 3.62881\tvalid_1's rmse: 3.61247\n",
      "[1500]\ttraining's rmse: 3.60263\tvalid_1's rmse: 3.60688\n",
      "[2000]\ttraining's rmse: 3.5812\tvalid_1's rmse: 3.60521\n",
      "[2500]\ttraining's rmse: 3.5613\tvalid_1's rmse: 3.60488\n",
      "[3000]\ttraining's rmse: 3.54282\tvalid_1's rmse: 3.604\n",
      "Early stopping, best iteration is:\n",
      "[3152]\ttraining's rmse: 3.53698\tvalid_1's rmse: 3.60351\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62379\tvalid_1's rmse: 3.81921\n",
      "[1000]\ttraining's rmse: 3.58082\tvalid_1's rmse: 3.80336\n",
      "[1500]\ttraining's rmse: 3.55565\tvalid_1's rmse: 3.79859\n",
      "[2000]\ttraining's rmse: 3.53498\tvalid_1's rmse: 3.79665\n",
      "Early stopping, best iteration is:\n",
      "[2240]\ttraining's rmse: 3.52306\tvalid_1's rmse: 3.79573\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66597\tvalid_1's rmse: 3.64669\n",
      "[1000]\ttraining's rmse: 3.62202\tvalid_1's rmse: 3.62991\n",
      "[1500]\ttraining's rmse: 3.59618\tvalid_1's rmse: 3.62485\n",
      "[2000]\ttraining's rmse: 3.57517\tvalid_1's rmse: 3.62161\n",
      "[2500]\ttraining's rmse: 3.55347\tvalid_1's rmse: 3.62034\n",
      "Early stopping, best iteration is:\n",
      "[2479]\ttraining's rmse: 3.55402\tvalid_1's rmse: 3.62023\n",
      "  181 | 06m40s |   -3.66683 |             0.8346 |        16.0970 |             0.4062 |             0.6867 |      5.8809 |             31.0795 |            43.9948 |            86.0370 |           0.1239 |      32.1869 |      9.9090 |       1.4232 |      0.9929 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55741\tvalid_1's rmse: 3.70409\n",
      "[1000]\ttraining's rmse: 3.47218\tvalid_1's rmse: 3.68641\n",
      "[1500]\ttraining's rmse: 3.41133\tvalid_1's rmse: 3.68252\n",
      "[2000]\ttraining's rmse: 3.36003\tvalid_1's rmse: 3.68161\n",
      "[2500]\ttraining's rmse: 3.31512\tvalid_1's rmse: 3.68148\n",
      "Early stopping, best iteration is:\n",
      "[2350]\ttraining's rmse: 3.32824\tvalid_1's rmse: 3.68138\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56826\tvalid_1's rmse: 3.64813\n",
      "[1000]\ttraining's rmse: 3.48089\tvalid_1's rmse: 3.63193\n",
      "[1500]\ttraining's rmse: 3.41928\tvalid_1's rmse: 3.62755\n",
      "[2000]\ttraining's rmse: 3.36742\tvalid_1's rmse: 3.62663\n",
      "Early stopping, best iteration is:\n",
      "[2012]\ttraining's rmse: 3.36627\tvalid_1's rmse: 3.62654\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57269\tvalid_1's rmse: 3.62451\n",
      "[1000]\ttraining's rmse: 3.48449\tvalid_1's rmse: 3.6107\n",
      "[1500]\ttraining's rmse: 3.42419\tvalid_1's rmse: 3.60757\n",
      "Early stopping, best iteration is:\n",
      "[1787]\ttraining's rmse: 3.39298\tvalid_1's rmse: 3.60681\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.52919\tvalid_1's rmse: 3.80471\n",
      "[1000]\ttraining's rmse: 3.44018\tvalid_1's rmse: 3.79094\n",
      "[1500]\ttraining's rmse: 3.3789\tvalid_1's rmse: 3.78813\n",
      "[2000]\ttraining's rmse: 3.32832\tvalid_1's rmse: 3.78786\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's rmse: 3.34035\tvalid_1's rmse: 3.78754\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56668\tvalid_1's rmse: 3.64441\n",
      "[1000]\ttraining's rmse: 3.47867\tvalid_1's rmse: 3.63012\n",
      "[1500]\ttraining's rmse: 3.41835\tvalid_1's rmse: 3.62644\n",
      "[2000]\ttraining's rmse: 3.36803\tvalid_1's rmse: 3.62561\n",
      "Early stopping, best iteration is:\n",
      "[1923]\ttraining's rmse: 3.37552\tvalid_1's rmse: 3.62556\n",
      "  182 | 06m53s |   -3.66616 |             0.9419 |         1.6375 |             0.1123 |             0.7392 |     10.5638 |             11.6348 |            33.8900 |            55.6652 |           0.9128 |      44.9599 |      8.5758 |       0.2942 |      0.4301 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6124\tvalid_1's rmse: 3.70701\n",
      "[1000]\ttraining's rmse: 3.5625\tvalid_1's rmse: 3.69101\n",
      "[1500]\ttraining's rmse: 3.52384\tvalid_1's rmse: 3.68523\n",
      "[2000]\ttraining's rmse: 3.49348\tvalid_1's rmse: 3.685\n",
      "Early stopping, best iteration is:\n",
      "[1835]\ttraining's rmse: 3.5026\tvalid_1's rmse: 3.68456\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62458\tvalid_1's rmse: 3.64952\n",
      "[1000]\ttraining's rmse: 3.56974\tvalid_1's rmse: 3.63534\n",
      "[1500]\ttraining's rmse: 3.53388\tvalid_1's rmse: 3.63163\n",
      "[2000]\ttraining's rmse: 3.50302\tvalid_1's rmse: 3.63071\n",
      "Early stopping, best iteration is:\n",
      "[1925]\ttraining's rmse: 3.50756\tvalid_1's rmse: 3.63065\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63046\tvalid_1's rmse: 3.62435\n",
      "[1000]\ttraining's rmse: 3.57646\tvalid_1's rmse: 3.61114\n",
      "[1500]\ttraining's rmse: 3.5413\tvalid_1's rmse: 3.60916\n",
      "[2000]\ttraining's rmse: 3.50876\tvalid_1's rmse: 3.60804\n",
      "[2500]\ttraining's rmse: 3.47874\tvalid_1's rmse: 3.60748\n",
      "Early stopping, best iteration is:\n",
      "[2441]\ttraining's rmse: 3.48201\tvalid_1's rmse: 3.60733\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58188\tvalid_1's rmse: 3.80693\n",
      "[1000]\ttraining's rmse: 3.52497\tvalid_1's rmse: 3.79319\n",
      "[1500]\ttraining's rmse: 3.48865\tvalid_1's rmse: 3.79069\n",
      "[2000]\ttraining's rmse: 3.45711\tvalid_1's rmse: 3.7903\n",
      "Early stopping, best iteration is:\n",
      "[1902]\ttraining's rmse: 3.46277\tvalid_1's rmse: 3.79019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62417\tvalid_1's rmse: 3.64047\n",
      "[1000]\ttraining's rmse: 3.56777\tvalid_1's rmse: 3.62773\n",
      "[1500]\ttraining's rmse: 3.52984\tvalid_1's rmse: 3.62411\n",
      "[2000]\ttraining's rmse: 3.49715\tvalid_1's rmse: 3.62305\n",
      "Early stopping, best iteration is:\n",
      "[1979]\ttraining's rmse: 3.49856\tvalid_1's rmse: 3.62293\n",
      "  183 | 06m41s |   -3.66774 |             0.9858 |         0.2139 |             0.5315 |             0.8728 |      6.5690 |             21.4463 |            42.8022 |            57.5621 |           0.0629 |      43.6622 |      7.1954 |       2.9036 |      0.5556 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00207507]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61806\tvalid_1's rmse: 3.70861\n",
      "[1000]\ttraining's rmse: 3.56539\tvalid_1's rmse: 3.68964\n",
      "[1500]\ttraining's rmse: 3.52702\tvalid_1's rmse: 3.68403\n",
      "[2000]\ttraining's rmse: 3.49489\tvalid_1's rmse: 3.68258\n",
      "[2500]\ttraining's rmse: 3.46651\tvalid_1's rmse: 3.68232\n",
      "Early stopping, best iteration is:\n",
      "[2380]\ttraining's rmse: 3.47326\tvalid_1's rmse: 3.68211\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63131\tvalid_1's rmse: 3.65096\n",
      "[1000]\ttraining's rmse: 3.57469\tvalid_1's rmse: 3.63393\n",
      "[1500]\ttraining's rmse: 3.53772\tvalid_1's rmse: 3.62938\n",
      "[2000]\ttraining's rmse: 3.50654\tvalid_1's rmse: 3.62757\n",
      "[2500]\ttraining's rmse: 3.477\tvalid_1's rmse: 3.62669\n",
      "[3000]\ttraining's rmse: 3.44918\tvalid_1's rmse: 3.62629\n",
      "Early stopping, best iteration is:\n",
      "[2880]\ttraining's rmse: 3.4557\tvalid_1's rmse: 3.62622\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63684\tvalid_1's rmse: 3.62277\n",
      "[1000]\ttraining's rmse: 3.58114\tvalid_1's rmse: 3.60655\n",
      "[1500]\ttraining's rmse: 3.54483\tvalid_1's rmse: 3.60312\n",
      "[2000]\ttraining's rmse: 3.51234\tvalid_1's rmse: 3.60211\n",
      "[2500]\ttraining's rmse: 3.48169\tvalid_1's rmse: 3.602\n",
      "Early stopping, best iteration is:\n",
      "[2391]\ttraining's rmse: 3.48832\tvalid_1's rmse: 3.60183\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58893\tvalid_1's rmse: 3.81361\n",
      "[1000]\ttraining's rmse: 3.53254\tvalid_1's rmse: 3.7975\n",
      "[1500]\ttraining's rmse: 3.49455\tvalid_1's rmse: 3.79345\n",
      "[2000]\ttraining's rmse: 3.46242\tvalid_1's rmse: 3.79188\n",
      "[2500]\ttraining's rmse: 3.43371\tvalid_1's rmse: 3.79178\n",
      "Early stopping, best iteration is:\n",
      "[2341]\ttraining's rmse: 3.44248\tvalid_1's rmse: 3.79166\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62997\tvalid_1's rmse: 3.64314\n",
      "[1000]\ttraining's rmse: 3.57102\tvalid_1's rmse: 3.6274\n",
      "[1500]\ttraining's rmse: 3.53307\tvalid_1's rmse: 3.62324\n",
      "[2000]\ttraining's rmse: 3.5008\tvalid_1's rmse: 3.62212\n",
      "Early stopping, best iteration is:\n",
      "[2170]\ttraining's rmse: 3.49035\tvalid_1's rmse: 3.62202\n",
      "  184 | 06m05s |   -3.66541 |             0.7889 |         0.0484 |             0.9889 |             0.4751 |      6.2873 |              6.1826 |            44.9101 |            10.6571 |           0.4849 |      41.9835 |      0.8007 |       1.0992 |      0.2046 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6102\tvalid_1's rmse: 3.71129\n",
      "[1000]\ttraining's rmse: 3.54065\tvalid_1's rmse: 3.69063\n",
      "[1500]\ttraining's rmse: 3.49288\tvalid_1's rmse: 3.68482\n",
      "[2000]\ttraining's rmse: 3.45347\tvalid_1's rmse: 3.6818\n",
      "[2500]\ttraining's rmse: 3.41731\tvalid_1's rmse: 3.68078\n",
      "Early stopping, best iteration is:\n",
      "[2471]\ttraining's rmse: 3.41902\tvalid_1's rmse: 3.68057\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62295\tvalid_1's rmse: 3.65375\n",
      "[1000]\ttraining's rmse: 3.55183\tvalid_1's rmse: 3.63561\n",
      "[1500]\ttraining's rmse: 3.50455\tvalid_1's rmse: 3.62993\n",
      "[2000]\ttraining's rmse: 3.46573\tvalid_1's rmse: 3.62767\n",
      "Early stopping, best iteration is:\n",
      "[1973]\ttraining's rmse: 3.46759\tvalid_1's rmse: 3.62763\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62818\tvalid_1's rmse: 3.62854\n",
      "[1000]\ttraining's rmse: 3.55888\tvalid_1's rmse: 3.61035\n",
      "[1500]\ttraining's rmse: 3.51176\tvalid_1's rmse: 3.60509\n",
      "[2000]\ttraining's rmse: 3.47151\tvalid_1's rmse: 3.6033\n",
      "Early stopping, best iteration is:\n",
      "[2001]\ttraining's rmse: 3.47141\tvalid_1's rmse: 3.60327\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58353\tvalid_1's rmse: 3.81398\n",
      "[1000]\ttraining's rmse: 3.51176\tvalid_1's rmse: 3.79625\n",
      "[1500]\ttraining's rmse: 3.46473\tvalid_1's rmse: 3.79126\n",
      "[2000]\ttraining's rmse: 3.42446\tvalid_1's rmse: 3.78946\n",
      "Early stopping, best iteration is:\n",
      "[1899]\ttraining's rmse: 3.43227\tvalid_1's rmse: 3.78925\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62303\tvalid_1's rmse: 3.64885\n",
      "[1000]\ttraining's rmse: 3.55212\tvalid_1's rmse: 3.6324\n",
      "[1500]\ttraining's rmse: 3.505\tvalid_1's rmse: 3.62676\n",
      "[2000]\ttraining's rmse: 3.46482\tvalid_1's rmse: 3.62538\n",
      "Early stopping, best iteration is:\n",
      "[2111]\ttraining's rmse: 3.45707\tvalid_1's rmse: 3.62491\n",
      "  185 | 06m09s |   -3.66574 |             0.7542 |        19.0332 |             0.3351 |             0.6579 |     14.3065 |             45.7807 |            30.7563 |            72.1047 |           0.5416 |      30.4620 |      1.0723 |       9.2436 |      0.4919 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60999\tvalid_1's rmse: 3.70926\n",
      "[1000]\ttraining's rmse: 3.54309\tvalid_1's rmse: 3.68949\n",
      "[1500]\ttraining's rmse: 3.49838\tvalid_1's rmse: 3.68334\n",
      "[2000]\ttraining's rmse: 3.46079\tvalid_1's rmse: 3.68156\n",
      "[2500]\ttraining's rmse: 3.42661\tvalid_1's rmse: 3.68071\n",
      "[3000]\ttraining's rmse: 3.39502\tvalid_1's rmse: 3.68036\n",
      "Early stopping, best iteration is:\n",
      "[2842]\ttraining's rmse: 3.4047\tvalid_1's rmse: 3.68029\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62389\tvalid_1's rmse: 3.65264\n",
      "[1000]\ttraining's rmse: 3.55609\tvalid_1's rmse: 3.63442\n",
      "[1500]\ttraining's rmse: 3.51114\tvalid_1's rmse: 3.62882\n",
      "[2000]\ttraining's rmse: 3.47242\tvalid_1's rmse: 3.62627\n",
      "[2500]\ttraining's rmse: 3.4382\tvalid_1's rmse: 3.62561\n",
      "[3000]\ttraining's rmse: 3.40643\tvalid_1's rmse: 3.62503\n",
      "[3500]\ttraining's rmse: 3.37597\tvalid_1's rmse: 3.62462\n",
      "Early stopping, best iteration is:\n",
      "[3737]\ttraining's rmse: 3.36253\tvalid_1's rmse: 3.62431\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6292\tvalid_1's rmse: 3.62748\n",
      "[1000]\ttraining's rmse: 3.56105\tvalid_1's rmse: 3.6106\n",
      "[1500]\ttraining's rmse: 3.51578\tvalid_1's rmse: 3.60673\n",
      "[2000]\ttraining's rmse: 3.47796\tvalid_1's rmse: 3.60495\n",
      "Early stopping, best iteration is:\n",
      "[2067]\ttraining's rmse: 3.4732\tvalid_1's rmse: 3.60482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58391\tvalid_1's rmse: 3.81121\n",
      "[1000]\ttraining's rmse: 3.51481\tvalid_1's rmse: 3.79502\n",
      "[1500]\ttraining's rmse: 3.47023\tvalid_1's rmse: 3.79099\n",
      "[2000]\ttraining's rmse: 3.43215\tvalid_1's rmse: 3.78964\n",
      "[2500]\ttraining's rmse: 3.39794\tvalid_1's rmse: 3.78872\n",
      "Early stopping, best iteration is:\n",
      "[2611]\ttraining's rmse: 3.39073\tvalid_1's rmse: 3.78856\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62366\tvalid_1's rmse: 3.64715\n",
      "[1000]\ttraining's rmse: 3.55567\tvalid_1's rmse: 3.63197\n",
      "[1500]\ttraining's rmse: 3.50994\tvalid_1's rmse: 3.62775\n",
      "[2000]\ttraining's rmse: 3.47201\tvalid_1's rmse: 3.62568\n",
      "Early stopping, best iteration is:\n",
      "[2184]\ttraining's rmse: 3.45926\tvalid_1's rmse: 3.62528\n",
      "  186 | 07m52s |   -3.66526 |             0.8253 |         2.6110 |             0.6486 |             0.7718 |     14.3675 |              6.9145 |            41.7280 |            92.8054 |           0.2829 |      30.1913 |      1.4815 |       9.7871 |      0.7257 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0006319]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56802\tvalid_1's rmse: 3.71562\n",
      "[1000]\ttraining's rmse: 3.47497\tvalid_1's rmse: 3.69636\n",
      "[1500]\ttraining's rmse: 3.41041\tvalid_1's rmse: 3.68928\n",
      "[2000]\ttraining's rmse: 3.3635\tvalid_1's rmse: 3.68759\n",
      "Early stopping, best iteration is:\n",
      "[2132]\ttraining's rmse: 3.35208\tvalid_1's rmse: 3.68736\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58195\tvalid_1's rmse: 3.65413\n",
      "[1000]\ttraining's rmse: 3.48695\tvalid_1's rmse: 3.63644\n",
      "[1500]\ttraining's rmse: 3.42495\tvalid_1's rmse: 3.63148\n",
      "[2000]\ttraining's rmse: 3.37745\tvalid_1's rmse: 3.62992\n",
      "Early stopping, best iteration is:\n",
      "[1952]\ttraining's rmse: 3.38165\tvalid_1's rmse: 3.62972\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58621\tvalid_1's rmse: 3.63324\n",
      "[1000]\ttraining's rmse: 3.49064\tvalid_1's rmse: 3.6166\n",
      "[1500]\ttraining's rmse: 3.42679\tvalid_1's rmse: 3.61287\n",
      "[2000]\ttraining's rmse: 3.37968\tvalid_1's rmse: 3.61203\n",
      "Early stopping, best iteration is:\n",
      "[2127]\ttraining's rmse: 3.36921\tvalid_1's rmse: 3.61185\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54233\tvalid_1's rmse: 3.81013\n",
      "[1000]\ttraining's rmse: 3.44494\tvalid_1's rmse: 3.79491\n",
      "[1500]\ttraining's rmse: 3.38073\tvalid_1's rmse: 3.78953\n",
      "[2000]\ttraining's rmse: 3.33407\tvalid_1's rmse: 3.78848\n",
      "[2500]\ttraining's rmse: 3.29534\tvalid_1's rmse: 3.78829\n",
      "Early stopping, best iteration is:\n",
      "[2309]\ttraining's rmse: 3.30975\tvalid_1's rmse: 3.78817\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57907\tvalid_1's rmse: 3.65217\n",
      "[1000]\ttraining's rmse: 3.48326\tvalid_1's rmse: 3.63706\n",
      "[1500]\ttraining's rmse: 3.42057\tvalid_1's rmse: 3.63242\n",
      "[2000]\ttraining's rmse: 3.37185\tvalid_1's rmse: 3.63112\n",
      "Early stopping, best iteration is:\n",
      "[2270]\ttraining's rmse: 3.34922\tvalid_1's rmse: 3.63069\n",
      "  187 | 06m45s |   -3.67012 |             0.8021 |         0.2509 |             0.1774 |             0.7921 |     14.6690 |              5.2594 |            33.7697 |            10.3088 |           0.9020 |      33.9999 |      1.1096 |       1.4385 |      0.9840 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64704\tvalid_1's rmse: 3.71645\n",
      "[1000]\ttraining's rmse: 3.60345\tvalid_1's rmse: 3.69758\n",
      "[1500]\ttraining's rmse: 3.5727\tvalid_1's rmse: 3.69015\n",
      "[2000]\ttraining's rmse: 3.54631\tvalid_1's rmse: 3.6875\n",
      "[2500]\ttraining's rmse: 3.52327\tvalid_1's rmse: 3.68569\n",
      "[3000]\ttraining's rmse: 3.50119\tvalid_1's rmse: 3.68514\n",
      "[3500]\ttraining's rmse: 3.47968\tvalid_1's rmse: 3.68454\n",
      "Early stopping, best iteration is:\n",
      "[3500]\ttraining's rmse: 3.47968\tvalid_1's rmse: 3.68454\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6612\tvalid_1's rmse: 3.65772\n",
      "[1000]\ttraining's rmse: 3.61646\tvalid_1's rmse: 3.6404\n",
      "[1500]\ttraining's rmse: 3.58592\tvalid_1's rmse: 3.63406\n",
      "[2000]\ttraining's rmse: 3.55945\tvalid_1's rmse: 3.63088\n",
      "[2500]\ttraining's rmse: 3.53578\tvalid_1's rmse: 3.62865\n",
      "[3000]\ttraining's rmse: 3.5129\tvalid_1's rmse: 3.6273\n",
      "[3500]\ttraining's rmse: 3.49025\tvalid_1's rmse: 3.62617\n",
      "[4000]\ttraining's rmse: 3.47051\tvalid_1's rmse: 3.62594\n",
      "Early stopping, best iteration is:\n",
      "[3890]\ttraining's rmse: 3.47474\tvalid_1's rmse: 3.62586\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66684\tvalid_1's rmse: 3.6297\n",
      "[1000]\ttraining's rmse: 3.61984\tvalid_1's rmse: 3.61179\n",
      "[1500]\ttraining's rmse: 3.5897\tvalid_1's rmse: 3.60793\n",
      "[2000]\ttraining's rmse: 3.56438\tvalid_1's rmse: 3.60609\n",
      "Early stopping, best iteration is:\n",
      "[2185]\ttraining's rmse: 3.55543\tvalid_1's rmse: 3.60581\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61912\tvalid_1's rmse: 3.81874\n",
      "[1000]\ttraining's rmse: 3.57174\tvalid_1's rmse: 3.80215\n",
      "[1500]\ttraining's rmse: 3.542\tvalid_1's rmse: 3.79748\n",
      "[2000]\ttraining's rmse: 3.51671\tvalid_1's rmse: 3.79552\n",
      "[2500]\ttraining's rmse: 3.49286\tvalid_1's rmse: 3.79396\n",
      "[3000]\ttraining's rmse: 3.47042\tvalid_1's rmse: 3.79308\n",
      "Early stopping, best iteration is:\n",
      "[3259]\ttraining's rmse: 3.45849\tvalid_1's rmse: 3.79264\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66191\tvalid_1's rmse: 3.64825\n",
      "[1000]\ttraining's rmse: 3.61322\tvalid_1's rmse: 3.63193\n",
      "[1500]\ttraining's rmse: 3.58208\tvalid_1's rmse: 3.62596\n",
      "[2000]\ttraining's rmse: 3.55577\tvalid_1's rmse: 3.62395\n",
      "[2500]\ttraining's rmse: 3.53236\tvalid_1's rmse: 3.62313\n",
      "Early stopping, best iteration is:\n",
      "[2643]\ttraining's rmse: 3.52639\tvalid_1's rmse: 3.62292\n",
      "  188 | 07m27s |   -3.66699 |             0.8823 |         5.4951 |             0.9717 |             0.7489 |      5.8539 |             24.9187 |            32.2262 |            24.4998 |           0.1185 |      30.3262 |      5.3880 |       8.9318 |      0.5743 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62719\tvalid_1's rmse: 3.72611\n",
      "[1000]\ttraining's rmse: 3.54728\tvalid_1's rmse: 3.70008\n",
      "[1500]\ttraining's rmse: 3.49358\tvalid_1's rmse: 3.69058\n",
      "[2000]\ttraining's rmse: 3.45036\tvalid_1's rmse: 3.68667\n",
      "[2500]\ttraining's rmse: 3.4126\tvalid_1's rmse: 3.68434\n",
      "[3000]\ttraining's rmse: 3.37905\tvalid_1's rmse: 3.68335\n",
      "[3500]\ttraining's rmse: 3.34791\tvalid_1's rmse: 3.68287\n",
      "Early stopping, best iteration is:\n",
      "[3430]\ttraining's rmse: 3.3523\tvalid_1's rmse: 3.68274\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64033\tvalid_1's rmse: 3.66444\n",
      "[1000]\ttraining's rmse: 3.55911\tvalid_1's rmse: 3.64262\n",
      "[1500]\ttraining's rmse: 3.50522\tvalid_1's rmse: 3.63461\n",
      "[2000]\ttraining's rmse: 3.46207\tvalid_1's rmse: 3.63091\n",
      "[2500]\ttraining's rmse: 3.42396\tvalid_1's rmse: 3.62922\n",
      "[3000]\ttraining's rmse: 3.38983\tvalid_1's rmse: 3.62803\n",
      "[3500]\ttraining's rmse: 3.35856\tvalid_1's rmse: 3.62746\n",
      "Early stopping, best iteration is:\n",
      "[3555]\ttraining's rmse: 3.35517\tvalid_1's rmse: 3.62723\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64578\tvalid_1's rmse: 3.63925\n",
      "[1000]\ttraining's rmse: 3.56511\tvalid_1's rmse: 3.61768\n",
      "[1500]\ttraining's rmse: 3.51065\tvalid_1's rmse: 3.60996\n",
      "[2000]\ttraining's rmse: 3.4675\tvalid_1's rmse: 3.60659\n",
      "[2500]\ttraining's rmse: 3.43\tvalid_1's rmse: 3.60481\n",
      "[3000]\ttraining's rmse: 3.39551\tvalid_1's rmse: 3.6042\n",
      "Early stopping, best iteration is:\n",
      "[3122]\ttraining's rmse: 3.38743\tvalid_1's rmse: 3.60395\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59788\tvalid_1's rmse: 3.83343\n",
      "[1000]\ttraining's rmse: 3.51786\tvalid_1's rmse: 3.81044\n",
      "[1500]\ttraining's rmse: 3.46437\tvalid_1's rmse: 3.80225\n",
      "[2000]\ttraining's rmse: 3.42154\tvalid_1's rmse: 3.79897\n",
      "[2500]\ttraining's rmse: 3.385\tvalid_1's rmse: 3.79768\n",
      "[3000]\ttraining's rmse: 3.35192\tvalid_1's rmse: 3.79645\n",
      "[3500]\ttraining's rmse: 3.32044\tvalid_1's rmse: 3.79596\n",
      "Early stopping, best iteration is:\n",
      "[3374]\ttraining's rmse: 3.3282\tvalid_1's rmse: 3.79582\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63981\tvalid_1's rmse: 3.65822\n",
      "[1000]\ttraining's rmse: 3.55855\tvalid_1's rmse: 3.6379\n",
      "[1500]\ttraining's rmse: 3.50424\tvalid_1's rmse: 3.63035\n",
      "[2000]\ttraining's rmse: 3.46061\tvalid_1's rmse: 3.62691\n",
      "[2500]\ttraining's rmse: 3.42298\tvalid_1's rmse: 3.62555\n",
      "[3000]\ttraining's rmse: 3.38917\tvalid_1's rmse: 3.62497\n",
      "Early stopping, best iteration is:\n",
      "[2861]\ttraining's rmse: 3.39814\tvalid_1's rmse: 3.62491\n",
      "  189 | 06m25s |   -3.66759 |             0.9584 |         1.4845 |             0.2748 |             0.1771 |     14.6622 |             49.2947 |            32.1565 |            94.9967 |           0.4314 |      44.7282 |      5.0214 |       9.6632 |      0.7617 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60094\tvalid_1's rmse: 3.71246\n",
      "[1000]\ttraining's rmse: 3.52712\tvalid_1's rmse: 3.69278\n",
      "[1500]\ttraining's rmse: 3.47526\tvalid_1's rmse: 3.68502\n",
      "Early stopping, best iteration is:\n",
      "[1758]\ttraining's rmse: 3.45163\tvalid_1's rmse: 3.6842\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61462\tvalid_1's rmse: 3.65562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.5383\tvalid_1's rmse: 3.63765\n",
      "[1500]\ttraining's rmse: 3.48596\tvalid_1's rmse: 3.62909\n",
      "[2000]\ttraining's rmse: 3.44341\tvalid_1's rmse: 3.6261\n",
      "Early stopping, best iteration is:\n",
      "[1919]\ttraining's rmse: 3.45011\tvalid_1's rmse: 3.62596\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61843\tvalid_1's rmse: 3.63095\n",
      "[1000]\ttraining's rmse: 3.54275\tvalid_1's rmse: 3.61341\n",
      "[1500]\ttraining's rmse: 3.48958\tvalid_1's rmse: 3.60961\n",
      "Early stopping, best iteration is:\n",
      "[1674]\ttraining's rmse: 3.47408\tvalid_1's rmse: 3.6089\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57399\tvalid_1's rmse: 3.81416\n",
      "[1000]\ttraining's rmse: 3.49557\tvalid_1's rmse: 3.79764\n",
      "[1500]\ttraining's rmse: 3.44475\tvalid_1's rmse: 3.79361\n",
      "Early stopping, best iteration is:\n",
      "[1558]\ttraining's rmse: 3.43945\tvalid_1's rmse: 3.79307\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61218\tvalid_1's rmse: 3.65019\n",
      "[1000]\ttraining's rmse: 3.53852\tvalid_1's rmse: 3.63654\n",
      "[1500]\ttraining's rmse: 3.48374\tvalid_1's rmse: 3.6318\n",
      "[2000]\ttraining's rmse: 3.44028\tvalid_1's rmse: 3.63015\n",
      "Early stopping, best iteration is:\n",
      "[2160]\ttraining's rmse: 3.42639\tvalid_1's rmse: 3.62943\n",
      "  190 | 06m03s |   -3.66893 |             0.5405 |        19.7625 |             0.2373 |             0.9053 |     13.8594 |             49.6091 |            42.8838 |            41.4802 |           0.3099 |      31.4281 |      1.5020 |       9.3428 |      0.1434 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00418278]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61646\tvalid_1's rmse: 3.70858\n",
      "[1000]\ttraining's rmse: 3.56157\tvalid_1's rmse: 3.68873\n",
      "[1500]\ttraining's rmse: 3.52285\tvalid_1's rmse: 3.68312\n",
      "[2000]\ttraining's rmse: 3.48792\tvalid_1's rmse: 3.68073\n",
      "Early stopping, best iteration is:\n",
      "[2258]\ttraining's rmse: 3.47358\tvalid_1's rmse: 3.68061\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62942\tvalid_1's rmse: 3.65311\n",
      "[1000]\ttraining's rmse: 3.57111\tvalid_1's rmse: 3.63599\n",
      "[1500]\ttraining's rmse: 3.53087\tvalid_1's rmse: 3.63072\n",
      "[2000]\ttraining's rmse: 3.49896\tvalid_1's rmse: 3.62844\n",
      "[2500]\ttraining's rmse: 3.46509\tvalid_1's rmse: 3.6274\n",
      "Early stopping, best iteration is:\n",
      "[2538]\ttraining's rmse: 3.46286\tvalid_1's rmse: 3.62728\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63525\tvalid_1's rmse: 3.62351\n",
      "[1000]\ttraining's rmse: 3.57554\tvalid_1's rmse: 3.60707\n",
      "[1500]\ttraining's rmse: 3.53809\tvalid_1's rmse: 3.60281\n",
      "[2000]\ttraining's rmse: 3.50356\tvalid_1's rmse: 3.60237\n",
      "Early stopping, best iteration is:\n",
      "[1870]\ttraining's rmse: 3.51245\tvalid_1's rmse: 3.60205\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58822\tvalid_1's rmse: 3.81436\n",
      "[1000]\ttraining's rmse: 3.52795\tvalid_1's rmse: 3.79678\n",
      "[1500]\ttraining's rmse: 3.49121\tvalid_1's rmse: 3.79289\n",
      "[2000]\ttraining's rmse: 3.45613\tvalid_1's rmse: 3.79135\n",
      "[2500]\ttraining's rmse: 3.42474\tvalid_1's rmse: 3.79076\n",
      "[3000]\ttraining's rmse: 3.39685\tvalid_1's rmse: 3.79043\n",
      "[3500]\ttraining's rmse: 3.36937\tvalid_1's rmse: 3.79003\n",
      "Early stopping, best iteration is:\n",
      "[3308]\ttraining's rmse: 3.37983\tvalid_1's rmse: 3.78989\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62824\tvalid_1's rmse: 3.64269\n",
      "[1000]\ttraining's rmse: 3.5672\tvalid_1's rmse: 3.62732\n",
      "[1500]\ttraining's rmse: 3.52699\tvalid_1's rmse: 3.62265\n",
      "Early stopping, best iteration is:\n",
      "[1711]\ttraining's rmse: 3.51382\tvalid_1's rmse: 3.62182\n",
      "  191 | 06m50s |   -3.66496 |             0.9627 |        18.1335 |             0.5791 |             0.4367 |      6.7674 |             49.9914 |            41.7335 |            18.0926 |           0.1581 |      44.8113 |      8.7848 |       0.1884 |      0.1151 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00124632]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63116\tvalid_1's rmse: 3.72306\n",
      "[1000]\ttraining's rmse: 3.56087\tvalid_1's rmse: 3.69757\n",
      "[1500]\ttraining's rmse: 3.51478\tvalid_1's rmse: 3.68827\n",
      "[2000]\ttraining's rmse: 3.47568\tvalid_1's rmse: 3.68491\n",
      "[2500]\ttraining's rmse: 3.44032\tvalid_1's rmse: 3.68261\n",
      "Early stopping, best iteration is:\n",
      "[2799]\ttraining's rmse: 3.4202\tvalid_1's rmse: 3.68187\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64354\tvalid_1's rmse: 3.66083\n",
      "[1000]\ttraining's rmse: 3.57141\tvalid_1's rmse: 3.63889\n",
      "[1500]\ttraining's rmse: 3.5241\tvalid_1's rmse: 3.63132\n",
      "[2000]\ttraining's rmse: 3.48531\tvalid_1's rmse: 3.62765\n",
      "[2500]\ttraining's rmse: 3.44966\tvalid_1's rmse: 3.62573\n",
      "Early stopping, best iteration is:\n",
      "[2588]\ttraining's rmse: 3.44333\tvalid_1's rmse: 3.62539\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64794\tvalid_1's rmse: 3.63654\n",
      "[1000]\ttraining's rmse: 3.57679\tvalid_1's rmse: 3.61581\n",
      "[1500]\ttraining's rmse: 3.52878\tvalid_1's rmse: 3.60979\n",
      "[2000]\ttraining's rmse: 3.48946\tvalid_1's rmse: 3.60756\n",
      "[2500]\ttraining's rmse: 3.4534\tvalid_1's rmse: 3.60663\n",
      "Early stopping, best iteration is:\n",
      "[2577]\ttraining's rmse: 3.448\tvalid_1's rmse: 3.6064\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60153\tvalid_1's rmse: 3.83076\n",
      "[1000]\ttraining's rmse: 3.53053\tvalid_1's rmse: 3.80795\n",
      "[1500]\ttraining's rmse: 3.4836\tvalid_1's rmse: 3.80037\n",
      "[2000]\ttraining's rmse: 3.44416\tvalid_1's rmse: 3.79764\n",
      "[2500]\ttraining's rmse: 3.40853\tvalid_1's rmse: 3.79642\n",
      "[3000]\ttraining's rmse: 3.37524\tvalid_1's rmse: 3.79612\n",
      "Early stopping, best iteration is:\n",
      "[2942]\ttraining's rmse: 3.37934\tvalid_1's rmse: 3.79605\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6432\tvalid_1's rmse: 3.6552\n",
      "[1000]\ttraining's rmse: 3.5708\tvalid_1's rmse: 3.63477\n",
      "[1500]\ttraining's rmse: 3.52205\tvalid_1's rmse: 3.62834\n",
      "[2000]\ttraining's rmse: 3.48248\tvalid_1's rmse: 3.62578\n",
      "[2500]\ttraining's rmse: 3.44809\tvalid_1's rmse: 3.62543\n",
      "Early stopping, best iteration is:\n",
      "[2325]\ttraining's rmse: 3.45982\tvalid_1's rmse: 3.62501\n",
      "  192 | 06m03s |   -3.66760 |             0.7698 |        19.0752 |             0.3470 |             0.2117 |      9.4005 |             49.9746 |            42.9707 |            98.5200 |           0.2707 |      44.7507 |      2.5039 |       7.1834 |      0.4779 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54106\tvalid_1's rmse: 3.70917\n",
      "[1000]\ttraining's rmse: 3.43938\tvalid_1's rmse: 3.69172\n",
      "[1500]\ttraining's rmse: 3.37002\tvalid_1's rmse: 3.68632\n",
      "[2000]\ttraining's rmse: 3.31496\tvalid_1's rmse: 3.68568\n",
      "Early stopping, best iteration is:\n",
      "[2069]\ttraining's rmse: 3.30835\tvalid_1's rmse: 3.6852\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55315\tvalid_1's rmse: 3.65246\n",
      "[1000]\ttraining's rmse: 3.45007\tvalid_1's rmse: 3.63619\n",
      "[1500]\ttraining's rmse: 3.38114\tvalid_1's rmse: 3.6318\n",
      "[2000]\ttraining's rmse: 3.32691\tvalid_1's rmse: 3.63122\n",
      "Early stopping, best iteration is:\n",
      "[2069]\ttraining's rmse: 3.31907\tvalid_1's rmse: 3.63095\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55767\tvalid_1's rmse: 3.62708\n",
      "[1000]\ttraining's rmse: 3.45613\tvalid_1's rmse: 3.61301\n",
      "[1500]\ttraining's rmse: 3.38443\tvalid_1's rmse: 3.60897\n",
      "Early stopping, best iteration is:\n",
      "[1556]\ttraining's rmse: 3.37781\tvalid_1's rmse: 3.60869\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5133\tvalid_1's rmse: 3.80631\n",
      "[1000]\ttraining's rmse: 3.40787\tvalid_1's rmse: 3.7911\n",
      "[1500]\ttraining's rmse: 3.34097\tvalid_1's rmse: 3.78741\n",
      "Early stopping, best iteration is:\n",
      "[1416]\ttraining's rmse: 3.35054\tvalid_1's rmse: 3.78729\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5516\tvalid_1's rmse: 3.6483\n",
      "[1000]\ttraining's rmse: 3.4486\tvalid_1's rmse: 3.63477\n",
      "[1500]\ttraining's rmse: 3.38082\tvalid_1's rmse: 3.63071\n",
      "Early stopping, best iteration is:\n",
      "[1517]\ttraining's rmse: 3.37881\tvalid_1's rmse: 3.63061\n",
      "  193 | 07m18s |   -3.66912 |             0.9697 |        18.1431 |             0.8192 |             0.8496 |     13.2085 |              6.8966 |            42.9348 |            10.0920 |           0.2108 |      43.9038 |      7.8835 |       0.8088 |      0.1186 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0001805]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60697\tvalid_1's rmse: 3.70437\n",
      "[1000]\ttraining's rmse: 3.55329\tvalid_1's rmse: 3.68792\n",
      "[1500]\ttraining's rmse: 3.51386\tvalid_1's rmse: 3.68359\n",
      "[2000]\ttraining's rmse: 3.47937\tvalid_1's rmse: 3.68262\n",
      "Early stopping, best iteration is:\n",
      "[2159]\ttraining's rmse: 3.46969\tvalid_1's rmse: 3.68215\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61882\tvalid_1's rmse: 3.64944\n",
      "[1000]\ttraining's rmse: 3.56073\tvalid_1's rmse: 3.63446\n",
      "[1500]\ttraining's rmse: 3.51819\tvalid_1's rmse: 3.63026\n",
      "[2000]\ttraining's rmse: 3.48556\tvalid_1's rmse: 3.62923\n",
      "[2500]\ttraining's rmse: 3.45397\tvalid_1's rmse: 3.6292\n",
      "Early stopping, best iteration is:\n",
      "[2427]\ttraining's rmse: 3.45894\tvalid_1's rmse: 3.62872\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62549\tvalid_1's rmse: 3.62458\n",
      "[1000]\ttraining's rmse: 3.56887\tvalid_1's rmse: 3.61165\n",
      "[1500]\ttraining's rmse: 3.52964\tvalid_1's rmse: 3.60891\n",
      "[2000]\ttraining's rmse: 3.49536\tvalid_1's rmse: 3.6083\n",
      "Early stopping, best iteration is:\n",
      "[1945]\ttraining's rmse: 3.50007\tvalid_1's rmse: 3.60817\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57913\tvalid_1's rmse: 3.80768\n",
      "[1000]\ttraining's rmse: 3.51976\tvalid_1's rmse: 3.79431\n",
      "[1500]\ttraining's rmse: 3.48163\tvalid_1's rmse: 3.79155\n",
      "[2000]\ttraining's rmse: 3.44571\tvalid_1's rmse: 3.7904\n",
      "Early stopping, best iteration is:\n",
      "[2176]\ttraining's rmse: 3.43557\tvalid_1's rmse: 3.78989\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61977\tvalid_1's rmse: 3.64055\n",
      "[1000]\ttraining's rmse: 3.55904\tvalid_1's rmse: 3.62776\n",
      "[1500]\ttraining's rmse: 3.51755\tvalid_1's rmse: 3.62505\n",
      "Early stopping, best iteration is:\n",
      "[1772]\ttraining's rmse: 3.49869\tvalid_1's rmse: 3.62433\n",
      "  194 | 07m23s |   -3.66725 |             0.9821 |        18.3959 |             0.1606 |             0.8334 |      6.5808 |             45.7437 |            44.3353 |            35.0380 |           0.8005 |      44.7677 |      4.7321 |       1.5320 |      0.7098 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65168\tvalid_1's rmse: 3.7148\n",
      "[1000]\ttraining's rmse: 3.61331\tvalid_1's rmse: 3.69727\n",
      "[1500]\ttraining's rmse: 3.58534\tvalid_1's rmse: 3.69017\n",
      "[2000]\ttraining's rmse: 3.56435\tvalid_1's rmse: 3.68904\n",
      "[2500]\ttraining's rmse: 3.54656\tvalid_1's rmse: 3.68792\n",
      "Early stopping, best iteration is:\n",
      "[2448]\ttraining's rmse: 3.54803\tvalid_1's rmse: 3.68765\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66488\tvalid_1's rmse: 3.65665\n",
      "[1000]\ttraining's rmse: 3.62427\tvalid_1's rmse: 3.63892\n",
      "[1500]\ttraining's rmse: 3.59976\tvalid_1's rmse: 3.63377\n",
      "[2000]\ttraining's rmse: 3.57839\tvalid_1's rmse: 3.6318\n",
      "[2500]\ttraining's rmse: 3.56007\tvalid_1's rmse: 3.62993\n",
      "Early stopping, best iteration is:\n",
      "[2640]\ttraining's rmse: 3.55507\tvalid_1's rmse: 3.62968\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66946\tvalid_1's rmse: 3.63183\n",
      "[1000]\ttraining's rmse: 3.6288\tvalid_1's rmse: 3.61574\n",
      "[1500]\ttraining's rmse: 3.602\tvalid_1's rmse: 3.61205\n",
      "[2000]\ttraining's rmse: 3.57844\tvalid_1's rmse: 3.60917\n",
      "Early stopping, best iteration is:\n",
      "[1976]\ttraining's rmse: 3.57971\tvalid_1's rmse: 3.60902\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62402\tvalid_1's rmse: 3.82017\n",
      "[1000]\ttraining's rmse: 3.58387\tvalid_1's rmse: 3.80562\n",
      "[1500]\ttraining's rmse: 3.55759\tvalid_1's rmse: 3.80103\n",
      "[2000]\ttraining's rmse: 3.53647\tvalid_1's rmse: 3.7991\n",
      "[2500]\ttraining's rmse: 3.51707\tvalid_1's rmse: 3.79783\n",
      "Early stopping, best iteration is:\n",
      "[2736]\ttraining's rmse: 3.508\tvalid_1's rmse: 3.79731\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66704\tvalid_1's rmse: 3.649\n",
      "[1000]\ttraining's rmse: 3.62714\tvalid_1's rmse: 3.63424\n",
      "[1500]\ttraining's rmse: 3.59824\tvalid_1's rmse: 3.62905\n",
      "[2000]\ttraining's rmse: 3.57663\tvalid_1's rmse: 3.62754\n",
      "Early stopping, best iteration is:\n",
      "[2242]\ttraining's rmse: 3.56655\tvalid_1's rmse: 3.62675\n",
      "  195 | 06m43s |   -3.67073 |             0.7572 |        19.2926 |             0.5144 |             0.9330 |      5.1287 |              5.2400 |            44.5761 |            83.8781 |           0.4221 |      30.2467 |      6.4075 |       8.2688 |      0.8537 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60761\tvalid_1's rmse: 3.70982\n",
      "[1000]\ttraining's rmse: 3.53987\tvalid_1's rmse: 3.6899\n",
      "[1500]\ttraining's rmse: 3.49519\tvalid_1's rmse: 3.683\n",
      "[2000]\ttraining's rmse: 3.46094\tvalid_1's rmse: 3.68094\n",
      "[2500]\ttraining's rmse: 3.43046\tvalid_1's rmse: 3.68033\n",
      "Early stopping, best iteration is:\n",
      "[2549]\ttraining's rmse: 3.42748\tvalid_1's rmse: 3.68026\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62085\tvalid_1's rmse: 3.65088\n",
      "[1000]\ttraining's rmse: 3.55141\tvalid_1's rmse: 3.6334\n",
      "[1500]\ttraining's rmse: 3.50744\tvalid_1's rmse: 3.62863\n",
      "[2000]\ttraining's rmse: 3.4711\tvalid_1's rmse: 3.6269\n",
      "[2500]\ttraining's rmse: 3.44024\tvalid_1's rmse: 3.62575\n",
      "Early stopping, best iteration is:\n",
      "[2729]\ttraining's rmse: 3.42741\tvalid_1's rmse: 3.62546\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62517\tvalid_1's rmse: 3.62721\n",
      "[1000]\ttraining's rmse: 3.55637\tvalid_1's rmse: 3.61022\n",
      "[1500]\ttraining's rmse: 3.51056\tvalid_1's rmse: 3.60568\n",
      "[2000]\ttraining's rmse: 3.47525\tvalid_1's rmse: 3.60407\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's rmse: 3.48181\tvalid_1's rmse: 3.60395\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58076\tvalid_1's rmse: 3.81135\n",
      "[1000]\ttraining's rmse: 3.51054\tvalid_1's rmse: 3.79503\n",
      "[1500]\ttraining's rmse: 3.46633\tvalid_1's rmse: 3.79056\n",
      "[2000]\ttraining's rmse: 3.43195\tvalid_1's rmse: 3.78961\n",
      "Early stopping, best iteration is:\n",
      "[2089]\ttraining's rmse: 3.42654\tvalid_1's rmse: 3.78936\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62\tvalid_1's rmse: 3.6463\n",
      "[1000]\ttraining's rmse: 3.55026\tvalid_1's rmse: 3.63071\n",
      "[1500]\ttraining's rmse: 3.50703\tvalid_1's rmse: 3.62498\n",
      "[2000]\ttraining's rmse: 3.47185\tvalid_1's rmse: 3.6224\n",
      "[2500]\ttraining's rmse: 3.44148\tvalid_1's rmse: 3.62148\n",
      "Early stopping, best iteration is:\n",
      "[2598]\ttraining's rmse: 3.4358\tvalid_1's rmse: 3.62144\n",
      "  196 | 06m53s |   -3.66472 |             0.9892 |         0.0720 |             0.4314 |             0.7542 |     12.9870 |             13.6092 |            44.2670 |            99.0639 |           0.9091 |      31.5148 |      0.3887 |       9.7479 |      0.9999 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00196648]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60233\tvalid_1's rmse: 3.70953\n",
      "[1000]\ttraining's rmse: 3.53169\tvalid_1's rmse: 3.68941\n",
      "[1500]\ttraining's rmse: 3.4843\tvalid_1's rmse: 3.68378\n",
      "[2000]\ttraining's rmse: 3.44353\tvalid_1's rmse: 3.68161\n",
      "[2500]\ttraining's rmse: 3.40826\tvalid_1's rmse: 3.68124\n",
      "Early stopping, best iteration is:\n",
      "[2372]\ttraining's rmse: 3.41656\tvalid_1's rmse: 3.68074\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61626\tvalid_1's rmse: 3.65041\n",
      "[1000]\ttraining's rmse: 3.54442\tvalid_1's rmse: 3.6327\n",
      "[1500]\ttraining's rmse: 3.49677\tvalid_1's rmse: 3.62781\n",
      "[2000]\ttraining's rmse: 3.45674\tvalid_1's rmse: 3.62606\n",
      "Early stopping, best iteration is:\n",
      "[2147]\ttraining's rmse: 3.44565\tvalid_1's rmse: 3.62567\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62109\tvalid_1's rmse: 3.62731\n",
      "[1000]\ttraining's rmse: 3.54919\tvalid_1's rmse: 3.61015\n",
      "[1500]\ttraining's rmse: 3.50113\tvalid_1's rmse: 3.60536\n",
      "[2000]\ttraining's rmse: 3.46147\tvalid_1's rmse: 3.604\n",
      "Early stopping, best iteration is:\n",
      "[2052]\ttraining's rmse: 3.45769\tvalid_1's rmse: 3.60383\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57645\tvalid_1's rmse: 3.81087\n",
      "[1000]\ttraining's rmse: 3.50363\tvalid_1's rmse: 3.79447\n",
      "[1500]\ttraining's rmse: 3.45615\tvalid_1's rmse: 3.7906\n",
      "Early stopping, best iteration is:\n",
      "[1726]\ttraining's rmse: 3.43674\tvalid_1's rmse: 3.78943\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61528\tvalid_1's rmse: 3.6466\n",
      "[1000]\ttraining's rmse: 3.54337\tvalid_1's rmse: 3.63125\n",
      "[1500]\ttraining's rmse: 3.49634\tvalid_1's rmse: 3.62612\n",
      "[2000]\ttraining's rmse: 3.45628\tvalid_1's rmse: 3.62504\n",
      "Early stopping, best iteration is:\n",
      "[1938]\ttraining's rmse: 3.46123\tvalid_1's rmse: 3.62473\n",
      "  197 | 06m59s |   -3.66550 |             0.8419 |         5.0827 |             0.7805 |             0.7697 |     13.6140 |             36.4496 |            37.9953 |            85.3859 |           0.2074 |      32.7688 |      7.2996 |       8.6533 |      0.6866 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00633746]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60234\tvalid_1's rmse: 3.71242\n",
      "[1000]\ttraining's rmse: 3.53523\tvalid_1's rmse: 3.69403\n",
      "[1500]\ttraining's rmse: 3.48473\tvalid_1's rmse: 3.68941\n",
      "[2000]\ttraining's rmse: 3.44093\tvalid_1's rmse: 3.68807\n",
      "Early stopping, best iteration is:\n",
      "[2015]\ttraining's rmse: 3.43937\tvalid_1's rmse: 3.68778\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61346\tvalid_1's rmse: 3.65237\n",
      "[1000]\ttraining's rmse: 3.54608\tvalid_1's rmse: 3.63813\n",
      "[1500]\ttraining's rmse: 3.49644\tvalid_1's rmse: 3.6336\n",
      "[2000]\ttraining's rmse: 3.45162\tvalid_1's rmse: 3.63163\n",
      "Early stopping, best iteration is:\n",
      "[1861]\ttraining's rmse: 3.46376\tvalid_1's rmse: 3.63133\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61974\tvalid_1's rmse: 3.62787\n",
      "[1000]\ttraining's rmse: 3.54823\tvalid_1's rmse: 3.61581\n",
      "[1500]\ttraining's rmse: 3.49729\tvalid_1's rmse: 3.61408\n",
      "Early stopping, best iteration is:\n",
      "[1549]\ttraining's rmse: 3.49233\tvalid_1's rmse: 3.61364\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57101\tvalid_1's rmse: 3.81603\n",
      "[1000]\ttraining's rmse: 3.50355\tvalid_1's rmse: 3.80237\n",
      "[1500]\ttraining's rmse: 3.45247\tvalid_1's rmse: 3.80036\n",
      "Early stopping, best iteration is:\n",
      "[1497]\ttraining's rmse: 3.45279\tvalid_1's rmse: 3.8003\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61455\tvalid_1's rmse: 3.64651\n",
      "[1000]\ttraining's rmse: 3.54601\tvalid_1's rmse: 3.63393\n",
      "[1500]\ttraining's rmse: 3.49504\tvalid_1's rmse: 3.63192\n",
      "Early stopping, best iteration is:\n",
      "[1780]\ttraining's rmse: 3.46954\tvalid_1's rmse: 3.63083\n",
      "  198 | 05m58s |   -3.67342 |             0.2826 |         3.8665 |             0.6816 |             0.4940 |      8.9763 |              8.2408 |            30.4872 |            10.2940 |           0.0170 |      44.4153 |      9.2449 |       0.2096 |      0.2417 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5877\tvalid_1's rmse: 3.7154\n",
      "[1000]\ttraining's rmse: 3.50278\tvalid_1's rmse: 3.69518\n",
      "[1500]\ttraining's rmse: 3.44596\tvalid_1's rmse: 3.68778\n",
      "[2000]\ttraining's rmse: 3.40177\tvalid_1's rmse: 3.68552\n",
      "[2500]\ttraining's rmse: 3.36506\tvalid_1's rmse: 3.68491\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's rmse: 3.37509\tvalid_1's rmse: 3.68482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60021\tvalid_1's rmse: 3.65557\n",
      "[1000]\ttraining's rmse: 3.5151\tvalid_1's rmse: 3.63823\n",
      "[1500]\ttraining's rmse: 3.45811\tvalid_1's rmse: 3.63362\n",
      "Early stopping, best iteration is:\n",
      "[1792]\ttraining's rmse: 3.43175\tvalid_1's rmse: 3.63263\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60585\tvalid_1's rmse: 3.63078\n",
      "[1000]\ttraining's rmse: 3.52081\tvalid_1's rmse: 3.61417\n",
      "[1500]\ttraining's rmse: 3.46227\tvalid_1's rmse: 3.60917\n",
      "[2000]\ttraining's rmse: 3.41962\tvalid_1's rmse: 3.60794\n",
      "Early stopping, best iteration is:\n",
      "[2254]\ttraining's rmse: 3.40107\tvalid_1's rmse: 3.60766\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56118\tvalid_1's rmse: 3.81302\n",
      "[1000]\ttraining's rmse: 3.47328\tvalid_1's rmse: 3.79644\n",
      "[1500]\ttraining's rmse: 3.41673\tvalid_1's rmse: 3.79119\n",
      "[2000]\ttraining's rmse: 3.37454\tvalid_1's rmse: 3.7894\n",
      "Early stopping, best iteration is:\n",
      "[2167]\ttraining's rmse: 3.36202\tvalid_1's rmse: 3.78903\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59817\tvalid_1's rmse: 3.65273\n",
      "[1000]\ttraining's rmse: 3.51162\tvalid_1's rmse: 3.63734\n",
      "[1500]\ttraining's rmse: 3.45591\tvalid_1's rmse: 3.63174\n",
      "[2000]\ttraining's rmse: 3.41309\tvalid_1's rmse: 3.63051\n",
      "[2500]\ttraining's rmse: 3.37748\tvalid_1's rmse: 3.63\n",
      "Early stopping, best iteration is:\n",
      "[2348]\ttraining's rmse: 3.38757\tvalid_1's rmse: 3.62981\n",
      "  199 | 06m52s |   -3.66937 |             0.9849 |         0.0874 |             0.3928 |             0.8804 |     12.9563 |             17.8560 |            32.5721 |            39.6413 |           0.7852 |      32.6198 |      4.9413 |       9.8906 |      0.9041 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63128\tvalid_1's rmse: 3.71005\n",
      "[1000]\ttraining's rmse: 3.58593\tvalid_1's rmse: 3.6916\n",
      "[1500]\ttraining's rmse: 3.55495\tvalid_1's rmse: 3.68609\n",
      "[2000]\ttraining's rmse: 3.52844\tvalid_1's rmse: 3.6843\n",
      "[2500]\ttraining's rmse: 3.50437\tvalid_1's rmse: 3.68385\n",
      "Early stopping, best iteration is:\n",
      "[2760]\ttraining's rmse: 3.49193\tvalid_1's rmse: 3.68351\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6444\tvalid_1's rmse: 3.65272\n",
      "[1000]\ttraining's rmse: 3.59702\tvalid_1's rmse: 3.63621\n",
      "[1500]\ttraining's rmse: 3.56646\tvalid_1's rmse: 3.63072\n",
      "[2000]\ttraining's rmse: 3.53958\tvalid_1's rmse: 3.62826\n",
      "[2500]\ttraining's rmse: 3.51506\tvalid_1's rmse: 3.62724\n",
      "[3000]\ttraining's rmse: 3.4923\tvalid_1's rmse: 3.62681\n",
      "Early stopping, best iteration is:\n",
      "[2829]\ttraining's rmse: 3.49994\tvalid_1's rmse: 3.62652\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64956\tvalid_1's rmse: 3.62755\n",
      "[1000]\ttraining's rmse: 3.60253\tvalid_1's rmse: 3.61219\n",
      "[1500]\ttraining's rmse: 3.57014\tvalid_1's rmse: 3.6074\n",
      "[2000]\ttraining's rmse: 3.54257\tvalid_1's rmse: 3.60654\n",
      "Early stopping, best iteration is:\n",
      "[1850]\ttraining's rmse: 3.55076\tvalid_1's rmse: 3.6064\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60272\tvalid_1's rmse: 3.81226\n",
      "[1000]\ttraining's rmse: 3.55519\tvalid_1's rmse: 3.79645\n",
      "[1500]\ttraining's rmse: 3.52183\tvalid_1's rmse: 3.79228\n",
      "[2000]\ttraining's rmse: 3.49514\tvalid_1's rmse: 3.79046\n",
      "[2500]\ttraining's rmse: 3.47172\tvalid_1's rmse: 3.79018\n",
      "[3000]\ttraining's rmse: 3.44961\tvalid_1's rmse: 3.78994\n",
      "Early stopping, best iteration is:\n",
      "[3042]\ttraining's rmse: 3.4479\tvalid_1's rmse: 3.78988\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64514\tvalid_1's rmse: 3.64457\n",
      "[1000]\ttraining's rmse: 3.59631\tvalid_1's rmse: 3.62989\n",
      "[1500]\ttraining's rmse: 3.56349\tvalid_1's rmse: 3.62467\n",
      "[2000]\ttraining's rmse: 3.53556\tvalid_1's rmse: 3.62286\n",
      "[2500]\ttraining's rmse: 3.51188\tvalid_1's rmse: 3.62269\n",
      "Early stopping, best iteration is:\n",
      "[2362]\ttraining's rmse: 3.51864\tvalid_1's rmse: 3.6224\n",
      "  200 | 07m03s |   -3.66636 |             0.9433 |         0.1246 |             0.3594 |             0.8019 |      6.5204 |             36.0765 |            31.5898 |            95.0598 |           0.8761 |      30.3382 |      8.8507 |       0.5145 |      0.7957 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62965\tvalid_1's rmse: 3.73359\n",
      "[1000]\ttraining's rmse: 3.54724\tvalid_1's rmse: 3.70596\n",
      "[1500]\ttraining's rmse: 3.48941\tvalid_1's rmse: 3.69542\n",
      "[2000]\ttraining's rmse: 3.44395\tvalid_1's rmse: 3.69094\n",
      "[2500]\ttraining's rmse: 3.40355\tvalid_1's rmse: 3.68835\n",
      "[3000]\ttraining's rmse: 3.36691\tvalid_1's rmse: 3.68696\n",
      "[3500]\ttraining's rmse: 3.33254\tvalid_1's rmse: 3.68615\n",
      "Early stopping, best iteration is:\n",
      "[3492]\ttraining's rmse: 3.33303\tvalid_1's rmse: 3.6861\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64325\tvalid_1's rmse: 3.67089\n",
      "[1000]\ttraining's rmse: 3.5584\tvalid_1's rmse: 3.64804\n",
      "[1500]\ttraining's rmse: 3.50081\tvalid_1's rmse: 3.63883\n",
      "[2000]\ttraining's rmse: 3.45427\tvalid_1's rmse: 3.63382\n",
      "[2500]\ttraining's rmse: 3.4139\tvalid_1's rmse: 3.63116\n",
      "[3000]\ttraining's rmse: 3.37789\tvalid_1's rmse: 3.62982\n",
      "[3500]\ttraining's rmse: 3.34396\tvalid_1's rmse: 3.6288\n",
      "[4000]\ttraining's rmse: 3.3115\tvalid_1's rmse: 3.62891\n",
      "Early stopping, best iteration is:\n",
      "[3802]\ttraining's rmse: 3.32429\tvalid_1's rmse: 3.6286\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64891\tvalid_1's rmse: 3.64641\n",
      "[1000]\ttraining's rmse: 3.56504\tvalid_1's rmse: 3.62425\n",
      "[1500]\ttraining's rmse: 3.50666\tvalid_1's rmse: 3.61622\n",
      "[2000]\ttraining's rmse: 3.46017\tvalid_1's rmse: 3.61216\n",
      "[2500]\ttraining's rmse: 3.41968\tvalid_1's rmse: 3.60979\n",
      "Early stopping, best iteration is:\n",
      "[2719]\ttraining's rmse: 3.40357\tvalid_1's rmse: 3.60914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60107\tvalid_1's rmse: 3.84092\n",
      "[1000]\ttraining's rmse: 3.51696\tvalid_1's rmse: 3.81576\n",
      "[1500]\ttraining's rmse: 3.45935\tvalid_1's rmse: 3.8064\n",
      "[2000]\ttraining's rmse: 3.41337\tvalid_1's rmse: 3.80183\n",
      "[2500]\ttraining's rmse: 3.37392\tvalid_1's rmse: 3.7997\n",
      "[3000]\ttraining's rmse: 3.33851\tvalid_1's rmse: 3.7983\n",
      "[3500]\ttraining's rmse: 3.30451\tvalid_1's rmse: 3.7974\n",
      "Early stopping, best iteration is:\n",
      "[3504]\ttraining's rmse: 3.30426\tvalid_1's rmse: 3.79738\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64317\tvalid_1's rmse: 3.66551\n",
      "[1000]\ttraining's rmse: 3.55743\tvalid_1's rmse: 3.64442\n",
      "[1500]\ttraining's rmse: 3.49918\tvalid_1's rmse: 3.63646\n",
      "[2000]\ttraining's rmse: 3.4531\tvalid_1's rmse: 3.6325\n",
      "[2500]\ttraining's rmse: 3.41316\tvalid_1's rmse: 3.63094\n",
      "[3000]\ttraining's rmse: 3.37725\tvalid_1's rmse: 3.62998\n",
      "[3500]\ttraining's rmse: 3.34315\tvalid_1's rmse: 3.6298\n",
      "Early stopping, best iteration is:\n",
      "[3312]\ttraining's rmse: 3.35558\tvalid_1's rmse: 3.6297\n",
      "  201 | 06m46s |   -3.67083 |             0.8911 |        15.4728 |             0.9063 |             0.1417 |     13.4066 |              6.2981 |            30.1965 |            69.4913 |           0.1820 |      44.5698 |      1.2829 |       0.1614 |      0.8100 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57326\tvalid_1's rmse: 3.71336\n",
      "[1000]\ttraining's rmse: 3.4863\tvalid_1's rmse: 3.69531\n",
      "[1500]\ttraining's rmse: 3.42712\tvalid_1's rmse: 3.6901\n",
      "[2000]\ttraining's rmse: 3.38085\tvalid_1's rmse: 3.68687\n",
      "Early stopping, best iteration is:\n",
      "[2236]\ttraining's rmse: 3.36115\tvalid_1's rmse: 3.68626\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5876\tvalid_1's rmse: 3.65476\n",
      "[1000]\ttraining's rmse: 3.49822\tvalid_1's rmse: 3.63718\n",
      "[1500]\ttraining's rmse: 3.43991\tvalid_1's rmse: 3.63139\n",
      "[2000]\ttraining's rmse: 3.39191\tvalid_1's rmse: 3.62979\n",
      "[2500]\ttraining's rmse: 3.35139\tvalid_1's rmse: 3.62915\n",
      "Early stopping, best iteration is:\n",
      "[2391]\ttraining's rmse: 3.35961\tvalid_1's rmse: 3.62911\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59106\tvalid_1's rmse: 3.63052\n",
      "[1000]\ttraining's rmse: 3.5014\tvalid_1's rmse: 3.61424\n",
      "[1500]\ttraining's rmse: 3.44232\tvalid_1's rmse: 3.61027\n",
      "Early stopping, best iteration is:\n",
      "[1735]\ttraining's rmse: 3.42058\tvalid_1's rmse: 3.60943\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54678\tvalid_1's rmse: 3.80725\n",
      "[1000]\ttraining's rmse: 3.45621\tvalid_1's rmse: 3.79296\n",
      "[1500]\ttraining's rmse: 3.39695\tvalid_1's rmse: 3.78912\n",
      "Early stopping, best iteration is:\n",
      "[1712]\ttraining's rmse: 3.3771\tvalid_1's rmse: 3.78874\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58425\tvalid_1's rmse: 3.65022\n",
      "[1000]\ttraining's rmse: 3.49668\tvalid_1's rmse: 3.63474\n",
      "[1500]\ttraining's rmse: 3.4377\tvalid_1's rmse: 3.63076\n",
      "[2000]\ttraining's rmse: 3.39191\tvalid_1's rmse: 3.62886\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's rmse: 3.40402\tvalid_1's rmse: 3.62864\n",
      "  202 | 07m43s |   -3.66902 |             0.9353 |        16.0459 |             0.7819 |             0.9242 |     14.0169 |              6.5867 |            44.8721 |            35.5229 |           0.8459 |      33.0235 |      9.6059 |       1.2237 |      0.1216 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55757\tvalid_1's rmse: 3.70632\n",
      "[1000]\ttraining's rmse: 3.46253\tvalid_1's rmse: 3.6888\n",
      "[1500]\ttraining's rmse: 3.39611\tvalid_1's rmse: 3.68339\n",
      "[2000]\ttraining's rmse: 3.34128\tvalid_1's rmse: 3.6819\n",
      "Early stopping, best iteration is:\n",
      "[1976]\ttraining's rmse: 3.34348\tvalid_1's rmse: 3.68178\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56894\tvalid_1's rmse: 3.6503\n",
      "[1000]\ttraining's rmse: 3.47504\tvalid_1's rmse: 3.63405\n",
      "[1500]\ttraining's rmse: 3.40922\tvalid_1's rmse: 3.63013\n",
      "Early stopping, best iteration is:\n",
      "[1767]\ttraining's rmse: 3.37867\tvalid_1's rmse: 3.6291\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57464\tvalid_1's rmse: 3.6266\n",
      "[1000]\ttraining's rmse: 3.47947\tvalid_1's rmse: 3.61084\n",
      "[1500]\ttraining's rmse: 3.41594\tvalid_1's rmse: 3.60702\n",
      "Early stopping, best iteration is:\n",
      "[1650]\ttraining's rmse: 3.39792\tvalid_1's rmse: 3.60629\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.52904\tvalid_1's rmse: 3.80758\n",
      "[1000]\ttraining's rmse: 3.4323\tvalid_1's rmse: 3.79219\n",
      "[1500]\ttraining's rmse: 3.36779\tvalid_1's rmse: 3.78875\n",
      "Early stopping, best iteration is:\n",
      "[1474]\ttraining's rmse: 3.3712\tvalid_1's rmse: 3.78857\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56662\tvalid_1's rmse: 3.64627\n",
      "[1000]\ttraining's rmse: 3.47094\tvalid_1's rmse: 3.63123\n",
      "[1500]\ttraining's rmse: 3.40478\tvalid_1's rmse: 3.62749\n",
      "Early stopping, best iteration is:\n",
      "[1422]\ttraining's rmse: 3.41442\tvalid_1's rmse: 3.62699\n",
      "  203 | 07m29s |   -3.66714 |             0.8721 |        13.4931 |             0.2351 |             0.8430 |     12.5544 |              7.6206 |            31.3112 |            49.8044 |           0.8102 |      44.9365 |      0.4965 |       8.9790 |      0.1535 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57131\tvalid_1's rmse: 3.70993\n",
      "[1000]\ttraining's rmse: 3.48\tvalid_1's rmse: 3.68974\n",
      "[1500]\ttraining's rmse: 3.41935\tvalid_1's rmse: 3.68374\n",
      "[2000]\ttraining's rmse: 3.37039\tvalid_1's rmse: 3.6818\n",
      "Early stopping, best iteration is:\n",
      "[2288]\ttraining's rmse: 3.34622\tvalid_1's rmse: 3.68153\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58431\tvalid_1's rmse: 3.65238\n",
      "[1000]\ttraining's rmse: 3.49103\tvalid_1's rmse: 3.63403\n",
      "[1500]\ttraining's rmse: 3.42954\tvalid_1's rmse: 3.62859\n",
      "[2000]\ttraining's rmse: 3.38123\tvalid_1's rmse: 3.62666\n",
      "[2500]\ttraining's rmse: 3.33955\tvalid_1's rmse: 3.62582\n",
      "Early stopping, best iteration is:\n",
      "[2422]\ttraining's rmse: 3.34612\tvalid_1's rmse: 3.62557\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5889\tvalid_1's rmse: 3.62829\n",
      "[1000]\ttraining's rmse: 3.49721\tvalid_1's rmse: 3.61079\n",
      "[1500]\ttraining's rmse: 3.43692\tvalid_1's rmse: 3.60697\n",
      "[2000]\ttraining's rmse: 3.38804\tvalid_1's rmse: 3.60573\n",
      "Early stopping, best iteration is:\n",
      "[2171]\ttraining's rmse: 3.37284\tvalid_1's rmse: 3.6056\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5429\tvalid_1's rmse: 3.81322\n",
      "[1000]\ttraining's rmse: 3.45184\tvalid_1's rmse: 3.79601\n",
      "[1500]\ttraining's rmse: 3.39038\tvalid_1's rmse: 3.79127\n",
      "[2000]\ttraining's rmse: 3.3419\tvalid_1's rmse: 3.78978\n",
      "[2500]\ttraining's rmse: 3.30176\tvalid_1's rmse: 3.78974\n",
      "Early stopping, best iteration is:\n",
      "[2301]\ttraining's rmse: 3.31736\tvalid_1's rmse: 3.78947\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58213\tvalid_1's rmse: 3.64748\n",
      "[1000]\ttraining's rmse: 3.48945\tvalid_1's rmse: 3.63106\n",
      "[1500]\ttraining's rmse: 3.42898\tvalid_1's rmse: 3.62581\n",
      "[2000]\ttraining's rmse: 3.37953\tvalid_1's rmse: 3.62416\n",
      "Early stopping, best iteration is:\n",
      "[2013]\ttraining's rmse: 3.37838\tvalid_1's rmse: 3.62412\n",
      "  204 | 06m30s |   -3.66587 |             0.9537 |         0.1742 |             0.1952 |             0.4014 |     14.3684 |             33.6405 |            30.5906 |            63.1284 |           0.2583 |      44.5813 |      9.1537 |       1.1560 |      0.7881 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63076\tvalid_1's rmse: 3.72833\n",
      "[1000]\ttraining's rmse: 3.55346\tvalid_1's rmse: 3.70297\n",
      "[1500]\ttraining's rmse: 3.50078\tvalid_1's rmse: 3.69283\n",
      "[2000]\ttraining's rmse: 3.45848\tvalid_1's rmse: 3.6888\n",
      "[2500]\ttraining's rmse: 3.42025\tvalid_1's rmse: 3.6868\n",
      "[3000]\ttraining's rmse: 3.38616\tvalid_1's rmse: 3.68559\n",
      "[3500]\ttraining's rmse: 3.35403\tvalid_1's rmse: 3.685\n",
      "[4000]\ttraining's rmse: 3.32255\tvalid_1's rmse: 3.68461\n",
      "Early stopping, best iteration is:\n",
      "[3977]\ttraining's rmse: 3.3238\tvalid_1's rmse: 3.68455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64424\tvalid_1's rmse: 3.66636\n",
      "[1000]\ttraining's rmse: 3.56458\tvalid_1's rmse: 3.64521\n",
      "[1500]\ttraining's rmse: 3.51052\tvalid_1's rmse: 3.63638\n",
      "[2000]\ttraining's rmse: 3.4678\tvalid_1's rmse: 3.63258\n",
      "[2500]\ttraining's rmse: 3.43017\tvalid_1's rmse: 3.63058\n",
      "[3000]\ttraining's rmse: 3.39552\tvalid_1's rmse: 3.62953\n",
      "[3500]\ttraining's rmse: 3.36289\tvalid_1's rmse: 3.62884\n",
      "[4000]\ttraining's rmse: 3.33203\tvalid_1's rmse: 3.62842\n",
      "[4500]\ttraining's rmse: 3.30199\tvalid_1's rmse: 3.62821\n",
      "Early stopping, best iteration is:\n",
      "[4521]\ttraining's rmse: 3.30086\tvalid_1's rmse: 3.62816\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65\tvalid_1's rmse: 3.64189\n",
      "[1000]\ttraining's rmse: 3.57103\tvalid_1's rmse: 3.61938\n",
      "[1500]\ttraining's rmse: 3.51848\tvalid_1's rmse: 3.61184\n",
      "[2000]\ttraining's rmse: 3.47486\tvalid_1's rmse: 3.60882\n",
      "[2500]\ttraining's rmse: 3.43651\tvalid_1's rmse: 3.60724\n",
      "[3000]\ttraining's rmse: 3.40105\tvalid_1's rmse: 3.60644\n",
      "Early stopping, best iteration is:\n",
      "[3164]\ttraining's rmse: 3.39001\tvalid_1's rmse: 3.60606\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60235\tvalid_1's rmse: 3.83566\n",
      "[1000]\ttraining's rmse: 3.52284\tvalid_1's rmse: 3.8113\n",
      "[1500]\ttraining's rmse: 3.47068\tvalid_1's rmse: 3.80263\n",
      "[2000]\ttraining's rmse: 3.42778\tvalid_1's rmse: 3.79877\n",
      "[2500]\ttraining's rmse: 3.38987\tvalid_1's rmse: 3.79642\n",
      "[3000]\ttraining's rmse: 3.35669\tvalid_1's rmse: 3.79553\n",
      "Early stopping, best iteration is:\n",
      "[3117]\ttraining's rmse: 3.34938\tvalid_1's rmse: 3.79527\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64444\tvalid_1's rmse: 3.66054\n",
      "[1000]\ttraining's rmse: 3.56406\tvalid_1's rmse: 3.64119\n",
      "[1500]\ttraining's rmse: 3.51179\tvalid_1's rmse: 3.63404\n",
      "[2000]\ttraining's rmse: 3.46859\tvalid_1's rmse: 3.63031\n",
      "[2500]\ttraining's rmse: 3.43049\tvalid_1's rmse: 3.62913\n",
      "[3000]\ttraining's rmse: 3.39611\tvalid_1's rmse: 3.62891\n",
      "Early stopping, best iteration is:\n",
      "[2906]\ttraining's rmse: 3.40268\tvalid_1's rmse: 3.62877\n",
      "  205 | 07m03s |   -3.66920 |             0.8493 |        18.4990 |             0.2262 |             0.1812 |     14.6964 |             37.3626 |            30.5093 |            76.4541 |           0.7873 |      41.6403 |      0.5056 |       9.8761 |      0.7636 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00104884]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55471\tvalid_1's rmse: 3.71036\n",
      "[1000]\ttraining's rmse: 3.45837\tvalid_1's rmse: 3.69287\n",
      "[1500]\ttraining's rmse: 3.393\tvalid_1's rmse: 3.68805\n",
      "[2000]\ttraining's rmse: 3.34351\tvalid_1's rmse: 3.68689\n",
      "Early stopping, best iteration is:\n",
      "[2084]\ttraining's rmse: 3.33605\tvalid_1's rmse: 3.68668\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56583\tvalid_1's rmse: 3.65141\n",
      "[1000]\ttraining's rmse: 3.46983\tvalid_1's rmse: 3.63607\n",
      "[1500]\ttraining's rmse: 3.40756\tvalid_1's rmse: 3.63261\n",
      "[2000]\ttraining's rmse: 3.35721\tvalid_1's rmse: 3.63197\n",
      "Early stopping, best iteration is:\n",
      "[1966]\ttraining's rmse: 3.36014\tvalid_1's rmse: 3.63195\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57194\tvalid_1's rmse: 3.62682\n",
      "[1000]\ttraining's rmse: 3.4755\tvalid_1's rmse: 3.6116\n",
      "[1500]\ttraining's rmse: 3.40988\tvalid_1's rmse: 3.60783\n",
      "[2000]\ttraining's rmse: 3.36057\tvalid_1's rmse: 3.60707\n",
      "Early stopping, best iteration is:\n",
      "[1902]\ttraining's rmse: 3.36977\tvalid_1's rmse: 3.60686\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5263\tvalid_1's rmse: 3.80659\n",
      "[1000]\ttraining's rmse: 3.42878\tvalid_1's rmse: 3.79311\n",
      "[1500]\ttraining's rmse: 3.36622\tvalid_1's rmse: 3.7894\n",
      "Early stopping, best iteration is:\n",
      "[1546]\ttraining's rmse: 3.36146\tvalid_1's rmse: 3.78925\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56424\tvalid_1's rmse: 3.64998\n",
      "[1000]\ttraining's rmse: 3.4667\tvalid_1's rmse: 3.6356\n",
      "[1500]\ttraining's rmse: 3.40173\tvalid_1's rmse: 3.63233\n",
      "[2000]\ttraining's rmse: 3.35147\tvalid_1's rmse: 3.63121\n",
      "Early stopping, best iteration is:\n",
      "[1885]\ttraining's rmse: 3.36173\tvalid_1's rmse: 3.63107\n",
      "  206 | 07m19s |   -3.66975 |             0.9487 |         0.5292 |             0.6447 |             0.9268 |     14.9365 |             18.7810 |            35.3854 |            53.4331 |           0.1261 |      41.0668 |      2.7529 |       2.2640 |      0.1635 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00255113]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59325\tvalid_1's rmse: 3.71579\n",
      "[1000]\ttraining's rmse: 3.50724\tvalid_1's rmse: 3.69545\n",
      "[1500]\ttraining's rmse: 3.44981\tvalid_1's rmse: 3.68898\n",
      "[2000]\ttraining's rmse: 3.40267\tvalid_1's rmse: 3.68687\n",
      "[2500]\ttraining's rmse: 3.35915\tvalid_1's rmse: 3.68553\n",
      "Early stopping, best iteration is:\n",
      "[2317]\ttraining's rmse: 3.37464\tvalid_1's rmse: 3.68512\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60493\tvalid_1's rmse: 3.6557\n",
      "[1000]\ttraining's rmse: 3.51638\tvalid_1's rmse: 3.63807\n",
      "[1500]\ttraining's rmse: 3.45731\tvalid_1's rmse: 3.63087\n",
      "[2000]\ttraining's rmse: 3.41084\tvalid_1's rmse: 3.62803\n",
      "[2500]\ttraining's rmse: 3.37076\tvalid_1's rmse: 3.62698\n",
      "[3000]\ttraining's rmse: 3.33214\tvalid_1's rmse: 3.62661\n",
      "Early stopping, best iteration is:\n",
      "[2888]\ttraining's rmse: 3.34054\tvalid_1's rmse: 3.62633\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60846\tvalid_1's rmse: 3.63191\n",
      "[1000]\ttraining's rmse: 3.52386\tvalid_1's rmse: 3.61332\n",
      "[1500]\ttraining's rmse: 3.46471\tvalid_1's rmse: 3.60821\n",
      "[2000]\ttraining's rmse: 3.41712\tvalid_1's rmse: 3.60572\n",
      "[2500]\ttraining's rmse: 3.37662\tvalid_1's rmse: 3.60596\n",
      "Early stopping, best iteration is:\n",
      "[2329]\ttraining's rmse: 3.38934\tvalid_1's rmse: 3.60541\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.565\tvalid_1's rmse: 3.81347\n",
      "[1000]\ttraining's rmse: 3.47584\tvalid_1's rmse: 3.79733\n",
      "[1500]\ttraining's rmse: 3.41647\tvalid_1's rmse: 3.79236\n",
      "[2000]\ttraining's rmse: 3.36943\tvalid_1's rmse: 3.78969\n",
      "[2500]\ttraining's rmse: 3.32925\tvalid_1's rmse: 3.78982\n",
      "Early stopping, best iteration is:\n",
      "[2310]\ttraining's rmse: 3.34419\tvalid_1's rmse: 3.78923\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60326\tvalid_1's rmse: 3.65351\n",
      "[1000]\ttraining's rmse: 3.51618\tvalid_1's rmse: 3.63747\n",
      "[1500]\ttraining's rmse: 3.45711\tvalid_1's rmse: 3.63138\n",
      "[2000]\ttraining's rmse: 3.40794\tvalid_1's rmse: 3.62852\n",
      "[2500]\ttraining's rmse: 3.36522\tvalid_1's rmse: 3.62767\n",
      "Early stopping, best iteration is:\n",
      "[2747]\ttraining's rmse: 3.34589\tvalid_1's rmse: 3.6273\n",
      "  207 | 07m37s |   -3.66728 |             0.8669 |        19.4902 |             0.1449 |             0.7703 |     14.6214 |             37.4632 |            30.0697 |            33.3359 |           0.8512 |      31.5981 |      0.6710 |       9.8984 |      0.3912 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59892\tvalid_1's rmse: 3.70887\n",
      "[1000]\ttraining's rmse: 3.52796\tvalid_1's rmse: 3.68976\n",
      "[1500]\ttraining's rmse: 3.48056\tvalid_1's rmse: 3.68435\n",
      "[2000]\ttraining's rmse: 3.44228\tvalid_1's rmse: 3.68222\n",
      "[2500]\ttraining's rmse: 3.40962\tvalid_1's rmse: 3.68151\n",
      "Early stopping, best iteration is:\n",
      "[2465]\ttraining's rmse: 3.41177\tvalid_1's rmse: 3.68134\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61177\tvalid_1's rmse: 3.6518\n",
      "[1000]\ttraining's rmse: 3.53886\tvalid_1's rmse: 3.63468\n",
      "[1500]\ttraining's rmse: 3.49189\tvalid_1's rmse: 3.62966\n",
      "[2000]\ttraining's rmse: 3.45337\tvalid_1's rmse: 3.62819\n",
      "[2500]\ttraining's rmse: 3.41933\tvalid_1's rmse: 3.62753\n",
      "[3000]\ttraining's rmse: 3.38827\tvalid_1's rmse: 3.62727\n",
      "Early stopping, best iteration is:\n",
      "[2893]\ttraining's rmse: 3.39466\tvalid_1's rmse: 3.62716\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61704\tvalid_1's rmse: 3.62749\n",
      "[1000]\ttraining's rmse: 3.54501\tvalid_1's rmse: 3.61094\n",
      "[1500]\ttraining's rmse: 3.49646\tvalid_1's rmse: 3.60663\n",
      "[2000]\ttraining's rmse: 3.45758\tvalid_1's rmse: 3.60547\n",
      "Early stopping, best iteration is:\n",
      "[2062]\ttraining's rmse: 3.45309\tvalid_1's rmse: 3.6053\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57218\tvalid_1's rmse: 3.80884\n",
      "[1000]\ttraining's rmse: 3.49899\tvalid_1's rmse: 3.79368\n",
      "[1500]\ttraining's rmse: 3.45126\tvalid_1's rmse: 3.79007\n",
      "[2000]\ttraining's rmse: 3.41401\tvalid_1's rmse: 3.78938\n",
      "[2500]\ttraining's rmse: 3.38087\tvalid_1's rmse: 3.78923\n",
      "Early stopping, best iteration is:\n",
      "[2303]\ttraining's rmse: 3.39359\tvalid_1's rmse: 3.78898\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.611\tvalid_1's rmse: 3.64596\n",
      "[1000]\ttraining's rmse: 3.5383\tvalid_1's rmse: 3.63131\n",
      "[1500]\ttraining's rmse: 3.49148\tvalid_1's rmse: 3.62638\n",
      "[2000]\ttraining's rmse: 3.45447\tvalid_1's rmse: 3.62434\n",
      "[2500]\ttraining's rmse: 3.42113\tvalid_1's rmse: 3.62402\n",
      "Early stopping, best iteration is:\n",
      "[2540]\ttraining's rmse: 3.41872\tvalid_1's rmse: 3.6239\n",
      "  208 | 07m37s |   -3.66595 |             0.9730 |         1.8723 |             0.4543 |             0.7895 |     14.5831 |             47.6445 |            44.6494 |            98.8172 |           0.6438 |      32.8808 |      9.5170 |       0.4361 |      0.9653 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00042946]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 58, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65033\tvalid_1's rmse: 3.71748\n",
      "[1000]\ttraining's rmse: 3.60324\tvalid_1's rmse: 3.70255\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttraining's rmse: 3.60122\tvalid_1's rmse: 3.70227\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66423\tvalid_1's rmse: 3.66019\n",
      "[1000]\ttraining's rmse: 3.61652\tvalid_1's rmse: 3.65078\n",
      "Early stopping, best iteration is:\n",
      "[1029]\ttraining's rmse: 3.61399\tvalid_1's rmse: 3.64966\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66968\tvalid_1's rmse: 3.63606\n",
      "[1000]\ttraining's rmse: 3.62189\tvalid_1's rmse: 3.62388\n",
      "[1500]\ttraining's rmse: 3.58904\tvalid_1's rmse: 3.62448\n",
      "Early stopping, best iteration is:\n",
      "[1330]\ttraining's rmse: 3.59887\tvalid_1's rmse: 3.62237\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62761\tvalid_1's rmse: 3.83714\n",
      "[1000]\ttraining's rmse: 3.57892\tvalid_1's rmse: 3.82269\n",
      "Early stopping, best iteration is:\n",
      "[1291]\ttraining's rmse: 3.55859\tvalid_1's rmse: 3.82175\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66492\tvalid_1's rmse: 3.65151\n",
      "[1000]\ttraining's rmse: 3.61734\tvalid_1's rmse: 3.6437\n",
      "[1500]\ttraining's rmse: 3.58007\tvalid_1's rmse: 3.63958\n",
      "Early stopping, best iteration is:\n",
      "[1458]\ttraining's rmse: 3.58289\tvalid_1's rmse: 3.63892\n",
      "  209 | 05m40s |   -3.68771 |             0.1104 |        19.7848 |             0.8657 |             0.9059 |     13.3163 |             49.9169 |            30.0765 |            67.7312 |           0.9427 |      44.3991 |      9.6925 |       3.0127 |      0.9941 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61376\tvalid_1's rmse: 3.70814\n",
      "[1000]\ttraining's rmse: 3.56263\tvalid_1's rmse: 3.69206\n",
      "[1500]\ttraining's rmse: 3.52368\tvalid_1's rmse: 3.68794\n",
      "Early stopping, best iteration is:\n",
      "[1754]\ttraining's rmse: 3.5077\tvalid_1's rmse: 3.68713\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62555\tvalid_1's rmse: 3.64896\n",
      "[1000]\ttraining's rmse: 3.57075\tvalid_1's rmse: 3.63396\n",
      "[1500]\ttraining's rmse: 3.53487\tvalid_1's rmse: 3.63047\n",
      "[2000]\ttraining's rmse: 3.50222\tvalid_1's rmse: 3.6295\n",
      "Early stopping, best iteration is:\n",
      "[1943]\ttraining's rmse: 3.50576\tvalid_1's rmse: 3.62939\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63155\tvalid_1's rmse: 3.62602\n",
      "[1000]\ttraining's rmse: 3.57661\tvalid_1's rmse: 3.61258\n",
      "[1500]\ttraining's rmse: 3.53999\tvalid_1's rmse: 3.6096\n",
      "[2000]\ttraining's rmse: 3.50701\tvalid_1's rmse: 3.60877\n",
      "[2500]\ttraining's rmse: 3.47593\tvalid_1's rmse: 3.60794\n",
      "Early stopping, best iteration is:\n",
      "[2720]\ttraining's rmse: 3.4636\tvalid_1's rmse: 3.60763\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58444\tvalid_1's rmse: 3.80963\n",
      "[1000]\ttraining's rmse: 3.52736\tvalid_1's rmse: 3.79601\n",
      "[1500]\ttraining's rmse: 3.48987\tvalid_1's rmse: 3.7934\n",
      "Early stopping, best iteration is:\n",
      "[1697]\ttraining's rmse: 3.4759\tvalid_1's rmse: 3.79315\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62654\tvalid_1's rmse: 3.64263\n",
      "[1000]\ttraining's rmse: 3.57099\tvalid_1's rmse: 3.6305\n",
      "[1500]\ttraining's rmse: 3.53203\tvalid_1's rmse: 3.627\n",
      "[2000]\ttraining's rmse: 3.49715\tvalid_1's rmse: 3.62549\n",
      "Early stopping, best iteration is:\n",
      "[2253]\ttraining's rmse: 3.48183\tvalid_1's rmse: 3.62514\n",
      "  210 | 07m18s |   -3.66912 |             0.9756 |         0.2101 |             0.3891 |             0.9481 |      6.7251 |              6.4127 |            30.3149 |            50.8117 |           0.4415 |      41.6709 |      7.8166 |       7.6899 |      0.3624 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59637\tvalid_1's rmse: 3.70888\n",
      "[1000]\ttraining's rmse: 3.52256\tvalid_1's rmse: 3.6889\n",
      "[1500]\ttraining's rmse: 3.47232\tvalid_1's rmse: 3.68261\n",
      "[2000]\ttraining's rmse: 3.43133\tvalid_1's rmse: 3.68068\n",
      "[2500]\ttraining's rmse: 3.39459\tvalid_1's rmse: 3.67933\n",
      "[3000]\ttraining's rmse: 3.36135\tvalid_1's rmse: 3.67867\n",
      "Early stopping, best iteration is:\n",
      "[2897]\ttraining's rmse: 3.36805\tvalid_1's rmse: 3.67851\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60884\tvalid_1's rmse: 3.65219\n",
      "[1000]\ttraining's rmse: 3.53245\tvalid_1's rmse: 3.63539\n",
      "[1500]\ttraining's rmse: 3.48094\tvalid_1's rmse: 3.63033\n",
      "[2000]\ttraining's rmse: 3.43887\tvalid_1's rmse: 3.62916\n",
      "Early stopping, best iteration is:\n",
      "[1996]\ttraining's rmse: 3.43921\tvalid_1's rmse: 3.62909\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61395\tvalid_1's rmse: 3.62652\n",
      "[1000]\ttraining's rmse: 3.5387\tvalid_1's rmse: 3.60946\n",
      "[1500]\ttraining's rmse: 3.48831\tvalid_1's rmse: 3.60571\n",
      "[2000]\ttraining's rmse: 3.44608\tvalid_1's rmse: 3.60453\n",
      "Early stopping, best iteration is:\n",
      "[2083]\ttraining's rmse: 3.4398\tvalid_1's rmse: 3.60448\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56975\tvalid_1's rmse: 3.81003\n",
      "[1000]\ttraining's rmse: 3.49262\tvalid_1's rmse: 3.79348\n",
      "[1500]\ttraining's rmse: 3.44317\tvalid_1's rmse: 3.78885\n",
      "[2000]\ttraining's rmse: 3.40194\tvalid_1's rmse: 3.78805\n",
      "Early stopping, best iteration is:\n",
      "[2205]\ttraining's rmse: 3.3866\tvalid_1's rmse: 3.78775\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60797\tvalid_1's rmse: 3.64619\n",
      "[1000]\ttraining's rmse: 3.5338\tvalid_1's rmse: 3.6304\n",
      "[1500]\ttraining's rmse: 3.48369\tvalid_1's rmse: 3.62607\n",
      "Early stopping, best iteration is:\n",
      "[1753]\ttraining's rmse: 3.46091\tvalid_1's rmse: 3.62465\n",
      "  211 | 07m39s |   -3.66549 |             0.8903 |        19.9676 |             0.1501 |             0.7450 |     13.4904 |              6.2435 |            31.6909 |            86.8334 |           0.1884 |      35.8592 |      5.1315 |       9.8363 |      0.8561 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66354\tvalid_1's rmse: 3.72642\n",
      "[1000]\ttraining's rmse: 3.61931\tvalid_1's rmse: 3.7016\n",
      "[1500]\ttraining's rmse: 3.59161\tvalid_1's rmse: 3.69309\n",
      "[2000]\ttraining's rmse: 3.56854\tvalid_1's rmse: 3.68892\n",
      "[2500]\ttraining's rmse: 3.54778\tvalid_1's rmse: 3.68703\n",
      "[3000]\ttraining's rmse: 3.52869\tvalid_1's rmse: 3.6859\n",
      "[3500]\ttraining's rmse: 3.51052\tvalid_1's rmse: 3.68511\n",
      "[4000]\ttraining's rmse: 3.49245\tvalid_1's rmse: 3.68465\n",
      "[4500]\ttraining's rmse: 3.47555\tvalid_1's rmse: 3.68431\n",
      "Early stopping, best iteration is:\n",
      "[4458]\ttraining's rmse: 3.47688\tvalid_1's rmse: 3.68424\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67752\tvalid_1's rmse: 3.66526\n",
      "[1000]\ttraining's rmse: 3.63131\tvalid_1's rmse: 3.64454\n",
      "[1500]\ttraining's rmse: 3.60359\tvalid_1's rmse: 3.63699\n",
      "[2000]\ttraining's rmse: 3.58028\tvalid_1's rmse: 3.63272\n",
      "[2500]\ttraining's rmse: 3.56014\tvalid_1's rmse: 3.63044\n",
      "[3000]\ttraining's rmse: 3.5412\tvalid_1's rmse: 3.62935\n",
      "[3500]\ttraining's rmse: 3.5228\tvalid_1's rmse: 3.62837\n",
      "[4000]\ttraining's rmse: 3.50583\tvalid_1's rmse: 3.62775\n",
      "[4500]\ttraining's rmse: 3.48799\tvalid_1's rmse: 3.62707\n",
      "Early stopping, best iteration is:\n",
      "[4401]\ttraining's rmse: 3.49115\tvalid_1's rmse: 3.627\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68394\tvalid_1's rmse: 3.63879\n",
      "[1000]\ttraining's rmse: 3.63698\tvalid_1's rmse: 3.61757\n",
      "[1500]\ttraining's rmse: 3.60905\tvalid_1's rmse: 3.61103\n",
      "[2000]\ttraining's rmse: 3.58564\tvalid_1's rmse: 3.60821\n",
      "Early stopping, best iteration is:\n",
      "[2226]\ttraining's rmse: 3.57597\tvalid_1's rmse: 3.6074\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63551\tvalid_1's rmse: 3.83132\n",
      "[1000]\ttraining's rmse: 3.58936\tvalid_1's rmse: 3.80924\n",
      "[1500]\ttraining's rmse: 3.56135\tvalid_1's rmse: 3.80246\n",
      "[2000]\ttraining's rmse: 3.53849\tvalid_1's rmse: 3.79858\n",
      "[2500]\ttraining's rmse: 3.51844\tvalid_1's rmse: 3.79661\n",
      "[3000]\ttraining's rmse: 3.49927\tvalid_1's rmse: 3.79513\n",
      "[3500]\ttraining's rmse: 3.4804\tvalid_1's rmse: 3.79449\n",
      "[4000]\ttraining's rmse: 3.46258\tvalid_1's rmse: 3.79389\n",
      "[4500]\ttraining's rmse: 3.44504\tvalid_1's rmse: 3.79356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4339]\ttraining's rmse: 3.45063\tvalid_1's rmse: 3.79342\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6785\tvalid_1's rmse: 3.65741\n",
      "[1000]\ttraining's rmse: 3.63109\tvalid_1's rmse: 3.6365\n",
      "[1500]\ttraining's rmse: 3.60232\tvalid_1's rmse: 3.6299\n",
      "[2000]\ttraining's rmse: 3.57869\tvalid_1's rmse: 3.6261\n",
      "[2500]\ttraining's rmse: 3.55883\tvalid_1's rmse: 3.62504\n",
      "[3000]\ttraining's rmse: 3.53917\tvalid_1's rmse: 3.62443\n",
      "Early stopping, best iteration is:\n",
      "[3260]\ttraining's rmse: 3.52927\tvalid_1's rmse: 3.62416\n",
      "  212 | 06m38s |   -3.66788 |             0.8815 |         1.6575 |             0.9019 |             0.2837 |      5.2683 |             30.4031 |            44.4325 |            34.0718 |           0.2854 |      30.3584 |      8.2494 |       1.7012 |      0.3158 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62851\tvalid_1's rmse: 3.71938\n",
      "[1000]\ttraining's rmse: 3.56537\tvalid_1's rmse: 3.69507\n",
      "[1500]\ttraining's rmse: 3.52399\tvalid_1's rmse: 3.68747\n",
      "[2000]\ttraining's rmse: 3.48842\tvalid_1's rmse: 3.68391\n",
      "[2500]\ttraining's rmse: 3.45688\tvalid_1's rmse: 3.68232\n",
      "[3000]\ttraining's rmse: 3.42801\tvalid_1's rmse: 3.68141\n",
      "[3500]\ttraining's rmse: 3.40088\tvalid_1's rmse: 3.68095\n",
      "Early stopping, best iteration is:\n",
      "[3761]\ttraining's rmse: 3.38717\tvalid_1's rmse: 3.68068\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64255\tvalid_1's rmse: 3.65933\n",
      "[1000]\ttraining's rmse: 3.57718\tvalid_1's rmse: 3.63828\n",
      "[1500]\ttraining's rmse: 3.53531\tvalid_1's rmse: 3.63066\n",
      "[2000]\ttraining's rmse: 3.49927\tvalid_1's rmse: 3.62723\n",
      "[2500]\ttraining's rmse: 3.46732\tvalid_1's rmse: 3.626\n",
      "[3000]\ttraining's rmse: 3.43784\tvalid_1's rmse: 3.62494\n",
      "[3500]\ttraining's rmse: 3.41035\tvalid_1's rmse: 3.62424\n",
      "[4000]\ttraining's rmse: 3.38387\tvalid_1's rmse: 3.62351\n",
      "[4500]\ttraining's rmse: 3.35891\tvalid_1's rmse: 3.62365\n",
      "Early stopping, best iteration is:\n",
      "[4356]\ttraining's rmse: 3.36638\tvalid_1's rmse: 3.62338\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64688\tvalid_1's rmse: 3.63533\n",
      "[1000]\ttraining's rmse: 3.58059\tvalid_1's rmse: 3.61394\n",
      "[1500]\ttraining's rmse: 3.53841\tvalid_1's rmse: 3.60809\n",
      "[2000]\ttraining's rmse: 3.50364\tvalid_1's rmse: 3.60583\n",
      "[2500]\ttraining's rmse: 3.4725\tvalid_1's rmse: 3.60447\n",
      "[3000]\ttraining's rmse: 3.44364\tvalid_1's rmse: 3.60427\n",
      "Early stopping, best iteration is:\n",
      "[2906]\ttraining's rmse: 3.44875\tvalid_1's rmse: 3.60409\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60053\tvalid_1's rmse: 3.82471\n",
      "[1000]\ttraining's rmse: 3.53472\tvalid_1's rmse: 3.8033\n",
      "[1500]\ttraining's rmse: 3.49272\tvalid_1's rmse: 3.79717\n",
      "[2000]\ttraining's rmse: 3.45769\tvalid_1's rmse: 3.79445\n",
      "[2500]\ttraining's rmse: 3.42716\tvalid_1's rmse: 3.79311\n",
      "[3000]\ttraining's rmse: 3.3982\tvalid_1's rmse: 3.79249\n",
      "[3500]\ttraining's rmse: 3.37034\tvalid_1's rmse: 3.79215\n",
      "Early stopping, best iteration is:\n",
      "[3379]\ttraining's rmse: 3.37699\tvalid_1's rmse: 3.79198\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64155\tvalid_1's rmse: 3.65298\n",
      "[1000]\ttraining's rmse: 3.57419\tvalid_1's rmse: 3.63331\n",
      "[1500]\ttraining's rmse: 3.53216\tvalid_1's rmse: 3.62663\n",
      "[2000]\ttraining's rmse: 3.49784\tvalid_1's rmse: 3.62366\n",
      "[2500]\ttraining's rmse: 3.46667\tvalid_1's rmse: 3.62301\n",
      "Early stopping, best iteration is:\n",
      "[2601]\ttraining's rmse: 3.4608\tvalid_1's rmse: 3.62284\n",
      "  213 | 07m11s |   -3.66524 |             0.9234 |        15.0840 |             0.2266 |             0.2929 |      8.7047 |              5.8163 |            30.3822 |            54.3147 |           0.8999 |      32.2749 |      8.8075 |       9.7990 |      0.7926 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00198906]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67992\tvalid_1's rmse: 3.73879\n",
      "[1000]\ttraining's rmse: 3.63597\tvalid_1's rmse: 3.71259\n",
      "[1500]\ttraining's rmse: 3.60801\tvalid_1's rmse: 3.70218\n",
      "[2000]\ttraining's rmse: 3.58664\tvalid_1's rmse: 3.69662\n",
      "[2500]\ttraining's rmse: 3.56753\tvalid_1's rmse: 3.69318\n",
      "[3000]\ttraining's rmse: 3.55001\tvalid_1's rmse: 3.6912\n",
      "[3500]\ttraining's rmse: 3.53269\tvalid_1's rmse: 3.69043\n",
      "Early stopping, best iteration is:\n",
      "[3699]\ttraining's rmse: 3.52666\tvalid_1's rmse: 3.69007\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69558\tvalid_1's rmse: 3.6765\n",
      "[1000]\ttraining's rmse: 3.64884\tvalid_1's rmse: 3.65207\n",
      "[1500]\ttraining's rmse: 3.62149\tvalid_1's rmse: 3.64314\n",
      "[2000]\ttraining's rmse: 3.59956\tvalid_1's rmse: 3.6384\n",
      "[2500]\ttraining's rmse: 3.57997\tvalid_1's rmse: 3.63493\n",
      "[3000]\ttraining's rmse: 3.56179\tvalid_1's rmse: 3.63298\n",
      "[3500]\ttraining's rmse: 3.54562\tvalid_1's rmse: 3.63167\n",
      "[4000]\ttraining's rmse: 3.53046\tvalid_1's rmse: 3.63079\n",
      "Early stopping, best iteration is:\n",
      "[3830]\ttraining's rmse: 3.53548\tvalid_1's rmse: 3.63058\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.70046\tvalid_1's rmse: 3.64988\n",
      "[1000]\ttraining's rmse: 3.65257\tvalid_1's rmse: 3.62635\n",
      "[1500]\ttraining's rmse: 3.62503\tvalid_1's rmse: 3.6176\n",
      "[2000]\ttraining's rmse: 3.60138\tvalid_1's rmse: 3.61397\n",
      "[2500]\ttraining's rmse: 3.58081\tvalid_1's rmse: 3.6123\n",
      "[3000]\ttraining's rmse: 3.56101\tvalid_1's rmse: 3.61054\n",
      "[3500]\ttraining's rmse: 3.54322\tvalid_1's rmse: 3.60992\n",
      "Early stopping, best iteration is:\n",
      "[3347]\ttraining's rmse: 3.549\tvalid_1's rmse: 3.60989\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65295\tvalid_1's rmse: 3.84587\n",
      "[1000]\ttraining's rmse: 3.60487\tvalid_1's rmse: 3.81976\n",
      "[1500]\ttraining's rmse: 3.57741\tvalid_1's rmse: 3.81112\n",
      "[2000]\ttraining's rmse: 3.55642\tvalid_1's rmse: 3.80652\n",
      "[2500]\ttraining's rmse: 3.53681\tvalid_1's rmse: 3.80418\n",
      "[3000]\ttraining's rmse: 3.51807\tvalid_1's rmse: 3.80196\n",
      "[3500]\ttraining's rmse: 3.50118\tvalid_1's rmse: 3.80124\n",
      "[4000]\ttraining's rmse: 3.48439\tvalid_1's rmse: 3.80004\n",
      "[4500]\ttraining's rmse: 3.46902\tvalid_1's rmse: 3.79966\n",
      "Early stopping, best iteration is:\n",
      "[4459]\ttraining's rmse: 3.47032\tvalid_1's rmse: 3.7996\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69655\tvalid_1's rmse: 3.66767\n",
      "[1000]\ttraining's rmse: 3.64757\tvalid_1's rmse: 3.64546\n",
      "[1500]\ttraining's rmse: 3.61972\tvalid_1's rmse: 3.6374\n",
      "[2000]\ttraining's rmse: 3.59696\tvalid_1's rmse: 3.63344\n",
      "[2500]\ttraining's rmse: 3.57707\tvalid_1's rmse: 3.63102\n",
      "[3000]\ttraining's rmse: 3.55912\tvalid_1's rmse: 3.63006\n",
      "Early stopping, best iteration is:\n",
      "[2956]\ttraining's rmse: 3.56078\tvalid_1's rmse: 3.62995\n",
      "  214 | 06m23s |   -3.67267 |             0.5623 |        18.1432 |             0.9540 |             0.1812 |      5.0870 |             49.9128 |            44.5914 |            25.1354 |           0.5967 |      30.9074 |      7.7152 |       1.3309 |      0.6150 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61922\tvalid_1's rmse: 3.71337\n",
      "[1000]\ttraining's rmse: 3.56161\tvalid_1's rmse: 3.69269\n",
      "[1500]\ttraining's rmse: 3.52268\tvalid_1's rmse: 3.68614\n",
      "[2000]\ttraining's rmse: 3.49062\tvalid_1's rmse: 3.68438\n",
      "Early stopping, best iteration is:\n",
      "[2079]\ttraining's rmse: 3.48575\tvalid_1's rmse: 3.68393\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63336\tvalid_1's rmse: 3.65377\n",
      "[1000]\ttraining's rmse: 3.574\tvalid_1's rmse: 3.63496\n",
      "[1500]\ttraining's rmse: 3.53521\tvalid_1's rmse: 3.62932\n",
      "[2000]\ttraining's rmse: 3.50189\tvalid_1's rmse: 3.62732\n",
      "[2500]\ttraining's rmse: 3.47242\tvalid_1's rmse: 3.62605\n",
      "Early stopping, best iteration is:\n",
      "[2517]\ttraining's rmse: 3.47161\tvalid_1's rmse: 3.62597\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63611\tvalid_1's rmse: 3.6292\n",
      "[1000]\ttraining's rmse: 3.57593\tvalid_1's rmse: 3.61069\n",
      "[1500]\ttraining's rmse: 3.53671\tvalid_1's rmse: 3.60524\n",
      "[2000]\ttraining's rmse: 3.50313\tvalid_1's rmse: 3.60359\n",
      "[2500]\ttraining's rmse: 3.47373\tvalid_1's rmse: 3.60296\n",
      "Early stopping, best iteration is:\n",
      "[2740]\ttraining's rmse: 3.46059\tvalid_1's rmse: 3.60283\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59105\tvalid_1's rmse: 3.81487\n",
      "[1000]\ttraining's rmse: 3.53074\tvalid_1's rmse: 3.79767\n",
      "[1500]\ttraining's rmse: 3.49237\tvalid_1's rmse: 3.79276\n",
      "[2000]\ttraining's rmse: 3.45971\tvalid_1's rmse: 3.79086\n",
      "[2500]\ttraining's rmse: 3.43128\tvalid_1's rmse: 3.79051\n",
      "[3000]\ttraining's rmse: 3.40558\tvalid_1's rmse: 3.78998\n",
      "Early stopping, best iteration is:\n",
      "[2911]\ttraining's rmse: 3.40989\tvalid_1's rmse: 3.78991\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63133\tvalid_1's rmse: 3.64732\n",
      "[1000]\ttraining's rmse: 3.56977\tvalid_1's rmse: 3.63051\n",
      "[1500]\ttraining's rmse: 3.53082\tvalid_1's rmse: 3.62474\n",
      "[2000]\ttraining's rmse: 3.49848\tvalid_1's rmse: 3.62222\n",
      "[2500]\ttraining's rmse: 3.46972\tvalid_1's rmse: 3.62187\n",
      "Early stopping, best iteration is:\n",
      "[2395]\ttraining's rmse: 3.47566\tvalid_1's rmse: 3.62169\n",
      "  215 | 07m20s |   -3.66550 |             0.9872 |        10.9377 |             0.2499 |             0.4498 |      8.4205 |             22.1467 |            30.2883 |            79.8134 |           0.0436 |      30.5757 |      8.4105 |       0.9801 |      0.9548 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00327556]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.0040893]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64841\tvalid_1's rmse: 3.71651\n",
      "[1000]\ttraining's rmse: 3.60619\tvalid_1's rmse: 3.69695\n",
      "[1500]\ttraining's rmse: 3.57717\tvalid_1's rmse: 3.68969\n",
      "[2000]\ttraining's rmse: 3.55283\tvalid_1's rmse: 3.68656\n",
      "[2500]\ttraining's rmse: 3.53083\tvalid_1's rmse: 3.68495\n",
      "[3000]\ttraining's rmse: 3.50984\tvalid_1's rmse: 3.68399\n",
      "Early stopping, best iteration is:\n",
      "[3089]\ttraining's rmse: 3.50686\tvalid_1's rmse: 3.68385\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66208\tvalid_1's rmse: 3.65837\n",
      "[1000]\ttraining's rmse: 3.61831\tvalid_1's rmse: 3.64046\n",
      "[1500]\ttraining's rmse: 3.58952\tvalid_1's rmse: 3.63404\n",
      "[2000]\ttraining's rmse: 3.56505\tvalid_1's rmse: 3.63113\n",
      "[2500]\ttraining's rmse: 3.54396\tvalid_1's rmse: 3.62938\n",
      "[3000]\ttraining's rmse: 3.52345\tvalid_1's rmse: 3.62813\n",
      "[3500]\ttraining's rmse: 3.50446\tvalid_1's rmse: 3.62763\n",
      "[4000]\ttraining's rmse: 3.48591\tvalid_1's rmse: 3.62748\n",
      "Early stopping, best iteration is:\n",
      "[4084]\ttraining's rmse: 3.48278\tvalid_1's rmse: 3.62735\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66824\tvalid_1's rmse: 3.62981\n",
      "[1000]\ttraining's rmse: 3.62335\tvalid_1's rmse: 3.61193\n",
      "[1500]\ttraining's rmse: 3.59449\tvalid_1's rmse: 3.60683\n",
      "[2000]\ttraining's rmse: 3.57081\tvalid_1's rmse: 3.60513\n",
      "[2500]\ttraining's rmse: 3.54901\tvalid_1's rmse: 3.60397\n",
      "Early stopping, best iteration is:\n",
      "[2495]\ttraining's rmse: 3.54915\tvalid_1's rmse: 3.60393\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62011\tvalid_1's rmse: 3.82031\n",
      "[1000]\ttraining's rmse: 3.57487\tvalid_1's rmse: 3.80379\n",
      "[1500]\ttraining's rmse: 3.54702\tvalid_1's rmse: 3.79857\n",
      "[2000]\ttraining's rmse: 3.52357\tvalid_1's rmse: 3.79648\n",
      "[2500]\ttraining's rmse: 3.50193\tvalid_1's rmse: 3.79523\n",
      "[3000]\ttraining's rmse: 3.48153\tvalid_1's rmse: 3.79481\n",
      "[3500]\ttraining's rmse: 3.46258\tvalid_1's rmse: 3.79444\n",
      "[4000]\ttraining's rmse: 3.44422\tvalid_1's rmse: 3.79412\n",
      "[4500]\ttraining's rmse: 3.42599\tvalid_1's rmse: 3.79375\n",
      "Early stopping, best iteration is:\n",
      "[4671]\ttraining's rmse: 3.41965\tvalid_1's rmse: 3.79363\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66273\tvalid_1's rmse: 3.64945\n",
      "[1000]\ttraining's rmse: 3.6165\tvalid_1's rmse: 3.63219\n",
      "[1500]\ttraining's rmse: 3.58624\tvalid_1's rmse: 3.62641\n",
      "[2000]\ttraining's rmse: 3.5627\tvalid_1's rmse: 3.62419\n",
      "[2500]\ttraining's rmse: 3.54062\tvalid_1's rmse: 3.62338\n",
      "Early stopping, best iteration is:\n",
      "[2480]\ttraining's rmse: 3.54153\tvalid_1's rmse: 3.6233\n",
      "  216 | 08m17s |   -3.66706 |             0.9557 |         2.2572 |             0.4799 |             0.5336 |      5.7411 |              5.7374 |            44.5198 |            41.2025 |           0.3195 |      33.8999 |      9.1041 |       0.0242 |      0.7887 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63643\tvalid_1's rmse: 3.72331\n",
      "[1000]\ttraining's rmse: 3.57646\tvalid_1's rmse: 3.69764\n",
      "[1500]\ttraining's rmse: 3.53794\tvalid_1's rmse: 3.6897\n",
      "[2000]\ttraining's rmse: 3.50554\tvalid_1's rmse: 3.68592\n",
      "[2500]\ttraining's rmse: 3.47591\tvalid_1's rmse: 3.68445\n",
      "[3000]\ttraining's rmse: 3.44921\tvalid_1's rmse: 3.68353\n",
      "Early stopping, best iteration is:\n",
      "[3294]\ttraining's rmse: 3.43423\tvalid_1's rmse: 3.68325\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65005\tvalid_1's rmse: 3.66182\n",
      "[1000]\ttraining's rmse: 3.58804\tvalid_1's rmse: 3.64029\n",
      "[1500]\ttraining's rmse: 3.55006\tvalid_1's rmse: 3.63263\n",
      "[2000]\ttraining's rmse: 3.51686\tvalid_1's rmse: 3.62863\n",
      "[2500]\ttraining's rmse: 3.48716\tvalid_1's rmse: 3.62658\n",
      "[3000]\ttraining's rmse: 3.45923\tvalid_1's rmse: 3.62566\n",
      "[3500]\ttraining's rmse: 3.43406\tvalid_1's rmse: 3.62538\n",
      "Early stopping, best iteration is:\n",
      "[3403]\ttraining's rmse: 3.43855\tvalid_1's rmse: 3.62523\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65539\tvalid_1's rmse: 3.63785\n",
      "[1000]\ttraining's rmse: 3.59352\tvalid_1's rmse: 3.61601\n",
      "[1500]\ttraining's rmse: 3.55457\tvalid_1's rmse: 3.61027\n",
      "[2000]\ttraining's rmse: 3.52217\tvalid_1's rmse: 3.60768\n",
      "[2500]\ttraining's rmse: 3.49333\tvalid_1's rmse: 3.60657\n",
      "Early stopping, best iteration is:\n",
      "[2407]\ttraining's rmse: 3.49851\tvalid_1's rmse: 3.60653\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60781\tvalid_1's rmse: 3.82758\n",
      "[1000]\ttraining's rmse: 3.54593\tvalid_1's rmse: 3.80595\n",
      "[1500]\ttraining's rmse: 3.50687\tvalid_1's rmse: 3.79938\n",
      "[2000]\ttraining's rmse: 3.47484\tvalid_1's rmse: 3.7966\n",
      "[2500]\ttraining's rmse: 3.44641\tvalid_1's rmse: 3.79512\n",
      "[3000]\ttraining's rmse: 3.41931\tvalid_1's rmse: 3.79443\n",
      "Early stopping, best iteration is:\n",
      "[3088]\ttraining's rmse: 3.41466\tvalid_1's rmse: 3.79431\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6494\tvalid_1's rmse: 3.65474\n",
      "[1000]\ttraining's rmse: 3.586\tvalid_1's rmse: 3.63424\n",
      "[1500]\ttraining's rmse: 3.54647\tvalid_1's rmse: 3.62801\n",
      "[2000]\ttraining's rmse: 3.51409\tvalid_1's rmse: 3.62493\n",
      "[2500]\ttraining's rmse: 3.48553\tvalid_1's rmse: 3.62378\n",
      "Early stopping, best iteration is:\n",
      "[2722]\ttraining's rmse: 3.4737\tvalid_1's rmse: 3.62356\n",
      "  217 | 07m05s |   -3.66722 |             0.9741 |         4.1889 |             0.1459 |             0.2599 |      7.8624 |              5.7274 |            30.1589 |            46.5228 |           0.1361 |      30.6141 |      5.8129 |       0.2412 |      0.7395 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58119\tvalid_1's rmse: 3.71076\n",
      "[1000]\ttraining's rmse: 3.49809\tvalid_1's rmse: 3.69107\n",
      "[1500]\ttraining's rmse: 3.43839\tvalid_1's rmse: 3.68509\n",
      "[2000]\ttraining's rmse: 3.38877\tvalid_1's rmse: 3.68273\n",
      "[2500]\ttraining's rmse: 3.34446\tvalid_1's rmse: 3.68162\n",
      "Early stopping, best iteration is:\n",
      "[2587]\ttraining's rmse: 3.33725\tvalid_1's rmse: 3.68157\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59419\tvalid_1's rmse: 3.65151\n",
      "[1000]\ttraining's rmse: 3.50774\tvalid_1's rmse: 3.63343\n",
      "[1500]\ttraining's rmse: 3.44829\tvalid_1's rmse: 3.62731\n",
      "[2000]\ttraining's rmse: 3.39797\tvalid_1's rmse: 3.62527\n",
      "Early stopping, best iteration is:\n",
      "[2103]\ttraining's rmse: 3.38824\tvalid_1's rmse: 3.6248\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59944\tvalid_1's rmse: 3.62803\n",
      "[1000]\ttraining's rmse: 3.51398\tvalid_1's rmse: 3.6101\n",
      "[1500]\ttraining's rmse: 3.45455\tvalid_1's rmse: 3.60559\n",
      "Early stopping, best iteration is:\n",
      "[1780]\ttraining's rmse: 3.42499\tvalid_1's rmse: 3.60483\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55478\tvalid_1's rmse: 3.81585\n",
      "[1000]\ttraining's rmse: 3.46653\tvalid_1's rmse: 3.7967\n",
      "[1500]\ttraining's rmse: 3.40738\tvalid_1's rmse: 3.79195\n",
      "[2000]\ttraining's rmse: 3.35791\tvalid_1's rmse: 3.79105\n",
      "[2500]\ttraining's rmse: 3.31218\tvalid_1's rmse: 3.7899\n",
      "Early stopping, best iteration is:\n",
      "[2446]\ttraining's rmse: 3.31704\tvalid_1's rmse: 3.78974\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59322\tvalid_1's rmse: 3.64772\n",
      "[1000]\ttraining's rmse: 3.50451\tvalid_1's rmse: 3.63303\n",
      "[1500]\ttraining's rmse: 3.44661\tvalid_1's rmse: 3.6285\n",
      "[2000]\ttraining's rmse: 3.39624\tvalid_1's rmse: 3.62711\n",
      "Early stopping, best iteration is:\n",
      "[2153]\ttraining's rmse: 3.38076\tvalid_1's rmse: 3.62667\n",
      "  218 | 07m08s |   -3.66614 |             0.7366 |        18.7080 |             0.7441 |             0.4805 |     11.5449 |             37.7721 |            44.6206 |            45.2763 |           0.9583 |      41.9820 |      0.4398 |       7.9831 |      0.5008 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00887994]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61714\tvalid_1's rmse: 3.70558\n",
      "[1000]\ttraining's rmse: 3.56955\tvalid_1's rmse: 3.68938\n",
      "[1500]\ttraining's rmse: 3.53619\tvalid_1's rmse: 3.68452\n",
      "[2000]\ttraining's rmse: 3.50762\tvalid_1's rmse: 3.68276\n",
      "Early stopping, best iteration is:\n",
      "[2192]\ttraining's rmse: 3.49757\tvalid_1's rmse: 3.68252\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63026\tvalid_1's rmse: 3.64865\n",
      "[1000]\ttraining's rmse: 3.57874\tvalid_1's rmse: 3.63461\n",
      "[1500]\ttraining's rmse: 3.54392\tvalid_1's rmse: 3.63001\n",
      "[2000]\ttraining's rmse: 3.51397\tvalid_1's rmse: 3.62868\n",
      "[2500]\ttraining's rmse: 3.48581\tvalid_1's rmse: 3.62778\n",
      "Early stopping, best iteration is:\n",
      "[2446]\ttraining's rmse: 3.48877\tvalid_1's rmse: 3.6277\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6352\tvalid_1's rmse: 3.6237\n",
      "[1000]\ttraining's rmse: 3.58271\tvalid_1's rmse: 3.61043\n",
      "[1500]\ttraining's rmse: 3.54726\tvalid_1's rmse: 3.60634\n",
      "[2000]\ttraining's rmse: 3.51683\tvalid_1's rmse: 3.60497\n",
      "[2500]\ttraining's rmse: 3.48902\tvalid_1's rmse: 3.60424\n",
      "Early stopping, best iteration is:\n",
      "[2436]\ttraining's rmse: 3.49249\tvalid_1's rmse: 3.60394\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58847\tvalid_1's rmse: 3.80818\n",
      "[1000]\ttraining's rmse: 3.5361\tvalid_1's rmse: 3.79459\n",
      "[1500]\ttraining's rmse: 3.50352\tvalid_1's rmse: 3.79149\n",
      "[2000]\ttraining's rmse: 3.47434\tvalid_1's rmse: 3.79028\n",
      "Early stopping, best iteration is:\n",
      "[2255]\ttraining's rmse: 3.46021\tvalid_1's rmse: 3.79003\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6322\tvalid_1's rmse: 3.63935\n",
      "[1000]\ttraining's rmse: 3.57858\tvalid_1's rmse: 3.62616\n",
      "[1500]\ttraining's rmse: 3.54387\tvalid_1's rmse: 3.62271\n",
      "[2000]\ttraining's rmse: 3.51426\tvalid_1's rmse: 3.62134\n",
      "Early stopping, best iteration is:\n",
      "[2260]\ttraining's rmse: 3.49965\tvalid_1's rmse: 3.62108\n",
      "  219 | 08m21s |   -3.66568 |             0.9682 |         6.4502 |             0.8630 |             0.8707 |      6.1593 |             44.6338 |            43.2349 |            90.7709 |           0.2861 |      44.6339 |      7.5541 |       5.1473 |      0.1458 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00493811]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59292\tvalid_1's rmse: 3.71012\n",
      "[1000]\ttraining's rmse: 3.51853\tvalid_1's rmse: 3.69182\n",
      "[1500]\ttraining's rmse: 3.46796\tvalid_1's rmse: 3.68575\n",
      "[2000]\ttraining's rmse: 3.42562\tvalid_1's rmse: 3.6833\n",
      "[2500]\ttraining's rmse: 3.38906\tvalid_1's rmse: 3.68271\n",
      "Early stopping, best iteration is:\n",
      "[2329]\ttraining's rmse: 3.40147\tvalid_1's rmse: 3.68215\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60498\tvalid_1's rmse: 3.65189\n",
      "[1000]\ttraining's rmse: 3.52933\tvalid_1's rmse: 3.63565\n",
      "[1500]\ttraining's rmse: 3.4779\tvalid_1's rmse: 3.62992\n",
      "[2000]\ttraining's rmse: 3.43621\tvalid_1's rmse: 3.62767\n",
      "[2500]\ttraining's rmse: 3.39805\tvalid_1's rmse: 3.62759\n",
      "Early stopping, best iteration is:\n",
      "[2431]\ttraining's rmse: 3.4032\tvalid_1's rmse: 3.62724\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61098\tvalid_1's rmse: 3.63124\n",
      "[1000]\ttraining's rmse: 3.53389\tvalid_1's rmse: 3.61401\n",
      "[1500]\ttraining's rmse: 3.48233\tvalid_1's rmse: 3.61033\n",
      "[2000]\ttraining's rmse: 3.43973\tvalid_1's rmse: 3.60908\n",
      "Early stopping, best iteration is:\n",
      "[2219]\ttraining's rmse: 3.42253\tvalid_1's rmse: 3.60833\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56623\tvalid_1's rmse: 3.80925\n",
      "[1000]\ttraining's rmse: 3.48906\tvalid_1's rmse: 3.79351\n",
      "[1500]\ttraining's rmse: 3.43818\tvalid_1's rmse: 3.78986\n",
      "[2000]\ttraining's rmse: 3.39755\tvalid_1's rmse: 3.78955\n",
      "Early stopping, best iteration is:\n",
      "[1857]\ttraining's rmse: 3.40813\tvalid_1's rmse: 3.78936\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60345\tvalid_1's rmse: 3.64823\n",
      "[1000]\ttraining's rmse: 3.52785\tvalid_1's rmse: 3.63286\n",
      "[1500]\ttraining's rmse: 3.47805\tvalid_1's rmse: 3.62748\n",
      "[2000]\ttraining's rmse: 3.43514\tvalid_1's rmse: 3.62644\n",
      "[2500]\ttraining's rmse: 3.39854\tvalid_1's rmse: 3.62588\n",
      "Early stopping, best iteration is:\n",
      "[2343]\ttraining's rmse: 3.41001\tvalid_1's rmse: 3.62576\n",
      "  220 | 07m43s |   -3.66716 |             0.8895 |         9.8557 |             0.1483 |             0.8533 |     14.7358 |             27.1208 |            44.7512 |            69.2418 |           0.6034 |      31.8766 |      9.7130 |       0.3634 |      0.9004 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00387162]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6283\tvalid_1's rmse: 3.71497\n",
      "[1000]\ttraining's rmse: 3.56739\tvalid_1's rmse: 3.69415\n",
      "[1500]\ttraining's rmse: 3.52597\tvalid_1's rmse: 3.6885\n",
      "[2000]\ttraining's rmse: 3.4901\tvalid_1's rmse: 3.68716\n",
      "[2500]\ttraining's rmse: 3.45669\tvalid_1's rmse: 3.68661\n",
      "Early stopping, best iteration is:\n",
      "[2339]\ttraining's rmse: 3.46749\tvalid_1's rmse: 3.686\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64195\tvalid_1's rmse: 3.65517\n",
      "[1000]\ttraining's rmse: 3.57994\tvalid_1's rmse: 3.63694\n",
      "[1500]\ttraining's rmse: 3.53856\tvalid_1's rmse: 3.63136\n",
      "[2000]\ttraining's rmse: 3.50354\tvalid_1's rmse: 3.62759\n",
      "Early stopping, best iteration is:\n",
      "[2281]\ttraining's rmse: 3.48465\tvalid_1's rmse: 3.62672\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64585\tvalid_1's rmse: 3.63037\n",
      "[1000]\ttraining's rmse: 3.58525\tvalid_1's rmse: 3.61318\n",
      "[1500]\ttraining's rmse: 3.54408\tvalid_1's rmse: 3.60821\n",
      "[2000]\ttraining's rmse: 3.50781\tvalid_1's rmse: 3.60659\n",
      "Early stopping, best iteration is:\n",
      "[2283]\ttraining's rmse: 3.4889\tvalid_1's rmse: 3.60613\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60001\tvalid_1's rmse: 3.81912\n",
      "[1000]\ttraining's rmse: 3.5389\tvalid_1's rmse: 3.80164\n",
      "[1500]\ttraining's rmse: 3.49712\tvalid_1's rmse: 3.79632\n",
      "[2000]\ttraining's rmse: 3.46114\tvalid_1's rmse: 3.79479\n",
      "Early stopping, best iteration is:\n",
      "[2068]\ttraining's rmse: 3.45687\tvalid_1's rmse: 3.79434\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64059\tvalid_1's rmse: 3.64865\n",
      "[1000]\ttraining's rmse: 3.58055\tvalid_1's rmse: 3.63328\n",
      "[1500]\ttraining's rmse: 3.53868\tvalid_1's rmse: 3.62833\n",
      "[2000]\ttraining's rmse: 3.50312\tvalid_1's rmse: 3.62635\n",
      "Early stopping, best iteration is:\n",
      "[2033]\ttraining's rmse: 3.50086\tvalid_1's rmse: 3.62617\n",
      "  221 | 06m10s |   -3.66851 |             0.5134 |        19.0944 |             0.9030 |             0.4507 |     14.7867 |             47.3951 |            39.5709 |            90.1375 |           0.3839 |      30.2046 |      2.0356 |       0.5607 |      0.9578 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59501\tvalid_1's rmse: 3.71566\n",
      "[1000]\ttraining's rmse: 3.50932\tvalid_1's rmse: 3.69522\n",
      "[1500]\ttraining's rmse: 3.4504\tvalid_1's rmse: 3.68713\n",
      "[2000]\ttraining's rmse: 3.40269\tvalid_1's rmse: 3.68398\n",
      "[2500]\ttraining's rmse: 3.36306\tvalid_1's rmse: 3.68326\n",
      "Early stopping, best iteration is:\n",
      "[2524]\ttraining's rmse: 3.36116\tvalid_1's rmse: 3.68311\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60872\tvalid_1's rmse: 3.65654\n",
      "[1000]\ttraining's rmse: 3.52257\tvalid_1's rmse: 3.63755\n",
      "[1500]\ttraining's rmse: 3.46448\tvalid_1's rmse: 3.63052\n",
      "[2000]\ttraining's rmse: 3.4184\tvalid_1's rmse: 3.62761\n",
      "[2500]\ttraining's rmse: 3.37508\tvalid_1's rmse: 3.62601\n",
      "Early stopping, best iteration is:\n",
      "[2700]\ttraining's rmse: 3.3592\tvalid_1's rmse: 3.62557\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61202\tvalid_1's rmse: 3.63322\n",
      "[1000]\ttraining's rmse: 3.52599\tvalid_1's rmse: 3.61516\n",
      "[1500]\ttraining's rmse: 3.46877\tvalid_1's rmse: 3.60942\n",
      "[2000]\ttraining's rmse: 3.42169\tvalid_1's rmse: 3.60702\n",
      "Early stopping, best iteration is:\n",
      "[2106]\ttraining's rmse: 3.41257\tvalid_1's rmse: 3.60673\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56728\tvalid_1's rmse: 3.81636\n",
      "[1000]\ttraining's rmse: 3.4792\tvalid_1's rmse: 3.79804\n",
      "[1500]\ttraining's rmse: 3.42007\tvalid_1's rmse: 3.79219\n",
      "[2000]\ttraining's rmse: 3.3724\tvalid_1's rmse: 3.78983\n",
      "[2500]\ttraining's rmse: 3.33064\tvalid_1's rmse: 3.78877\n",
      "Early stopping, best iteration is:\n",
      "[2690]\ttraining's rmse: 3.31513\tvalid_1's rmse: 3.78825\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6068\tvalid_1's rmse: 3.65242\n",
      "[1000]\ttraining's rmse: 3.52075\tvalid_1's rmse: 3.63581\n",
      "[1500]\ttraining's rmse: 3.46139\tvalid_1's rmse: 3.62946\n",
      "[2000]\ttraining's rmse: 3.41501\tvalid_1's rmse: 3.62722\n",
      "[2500]\ttraining's rmse: 3.37337\tvalid_1's rmse: 3.62597\n",
      "Early stopping, best iteration is:\n",
      "[2554]\ttraining's rmse: 3.36915\tvalid_1's rmse: 3.62581\n",
      "  222 | 07m31s |   -3.66650 |             0.8710 |        13.6296 |             0.1324 |             0.5870 |     14.6875 |              5.1966 |            30.5493 |            10.9957 |           0.0391 |      31.5111 |      4.4753 |       8.8064 |      0.8445 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66878\tvalid_1's rmse: 3.73201\n",
      "[1000]\ttraining's rmse: 3.62312\tvalid_1's rmse: 3.70526\n",
      "[1500]\ttraining's rmse: 3.59583\tvalid_1's rmse: 3.69573\n",
      "[2000]\ttraining's rmse: 3.57344\tvalid_1's rmse: 3.69125\n",
      "[2500]\ttraining's rmse: 3.55415\tvalid_1's rmse: 3.68856\n",
      "[3000]\ttraining's rmse: 3.53591\tvalid_1's rmse: 3.68726\n",
      "[3500]\ttraining's rmse: 3.51961\tvalid_1's rmse: 3.68665\n",
      "[4000]\ttraining's rmse: 3.503\tvalid_1's rmse: 3.68614\n",
      "[4500]\ttraining's rmse: 3.48582\tvalid_1's rmse: 3.68571\n",
      "Early stopping, best iteration is:\n",
      "[4479]\ttraining's rmse: 3.48648\tvalid_1's rmse: 3.68569\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68258\tvalid_1's rmse: 3.66911\n",
      "[1000]\ttraining's rmse: 3.63451\tvalid_1's rmse: 3.64641\n",
      "[1500]\ttraining's rmse: 3.6064\tvalid_1's rmse: 3.63691\n",
      "[2000]\ttraining's rmse: 3.58457\tvalid_1's rmse: 3.63219\n",
      "[2500]\ttraining's rmse: 3.56618\tvalid_1's rmse: 3.62985\n",
      "[3000]\ttraining's rmse: 3.5483\tvalid_1's rmse: 3.62855\n",
      "[3500]\ttraining's rmse: 3.53151\tvalid_1's rmse: 3.62762\n",
      "[4000]\ttraining's rmse: 3.51426\tvalid_1's rmse: 3.62691\n",
      "[4500]\ttraining's rmse: 3.49792\tvalid_1's rmse: 3.62648\n",
      "[5000]\ttraining's rmse: 3.48191\tvalid_1's rmse: 3.62619\n",
      "[5500]\ttraining's rmse: 3.46626\tvalid_1's rmse: 3.62589\n",
      "Early stopping, best iteration is:\n",
      "[5509]\ttraining's rmse: 3.46594\tvalid_1's rmse: 3.62587\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68902\tvalid_1's rmse: 3.64246\n",
      "[1000]\ttraining's rmse: 3.64035\tvalid_1's rmse: 3.61912\n",
      "[1500]\ttraining's rmse: 3.61332\tvalid_1's rmse: 3.61133\n",
      "[2000]\ttraining's rmse: 3.59254\tvalid_1's rmse: 3.60824\n",
      "[2500]\ttraining's rmse: 3.57314\tvalid_1's rmse: 3.60713\n",
      "[3000]\ttraining's rmse: 3.55413\tvalid_1's rmse: 3.60616\n",
      "[3500]\ttraining's rmse: 3.53644\tvalid_1's rmse: 3.60593\n",
      "Early stopping, best iteration is:\n",
      "[3616]\ttraining's rmse: 3.53232\tvalid_1's rmse: 3.60581\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64069\tvalid_1's rmse: 3.83688\n",
      "[1000]\ttraining's rmse: 3.5925\tvalid_1's rmse: 3.81244\n",
      "[1500]\ttraining's rmse: 3.56503\tvalid_1's rmse: 3.80481\n",
      "[2000]\ttraining's rmse: 3.54232\tvalid_1's rmse: 3.80077\n",
      "[2500]\ttraining's rmse: 3.52334\tvalid_1's rmse: 3.79896\n",
      "[3000]\ttraining's rmse: 3.50542\tvalid_1's rmse: 3.798\n",
      "[3500]\ttraining's rmse: 3.48876\tvalid_1's rmse: 3.79723\n",
      "[4000]\ttraining's rmse: 3.47289\tvalid_1's rmse: 3.79674\n",
      "[4500]\ttraining's rmse: 3.45663\tvalid_1's rmse: 3.79653\n",
      "Early stopping, best iteration is:\n",
      "[4636]\ttraining's rmse: 3.4528\tvalid_1's rmse: 3.79647\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.68401\tvalid_1's rmse: 3.66153\n",
      "[1000]\ttraining's rmse: 3.63459\tvalid_1's rmse: 3.63866\n",
      "[1500]\ttraining's rmse: 3.60526\tvalid_1's rmse: 3.63106\n",
      "[2000]\ttraining's rmse: 3.58387\tvalid_1's rmse: 3.6274\n",
      "[2500]\ttraining's rmse: 3.56475\tvalid_1's rmse: 3.62621\n",
      "[3000]\ttraining's rmse: 3.54666\tvalid_1's rmse: 3.62556\n",
      "Early stopping, best iteration is:\n",
      "[3195]\ttraining's rmse: 3.53989\tvalid_1's rmse: 3.62538\n",
      "  223 | 06m57s |   -3.66851 |             0.9624 |         0.6231 |             0.9244 |             0.2387 |      5.5223 |             32.1951 |            34.5223 |            12.6760 |           0.6279 |      30.2128 |      9.2433 |       4.6515 |      0.2910 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57123\tvalid_1's rmse: 3.71027\n",
      "[1000]\ttraining's rmse: 3.47653\tvalid_1's rmse: 3.69006\n",
      "[1500]\ttraining's rmse: 3.41301\tvalid_1's rmse: 3.68433\n",
      "[2000]\ttraining's rmse: 3.36196\tvalid_1's rmse: 3.68313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\ttraining's rmse: 3.31883\tvalid_1's rmse: 3.68255\n",
      "Early stopping, best iteration is:\n",
      "[2565]\ttraining's rmse: 3.31384\tvalid_1's rmse: 3.68248\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58544\tvalid_1's rmse: 3.65207\n",
      "[1000]\ttraining's rmse: 3.48802\tvalid_1's rmse: 3.63336\n",
      "[1500]\ttraining's rmse: 3.42478\tvalid_1's rmse: 3.62746\n",
      "[2000]\ttraining's rmse: 3.37277\tvalid_1's rmse: 3.62546\n",
      "Early stopping, best iteration is:\n",
      "[2247]\ttraining's rmse: 3.34986\tvalid_1's rmse: 3.62501\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58926\tvalid_1's rmse: 3.62775\n",
      "[1000]\ttraining's rmse: 3.49273\tvalid_1's rmse: 3.60993\n",
      "[1500]\ttraining's rmse: 3.42935\tvalid_1's rmse: 3.60467\n",
      "[2000]\ttraining's rmse: 3.37881\tvalid_1's rmse: 3.60289\n",
      "Early stopping, best iteration is:\n",
      "[2231]\ttraining's rmse: 3.35765\tvalid_1's rmse: 3.6027\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54488\tvalid_1's rmse: 3.81512\n",
      "[1000]\ttraining's rmse: 3.44762\tvalid_1's rmse: 3.7958\n",
      "[1500]\ttraining's rmse: 3.384\tvalid_1's rmse: 3.79012\n",
      "[2000]\ttraining's rmse: 3.33335\tvalid_1's rmse: 3.78908\n",
      "Early stopping, best iteration is:\n",
      "[2145]\ttraining's rmse: 3.32025\tvalid_1's rmse: 3.78886\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58292\tvalid_1's rmse: 3.64739\n",
      "[1000]\ttraining's rmse: 3.4858\tvalid_1's rmse: 3.63147\n",
      "[1500]\ttraining's rmse: 3.42248\tvalid_1's rmse: 3.62552\n",
      "[2000]\ttraining's rmse: 3.3722\tvalid_1's rmse: 3.62389\n",
      "Early stopping, best iteration is:\n",
      "[2193]\ttraining's rmse: 3.35445\tvalid_1's rmse: 3.62364\n",
      "  224 | 07m46s |   -3.66516 |             0.9785 |         9.9535 |             0.3640 |             0.4176 |     14.8579 |             49.8260 |            42.7926 |            49.4924 |           0.9558 |      44.8692 |      4.9887 |       8.5724 |      0.7775 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60405\tvalid_1's rmse: 3.71274\n",
      "[1000]\ttraining's rmse: 3.53321\tvalid_1's rmse: 3.69251\n",
      "[1500]\ttraining's rmse: 3.48424\tvalid_1's rmse: 3.68628\n",
      "[2000]\ttraining's rmse: 3.44271\tvalid_1's rmse: 3.68366\n",
      "[2500]\ttraining's rmse: 3.40866\tvalid_1's rmse: 3.68349\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's rmse: 3.41789\tvalid_1's rmse: 3.6832\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61795\tvalid_1's rmse: 3.65388\n",
      "[1000]\ttraining's rmse: 3.54403\tvalid_1's rmse: 3.6352\n",
      "[1500]\ttraining's rmse: 3.49543\tvalid_1's rmse: 3.62931\n",
      "[2000]\ttraining's rmse: 3.45552\tvalid_1's rmse: 3.62653\n",
      "[2500]\ttraining's rmse: 3.41765\tvalid_1's rmse: 3.62555\n",
      "[3000]\ttraining's rmse: 3.38389\tvalid_1's rmse: 3.62484\n",
      "Early stopping, best iteration is:\n",
      "[2878]\ttraining's rmse: 3.39204\tvalid_1's rmse: 3.62456\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62067\tvalid_1's rmse: 3.62902\n",
      "[1000]\ttraining's rmse: 3.54922\tvalid_1's rmse: 3.61283\n",
      "[1500]\ttraining's rmse: 3.49987\tvalid_1's rmse: 3.60756\n",
      "Early stopping, best iteration is:\n",
      "[1680]\ttraining's rmse: 3.4849\tvalid_1's rmse: 3.60681\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57796\tvalid_1's rmse: 3.814\n",
      "[1000]\ttraining's rmse: 3.50278\tvalid_1's rmse: 3.7959\n",
      "[1500]\ttraining's rmse: 3.45505\tvalid_1's rmse: 3.79153\n",
      "[2000]\ttraining's rmse: 3.41286\tvalid_1's rmse: 3.78998\n",
      "Early stopping, best iteration is:\n",
      "[1870]\ttraining's rmse: 3.42302\tvalid_1's rmse: 3.78976\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61672\tvalid_1's rmse: 3.64894\n",
      "[1000]\ttraining's rmse: 3.54239\tvalid_1's rmse: 3.63246\n",
      "[1500]\ttraining's rmse: 3.49465\tvalid_1's rmse: 3.62701\n",
      "[2000]\ttraining's rmse: 3.45385\tvalid_1's rmse: 3.62517\n",
      "Early stopping, best iteration is:\n",
      "[1966]\ttraining's rmse: 3.45656\tvalid_1's rmse: 3.62503\n",
      "  225 | 07m25s |   -3.66649 |             0.8451 |        10.7019 |             0.4639 |             0.6698 |     10.6964 |              6.1800 |            44.2870 |            49.6665 |           0.2955 |      30.4223 |      2.8681 |       9.3807 |      0.8767 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59369\tvalid_1's rmse: 3.71468\n",
      "[1000]\ttraining's rmse: 3.51073\tvalid_1's rmse: 3.69399\n",
      "[1500]\ttraining's rmse: 3.45655\tvalid_1's rmse: 3.68759\n",
      "[2000]\ttraining's rmse: 3.41303\tvalid_1's rmse: 3.68475\n",
      "[2500]\ttraining's rmse: 3.37641\tvalid_1's rmse: 3.68381\n",
      "[3000]\ttraining's rmse: 3.34146\tvalid_1's rmse: 3.68323\n",
      "Early stopping, best iteration is:\n",
      "[3165]\ttraining's rmse: 3.33181\tvalid_1's rmse: 3.68294\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60771\tvalid_1's rmse: 3.65677\n",
      "[1000]\ttraining's rmse: 3.52381\tvalid_1's rmse: 3.63812\n",
      "[1500]\ttraining's rmse: 3.46881\tvalid_1's rmse: 3.63076\n",
      "[2000]\ttraining's rmse: 3.42498\tvalid_1's rmse: 3.62846\n",
      "[2500]\ttraining's rmse: 3.38753\tvalid_1's rmse: 3.62728\n",
      "[3000]\ttraining's rmse: 3.35303\tvalid_1's rmse: 3.62663\n",
      "Early stopping, best iteration is:\n",
      "[2993]\ttraining's rmse: 3.35351\tvalid_1's rmse: 3.62656\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61036\tvalid_1's rmse: 3.63215\n",
      "[1000]\ttraining's rmse: 3.52817\tvalid_1's rmse: 3.61475\n",
      "[1500]\ttraining's rmse: 3.47189\tvalid_1's rmse: 3.60882\n",
      "[2000]\ttraining's rmse: 3.42843\tvalid_1's rmse: 3.60659\n",
      "[2500]\ttraining's rmse: 3.38982\tvalid_1's rmse: 3.60617\n",
      "Early stopping, best iteration is:\n",
      "[2603]\ttraining's rmse: 3.38195\tvalid_1's rmse: 3.60603\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56675\tvalid_1's rmse: 3.81509\n",
      "[1000]\ttraining's rmse: 3.48189\tvalid_1's rmse: 3.79678\n",
      "[1500]\ttraining's rmse: 3.42532\tvalid_1's rmse: 3.79192\n",
      "[2000]\ttraining's rmse: 3.38104\tvalid_1's rmse: 3.78967\n",
      "[2500]\ttraining's rmse: 3.34408\tvalid_1's rmse: 3.78862\n",
      "Early stopping, best iteration is:\n",
      "[2388]\ttraining's rmse: 3.35226\tvalid_1's rmse: 3.78851\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60548\tvalid_1's rmse: 3.65229\n",
      "[1000]\ttraining's rmse: 3.52076\tvalid_1's rmse: 3.63433\n",
      "[1500]\ttraining's rmse: 3.46553\tvalid_1's rmse: 3.62748\n",
      "[2000]\ttraining's rmse: 3.42286\tvalid_1's rmse: 3.62502\n",
      "Early stopping, best iteration is:\n",
      "[2150]\ttraining's rmse: 3.4105\tvalid_1's rmse: 3.62452\n",
      "  226 | 07m46s |   -3.66632 |             0.9458 |        14.7919 |             0.9898 |             0.5088 |     14.2338 |              5.9949 |            41.5204 |            22.5716 |           0.6115 |      30.6151 |      4.4378 |       0.4655 |      0.1418 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60222\tvalid_1's rmse: 3.71533\n",
      "[1000]\ttraining's rmse: 3.52446\tvalid_1's rmse: 3.69457\n",
      "[1500]\ttraining's rmse: 3.47151\tvalid_1's rmse: 3.68765\n",
      "[2000]\ttraining's rmse: 3.43181\tvalid_1's rmse: 3.68529\n",
      "[2500]\ttraining's rmse: 3.39741\tvalid_1's rmse: 3.68413\n",
      "Early stopping, best iteration is:\n",
      "[2644]\ttraining's rmse: 3.38832\tvalid_1's rmse: 3.68404\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61705\tvalid_1's rmse: 3.65568\n",
      "[1000]\ttraining's rmse: 3.53632\tvalid_1's rmse: 3.63636\n",
      "[1500]\ttraining's rmse: 3.48336\tvalid_1's rmse: 3.63026\n",
      "[2000]\ttraining's rmse: 3.44268\tvalid_1's rmse: 3.62745\n",
      "[2500]\ttraining's rmse: 3.40736\tvalid_1's rmse: 3.62664\n",
      "[3000]\ttraining's rmse: 3.37568\tvalid_1's rmse: 3.62609\n",
      "Early stopping, best iteration is:\n",
      "[2893]\ttraining's rmse: 3.3824\tvalid_1's rmse: 3.62602\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61979\tvalid_1's rmse: 3.63095\n",
      "[1000]\ttraining's rmse: 3.54093\tvalid_1's rmse: 3.61242\n",
      "[1500]\ttraining's rmse: 3.48869\tvalid_1's rmse: 3.60666\n",
      "[2000]\ttraining's rmse: 3.44799\tvalid_1's rmse: 3.60444\n",
      "Early stopping, best iteration is:\n",
      "[2253]\ttraining's rmse: 3.42979\tvalid_1's rmse: 3.604\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57531\tvalid_1's rmse: 3.81454\n",
      "[1000]\ttraining's rmse: 3.49423\tvalid_1's rmse: 3.79686\n",
      "[1500]\ttraining's rmse: 3.44038\tvalid_1's rmse: 3.79102\n",
      "[2000]\ttraining's rmse: 3.39981\tvalid_1's rmse: 3.78926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500]\ttraining's rmse: 3.36743\tvalid_1's rmse: 3.78842\n",
      "Early stopping, best iteration is:\n",
      "[2772]\ttraining's rmse: 3.35124\tvalid_1's rmse: 3.78807\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6147\tvalid_1's rmse: 3.65106\n",
      "[1000]\ttraining's rmse: 3.53472\tvalid_1's rmse: 3.63546\n",
      "[1500]\ttraining's rmse: 3.48252\tvalid_1's rmse: 3.62935\n",
      "[2000]\ttraining's rmse: 3.44157\tvalid_1's rmse: 3.62743\n",
      "[2500]\ttraining's rmse: 3.40683\tvalid_1's rmse: 3.62647\n",
      "Early stopping, best iteration is:\n",
      "[2348]\ttraining's rmse: 3.41674\tvalid_1's rmse: 3.62638\n",
      "  227 | 07m23s |   -3.66631 |             0.9557 |         0.1709 |             0.9707 |             0.5489 |     13.9892 |             49.0241 |            43.6858 |            11.1204 |           0.0305 |      30.6095 |      0.5541 |       9.2682 |      0.2103 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61415\tvalid_1's rmse: 3.70704\n",
      "[1000]\ttraining's rmse: 3.5582\tvalid_1's rmse: 3.68809\n",
      "[1500]\ttraining's rmse: 3.51805\tvalid_1's rmse: 3.68312\n",
      "[2000]\ttraining's rmse: 3.48329\tvalid_1's rmse: 3.68114\n",
      "Early stopping, best iteration is:\n",
      "[2149]\ttraining's rmse: 3.47383\tvalid_1's rmse: 3.68064\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62797\tvalid_1's rmse: 3.64733\n",
      "[1000]\ttraining's rmse: 3.57035\tvalid_1's rmse: 3.63056\n",
      "[1500]\ttraining's rmse: 3.53016\tvalid_1's rmse: 3.62616\n",
      "[2000]\ttraining's rmse: 3.49512\tvalid_1's rmse: 3.6242\n",
      "[2500]\ttraining's rmse: 3.46329\tvalid_1's rmse: 3.6231\n",
      "[3000]\ttraining's rmse: 3.43332\tvalid_1's rmse: 3.62237\n",
      "Early stopping, best iteration is:\n",
      "[3108]\ttraining's rmse: 3.42666\tvalid_1's rmse: 3.62204\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63161\tvalid_1's rmse: 3.62362\n",
      "[1000]\ttraining's rmse: 3.57217\tvalid_1's rmse: 3.60741\n",
      "[1500]\ttraining's rmse: 3.53225\tvalid_1's rmse: 3.60381\n",
      "[2000]\ttraining's rmse: 3.49704\tvalid_1's rmse: 3.60273\n",
      "Early stopping, best iteration is:\n",
      "[1944]\ttraining's rmse: 3.50093\tvalid_1's rmse: 3.60256\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58608\tvalid_1's rmse: 3.81125\n",
      "[1000]\ttraining's rmse: 3.5273\tvalid_1's rmse: 3.79526\n",
      "[1500]\ttraining's rmse: 3.48761\tvalid_1's rmse: 3.79145\n",
      "[2000]\ttraining's rmse: 3.45266\tvalid_1's rmse: 3.7898\n",
      "Early stopping, best iteration is:\n",
      "[2149]\ttraining's rmse: 3.44285\tvalid_1's rmse: 3.78955\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62777\tvalid_1's rmse: 3.6403\n",
      "[1000]\ttraining's rmse: 3.56819\tvalid_1's rmse: 3.62555\n",
      "[1500]\ttraining's rmse: 3.52776\tvalid_1's rmse: 3.62126\n",
      "[2000]\ttraining's rmse: 3.49368\tvalid_1's rmse: 3.62021\n",
      "Early stopping, best iteration is:\n",
      "[1955]\ttraining's rmse: 3.49637\tvalid_1's rmse: 3.62013\n",
      "  228 | 08m09s |   -3.66363 |             0.8357 |         2.3984 |             0.3251 |             0.5394 |      7.3598 |              5.1831 |            30.0743 |            99.6321 |           0.2334 |      41.5948 |      7.4565 |       9.2889 |      0.2972 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.575\tvalid_1's rmse: 3.71126\n",
      "[1000]\ttraining's rmse: 3.48812\tvalid_1's rmse: 3.69154\n",
      "[1500]\ttraining's rmse: 3.42977\tvalid_1's rmse: 3.68547\n",
      "[2000]\ttraining's rmse: 3.38225\tvalid_1's rmse: 3.6839\n",
      "Early stopping, best iteration is:\n",
      "[2109]\ttraining's rmse: 3.37285\tvalid_1's rmse: 3.68364\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58845\tvalid_1's rmse: 3.65286\n",
      "[1000]\ttraining's rmse: 3.49994\tvalid_1's rmse: 3.63457\n",
      "[1500]\ttraining's rmse: 3.44094\tvalid_1's rmse: 3.6294\n",
      "[2000]\ttraining's rmse: 3.39326\tvalid_1's rmse: 3.62722\n",
      "[2500]\ttraining's rmse: 3.35098\tvalid_1's rmse: 3.62654\n",
      "[3000]\ttraining's rmse: 3.31312\tvalid_1's rmse: 3.62614\n",
      "Early stopping, best iteration is:\n",
      "[3046]\ttraining's rmse: 3.3099\tvalid_1's rmse: 3.6259\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59314\tvalid_1's rmse: 3.63033\n",
      "[1000]\ttraining's rmse: 3.5049\tvalid_1's rmse: 3.61406\n",
      "[1500]\ttraining's rmse: 3.44621\tvalid_1's rmse: 3.60987\n",
      "[2000]\ttraining's rmse: 3.39874\tvalid_1's rmse: 3.60835\n",
      "Early stopping, best iteration is:\n",
      "[2274]\ttraining's rmse: 3.37539\tvalid_1's rmse: 3.60793\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5483\tvalid_1's rmse: 3.80855\n",
      "[1000]\ttraining's rmse: 3.45924\tvalid_1's rmse: 3.79299\n",
      "[1500]\ttraining's rmse: 3.39915\tvalid_1's rmse: 3.788\n",
      "[2000]\ttraining's rmse: 3.35186\tvalid_1's rmse: 3.78708\n",
      "[2500]\ttraining's rmse: 3.31018\tvalid_1's rmse: 3.78656\n",
      "Early stopping, best iteration is:\n",
      "[2500]\ttraining's rmse: 3.31018\tvalid_1's rmse: 3.78656\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58655\tvalid_1's rmse: 3.64999\n",
      "[1000]\ttraining's rmse: 3.49843\tvalid_1's rmse: 3.63438\n",
      "[1500]\ttraining's rmse: 3.44032\tvalid_1's rmse: 3.6288\n",
      "[2000]\ttraining's rmse: 3.39413\tvalid_1's rmse: 3.62752\n",
      "[2500]\ttraining's rmse: 3.35217\tvalid_1's rmse: 3.62724\n",
      "Early stopping, best iteration is:\n",
      "[2303]\ttraining's rmse: 3.36847\tvalid_1's rmse: 3.6272\n",
      "  229 | 08m06s |   -3.66683 |             0.9234 |         1.8633 |             0.8299 |             0.7141 |     14.2410 |             49.0294 |            43.9061 |            28.0414 |           0.6563 |      33.7655 |      8.4530 |       0.1206 |      0.5736 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58956\tvalid_1's rmse: 3.70266\n",
      "[1000]\ttraining's rmse: 3.52484\tvalid_1's rmse: 3.6852\n",
      "[1500]\ttraining's rmse: 3.47757\tvalid_1's rmse: 3.68154\n",
      "[2000]\ttraining's rmse: 3.43868\tvalid_1's rmse: 3.68056\n",
      "Early stopping, best iteration is:\n",
      "[1945]\ttraining's rmse: 3.44228\tvalid_1's rmse: 3.68036\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60281\tvalid_1's rmse: 3.64548\n",
      "[1000]\ttraining's rmse: 3.53562\tvalid_1's rmse: 3.63012\n",
      "[1500]\ttraining's rmse: 3.48838\tvalid_1's rmse: 3.62646\n",
      "[2000]\ttraining's rmse: 3.44665\tvalid_1's rmse: 3.62493\n",
      "Early stopping, best iteration is:\n",
      "[2002]\ttraining's rmse: 3.44659\tvalid_1's rmse: 3.62493\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60609\tvalid_1's rmse: 3.62202\n",
      "[1000]\ttraining's rmse: 3.54071\tvalid_1's rmse: 3.60743\n",
      "[1500]\ttraining's rmse: 3.49295\tvalid_1's rmse: 3.60468\n",
      "Early stopping, best iteration is:\n",
      "[1638]\ttraining's rmse: 3.47985\tvalid_1's rmse: 3.60442\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56033\tvalid_1's rmse: 3.80541\n",
      "[1000]\ttraining's rmse: 3.49382\tvalid_1's rmse: 3.79262\n",
      "[1500]\ttraining's rmse: 3.44744\tvalid_1's rmse: 3.78947\n",
      "Early stopping, best iteration is:\n",
      "[1683]\ttraining's rmse: 3.43206\tvalid_1's rmse: 3.78875\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60145\tvalid_1's rmse: 3.63902\n",
      "[1000]\ttraining's rmse: 3.53288\tvalid_1's rmse: 3.62606\n",
      "[1500]\ttraining's rmse: 3.48535\tvalid_1's rmse: 3.6224\n",
      "[2000]\ttraining's rmse: 3.44606\tvalid_1's rmse: 3.62156\n",
      "[2500]\ttraining's rmse: 3.41027\tvalid_1's rmse: 3.62148\n",
      "Early stopping, best iteration is:\n",
      "[2434]\ttraining's rmse: 3.41462\tvalid_1's rmse: 3.62123\n",
      "  230 | 08m09s |   -3.66456 |             0.9318 |        11.5532 |             0.5169 |             0.7502 |      8.1207 |             27.1809 |            30.2876 |            97.7282 |           0.0865 |      43.9352 |      4.2365 |       0.2771 |      0.4450 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66141\tvalid_1's rmse: 3.72768\n",
      "[1000]\ttraining's rmse: 3.61171\tvalid_1's rmse: 3.70059\n",
      "[1500]\ttraining's rmse: 3.58092\tvalid_1's rmse: 3.69186\n",
      "[2000]\ttraining's rmse: 3.55515\tvalid_1's rmse: 3.68732\n",
      "[2500]\ttraining's rmse: 3.53233\tvalid_1's rmse: 3.68475\n",
      "[3000]\ttraining's rmse: 3.51088\tvalid_1's rmse: 3.6833\n",
      "[3500]\ttraining's rmse: 3.49075\tvalid_1's rmse: 3.68221\n",
      "[4000]\ttraining's rmse: 3.47081\tvalid_1's rmse: 3.68171\n",
      "Early stopping, best iteration is:\n",
      "[3967]\ttraining's rmse: 3.47212\tvalid_1's rmse: 3.68162\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's rmse: 3.67523\tvalid_1's rmse: 3.66569\n",
      "[1000]\ttraining's rmse: 3.62423\tvalid_1's rmse: 3.64254\n",
      "[1500]\ttraining's rmse: 3.59217\tvalid_1's rmse: 3.63384\n",
      "[2000]\ttraining's rmse: 3.56619\tvalid_1's rmse: 3.62881\n",
      "[2500]\ttraining's rmse: 3.54309\tvalid_1's rmse: 3.6264\n",
      "[3000]\ttraining's rmse: 3.52083\tvalid_1's rmse: 3.62452\n",
      "[3500]\ttraining's rmse: 3.50004\tvalid_1's rmse: 3.62408\n",
      "Early stopping, best iteration is:\n",
      "[3745]\ttraining's rmse: 3.49037\tvalid_1's rmse: 3.62374\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67943\tvalid_1's rmse: 3.64031\n",
      "[1000]\ttraining's rmse: 3.62834\tvalid_1's rmse: 3.61782\n",
      "[1500]\ttraining's rmse: 3.59635\tvalid_1's rmse: 3.61105\n",
      "[2000]\ttraining's rmse: 3.57023\tvalid_1's rmse: 3.60816\n",
      "[2500]\ttraining's rmse: 3.54689\tvalid_1's rmse: 3.60659\n",
      "[3000]\ttraining's rmse: 3.52477\tvalid_1's rmse: 3.6057\n",
      "Early stopping, best iteration is:\n",
      "[3126]\ttraining's rmse: 3.51911\tvalid_1's rmse: 3.60561\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63222\tvalid_1's rmse: 3.83377\n",
      "[1000]\ttraining's rmse: 3.58187\tvalid_1's rmse: 3.81038\n",
      "[1500]\ttraining's rmse: 3.551\tvalid_1's rmse: 3.80315\n",
      "[2000]\ttraining's rmse: 3.52559\tvalid_1's rmse: 3.79869\n",
      "[2500]\ttraining's rmse: 3.50226\tvalid_1's rmse: 3.79664\n",
      "[3000]\ttraining's rmse: 3.48032\tvalid_1's rmse: 3.7956\n",
      "[3500]\ttraining's rmse: 3.45997\tvalid_1's rmse: 3.79512\n",
      "[4000]\ttraining's rmse: 3.4397\tvalid_1's rmse: 3.79485\n",
      "[4500]\ttraining's rmse: 3.42055\tvalid_1's rmse: 3.79431\n",
      "Early stopping, best iteration is:\n",
      "[4471]\ttraining's rmse: 3.42162\tvalid_1's rmse: 3.79427\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67579\tvalid_1's rmse: 3.65762\n",
      "[1000]\ttraining's rmse: 3.62378\tvalid_1's rmse: 3.63617\n",
      "[1500]\ttraining's rmse: 3.59235\tvalid_1's rmse: 3.62938\n",
      "[2000]\ttraining's rmse: 3.56661\tvalid_1's rmse: 3.62598\n",
      "[2500]\ttraining's rmse: 3.54409\tvalid_1's rmse: 3.62494\n",
      "[3000]\ttraining's rmse: 3.52249\tvalid_1's rmse: 3.62412\n",
      "Early stopping, best iteration is:\n",
      "[2952]\ttraining's rmse: 3.52433\tvalid_1's rmse: 3.62408\n",
      "  231 | 06m59s |   -3.66652 |             0.7292 |         1.0352 |             0.8162 |             0.2195 |      6.6720 |             49.4201 |            30.4270 |            99.8631 |           0.7553 |      31.4712 |      8.5573 |       0.7471 |      0.7687 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60829\tvalid_1's rmse: 3.72746\n",
      "[1000]\ttraining's rmse: 3.51946\tvalid_1's rmse: 3.70254\n",
      "[1500]\ttraining's rmse: 3.45882\tvalid_1's rmse: 3.69326\n",
      "[2000]\ttraining's rmse: 3.4104\tvalid_1's rmse: 3.68989\n",
      "[2500]\ttraining's rmse: 3.36734\tvalid_1's rmse: 3.68828\n",
      "[3000]\ttraining's rmse: 3.32782\tvalid_1's rmse: 3.68732\n",
      "Early stopping, best iteration is:\n",
      "[3074]\ttraining's rmse: 3.32191\tvalid_1's rmse: 3.68706\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62204\tvalid_1's rmse: 3.66768\n",
      "[1000]\ttraining's rmse: 3.53115\tvalid_1's rmse: 3.64598\n",
      "[1500]\ttraining's rmse: 3.46905\tvalid_1's rmse: 3.6371\n",
      "[2000]\ttraining's rmse: 3.41898\tvalid_1's rmse: 3.63348\n",
      "[2500]\ttraining's rmse: 3.37552\tvalid_1's rmse: 3.63154\n",
      "[3000]\ttraining's rmse: 3.33593\tvalid_1's rmse: 3.63042\n",
      "Early stopping, best iteration is:\n",
      "[2896]\ttraining's rmse: 3.34383\tvalid_1's rmse: 3.63032\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62697\tvalid_1's rmse: 3.64154\n",
      "[1000]\ttraining's rmse: 3.53683\tvalid_1's rmse: 3.62115\n",
      "[1500]\ttraining's rmse: 3.47655\tvalid_1's rmse: 3.61448\n",
      "[2000]\ttraining's rmse: 3.42662\tvalid_1's rmse: 3.61187\n",
      "[2500]\ttraining's rmse: 3.38277\tvalid_1's rmse: 3.61036\n",
      "Early stopping, best iteration is:\n",
      "[2377]\ttraining's rmse: 3.39334\tvalid_1's rmse: 3.61011\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58058\tvalid_1's rmse: 3.83296\n",
      "[1000]\ttraining's rmse: 3.49064\tvalid_1's rmse: 3.8096\n",
      "[1500]\ttraining's rmse: 3.43031\tvalid_1's rmse: 3.80139\n",
      "[2000]\ttraining's rmse: 3.38085\tvalid_1's rmse: 3.79769\n",
      "[2500]\ttraining's rmse: 3.33603\tvalid_1's rmse: 3.79653\n",
      "[3000]\ttraining's rmse: 3.29766\tvalid_1's rmse: 3.79543\n",
      "[3500]\ttraining's rmse: 3.26\tvalid_1's rmse: 3.79467\n",
      "[4000]\ttraining's rmse: 3.2246\tvalid_1's rmse: 3.79411\n",
      "[4500]\ttraining's rmse: 3.19184\tvalid_1's rmse: 3.79384\n",
      "Early stopping, best iteration is:\n",
      "[4476]\ttraining's rmse: 3.19334\tvalid_1's rmse: 3.79375\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62135\tvalid_1's rmse: 3.66232\n",
      "[1000]\ttraining's rmse: 3.52961\tvalid_1's rmse: 3.64158\n",
      "[1500]\ttraining's rmse: 3.46801\tvalid_1's rmse: 3.63391\n",
      "[2000]\ttraining's rmse: 3.41903\tvalid_1's rmse: 3.63043\n",
      "[2500]\ttraining's rmse: 3.37553\tvalid_1's rmse: 3.62896\n",
      "Early stopping, best iteration is:\n",
      "[2633]\ttraining's rmse: 3.36475\tvalid_1's rmse: 3.62867\n",
      "  232 | 07m34s |   -3.67059 |             0.8267 |        15.3475 |             0.3925 |             0.1840 |     12.7350 |              5.1272 |            31.1414 |            39.8700 |           0.9685 |      41.7109 |      8.8594 |       1.6337 |      0.7650 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60849\tvalid_1's rmse: 3.71203\n",
      "[1000]\ttraining's rmse: 3.53823\tvalid_1's rmse: 3.69218\n",
      "[1500]\ttraining's rmse: 3.49109\tvalid_1's rmse: 3.6855\n",
      "[2000]\ttraining's rmse: 3.45388\tvalid_1's rmse: 3.68303\n",
      "[2500]\ttraining's rmse: 3.42128\tvalid_1's rmse: 3.68216\n",
      "[3000]\ttraining's rmse: 3.39093\tvalid_1's rmse: 3.68096\n",
      "Early stopping, best iteration is:\n",
      "[3079]\ttraining's rmse: 3.38655\tvalid_1's rmse: 3.68077\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62212\tvalid_1's rmse: 3.65372\n",
      "[1000]\ttraining's rmse: 3.54965\tvalid_1's rmse: 3.63499\n",
      "[1500]\ttraining's rmse: 3.50459\tvalid_1's rmse: 3.62945\n",
      "[2000]\ttraining's rmse: 3.4669\tvalid_1's rmse: 3.62704\n",
      "[2500]\ttraining's rmse: 3.4333\tvalid_1's rmse: 3.62658\n",
      "[3000]\ttraining's rmse: 3.40184\tvalid_1's rmse: 3.6257\n",
      "Early stopping, best iteration is:\n",
      "[3046]\ttraining's rmse: 3.39897\tvalid_1's rmse: 3.62558\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62665\tvalid_1's rmse: 3.62944\n",
      "[1000]\ttraining's rmse: 3.55509\tvalid_1's rmse: 3.61113\n",
      "[1500]\ttraining's rmse: 3.50815\tvalid_1's rmse: 3.60559\n",
      "[2000]\ttraining's rmse: 3.47117\tvalid_1's rmse: 3.60437\n",
      "Early stopping, best iteration is:\n",
      "[2191]\ttraining's rmse: 3.45814\tvalid_1's rmse: 3.60404\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58206\tvalid_1's rmse: 3.81313\n",
      "[1000]\ttraining's rmse: 3.50987\tvalid_1's rmse: 3.79591\n",
      "[1500]\ttraining's rmse: 3.46343\tvalid_1's rmse: 3.79069\n",
      "[2000]\ttraining's rmse: 3.42689\tvalid_1's rmse: 3.78954\n",
      "[2500]\ttraining's rmse: 3.3945\tvalid_1's rmse: 3.78908\n",
      "Early stopping, best iteration is:\n",
      "[2770]\ttraining's rmse: 3.37773\tvalid_1's rmse: 3.78865\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62114\tvalid_1's rmse: 3.64661\n",
      "[1000]\ttraining's rmse: 3.54902\tvalid_1's rmse: 3.63032\n",
      "[1500]\ttraining's rmse: 3.50278\tvalid_1's rmse: 3.62503\n",
      "[2000]\ttraining's rmse: 3.46623\tvalid_1's rmse: 3.62248\n",
      "Early stopping, best iteration is:\n",
      "[2296]\ttraining's rmse: 3.44675\tvalid_1's rmse: 3.6215\n",
      "  233 | 07m56s |   -3.66473 |             0.9471 |        17.1345 |             0.4894 |             0.6049 |     14.7493 |             20.9037 |            30.0977 |            79.7370 |           0.9942 |      30.5025 |      3.7898 |       7.9639 |      0.7642 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00048532]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61124\tvalid_1's rmse: 3.71618\n",
      "[1000]\ttraining's rmse: 3.54525\tvalid_1's rmse: 3.69526\n",
      "[1500]\ttraining's rmse: 3.49893\tvalid_1's rmse: 3.68858\n",
      "[2000]\ttraining's rmse: 3.45894\tvalid_1's rmse: 3.68601\n",
      "[2500]\ttraining's rmse: 3.42348\tvalid_1's rmse: 3.68457\n",
      "Early stopping, best iteration is:\n",
      "[2482]\ttraining's rmse: 3.4248\tvalid_1's rmse: 3.68444\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62473\tvalid_1's rmse: 3.65657\n",
      "[1000]\ttraining's rmse: 3.556\tvalid_1's rmse: 3.63659\n",
      "[1500]\ttraining's rmse: 3.50912\tvalid_1's rmse: 3.629\n",
      "[2000]\ttraining's rmse: 3.46933\tvalid_1's rmse: 3.6259\n",
      "[2500]\ttraining's rmse: 3.43254\tvalid_1's rmse: 3.62481\n",
      "[3000]\ttraining's rmse: 3.3993\tvalid_1's rmse: 3.62457\n",
      "Early stopping, best iteration is:\n",
      "[3213]\ttraining's rmse: 3.38457\tvalid_1's rmse: 3.62393\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63003\tvalid_1's rmse: 3.62996\n",
      "[1000]\ttraining's rmse: 3.56161\tvalid_1's rmse: 3.611\n",
      "[1500]\ttraining's rmse: 3.51473\tvalid_1's rmse: 3.60642\n",
      "[2000]\ttraining's rmse: 3.47468\tvalid_1's rmse: 3.60502\n",
      "Early stopping, best iteration is:\n",
      "[2126]\ttraining's rmse: 3.46551\tvalid_1's rmse: 3.60453\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58361\tvalid_1's rmse: 3.81778\n",
      "[1000]\ttraining's rmse: 3.51451\tvalid_1's rmse: 3.79858\n",
      "[1500]\ttraining's rmse: 3.46787\tvalid_1's rmse: 3.79337\n",
      "[2000]\ttraining's rmse: 3.42813\tvalid_1's rmse: 3.79072\n",
      "[2500]\ttraining's rmse: 3.39197\tvalid_1's rmse: 3.78994\n",
      "[3000]\ttraining's rmse: 3.35918\tvalid_1's rmse: 3.78901\n",
      "Early stopping, best iteration is:\n",
      "[3010]\ttraining's rmse: 3.35855\tvalid_1's rmse: 3.78897\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62447\tvalid_1's rmse: 3.65035\n",
      "[1000]\ttraining's rmse: 3.55326\tvalid_1's rmse: 3.63235\n",
      "[1500]\ttraining's rmse: 3.50741\tvalid_1's rmse: 3.62653\n",
      "[2000]\ttraining's rmse: 3.46816\tvalid_1's rmse: 3.62535\n",
      "Early stopping, best iteration is:\n",
      "[1861]\ttraining's rmse: 3.4788\tvalid_1's rmse: 3.62522\n",
      "  234 | 07m06s |   -3.66604 |             0.7885 |         9.9199 |             0.6670 |             0.4189 |      8.3023 |              5.7255 |            34.6212 |            10.6918 |           0.3995 |      30.0765 |      9.8815 |       1.5555 |      0.1083 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57643\tvalid_1's rmse: 3.70409\n",
      "[1000]\ttraining's rmse: 3.50446\tvalid_1's rmse: 3.68774\n",
      "[1500]\ttraining's rmse: 3.45243\tvalid_1's rmse: 3.68367\n",
      "[2000]\ttraining's rmse: 3.40615\tvalid_1's rmse: 3.68244\n",
      "Early stopping, best iteration is:\n",
      "[2288]\ttraining's rmse: 3.38318\tvalid_1's rmse: 3.68225\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.5889\tvalid_1's rmse: 3.64572\n",
      "[1000]\ttraining's rmse: 3.51382\tvalid_1's rmse: 3.63035\n",
      "[1500]\ttraining's rmse: 3.46142\tvalid_1's rmse: 3.62676\n",
      "[2000]\ttraining's rmse: 3.41543\tvalid_1's rmse: 3.62529\n",
      "Early stopping, best iteration is:\n",
      "[2119]\ttraining's rmse: 3.40492\tvalid_1's rmse: 3.62511\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59325\tvalid_1's rmse: 3.62212\n",
      "[1000]\ttraining's rmse: 3.51751\tvalid_1's rmse: 3.60866\n",
      "[1500]\ttraining's rmse: 3.46362\tvalid_1's rmse: 3.60551\n",
      "[2000]\ttraining's rmse: 3.41805\tvalid_1's rmse: 3.60527\n",
      "Early stopping, best iteration is:\n",
      "[1885]\ttraining's rmse: 3.42833\tvalid_1's rmse: 3.605\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54762\tvalid_1's rmse: 3.8052\n",
      "[1000]\ttraining's rmse: 3.47362\tvalid_1's rmse: 3.79171\n",
      "[1500]\ttraining's rmse: 3.41956\tvalid_1's rmse: 3.78921\n",
      "[2000]\ttraining's rmse: 3.37548\tvalid_1's rmse: 3.78901\n",
      "Early stopping, best iteration is:\n",
      "[1863]\ttraining's rmse: 3.38728\tvalid_1's rmse: 3.78871\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58794\tvalid_1's rmse: 3.64095\n",
      "[1000]\ttraining's rmse: 3.51317\tvalid_1's rmse: 3.62803\n",
      "[1500]\ttraining's rmse: 3.46108\tvalid_1's rmse: 3.62538\n",
      "Early stopping, best iteration is:\n",
      "[1789]\ttraining's rmse: 3.43377\tvalid_1's rmse: 3.62497\n",
      "  235 | 08m10s |   -3.66582 |             0.9131 |         6.9987 |             0.1154 |             0.7437 |      8.3425 |             23.0782 |            31.5570 |            62.5434 |           0.9716 |      44.5486 |      8.6300 |       0.5649 |      0.9302 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60012\tvalid_1's rmse: 3.70621\n",
      "[1000]\ttraining's rmse: 3.53058\tvalid_1's rmse: 3.68804\n",
      "[1500]\ttraining's rmse: 3.48192\tvalid_1's rmse: 3.68308\n",
      "[2000]\ttraining's rmse: 3.44106\tvalid_1's rmse: 3.68084\n",
      "Early stopping, best iteration is:\n",
      "[2256]\ttraining's rmse: 3.42223\tvalid_1's rmse: 3.68032\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61414\tvalid_1's rmse: 3.64881\n",
      "[1000]\ttraining's rmse: 3.5455\tvalid_1's rmse: 3.63234\n",
      "[1500]\ttraining's rmse: 3.49712\tvalid_1's rmse: 3.62693\n",
      "[2000]\ttraining's rmse: 3.45695\tvalid_1's rmse: 3.62547\n",
      "[2500]\ttraining's rmse: 3.41896\tvalid_1's rmse: 3.62513\n",
      "Early stopping, best iteration is:\n",
      "[2731]\ttraining's rmse: 3.40242\tvalid_1's rmse: 3.62448\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61896\tvalid_1's rmse: 3.62507\n",
      "[1000]\ttraining's rmse: 3.54894\tvalid_1's rmse: 3.60873\n",
      "[1500]\ttraining's rmse: 3.50047\tvalid_1's rmse: 3.60507\n",
      "[2000]\ttraining's rmse: 3.46028\tvalid_1's rmse: 3.60401\n",
      "Early stopping, best iteration is:\n",
      "[2059]\ttraining's rmse: 3.45558\tvalid_1's rmse: 3.60365\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57409\tvalid_1's rmse: 3.80873\n",
      "[1000]\ttraining's rmse: 3.50387\tvalid_1's rmse: 3.7948\n",
      "[1500]\ttraining's rmse: 3.45639\tvalid_1's rmse: 3.79129\n",
      "[2000]\ttraining's rmse: 3.41471\tvalid_1's rmse: 3.79024\n",
      "Early stopping, best iteration is:\n",
      "[2283]\ttraining's rmse: 3.39318\tvalid_1's rmse: 3.7897\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61385\tvalid_1's rmse: 3.64521\n",
      "[1000]\ttraining's rmse: 3.54382\tvalid_1's rmse: 3.63126\n",
      "[1500]\ttraining's rmse: 3.49664\tvalid_1's rmse: 3.62712\n",
      "[2000]\ttraining's rmse: 3.45536\tvalid_1's rmse: 3.62616\n",
      "Early stopping, best iteration is:\n",
      "[2050]\ttraining's rmse: 3.45163\tvalid_1's rmse: 3.62596\n",
      "  236 | 08m17s |   -3.66544 |             0.7863 |         5.1694 |             0.3423 |             0.8565 |     14.3195 |             30.0054 |            41.2738 |            99.6087 |           0.0016 |      33.4620 |      2.7916 |       3.1208 |      0.8282 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00195075]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([7.90245831e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 60, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57999\tvalid_1's rmse: 3.70406\n",
      "[1000]\ttraining's rmse: 3.50161\tvalid_1's rmse: 3.68706\n",
      "[1500]\ttraining's rmse: 3.44678\tvalid_1's rmse: 3.68267\n",
      "[2000]\ttraining's rmse: 3.39907\tvalid_1's rmse: 3.68127\n",
      "Early stopping, best iteration is:\n",
      "[2034]\ttraining's rmse: 3.39558\tvalid_1's rmse: 3.68104\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59217\tvalid_1's rmse: 3.64733\n",
      "[1000]\ttraining's rmse: 3.51291\tvalid_1's rmse: 3.63192\n",
      "[1500]\ttraining's rmse: 3.45775\tvalid_1's rmse: 3.62676\n",
      "[2000]\ttraining's rmse: 3.41168\tvalid_1's rmse: 3.62591\n",
      "Early stopping, best iteration is:\n",
      "[1857]\ttraining's rmse: 3.42494\tvalid_1's rmse: 3.62539\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59792\tvalid_1's rmse: 3.62518\n",
      "[1000]\ttraining's rmse: 3.51727\tvalid_1's rmse: 3.60864\n",
      "[1500]\ttraining's rmse: 3.46115\tvalid_1's rmse: 3.60574\n",
      "[2000]\ttraining's rmse: 3.4159\tvalid_1's rmse: 3.60497\n",
      "Early stopping, best iteration is:\n",
      "[1976]\ttraining's rmse: 3.41792\tvalid_1's rmse: 3.60482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55385\tvalid_1's rmse: 3.80723\n",
      "[1000]\ttraining's rmse: 3.47421\tvalid_1's rmse: 3.79458\n",
      "[1500]\ttraining's rmse: 3.41894\tvalid_1's rmse: 3.79113\n",
      "Early stopping, best iteration is:\n",
      "[1470]\ttraining's rmse: 3.42173\tvalid_1's rmse: 3.791\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59187\tvalid_1's rmse: 3.64351\n",
      "[1000]\ttraining's rmse: 3.51371\tvalid_1's rmse: 3.6296\n",
      "[1500]\ttraining's rmse: 3.46051\tvalid_1's rmse: 3.62622\n",
      "[2000]\ttraining's rmse: 3.41276\tvalid_1's rmse: 3.6245\n",
      "Early stopping, best iteration is:\n",
      "[1979]\ttraining's rmse: 3.41455\tvalid_1's rmse: 3.6244\n",
      "  237 | 08m24s |   -3.66596 |             0.8866 |         9.4604 |             0.2164 |             0.9071 |     13.3022 |              5.0331 |            30.1059 |            98.8816 |           0.3351 |      41.3555 |      4.3663 |       4.1052 |      0.9025 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63451\tvalid_1's rmse: 3.71101\n",
      "[1000]\ttraining's rmse: 3.58737\tvalid_1's rmse: 3.69116\n",
      "[1500]\ttraining's rmse: 3.55623\tvalid_1's rmse: 3.68512\n",
      "[2000]\ttraining's rmse: 3.52927\tvalid_1's rmse: 3.68246\n",
      "[2500]\ttraining's rmse: 3.50465\tvalid_1's rmse: 3.68166\n",
      "[3000]\ttraining's rmse: 3.48174\tvalid_1's rmse: 3.68136\n",
      "Early stopping, best iteration is:\n",
      "[2879]\ttraining's rmse: 3.48722\tvalid_1's rmse: 3.68116\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64863\tvalid_1's rmse: 3.65245\n",
      "[1000]\ttraining's rmse: 3.59977\tvalid_1's rmse: 3.6349\n",
      "[1500]\ttraining's rmse: 3.56813\tvalid_1's rmse: 3.62959\n",
      "[2000]\ttraining's rmse: 3.53947\tvalid_1's rmse: 3.62745\n",
      "[2500]\ttraining's rmse: 3.51334\tvalid_1's rmse: 3.62637\n",
      "[3000]\ttraining's rmse: 3.48956\tvalid_1's rmse: 3.62557\n",
      "[3500]\ttraining's rmse: 3.46687\tvalid_1's rmse: 3.62524\n",
      "Early stopping, best iteration is:\n",
      "[3613]\ttraining's rmse: 3.46194\tvalid_1's rmse: 3.62512\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65302\tvalid_1's rmse: 3.62649\n",
      "[1000]\ttraining's rmse: 3.60453\tvalid_1's rmse: 3.60934\n",
      "[1500]\ttraining's rmse: 3.57193\tvalid_1's rmse: 3.60458\n",
      "[2000]\ttraining's rmse: 3.54443\tvalid_1's rmse: 3.60298\n",
      "[2500]\ttraining's rmse: 3.51913\tvalid_1's rmse: 3.60254\n",
      "[3000]\ttraining's rmse: 3.49494\tvalid_1's rmse: 3.60209\n",
      "Early stopping, best iteration is:\n",
      "[2970]\ttraining's rmse: 3.49637\tvalid_1's rmse: 3.60202\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60621\tvalid_1's rmse: 3.81493\n",
      "[1000]\ttraining's rmse: 3.55749\tvalid_1's rmse: 3.79862\n",
      "[1500]\ttraining's rmse: 3.52516\tvalid_1's rmse: 3.7939\n",
      "[2000]\ttraining's rmse: 3.49785\tvalid_1's rmse: 3.79221\n",
      "[2500]\ttraining's rmse: 3.47209\tvalid_1's rmse: 3.79117\n",
      "[3000]\ttraining's rmse: 3.44864\tvalid_1's rmse: 3.79099\n",
      "Early stopping, best iteration is:\n",
      "[2838]\ttraining's rmse: 3.45593\tvalid_1's rmse: 3.79088\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64815\tvalid_1's rmse: 3.64487\n",
      "[1000]\ttraining's rmse: 3.5986\tvalid_1's rmse: 3.62927\n",
      "[1500]\ttraining's rmse: 3.56584\tvalid_1's rmse: 3.62366\n",
      "[2000]\ttraining's rmse: 3.53849\tvalid_1's rmse: 3.62193\n",
      "[2500]\ttraining's rmse: 3.51356\tvalid_1's rmse: 3.62139\n",
      "Early stopping, best iteration is:\n",
      "[2357]\ttraining's rmse: 3.52049\tvalid_1's rmse: 3.62129\n",
      "  238 | 08m01s |   -3.66474 |             0.9471 |         1.9079 |             0.1438 |             0.6270 |      6.2523 |              8.2998 |            30.0221 |            87.9431 |           0.4260 |      30.4259 |      8.6079 |       8.4551 |      0.3638 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00219728]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00716097]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63456\tvalid_1's rmse: 3.72816\n",
      "[1000]\ttraining's rmse: 3.55917\tvalid_1's rmse: 3.70133\n",
      "[1500]\ttraining's rmse: 3.51118\tvalid_1's rmse: 3.69177\n",
      "[2000]\ttraining's rmse: 3.47304\tvalid_1's rmse: 3.68766\n",
      "[2500]\ttraining's rmse: 3.44012\tvalid_1's rmse: 3.68582\n",
      "[3000]\ttraining's rmse: 3.41102\tvalid_1's rmse: 3.6844\n",
      "[3500]\ttraining's rmse: 3.38392\tvalid_1's rmse: 3.68363\n",
      "[4000]\ttraining's rmse: 3.35903\tvalid_1's rmse: 3.68325\n",
      "Early stopping, best iteration is:\n",
      "[4189]\ttraining's rmse: 3.35004\tvalid_1's rmse: 3.68298\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64811\tvalid_1's rmse: 3.66585\n",
      "[1000]\ttraining's rmse: 3.57163\tvalid_1's rmse: 3.64228\n",
      "[1500]\ttraining's rmse: 3.523\tvalid_1's rmse: 3.63439\n",
      "[2000]\ttraining's rmse: 3.48417\tvalid_1's rmse: 3.6301\n",
      "[2500]\ttraining's rmse: 3.45047\tvalid_1's rmse: 3.62758\n",
      "[3000]\ttraining's rmse: 3.4204\tvalid_1's rmse: 3.62667\n",
      "[3500]\ttraining's rmse: 3.39181\tvalid_1's rmse: 3.62618\n",
      "Early stopping, best iteration is:\n",
      "[3612]\ttraining's rmse: 3.38566\tvalid_1's rmse: 3.626\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65327\tvalid_1's rmse: 3.64159\n",
      "[1000]\ttraining's rmse: 3.57661\tvalid_1's rmse: 3.62002\n",
      "[1500]\ttraining's rmse: 3.52761\tvalid_1's rmse: 3.61266\n",
      "[2000]\ttraining's rmse: 3.48898\tvalid_1's rmse: 3.60893\n",
      "[2500]\ttraining's rmse: 3.45568\tvalid_1's rmse: 3.60705\n",
      "[3000]\ttraining's rmse: 3.42601\tvalid_1's rmse: 3.60638\n",
      "[3500]\ttraining's rmse: 3.39868\tvalid_1's rmse: 3.60619\n",
      "Early stopping, best iteration is:\n",
      "[3319]\ttraining's rmse: 3.40808\tvalid_1's rmse: 3.60602\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60638\tvalid_1's rmse: 3.83336\n",
      "[1000]\ttraining's rmse: 3.52974\tvalid_1's rmse: 3.81\n",
      "[1500]\ttraining's rmse: 3.48162\tvalid_1's rmse: 3.80154\n",
      "[2000]\ttraining's rmse: 3.44421\tvalid_1's rmse: 3.79792\n",
      "[2500]\ttraining's rmse: 3.41221\tvalid_1's rmse: 3.79629\n",
      "[3000]\ttraining's rmse: 3.38268\tvalid_1's rmse: 3.79508\n",
      "Early stopping, best iteration is:\n",
      "[3230]\ttraining's rmse: 3.37001\tvalid_1's rmse: 3.79489\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64777\tvalid_1's rmse: 3.66067\n",
      "[1000]\ttraining's rmse: 3.57112\tvalid_1's rmse: 3.64003\n",
      "[1500]\ttraining's rmse: 3.52237\tvalid_1's rmse: 3.63194\n",
      "[2000]\ttraining's rmse: 3.48357\tvalid_1's rmse: 3.62831\n",
      "[2500]\ttraining's rmse: 3.45084\tvalid_1's rmse: 3.62666\n",
      "[3000]\ttraining's rmse: 3.42148\tvalid_1's rmse: 3.62595\n",
      "Early stopping, best iteration is:\n",
      "[3205]\ttraining's rmse: 3.41047\tvalid_1's rmse: 3.62576\n",
      "  239 | 07m28s |   -3.66778 |             0.9730 |        14.9051 |             0.1811 |             0.2212 |     14.4747 |             11.1307 |            30.8291 |            55.6861 |           0.8983 |      31.9140 |      2.5025 |       9.9382 |      0.4507 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.67822\tvalid_1's rmse: 3.74929\n",
      "[1000]\ttraining's rmse: 3.61493\tvalid_1's rmse: 3.71864\n",
      "[1500]\ttraining's rmse: 3.57212\tvalid_1's rmse: 3.70525\n",
      "[2000]\ttraining's rmse: 3.53803\tvalid_1's rmse: 3.69805\n",
      "[2500]\ttraining's rmse: 3.50958\tvalid_1's rmse: 3.69368\n",
      "[3000]\ttraining's rmse: 3.48458\tvalid_1's rmse: 3.69099\n",
      "[3500]\ttraining's rmse: 3.46132\tvalid_1's rmse: 3.68908\n",
      "[4000]\ttraining's rmse: 3.43972\tvalid_1's rmse: 3.68791\n",
      "[4500]\ttraining's rmse: 3.41948\tvalid_1's rmse: 3.68721\n",
      "[5000]\ttraining's rmse: 3.39976\tvalid_1's rmse: 3.68658\n",
      "Early stopping, best iteration is:\n",
      "[5187]\ttraining's rmse: 3.39261\tvalid_1's rmse: 3.68626\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6928\tvalid_1's rmse: 3.6841\n",
      "[1000]\ttraining's rmse: 3.62798\tvalid_1's rmse: 3.65857\n",
      "[1500]\ttraining's rmse: 3.58481\tvalid_1's rmse: 3.64704\n",
      "[2000]\ttraining's rmse: 3.55134\tvalid_1's rmse: 3.6407\n",
      "[2500]\ttraining's rmse: 3.52268\tvalid_1's rmse: 3.63682\n",
      "[3000]\ttraining's rmse: 3.49714\tvalid_1's rmse: 3.63485\n",
      "[3500]\ttraining's rmse: 3.47361\tvalid_1's rmse: 3.63309\n",
      "[4000]\ttraining's rmse: 3.45248\tvalid_1's rmse: 3.63191\n",
      "[4500]\ttraining's rmse: 3.43211\tvalid_1's rmse: 3.63107\n",
      "[5000]\ttraining's rmse: 3.41272\tvalid_1's rmse: 3.63046\n",
      "[5500]\ttraining's rmse: 3.39397\tvalid_1's rmse: 3.62987\n",
      "[6000]\ttraining's rmse: 3.37615\tvalid_1's rmse: 3.62966\n",
      "Early stopping, best iteration is:\n",
      "[6011]\ttraining's rmse: 3.37578\tvalid_1's rmse: 3.62966\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6981\tvalid_1's rmse: 3.65976\n",
      "[1000]\ttraining's rmse: 3.63326\tvalid_1's rmse: 3.63406\n",
      "[1500]\ttraining's rmse: 3.59005\tvalid_1's rmse: 3.62334\n",
      "[2000]\ttraining's rmse: 3.55623\tvalid_1's rmse: 3.61822\n",
      "[2500]\ttraining's rmse: 3.52789\tvalid_1's rmse: 3.61544\n",
      "[3000]\ttraining's rmse: 3.50233\tvalid_1's rmse: 3.6133\n",
      "[3500]\ttraining's rmse: 3.47877\tvalid_1's rmse: 3.61195\n",
      "[4000]\ttraining's rmse: 3.45679\tvalid_1's rmse: 3.61102\n",
      "[4500]\ttraining's rmse: 3.43626\tvalid_1's rmse: 3.61053\n",
      "[5000]\ttraining's rmse: 3.41729\tvalid_1's rmse: 3.61032\n",
      "[5500]\ttraining's rmse: 3.39828\tvalid_1's rmse: 3.61008\n",
      "Early stopping, best iteration is:\n",
      "[5551]\ttraining's rmse: 3.39635\tvalid_1's rmse: 3.60995\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.6496\tvalid_1's rmse: 3.85756\n",
      "[1000]\ttraining's rmse: 3.58521\tvalid_1's rmse: 3.82861\n",
      "[1500]\ttraining's rmse: 3.54265\tvalid_1's rmse: 3.81717\n",
      "[2000]\ttraining's rmse: 3.50908\tvalid_1's rmse: 3.81038\n",
      "[2500]\ttraining's rmse: 3.48087\tvalid_1's rmse: 3.8068\n",
      "[3000]\ttraining's rmse: 3.45583\tvalid_1's rmse: 3.80464\n",
      "[3500]\ttraining's rmse: 3.43324\tvalid_1's rmse: 3.8034\n",
      "[4000]\ttraining's rmse: 3.41189\tvalid_1's rmse: 3.80185\n",
      "[4500]\ttraining's rmse: 3.39177\tvalid_1's rmse: 3.8011\n",
      "[5000]\ttraining's rmse: 3.37236\tvalid_1's rmse: 3.8005\n",
      "[5500]\ttraining's rmse: 3.35412\tvalid_1's rmse: 3.8002\n",
      "Early stopping, best iteration is:\n",
      "[5346]\ttraining's rmse: 3.35962\tvalid_1's rmse: 3.80015\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.69267\tvalid_1's rmse: 3.67819\n",
      "[1000]\ttraining's rmse: 3.62698\tvalid_1's rmse: 3.65343\n",
      "[1500]\ttraining's rmse: 3.58383\tvalid_1's rmse: 3.64342\n",
      "[2000]\ttraining's rmse: 3.55005\tvalid_1's rmse: 3.63764\n",
      "[2500]\ttraining's rmse: 3.52202\tvalid_1's rmse: 3.63463\n",
      "[3000]\ttraining's rmse: 3.497\tvalid_1's rmse: 3.63291\n",
      "[3500]\ttraining's rmse: 3.47358\tvalid_1's rmse: 3.63187\n",
      "[4000]\ttraining's rmse: 3.45232\tvalid_1's rmse: 3.63139\n",
      "[4500]\ttraining's rmse: 3.4319\tvalid_1's rmse: 3.63083\n",
      "[5000]\ttraining's rmse: 3.41296\tvalid_1's rmse: 3.63047\n",
      "Early stopping, best iteration is:\n",
      "[5041]\ttraining's rmse: 3.41128\tvalid_1's rmse: 3.63041\n",
      "  240 | 08m13s |   -3.67194 |             0.9553 |        18.2597 |             0.1127 |             0.1068 |     14.6416 |             48.2070 |            30.4736 |            99.4896 |           0.7481 |      30.9984 |      6.9090 |       4.4767 |      0.3778 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56933\tvalid_1's rmse: 3.70758\n",
      "[1000]\ttraining's rmse: 3.48736\tvalid_1's rmse: 3.69063\n",
      "[1500]\ttraining's rmse: 3.42995\tvalid_1's rmse: 3.68687\n",
      "[2000]\ttraining's rmse: 3.38014\tvalid_1's rmse: 3.68348\n",
      "Early stopping, best iteration is:\n",
      "[2023]\ttraining's rmse: 3.37806\tvalid_1's rmse: 3.68345\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58108\tvalid_1's rmse: 3.65103\n",
      "[1000]\ttraining's rmse: 3.4995\tvalid_1's rmse: 3.63488\n",
      "[1500]\ttraining's rmse: 3.44122\tvalid_1's rmse: 3.6315\n",
      "[2000]\ttraining's rmse: 3.39334\tvalid_1's rmse: 3.63029\n",
      "Early stopping, best iteration is:\n",
      "[1978]\ttraining's rmse: 3.3953\tvalid_1's rmse: 3.6301\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58581\tvalid_1's rmse: 3.62541\n",
      "[1000]\ttraining's rmse: 3.50281\tvalid_1's rmse: 3.61098\n",
      "[1500]\ttraining's rmse: 3.44498\tvalid_1's rmse: 3.6083\n",
      "Early stopping, best iteration is:\n",
      "[1798]\ttraining's rmse: 3.41496\tvalid_1's rmse: 3.60747\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54153\tvalid_1's rmse: 3.80882\n",
      "[1000]\ttraining's rmse: 3.45801\tvalid_1's rmse: 3.79301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's rmse: 3.40168\tvalid_1's rmse: 3.79128\n",
      "Early stopping, best iteration is:\n",
      "[1467]\ttraining's rmse: 3.40531\tvalid_1's rmse: 3.79104\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57935\tvalid_1's rmse: 3.64659\n",
      "[1000]\ttraining's rmse: 3.49447\tvalid_1's rmse: 3.63357\n",
      "[1500]\ttraining's rmse: 3.43665\tvalid_1's rmse: 3.63011\n",
      "Early stopping, best iteration is:\n",
      "[1711]\ttraining's rmse: 3.41654\tvalid_1's rmse: 3.6292\n",
      "  241 | 08m42s |   -3.66885 |             0.9567 |        12.0956 |             0.1127 |             0.9456 |      9.1489 |              5.2128 |            35.5935 |            49.0989 |           0.0086 |      42.6714 |      9.6864 |       8.0862 |      0.1487 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00187917]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00226465]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56765\tvalid_1's rmse: 3.70943\n",
      "[1000]\ttraining's rmse: 3.47826\tvalid_1's rmse: 3.69035\n",
      "[1500]\ttraining's rmse: 3.41751\tvalid_1's rmse: 3.68468\n",
      "[2000]\ttraining's rmse: 3.36668\tvalid_1's rmse: 3.68309\n",
      "[2500]\ttraining's rmse: 3.32133\tvalid_1's rmse: 3.68273\n",
      "Early stopping, best iteration is:\n",
      "[2421]\ttraining's rmse: 3.32849\tvalid_1's rmse: 3.68259\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57957\tvalid_1's rmse: 3.65016\n",
      "[1000]\ttraining's rmse: 3.48823\tvalid_1's rmse: 3.63323\n",
      "[1500]\ttraining's rmse: 3.42694\tvalid_1's rmse: 3.62907\n",
      "[2000]\ttraining's rmse: 3.3755\tvalid_1's rmse: 3.62718\n",
      "[2500]\ttraining's rmse: 3.32985\tvalid_1's rmse: 3.62725\n",
      "Early stopping, best iteration is:\n",
      "[2317]\ttraining's rmse: 3.34639\tvalid_1's rmse: 3.62697\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58668\tvalid_1's rmse: 3.62666\n",
      "[1000]\ttraining's rmse: 3.49472\tvalid_1's rmse: 3.61103\n",
      "[1500]\ttraining's rmse: 3.43154\tvalid_1's rmse: 3.60721\n",
      "[2000]\ttraining's rmse: 3.38024\tvalid_1's rmse: 3.60681\n",
      "Early stopping, best iteration is:\n",
      "[1860]\ttraining's rmse: 3.39373\tvalid_1's rmse: 3.60663\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.54001\tvalid_1's rmse: 3.80821\n",
      "[1000]\ttraining's rmse: 3.44795\tvalid_1's rmse: 3.79313\n",
      "[1500]\ttraining's rmse: 3.38623\tvalid_1's rmse: 3.78983\n",
      "[2000]\ttraining's rmse: 3.33541\tvalid_1's rmse: 3.78933\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's rmse: 3.34522\tvalid_1's rmse: 3.78915\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.57819\tvalid_1's rmse: 3.64745\n",
      "[1000]\ttraining's rmse: 3.48785\tvalid_1's rmse: 3.63278\n",
      "[1500]\ttraining's rmse: 3.42603\tvalid_1's rmse: 3.62815\n",
      "Early stopping, best iteration is:\n",
      "[1758]\ttraining's rmse: 3.39947\tvalid_1's rmse: 3.62745\n",
      "  242 | 08m46s |   -3.66716 |             0.8995 |         1.8540 |             0.1080 |             0.9281 |     14.5340 |             29.6078 |            43.9664 |            58.4295 |           0.8407 |      40.3689 |      4.1222 |       8.6875 |      0.9753 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00115891]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64181\tvalid_1's rmse: 3.72886\n",
      "[1000]\ttraining's rmse: 3.57232\tvalid_1's rmse: 3.70301\n",
      "[1500]\ttraining's rmse: 3.52815\tvalid_1's rmse: 3.69397\n",
      "[2000]\ttraining's rmse: 3.49166\tvalid_1's rmse: 3.68997\n",
      "[2500]\ttraining's rmse: 3.45865\tvalid_1's rmse: 3.68803\n",
      "[3000]\ttraining's rmse: 3.42881\tvalid_1's rmse: 3.68667\n",
      "[3500]\ttraining's rmse: 3.40134\tvalid_1's rmse: 3.68621\n",
      "[4000]\ttraining's rmse: 3.37432\tvalid_1's rmse: 3.68588\n",
      "[4500]\ttraining's rmse: 3.34818\tvalid_1's rmse: 3.6857\n",
      "Early stopping, best iteration is:\n",
      "[4375]\ttraining's rmse: 3.35495\tvalid_1's rmse: 3.6856\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65422\tvalid_1's rmse: 3.6667\n",
      "[1000]\ttraining's rmse: 3.58408\tvalid_1's rmse: 3.64424\n",
      "[1500]\ttraining's rmse: 3.53837\tvalid_1's rmse: 3.63629\n",
      "[2000]\ttraining's rmse: 3.50215\tvalid_1's rmse: 3.63261\n",
      "[2500]\ttraining's rmse: 3.46889\tvalid_1's rmse: 3.63065\n",
      "[3000]\ttraining's rmse: 3.43896\tvalid_1's rmse: 3.62852\n",
      "[3500]\ttraining's rmse: 3.41099\tvalid_1's rmse: 3.62796\n",
      "Early stopping, best iteration is:\n",
      "[3475]\ttraining's rmse: 3.41231\tvalid_1's rmse: 3.6279\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65877\tvalid_1's rmse: 3.64198\n",
      "[1000]\ttraining's rmse: 3.58944\tvalid_1's rmse: 3.62011\n",
      "[1500]\ttraining's rmse: 3.54494\tvalid_1's rmse: 3.61301\n",
      "[2000]\ttraining's rmse: 3.50894\tvalid_1's rmse: 3.61004\n",
      "[2500]\ttraining's rmse: 3.47644\tvalid_1's rmse: 3.60896\n",
      "Early stopping, best iteration is:\n",
      "[2629]\ttraining's rmse: 3.46839\tvalid_1's rmse: 3.60855\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61286\tvalid_1's rmse: 3.8327\n",
      "[1000]\ttraining's rmse: 3.54369\tvalid_1's rmse: 3.80995\n",
      "[1500]\ttraining's rmse: 3.49821\tvalid_1's rmse: 3.80169\n",
      "[2000]\ttraining's rmse: 3.46159\tvalid_1's rmse: 3.79808\n",
      "[2500]\ttraining's rmse: 3.42888\tvalid_1's rmse: 3.79652\n",
      "[3000]\ttraining's rmse: 3.39801\tvalid_1's rmse: 3.79543\n",
      "[3500]\ttraining's rmse: 3.36983\tvalid_1's rmse: 3.79484\n",
      "Early stopping, best iteration is:\n",
      "[3707]\ttraining's rmse: 3.35865\tvalid_1's rmse: 3.79482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65381\tvalid_1's rmse: 3.66276\n",
      "[1000]\ttraining's rmse: 3.58443\tvalid_1's rmse: 3.64147\n",
      "[1500]\ttraining's rmse: 3.53775\tvalid_1's rmse: 3.63437\n",
      "[2000]\ttraining's rmse: 3.50138\tvalid_1's rmse: 3.63056\n",
      "[2500]\ttraining's rmse: 3.46891\tvalid_1's rmse: 3.62963\n",
      "[3000]\ttraining's rmse: 3.43939\tvalid_1's rmse: 3.62916\n",
      "[3500]\ttraining's rmse: 3.41197\tvalid_1's rmse: 3.6291\n",
      "Early stopping, best iteration is:\n",
      "[3469]\ttraining's rmse: 3.41395\tvalid_1's rmse: 3.629\n",
      "  243 | 07m30s |   -3.66980 |             0.7060 |        19.2058 |             0.1109 |             0.2088 |     12.1261 |              5.1510 |            44.8745 |            66.2785 |           0.0453 |      30.7348 |      8.7952 |       0.0770 |      0.4882 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58241\tvalid_1's rmse: 3.70432\n",
      "[1000]\ttraining's rmse: 3.51143\tvalid_1's rmse: 3.68646\n",
      "[1500]\ttraining's rmse: 3.46348\tvalid_1's rmse: 3.68182\n",
      "Early stopping, best iteration is:\n",
      "[1506]\ttraining's rmse: 3.46294\tvalid_1's rmse: 3.6818\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59452\tvalid_1's rmse: 3.6482\n",
      "[1000]\ttraining's rmse: 3.52241\tvalid_1's rmse: 3.63235\n",
      "[1500]\ttraining's rmse: 3.47057\tvalid_1's rmse: 3.62902\n",
      "[2000]\ttraining's rmse: 3.42876\tvalid_1's rmse: 3.62834\n",
      "Early stopping, best iteration is:\n",
      "[2184]\ttraining's rmse: 3.41509\tvalid_1's rmse: 3.62812\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59875\tvalid_1's rmse: 3.624\n",
      "[1000]\ttraining's rmse: 3.52653\tvalid_1's rmse: 3.60824\n",
      "[1500]\ttraining's rmse: 3.47463\tvalid_1's rmse: 3.6057\n",
      "Early stopping, best iteration is:\n",
      "[1633]\ttraining's rmse: 3.46243\tvalid_1's rmse: 3.6055\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55373\tvalid_1's rmse: 3.80671\n",
      "[1000]\ttraining's rmse: 3.48101\tvalid_1's rmse: 3.79197\n",
      "[1500]\ttraining's rmse: 3.43066\tvalid_1's rmse: 3.78903\n",
      "Early stopping, best iteration is:\n",
      "[1715]\ttraining's rmse: 3.41253\tvalid_1's rmse: 3.78849\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.59434\tvalid_1's rmse: 3.64187\n",
      "[1000]\ttraining's rmse: 3.52088\tvalid_1's rmse: 3.62914\n",
      "[1500]\ttraining's rmse: 3.47083\tvalid_1's rmse: 3.62554\n",
      "[2000]\ttraining's rmse: 3.42921\tvalid_1's rmse: 3.62442\n",
      "Early stopping, best iteration is:\n",
      "[1842]\ttraining's rmse: 3.44176\tvalid_1's rmse: 3.62426\n",
      "  244 | 08m41s |   -3.66624 |             0.9826 |        19.8774 |             0.3547 |             0.8723 |      9.3604 |             12.1614 |            30.0215 |            98.4942 |           0.7074 |      44.4766 |      2.7627 |       7.5527 |      0.6553 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64824\tvalid_1's rmse: 3.71597\n",
      "[1000]\ttraining's rmse: 3.60813\tvalid_1's rmse: 3.69691\n",
      "[1500]\ttraining's rmse: 3.57822\tvalid_1's rmse: 3.69015\n",
      "[2000]\ttraining's rmse: 3.55433\tvalid_1's rmse: 3.68777\n",
      "[2500]\ttraining's rmse: 3.53293\tvalid_1's rmse: 3.68649\n",
      "[3000]\ttraining's rmse: 3.51394\tvalid_1's rmse: 3.68563\n",
      "[3500]\ttraining's rmse: 3.49573\tvalid_1's rmse: 3.68562\n",
      "Early stopping, best iteration is:\n",
      "[3329]\ttraining's rmse: 3.50174\tvalid_1's rmse: 3.68553\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66121\tvalid_1's rmse: 3.65812\n",
      "[1000]\ttraining's rmse: 3.61739\tvalid_1's rmse: 3.64042\n",
      "[1500]\ttraining's rmse: 3.58859\tvalid_1's rmse: 3.63425\n",
      "[2000]\ttraining's rmse: 3.56441\tvalid_1's rmse: 3.63156\n",
      "[2500]\ttraining's rmse: 3.54319\tvalid_1's rmse: 3.63082\n",
      "[3000]\ttraining's rmse: 3.52196\tvalid_1's rmse: 3.63041\n",
      "Early stopping, best iteration is:\n",
      "[2858]\ttraining's rmse: 3.52778\tvalid_1's rmse: 3.63025\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66771\tvalid_1's rmse: 3.62966\n",
      "[1000]\ttraining's rmse: 3.62321\tvalid_1's rmse: 3.61213\n",
      "[1500]\ttraining's rmse: 3.59556\tvalid_1's rmse: 3.60743\n",
      "[2000]\ttraining's rmse: 3.57273\tvalid_1's rmse: 3.60658\n",
      "[2500]\ttraining's rmse: 3.55091\tvalid_1's rmse: 3.60603\n",
      "[3000]\ttraining's rmse: 3.52937\tvalid_1's rmse: 3.60543\n",
      "[3500]\ttraining's rmse: 3.50924\tvalid_1's rmse: 3.60515\n",
      "Early stopping, best iteration is:\n",
      "[3485]\ttraining's rmse: 3.50978\tvalid_1's rmse: 3.60508\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61996\tvalid_1's rmse: 3.81793\n",
      "[1000]\ttraining's rmse: 3.57515\tvalid_1's rmse: 3.80211\n",
      "[1500]\ttraining's rmse: 3.54776\tvalid_1's rmse: 3.79703\n",
      "[2000]\ttraining's rmse: 3.52492\tvalid_1's rmse: 3.79593\n",
      "[2500]\ttraining's rmse: 3.50456\tvalid_1's rmse: 3.79499\n",
      "Early stopping, best iteration is:\n",
      "[2589]\ttraining's rmse: 3.50115\tvalid_1's rmse: 3.79492\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.66266\tvalid_1's rmse: 3.64878\n",
      "[1000]\ttraining's rmse: 3.61707\tvalid_1's rmse: 3.63165\n",
      "[1500]\ttraining's rmse: 3.58632\tvalid_1's rmse: 3.62549\n",
      "[2000]\ttraining's rmse: 3.56291\tvalid_1's rmse: 3.62365\n",
      "[2500]\ttraining's rmse: 3.54189\tvalid_1's rmse: 3.62318\n",
      "Early stopping, best iteration is:\n",
      "[2438]\ttraining's rmse: 3.54433\tvalid_1's rmse: 3.62309\n",
      "  245 | 08m05s |   -3.66842 |             0.9810 |         0.9021 |             0.7136 |             0.7213 |      5.7200 |              5.1646 |            41.8761 |            11.3172 |           0.0830 |      30.2086 |      5.7220 |       6.6844 |      0.8697 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61269\tvalid_1's rmse: 3.7107\n",
      "[1000]\ttraining's rmse: 3.55067\tvalid_1's rmse: 3.69028\n",
      "[1500]\ttraining's rmse: 3.50924\tvalid_1's rmse: 3.68434\n",
      "[2000]\ttraining's rmse: 3.47561\tvalid_1's rmse: 3.68233\n",
      "[2500]\ttraining's rmse: 3.44638\tvalid_1's rmse: 3.68199\n",
      "Early stopping, best iteration is:\n",
      "[2428]\ttraining's rmse: 3.45021\tvalid_1's rmse: 3.68186\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62675\tvalid_1's rmse: 3.65199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's rmse: 3.56188\tvalid_1's rmse: 3.63328\n",
      "[1500]\ttraining's rmse: 3.52017\tvalid_1's rmse: 3.62781\n",
      "[2000]\ttraining's rmse: 3.48563\tvalid_1's rmse: 3.62583\n",
      "[2500]\ttraining's rmse: 3.45478\tvalid_1's rmse: 3.62461\n",
      "Early stopping, best iteration is:\n",
      "[2483]\ttraining's rmse: 3.45587\tvalid_1's rmse: 3.62453\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62972\tvalid_1's rmse: 3.62747\n",
      "[1000]\ttraining's rmse: 3.56514\tvalid_1's rmse: 3.60918\n",
      "[1500]\ttraining's rmse: 3.52234\tvalid_1's rmse: 3.60396\n",
      "[2000]\ttraining's rmse: 3.48775\tvalid_1's rmse: 3.60239\n",
      "[2500]\ttraining's rmse: 3.45683\tvalid_1's rmse: 3.60215\n",
      "Early stopping, best iteration is:\n",
      "[2431]\ttraining's rmse: 3.461\tvalid_1's rmse: 3.60195\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58534\tvalid_1's rmse: 3.81385\n",
      "[1000]\ttraining's rmse: 3.52057\tvalid_1's rmse: 3.79668\n",
      "[1500]\ttraining's rmse: 3.47855\tvalid_1's rmse: 3.79183\n",
      "[2000]\ttraining's rmse: 3.44448\tvalid_1's rmse: 3.79041\n",
      "[2500]\ttraining's rmse: 3.41495\tvalid_1's rmse: 3.79001\n",
      "[3000]\ttraining's rmse: 3.38746\tvalid_1's rmse: 3.78961\n",
      "[3500]\ttraining's rmse: 3.36137\tvalid_1's rmse: 3.78922\n",
      "Early stopping, best iteration is:\n",
      "[3328]\ttraining's rmse: 3.37\tvalid_1's rmse: 3.78905\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62547\tvalid_1's rmse: 3.64658\n",
      "[1000]\ttraining's rmse: 3.5593\tvalid_1's rmse: 3.62962\n",
      "[1500]\ttraining's rmse: 3.51716\tvalid_1's rmse: 3.6231\n",
      "[2000]\ttraining's rmse: 3.48321\tvalid_1's rmse: 3.62114\n",
      "[2500]\ttraining's rmse: 3.45321\tvalid_1's rmse: 3.62086\n",
      "Early stopping, best iteration is:\n",
      "[2494]\ttraining's rmse: 3.45361\tvalid_1's rmse: 3.6208\n",
      "  246 | 07m45s |   -3.66427 |             0.8463 |         0.3974 |             0.9134 |             0.4703 |      9.2380 |             49.2544 |            31.1976 |            87.0970 |           0.6314 |      33.1101 |      6.8533 |       9.3779 |      0.9068 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00645061]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63471\tvalid_1's rmse: 3.72137\n",
      "[1000]\ttraining's rmse: 3.57031\tvalid_1's rmse: 3.69766\n",
      "[1500]\ttraining's rmse: 3.52671\tvalid_1's rmse: 3.68968\n",
      "[2000]\ttraining's rmse: 3.49096\tvalid_1's rmse: 3.68648\n",
      "[2500]\ttraining's rmse: 3.45744\tvalid_1's rmse: 3.68365\n",
      "[3000]\ttraining's rmse: 3.42668\tvalid_1's rmse: 3.68257\n",
      "[3500]\ttraining's rmse: 3.39793\tvalid_1's rmse: 3.68229\n",
      "Early stopping, best iteration is:\n",
      "[3618]\ttraining's rmse: 3.39115\tvalid_1's rmse: 3.68205\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65037\tvalid_1's rmse: 3.66037\n",
      "[1000]\ttraining's rmse: 3.58377\tvalid_1's rmse: 3.64042\n",
      "[1500]\ttraining's rmse: 3.53896\tvalid_1's rmse: 3.63202\n",
      "[2000]\ttraining's rmse: 3.50198\tvalid_1's rmse: 3.6283\n",
      "[2500]\ttraining's rmse: 3.46988\tvalid_1's rmse: 3.62671\n",
      "Early stopping, best iteration is:\n",
      "[2753]\ttraining's rmse: 3.4552\tvalid_1's rmse: 3.62613\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.65363\tvalid_1's rmse: 3.63793\n",
      "[1000]\ttraining's rmse: 3.58841\tvalid_1's rmse: 3.61722\n",
      "[1500]\ttraining's rmse: 3.5447\tvalid_1's rmse: 3.61099\n",
      "[2000]\ttraining's rmse: 3.508\tvalid_1's rmse: 3.60879\n",
      "[2500]\ttraining's rmse: 3.47505\tvalid_1's rmse: 3.60833\n",
      "Early stopping, best iteration is:\n",
      "[2388]\ttraining's rmse: 3.48229\tvalid_1's rmse: 3.60812\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60816\tvalid_1's rmse: 3.82773\n",
      "[1000]\ttraining's rmse: 3.5406\tvalid_1's rmse: 3.80542\n",
      "[1500]\ttraining's rmse: 3.49782\tvalid_1's rmse: 3.7987\n",
      "[2000]\ttraining's rmse: 3.46139\tvalid_1's rmse: 3.79582\n",
      "[2500]\ttraining's rmse: 3.429\tvalid_1's rmse: 3.79467\n",
      "[3000]\ttraining's rmse: 3.39868\tvalid_1's rmse: 3.79347\n",
      "Early stopping, best iteration is:\n",
      "[3148]\ttraining's rmse: 3.39019\tvalid_1's rmse: 3.79315\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.64901\tvalid_1's rmse: 3.65503\n",
      "[1000]\ttraining's rmse: 3.58197\tvalid_1's rmse: 3.63643\n",
      "[1500]\ttraining's rmse: 3.53908\tvalid_1's rmse: 3.62967\n",
      "[2000]\ttraining's rmse: 3.50115\tvalid_1's rmse: 3.62674\n",
      "[2500]\ttraining's rmse: 3.46884\tvalid_1's rmse: 3.62574\n",
      "Early stopping, best iteration is:\n",
      "[2597]\ttraining's rmse: 3.46272\tvalid_1's rmse: 3.62565\n",
      "  247 | 07m19s |   -3.66765 |             0.6641 |         9.4243 |             0.8130 |             0.2868 |     14.9675 |             49.1395 |            31.8531 |            80.2258 |           0.5103 |      31.1586 |      3.9843 |       9.6756 |      0.6130 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\magic\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00933369]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.60977\tvalid_1's rmse: 3.71075\n",
      "[1000]\ttraining's rmse: 3.53957\tvalid_1's rmse: 3.68989\n",
      "[1500]\ttraining's rmse: 3.49398\tvalid_1's rmse: 3.68374\n",
      "[2000]\ttraining's rmse: 3.45521\tvalid_1's rmse: 3.68195\n",
      "Early stopping, best iteration is:\n",
      "[1940]\ttraining's rmse: 3.45941\tvalid_1's rmse: 3.68147\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62333\tvalid_1's rmse: 3.65295\n",
      "[1000]\ttraining's rmse: 3.55199\tvalid_1's rmse: 3.63515\n",
      "[1500]\ttraining's rmse: 3.50481\tvalid_1's rmse: 3.6286\n",
      "[2000]\ttraining's rmse: 3.46701\tvalid_1's rmse: 3.62602\n",
      "[2500]\ttraining's rmse: 3.43339\tvalid_1's rmse: 3.62476\n",
      "[3000]\ttraining's rmse: 3.40178\tvalid_1's rmse: 3.62395\n",
      "[3500]\ttraining's rmse: 3.37058\tvalid_1's rmse: 3.62374\n",
      "Early stopping, best iteration is:\n",
      "[3330]\ttraining's rmse: 3.3811\tvalid_1's rmse: 3.62349\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62752\tvalid_1's rmse: 3.62923\n",
      "[1000]\ttraining's rmse: 3.55724\tvalid_1's rmse: 3.61087\n",
      "[1500]\ttraining's rmse: 3.51033\tvalid_1's rmse: 3.60676\n",
      "[2000]\ttraining's rmse: 3.47098\tvalid_1's rmse: 3.60541\n",
      "[2500]\ttraining's rmse: 3.43791\tvalid_1's rmse: 3.60529\n",
      "Early stopping, best iteration is:\n",
      "[2392]\ttraining's rmse: 3.44525\tvalid_1's rmse: 3.60482\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58271\tvalid_1's rmse: 3.81343\n",
      "[1000]\ttraining's rmse: 3.50949\tvalid_1's rmse: 3.79634\n",
      "[1500]\ttraining's rmse: 3.46283\tvalid_1's rmse: 3.79129\n",
      "[2000]\ttraining's rmse: 3.42393\tvalid_1's rmse: 3.78951\n",
      "[2500]\ttraining's rmse: 3.38992\tvalid_1's rmse: 3.78954\n",
      "Early stopping, best iteration is:\n",
      "[2402]\ttraining's rmse: 3.39612\tvalid_1's rmse: 3.78909\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62187\tvalid_1's rmse: 3.64927\n",
      "[1000]\ttraining's rmse: 3.55239\tvalid_1's rmse: 3.63258\n",
      "[1500]\ttraining's rmse: 3.5053\tvalid_1's rmse: 3.62733\n",
      "[2000]\ttraining's rmse: 3.46671\tvalid_1's rmse: 3.62607\n",
      "Early stopping, best iteration is:\n",
      "[1922]\ttraining's rmse: 3.47173\tvalid_1's rmse: 3.62587\n",
      "  248 | 07m53s |   -3.66557 |             0.8467 |        19.3317 |             0.7479 |             0.6325 |     14.1511 |             38.9316 |            32.0300 |            74.0900 |           0.8171 |      30.4539 |      2.5992 |       9.8656 |      0.8707 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.61328\tvalid_1's rmse: 3.71345\n",
      "[1000]\ttraining's rmse: 3.54341\tvalid_1's rmse: 3.69146\n",
      "[1500]\ttraining's rmse: 3.49687\tvalid_1's rmse: 3.68497\n",
      "[2000]\ttraining's rmse: 3.45826\tvalid_1's rmse: 3.68242\n",
      "[2500]\ttraining's rmse: 3.42352\tvalid_1's rmse: 3.68072\n",
      "Early stopping, best iteration is:\n",
      "[2717]\ttraining's rmse: 3.40922\tvalid_1's rmse: 3.67991\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62745\tvalid_1's rmse: 3.65378\n",
      "[1000]\ttraining's rmse: 3.55514\tvalid_1's rmse: 3.6354\n",
      "[1500]\ttraining's rmse: 3.50723\tvalid_1's rmse: 3.62964\n",
      "[2000]\ttraining's rmse: 3.46804\tvalid_1's rmse: 3.62695\n",
      "[2500]\ttraining's rmse: 3.43308\tvalid_1's rmse: 3.62538\n",
      "Early stopping, best iteration is:\n",
      "[2623]\ttraining's rmse: 3.42522\tvalid_1's rmse: 3.6251\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.63062\tvalid_1's rmse: 3.62937\n",
      "[1000]\ttraining's rmse: 3.56002\tvalid_1's rmse: 3.61074\n",
      "[1500]\ttraining's rmse: 3.51276\tvalid_1's rmse: 3.60554\n",
      "[2000]\ttraining's rmse: 3.47346\tvalid_1's rmse: 3.60372\n",
      "Early stopping, best iteration is:\n",
      "[2097]\ttraining's rmse: 3.46684\tvalid_1's rmse: 3.60337\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.58633\tvalid_1's rmse: 3.81779\n",
      "[1000]\ttraining's rmse: 3.51313\tvalid_1's rmse: 3.79814\n",
      "[1500]\ttraining's rmse: 3.46696\tvalid_1's rmse: 3.79266\n",
      "[2000]\ttraining's rmse: 3.42878\tvalid_1's rmse: 3.79077\n",
      "[2500]\ttraining's rmse: 3.39416\tvalid_1's rmse: 3.79014\n",
      "Early stopping, best iteration is:\n",
      "[2380]\ttraining's rmse: 3.40274\tvalid_1's rmse: 3.79\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.62619\tvalid_1's rmse: 3.64776\n",
      "[1000]\ttraining's rmse: 3.55447\tvalid_1's rmse: 3.63074\n",
      "[1500]\ttraining's rmse: 3.50764\tvalid_1's rmse: 3.62523\n",
      "[2000]\ttraining's rmse: 3.46873\tvalid_1's rmse: 3.62296\n",
      "Early stopping, best iteration is:\n",
      "[2297]\ttraining's rmse: 3.44838\tvalid_1's rmse: 3.62275\n",
      "  249 | 07m40s |   -3.66485 |             0.8918 |        19.9640 |             0.4665 |             0.4112 |     14.1512 |              5.0457 |            30.5007 |            94.6600 |           0.1026 |      34.3206 |      8.9036 |       9.3733 |      0.3485 | \n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.55317\tvalid_1's rmse: 3.70536\n",
      "[1000]\ttraining's rmse: 3.45826\tvalid_1's rmse: 3.68763\n",
      "[1500]\ttraining's rmse: 3.39336\tvalid_1's rmse: 3.68327\n",
      "Early stopping, best iteration is:\n",
      "[1675]\ttraining's rmse: 3.3738\tvalid_1's rmse: 3.68285\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56625\tvalid_1's rmse: 3.65094\n",
      "[1000]\ttraining's rmse: 3.46882\tvalid_1's rmse: 3.63555\n",
      "[1500]\ttraining's rmse: 3.40052\tvalid_1's rmse: 3.63131\n",
      "Early stopping, best iteration is:\n",
      "[1691]\ttraining's rmse: 3.37914\tvalid_1's rmse: 3.6304\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56933\tvalid_1's rmse: 3.62488\n",
      "[1000]\ttraining's rmse: 3.47333\tvalid_1's rmse: 3.61149\n",
      "[1500]\ttraining's rmse: 3.40892\tvalid_1's rmse: 3.60817\n",
      "[2000]\ttraining's rmse: 3.35261\tvalid_1's rmse: 3.60797\n",
      "Early stopping, best iteration is:\n",
      "[1862]\ttraining's rmse: 3.36786\tvalid_1's rmse: 3.60719\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.52503\tvalid_1's rmse: 3.80717\n",
      "[1000]\ttraining's rmse: 3.42761\tvalid_1's rmse: 3.79367\n",
      "[1500]\ttraining's rmse: 3.36249\tvalid_1's rmse: 3.79094\n",
      "Early stopping, best iteration is:\n",
      "[1488]\ttraining's rmse: 3.36394\tvalid_1's rmse: 3.79078\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's rmse: 3.56335\tvalid_1's rmse: 3.6472\n",
      "[1000]\ttraining's rmse: 3.46766\tvalid_1's rmse: 3.63291\n",
      "[1500]\ttraining's rmse: 3.40187\tvalid_1's rmse: 3.63024\n",
      "Early stopping, best iteration is:\n",
      "[1739]\ttraining's rmse: 3.37457\tvalid_1's rmse: 3.62989\n",
      "  250 | 08m20s |   -3.66882 |             0.8976 |        19.6220 |             0.5107 |             0.9022 |     14.6886 |             43.9834 |            42.0919 |            57.8001 |           0.1503 |      44.7251 |      0.1641 |       4.0571 |      0.3445 | \n"
     ]
    }
   ],
   "source": [
    "def lgbm_eval(num_leaves,\n",
    "              colsample_bytree,\n",
    "              min_data_in_leaf,\n",
    "              subsample,\n",
    "              max_depth,\n",
    "              reg_alpha,\n",
    "              reg_lambda,\n",
    "              min_split_gain,\n",
    "              min_child_weight,\n",
    "              min_child_samples,\n",
    "              feature_fraction,\n",
    "              bagging_freq,\n",
    "              bagging_fraction\n",
    "             ):\n",
    "    params[\"num_leaves\"] = int(num_leaves)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['reg_alpha'] = max(reg_alpha, 0)\n",
    "    params['reg_lambda'] = max(reg_lambda, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params[\"min_data_in_leaf\"] = int(min_data_in_leaf)\n",
    "    params[\"min_child_samples\"] = min_child_samples\n",
    "    params[\"feature_fraction\"] = feature_fraction\n",
    "    params[\"bagging_freq\"] = int(bagging_freq)\n",
    "    params[\"bagging_fraction\"] = bagging_fraction\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 200)\n",
    "        oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    \n",
    "    return -mean_squared_error(oof, target)**0.5\n",
    "\n",
    "\n",
    "clf_bo = BayesianOptimization(lgbm_eval, {'num_leaves': (30, 45),\n",
    "                                          'colsample_bytree': (0.1, 1),\n",
    "                                          'min_data_in_leaf': (10,100), \n",
    "                                          'subsample': (0.1, 1),\n",
    "                                          'max_depth': (5, 15),\n",
    "                                          'reg_alpha': (0, 10),\n",
    "                                          'reg_lambda': (0, 10),\n",
    "                                          'min_split_gain': (0, 1),\n",
    "                                          'min_child_weight': (30, 45),\n",
    "                                          \"min_child_samples\": (5,50),\n",
    "                                          \"feature_fraction\": (0.1,0.95),\n",
    "                                          \"bagging_freq\": (0, 20),\n",
    "                                          \"bagging_fraction\": (.01, .99)\n",
    "                                        })\n",
    "\n",
    "clf_bo.maximize(init_points=50, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max': {'max_val': -3.6634832089809057,\n",
       "  'max_params': {'num_leaves': 33.75666875369966,\n",
       "   'colsample_bytree': 0.9487665577702247,\n",
       "   'min_data_in_leaf': 99.57203804373107,\n",
       "   'subsample': 0.9249134183896071,\n",
       "   'max_depth': 9.772259169612244,\n",
       "   'reg_alpha': 4.27124810570163,\n",
       "   'reg_lambda': 9.968091139039558,\n",
       "   'min_split_gain': 0.13081300343962554,\n",
       "   'min_child_weight': 32.764114254518134,\n",
       "   'min_child_samples': 6.495607087283611,\n",
       "   'feature_fraction': 0.44004005856079653,\n",
       "   'bagging_freq': 2.846121545146736,\n",
       "   'bagging_fraction': 0.907936844347967}},\n",
       " 'all': {'values': [-3.664537897314143,\n",
       "   -3.6683843297163503,\n",
       "   -3.6702609379843696,\n",
       "   -3.665491792772642,\n",
       "   -3.6657492301145336,\n",
       "   -3.6675974714849233,\n",
       "   -3.667510241574269,\n",
       "   -3.6696428876938616,\n",
       "   -3.6681818560963118,\n",
       "   -3.6638759915444004,\n",
       "   -3.6651995257685237,\n",
       "   -3.6674461752233327,\n",
       "   -3.6680201959229217,\n",
       "   -3.6672729521945624,\n",
       "   -3.6683625382681706,\n",
       "   -3.671706158247252,\n",
       "   -3.6685374593332307,\n",
       "   -3.665146030002653,\n",
       "   -3.666389239522164,\n",
       "   -3.6795299607339533,\n",
       "   -3.6674731139342542,\n",
       "   -3.6677059408170876,\n",
       "   -3.668858296368752,\n",
       "   -3.6660614624726287,\n",
       "   -3.668636406648499,\n",
       "   -3.6677511831178724,\n",
       "   -3.6704405627950374,\n",
       "   -3.667359005289386,\n",
       "   -3.6670470235688795,\n",
       "   -3.6666813467167927,\n",
       "   -3.664626419846265,\n",
       "   -3.6707372129815776,\n",
       "   -3.6691186003489062,\n",
       "   -3.6669856391942424,\n",
       "   -3.669509415442931,\n",
       "   -3.6660101347402896,\n",
       "   -3.666373394202278,\n",
       "   -3.665205838856799,\n",
       "   -3.666052968795385,\n",
       "   -3.672723527740212,\n",
       "   -3.6657046246868323,\n",
       "   -3.667514751053504,\n",
       "   -3.666955501012682,\n",
       "   -3.6666860257545575,\n",
       "   -3.6661127953794512,\n",
       "   -3.6648176262140337,\n",
       "   -3.6664544071134784,\n",
       "   -3.664452952238262,\n",
       "   -3.67244969312039,\n",
       "   -3.6677687471866878,\n",
       "   -3.6680070485988137,\n",
       "   -3.6685436637884945,\n",
       "   -3.672622464350926,\n",
       "   -3.6680472806846827,\n",
       "   -3.6683848760127775,\n",
       "   -3.665529731928119,\n",
       "   -3.665797423508947,\n",
       "   -3.665726159339468,\n",
       "   -3.66427905695092,\n",
       "   -3.665828379035055,\n",
       "   -3.666081144693918,\n",
       "   -3.6644136886590903,\n",
       "   -3.668363454750333,\n",
       "   -3.6663495815713647,\n",
       "   -3.668508071450747,\n",
       "   -3.670368547478539,\n",
       "   -3.672097316778385,\n",
       "   -3.6656633476135854,\n",
       "   -3.6659899163364087,\n",
       "   -3.664260971638486,\n",
       "   -3.669027909313422,\n",
       "   -3.6678979438207,\n",
       "   -3.6676379611983108,\n",
       "   -3.666010836638174,\n",
       "   -3.6659227765006275,\n",
       "   -3.667154109583593,\n",
       "   -3.6730038285536017,\n",
       "   -3.6652904123927494,\n",
       "   -3.66727095336183,\n",
       "   -3.6678727517726513,\n",
       "   -3.669229996710386,\n",
       "   -3.668692474409126,\n",
       "   -3.666492340162906,\n",
       "   -3.665911901377592,\n",
       "   -3.6660016905168287,\n",
       "   -3.6676142284396613,\n",
       "   -3.6662060245114096,\n",
       "   -3.669091851310383,\n",
       "   -3.6652399387285977,\n",
       "   -3.6654950332151124,\n",
       "   -3.667118201768115,\n",
       "   -3.6683803772159016,\n",
       "   -3.667432697937298,\n",
       "   -3.6690661499957504,\n",
       "   -3.6673203482181225,\n",
       "   -3.6634832089809057,\n",
       "   -3.666670369313305,\n",
       "   -3.6655088394253443,\n",
       "   -3.6640474950676305,\n",
       "   -3.6682205379401736,\n",
       "   -3.6683778644540834,\n",
       "   -3.6656900187656634,\n",
       "   -3.671526577759985,\n",
       "   -3.669554528746826,\n",
       "   -3.6699729534781733,\n",
       "   -3.665695533805237,\n",
       "   -3.680985828419126,\n",
       "   -3.666884962396485,\n",
       "   -3.666007180532138,\n",
       "   -3.6659509213350407,\n",
       "   -3.6725573251550196,\n",
       "   -3.6671024140416506,\n",
       "   -3.6698908543749367,\n",
       "   -3.665510606548641,\n",
       "   -3.6663911650101997,\n",
       "   -3.6669718412968826,\n",
       "   -3.6653674144980193,\n",
       "   -3.66950332355896,\n",
       "   -3.6671435038164755,\n",
       "   -3.6689247497455284,\n",
       "   -3.6670070658022484,\n",
       "   -3.6658962578786523,\n",
       "   -3.6664525349269224,\n",
       "   -3.6660700743500785,\n",
       "   -3.6660696593347413,\n",
       "   -3.669069112125093,\n",
       "   -3.6686266753346093,\n",
       "   -3.666796518432362,\n",
       "   -3.6682317799810087,\n",
       "   -3.6665744925277486,\n",
       "   -3.6668314230889227,\n",
       "   -3.6661607815291846,\n",
       "   -3.6677391355285076,\n",
       "   -3.6654144936514728,\n",
       "   -3.6657415084163545,\n",
       "   -3.665262137603961,\n",
       "   -3.6701248412926493,\n",
       "   -3.6669934006441713,\n",
       "   -3.667589133539219,\n",
       "   -3.6689281451471643,\n",
       "   -3.664960695658986,\n",
       "   -3.667600188093809,\n",
       "   -3.669115454447436,\n",
       "   -3.667253033859969,\n",
       "   -3.6707303209346978,\n",
       "   -3.6647179226623243,\n",
       "   -3.665499748887732,\n",
       "   -3.673415766373813,\n",
       "   -3.6693693778939,\n",
       "   -3.6663594471117644,\n",
       "   -3.670825866652135,\n",
       "   -3.669019986018644,\n",
       "   -3.667139332176901,\n",
       "   -3.6658739739758324,\n",
       "   -3.669201769313539,\n",
       "   -3.6697450657851136,\n",
       "   -3.6672849306053497,\n",
       "   -3.665945242506892,\n",
       "   -3.687707956510759,\n",
       "   -3.669116035417568,\n",
       "   -3.665493255519687,\n",
       "   -3.6678778273444164,\n",
       "   -3.6652366246275028,\n",
       "   -3.672670581563906,\n",
       "   -3.6654987813546156,\n",
       "   -3.667060107451069,\n",
       "   -3.6672224728017673,\n",
       "   -3.666137147491674,\n",
       "   -3.665680442492268,\n",
       "   -3.667164017899988,\n",
       "   -3.668514185776649,\n",
       "   -3.666495465667304,\n",
       "   -3.66850533648559,\n",
       "   -3.6651630684453105,\n",
       "   -3.6664858119364934,\n",
       "   -3.666315592480145,\n",
       "   -3.666309771483617,\n",
       "   -3.6636260288736846,\n",
       "   -3.666827273985642,\n",
       "   -3.664559089075089,\n",
       "   -3.6665157427579027,\n",
       "   -3.6705949445781574,\n",
       "   -3.6647275762291276,\n",
       "   -3.6660362767085237,\n",
       "   -3.665818761014178,\n",
       "   -3.6654430379651783,\n",
       "   -3.6659580914777816,\n",
       "   -3.6647368327029826,\n",
       "   -3.6677750426185813,\n",
       "   -3.6719371251554267,\n",
       "   -3.6688489394726655,\n",
       "   -3.6671574099253346,\n",
       "   -3.669800836619799,\n",
       "   -3.6662361377395003,\n",
       "   -3.6684223345897906,\n",
       "   -3.6642730966112773,\n",
       "   -3.6676451178602556,\n",
       "   -3.6655659590017793,\n",
       "   -3.664853869845518,\n",
       "   -3.668817436608512],\n",
       "  'params': [{'num_leaves': 35.2750369203463,\n",
       "    'colsample_bytree': 0.945053763087716,\n",
       "    'min_data_in_leaf': 99.52631601945761,\n",
       "    'subsample': 0.878786875572771,\n",
       "    'max_depth': 14.976254377808925,\n",
       "    'reg_alpha': 7.665978803626482,\n",
       "    'reg_lambda': 1.5159878386204595,\n",
       "    'min_split_gain': 0.49484742239193324,\n",
       "    'min_child_weight': 41.958592727306204,\n",
       "    'min_child_samples': 48.97534426639042,\n",
       "    'feature_fraction': 0.5980245990839772,\n",
       "    'bagging_freq': 0.4591614208793393,\n",
       "    'bagging_fraction': 0.1409150225339448},\n",
       "   {'num_leaves': 30.35366063278294,\n",
       "    'colsample_bytree': 0.7530177684073285,\n",
       "    'min_data_in_leaf': 14.473092783749191,\n",
       "    'subsample': 0.3882862268338133,\n",
       "    'max_depth': 14.718314728496653,\n",
       "    'reg_alpha': 6.143078511173278,\n",
       "    'reg_lambda': 7.184040564542535,\n",
       "    'min_split_gain': 0.7532431851168324,\n",
       "    'min_child_weight': 44.894543555590445,\n",
       "    'min_child_samples': 49.9207934282912,\n",
       "    'feature_fraction': 0.8931248708374847,\n",
       "    'bagging_freq': 19.801553076763557,\n",
       "    'bagging_fraction': 0.803967900118883},\n",
       "   {'num_leaves': 31.4750528909437,\n",
       "    'colsample_bytree': 0.7848130380700391,\n",
       "    'min_data_in_leaf': 96.99344228615351,\n",
       "    'subsample': 0.801090051190588,\n",
       "    'max_depth': 5.301585683877091,\n",
       "    'reg_alpha': 9.024128077145336,\n",
       "    'reg_lambda': 0.47588591253516443,\n",
       "    'min_split_gain': 0.9690936775157848,\n",
       "    'min_child_weight': 32.845527073642074,\n",
       "    'min_child_samples': 49.552375328174,\n",
       "    'feature_fraction': 0.13030407823781287,\n",
       "    'bagging_freq': 17.098226630323097,\n",
       "    'bagging_fraction': 0.861206796250522},\n",
       "   {'num_leaves': 44.53988787836782,\n",
       "    'colsample_bytree': 0.1447299317409217,\n",
       "    'min_data_in_leaf': 96.19617771411514,\n",
       "    'subsample': 0.8924442767491212,\n",
       "    'max_depth': 13.335869497271696,\n",
       "    'reg_alpha': 8.496709617984472,\n",
       "    'reg_lambda': 2.212437021002367,\n",
       "    'min_split_gain': 0.11052211725269956,\n",
       "    'min_child_weight': 44.919322471207856,\n",
       "    'min_child_samples': 49.52519804987933,\n",
       "    'feature_fraction': 0.44024887642227206,\n",
       "    'bagging_freq': 15.431563998078063,\n",
       "    'bagging_fraction': 0.7366412666418792},\n",
       "   {'num_leaves': 43.86962009292387,\n",
       "    'colsample_bytree': 0.43947088863177985,\n",
       "    'min_data_in_leaf': 84.03697637782888,\n",
       "    'subsample': 0.3392941582821232,\n",
       "    'max_depth': 14.26928863003617,\n",
       "    'reg_alpha': 8.814465524312682,\n",
       "    'reg_lambda': 8.744516831536602,\n",
       "    'min_split_gain': 0.630445395963859,\n",
       "    'min_child_weight': 37.14789120002448,\n",
       "    'min_child_samples': 47.517853110419615,\n",
       "    'feature_fraction': 0.7732770010960086,\n",
       "    'bagging_freq': 1.5614572627060919,\n",
       "    'bagging_fraction': 0.9611251004151953},\n",
       "   {'num_leaves': 36.92277168824622,\n",
       "    'colsample_bytree': 0.6446956833789269,\n",
       "    'min_data_in_leaf': 98.73290185968884,\n",
       "    'subsample': 0.636387407119835,\n",
       "    'max_depth': 14.792698882937897,\n",
       "    'reg_alpha': 0.6582275866039233,\n",
       "    'reg_lambda': 1.4332377868753154,\n",
       "    'min_split_gain': 0.19094474534573236,\n",
       "    'min_child_weight': 42.950760851940274,\n",
       "    'min_child_samples': 5.818726184698772,\n",
       "    'feature_fraction': 0.9206265430131255,\n",
       "    'bagging_freq': 3.5270430063905733,\n",
       "    'bagging_fraction': 0.6189139740930303},\n",
       "   {'num_leaves': 44.40322852529117,\n",
       "    'colsample_bytree': 0.9322743967605243,\n",
       "    'min_data_in_leaf': 12.339395953437103,\n",
       "    'subsample': 0.6972875387006559,\n",
       "    'max_depth': 6.4224362847594385,\n",
       "    'reg_alpha': 0.36284856662556764,\n",
       "    'reg_lambda': 0.7336907468562703,\n",
       "    'min_split_gain': 0.7843941150225918,\n",
       "    'min_child_weight': 40.98757008698381,\n",
       "    'min_child_samples': 47.85915339219483,\n",
       "    'feature_fraction': 0.6442430678059629,\n",
       "    'bagging_freq': 18.458639220568735,\n",
       "    'bagging_fraction': 0.6945021629317115},\n",
       "   {'num_leaves': 31.790996486544255,\n",
       "    'colsample_bytree': 0.22959240040481618,\n",
       "    'min_data_in_leaf': 95.99678232632895,\n",
       "    'subsample': 0.3665248758301407,\n",
       "    'max_depth': 14.734052468371244,\n",
       "    'reg_alpha': 1.107443668889443,\n",
       "    'reg_lambda': 0.7623210166452288,\n",
       "    'min_split_gain': 0.43953067517225375,\n",
       "    'min_child_weight': 30.04623253475797,\n",
       "    'min_child_samples': 5.8157487321257975,\n",
       "    'feature_fraction': 0.9062306756577486,\n",
       "    'bagging_freq': 3.0946387691087884,\n",
       "    'bagging_fraction': 0.37657542346076855},\n",
       "   {'num_leaves': 42.51097275633763,\n",
       "    'colsample_bytree': 0.6317692289271654,\n",
       "    'min_data_in_leaf': 96.95668568071304,\n",
       "    'subsample': 0.3496785542839838,\n",
       "    'max_depth': 14.943096958769257,\n",
       "    'reg_alpha': 0.8502310715376415,\n",
       "    'reg_lambda': 0.23604384255473176,\n",
       "    'min_split_gain': 0.9852338954242198,\n",
       "    'min_child_weight': 44.58185095449306,\n",
       "    'min_child_samples': 49.57466885642929,\n",
       "    'feature_fraction': 0.7698453583499809,\n",
       "    'bagging_freq': 2.7658604800452147,\n",
       "    'bagging_fraction': 0.46067924358714624},\n",
       "   {'num_leaves': 40.582589801198964,\n",
       "    'colsample_bytree': 0.12728046863678863,\n",
       "    'min_data_in_leaf': 97.30267233647005,\n",
       "    'subsample': 0.31164984174324306,\n",
       "    'max_depth': 7.393756074716034,\n",
       "    'reg_alpha': 2.824480153405411,\n",
       "    'reg_lambda': 9.723337148926785,\n",
       "    'min_split_gain': 0.9779983166044357,\n",
       "    'min_child_weight': 30.279295981725486,\n",
       "    'min_child_samples': 6.499238456667635,\n",
       "    'feature_fraction': 0.6083306952870706,\n",
       "    'bagging_freq': 17.28323610223468,\n",
       "    'bagging_fraction': 0.8096389334384011},\n",
       "   {'num_leaves': 30.607922274490885,\n",
       "    'colsample_bytree': 0.5563976034336173,\n",
       "    'min_data_in_leaf': 99.75400885452446,\n",
       "    'subsample': 0.1664838183504188,\n",
       "    'max_depth': 13.824043324401979,\n",
       "    'reg_alpha': 5.531659996970485,\n",
       "    'reg_lambda': 9.402510160046495,\n",
       "    'min_split_gain': 0.6712902869357197,\n",
       "    'min_child_weight': 44.305932873853806,\n",
       "    'min_child_samples': 49.534385241231014,\n",
       "    'feature_fraction': 0.6667090998062297,\n",
       "    'bagging_freq': 17.696495952129755,\n",
       "    'bagging_fraction': 0.9598606924374165},\n",
       "   {'num_leaves': 37.029844636284636,\n",
       "    'colsample_bytree': 0.5731776538613018,\n",
       "    'min_data_in_leaf': 10.966414109866012,\n",
       "    'subsample': 0.11957225929293055,\n",
       "    'max_depth': 10.044523328866287,\n",
       "    'reg_alpha': 0.4646560912105846,\n",
       "    'reg_lambda': 9.302396885299991,\n",
       "    'min_split_gain': 0.029324076820940848,\n",
       "    'min_child_weight': 44.35768268344002,\n",
       "    'min_child_samples': 5.0529425764564975,\n",
       "    'feature_fraction': 0.6969084462935635,\n",
       "    'bagging_freq': 0.16307232688542062,\n",
       "    'bagging_fraction': 0.41086073725870276},\n",
       "   {'num_leaves': 44.41203525942661,\n",
       "    'colsample_bytree': 0.5336974246879851,\n",
       "    'min_data_in_leaf': 99.6356298669327,\n",
       "    'subsample': 0.6101510594318803,\n",
       "    'max_depth': 5.502135628617671,\n",
       "    'reg_alpha': 7.068056618208047,\n",
       "    'reg_lambda': 2.460571004749481,\n",
       "    'min_split_gain': 0.8052649828463034,\n",
       "    'min_child_weight': 41.79079603000528,\n",
       "    'min_child_samples': 5.230824997223195,\n",
       "    'feature_fraction': 0.9418990458771049,\n",
       "    'bagging_freq': 19.19963678068808,\n",
       "    'bagging_fraction': 0.8651668694919924},\n",
       "   {'num_leaves': 30.34374097058507,\n",
       "    'colsample_bytree': 0.6549859977353872,\n",
       "    'min_data_in_leaf': 11.973630937376601,\n",
       "    'subsample': 0.635084822379695,\n",
       "    'max_depth': 5.43627304584803,\n",
       "    'reg_alpha': 8.887336607629049,\n",
       "    'reg_lambda': 9.446771968570097,\n",
       "    'min_split_gain': 0.6795122187645353,\n",
       "    'min_child_weight': 44.94755905152635,\n",
       "    'min_child_samples': 48.73961224802017,\n",
       "    'feature_fraction': 0.8724481801503713,\n",
       "    'bagging_freq': 1.0747625244540893,\n",
       "    'bagging_fraction': 0.9408528597561442},\n",
       "   {'num_leaves': 42.85806415830413,\n",
       "    'colsample_bytree': 0.8115681731078072,\n",
       "    'min_data_in_leaf': 12.755413562692794,\n",
       "    'subsample': 0.42618418775637823,\n",
       "    'max_depth': 14.979618700954356,\n",
       "    'reg_alpha': 1.2317246676858995,\n",
       "    'reg_lambda': 9.28965778348972,\n",
       "    'min_split_gain': 0.7020843722042958,\n",
       "    'min_child_weight': 31.046624611438023,\n",
       "    'min_child_samples': 43.88672891786406,\n",
       "    'feature_fraction': 0.8796363448282304,\n",
       "    'bagging_freq': 2.810856913858508,\n",
       "    'bagging_fraction': 0.9533154502138111},\n",
       "   {'num_leaves': 42.23832054675102,\n",
       "    'colsample_bytree': 0.2737371965572,\n",
       "    'min_data_in_leaf': 42.2451226757962,\n",
       "    'subsample': 0.8725928506534211,\n",
       "    'max_depth': 14.77612911393258,\n",
       "    'reg_alpha': 8.755878684256043,\n",
       "    'reg_lambda': 3.6818125063786034,\n",
       "    'min_split_gain': 0.9647320212834806,\n",
       "    'min_child_weight': 44.87991600621045,\n",
       "    'min_child_samples': 32.96900497455242,\n",
       "    'feature_fraction': 0.9482329501611139,\n",
       "    'bagging_freq': 0.31864261049059817,\n",
       "    'bagging_fraction': 0.7670068031833164},\n",
       "   {'num_leaves': 43.545036993662336,\n",
       "    'colsample_bytree': 0.27343595665489834,\n",
       "    'min_data_in_leaf': 44.021004961503714,\n",
       "    'subsample': 0.9168784376382016,\n",
       "    'max_depth': 5.199640136408852,\n",
       "    'reg_alpha': 2.889254827715658,\n",
       "    'reg_lambda': 0.7134898059049399,\n",
       "    'min_split_gain': 0.8092795719114663,\n",
       "    'min_child_weight': 31.744408473398927,\n",
       "    'min_child_samples': 7.662359133012297,\n",
       "    'feature_fraction': 0.7515249873285962,\n",
       "    'bagging_freq': 15.99860867311058,\n",
       "    'bagging_fraction': 0.9174918114800015},\n",
       "   {'num_leaves': 37.679435470463716,\n",
       "    'colsample_bytree': 0.3284494402457252,\n",
       "    'min_data_in_leaf': 82.1115743740212,\n",
       "    'subsample': 0.5109729950652927,\n",
       "    'max_depth': 7.784424502724374,\n",
       "    'reg_alpha': 9.271322392582395,\n",
       "    'reg_lambda': 0.7401348064023316,\n",
       "    'min_split_gain': 0.8678984952422663,\n",
       "    'min_child_weight': 44.15786740388043,\n",
       "    'min_child_samples': 48.58558811779888,\n",
       "    'feature_fraction': 0.7770624622722994,\n",
       "    'bagging_freq': 9.388086697054161,\n",
       "    'bagging_fraction': 0.776388649864472},\n",
       "   {'num_leaves': 44.932124445177315,\n",
       "    'colsample_bytree': 0.4678834566703506,\n",
       "    'min_data_in_leaf': 99.53079881148749,\n",
       "    'subsample': 0.27369656789802405,\n",
       "    'max_depth': 11.320022961241829,\n",
       "    'reg_alpha': 3.1964796807080518,\n",
       "    'reg_lambda': 1.5779087330234753,\n",
       "    'min_split_gain': 0.057051274442296296,\n",
       "    'min_child_weight': 30.3070343570132,\n",
       "    'min_child_samples': 40.19423740480025,\n",
       "    'feature_fraction': 0.8639686578183503,\n",
       "    'bagging_freq': 18.64241827331636,\n",
       "    'bagging_fraction': 0.9281767752593822},\n",
       "   {'num_leaves': 44.08614794116133,\n",
       "    'colsample_bytree': 0.397629057694613,\n",
       "    'min_data_in_leaf': 11.712329847413587,\n",
       "    'subsample': 0.8479215230764071,\n",
       "    'max_depth': 11.278415939667997,\n",
       "    'reg_alpha': 9.411704470397842,\n",
       "    'reg_lambda': 9.683213532984633,\n",
       "    'min_split_gain': 0.94924487585844,\n",
       "    'min_child_weight': 32.83533541865127,\n",
       "    'min_child_samples': 47.89880590014859,\n",
       "    'feature_fraction': 0.11186779202495103,\n",
       "    'bagging_freq': 18.92591560436312,\n",
       "    'bagging_fraction': 0.3328855108372028},\n",
       "   {'num_leaves': 32.34457269113439,\n",
       "    'colsample_bytree': 0.3330233126901282,\n",
       "    'min_data_in_leaf': 12.169717887535208,\n",
       "    'subsample': 0.1482452602099386,\n",
       "    'max_depth': 5.717284278917745,\n",
       "    'reg_alpha': 4.161332072612743,\n",
       "    'reg_lambda': 2.5118327324629997,\n",
       "    'min_split_gain': 0.443930939811059,\n",
       "    'min_child_weight': 30.46437577837398,\n",
       "    'min_child_samples': 5.3044476888790015,\n",
       "    'feature_fraction': 0.46843667977387105,\n",
       "    'bagging_freq': 0.5679606943457172,\n",
       "    'bagging_fraction': 0.9822742345174992},\n",
       "   {'num_leaves': 44.81750525241756,\n",
       "    'colsample_bytree': 0.654750747954148,\n",
       "    'min_data_in_leaf': 31.303703761453114,\n",
       "    'subsample': 0.9569635805077285,\n",
       "    'max_depth': 6.204871605708192,\n",
       "    'reg_alpha': 6.614288065527244,\n",
       "    'reg_lambda': 8.471027778405427,\n",
       "    'min_split_gain': 0.573156725730434,\n",
       "    'min_child_weight': 44.90279796434986,\n",
       "    'min_child_samples': 48.58893911284814,\n",
       "    'feature_fraction': 0.8594820387319101,\n",
       "    'bagging_freq': 19.246693360405654,\n",
       "    'bagging_fraction': 0.6665831281503903},\n",
       "   {'num_leaves': 32.386993151669465,\n",
       "    'colsample_bytree': 0.9708176857211531,\n",
       "    'min_data_in_leaf': 19.128564701700828,\n",
       "    'subsample': 0.5734766921935317,\n",
       "    'max_depth': 14.171272406341416,\n",
       "    'reg_alpha': 9.087890430687555,\n",
       "    'reg_lambda': 8.241760535577047,\n",
       "    'min_split_gain': 0.815121350572571,\n",
       "    'min_child_weight': 30.28477720882442,\n",
       "    'min_child_samples': 49.69430276475384,\n",
       "    'feature_fraction': 0.8842675727839923,\n",
       "    'bagging_freq': 2.3126333332492166,\n",
       "    'bagging_fraction': 0.4934711851768127},\n",
       "   {'num_leaves': 30.36588261491337,\n",
       "    'colsample_bytree': 0.35243490775328923,\n",
       "    'min_data_in_leaf': 85.8625511685296,\n",
       "    'subsample': 0.8804107723929697,\n",
       "    'max_depth': 14.9953733882971,\n",
       "    'reg_alpha': 9.928699165821493,\n",
       "    'reg_lambda': 1.7037211612490466,\n",
       "    'min_split_gain': 0.6689504335330538,\n",
       "    'min_child_weight': 30.021552990933607,\n",
       "    'min_child_samples': 46.36092176042801,\n",
       "    'feature_fraction': 0.7892204742126089,\n",
       "    'bagging_freq': 2.974270361066904,\n",
       "    'bagging_fraction': 0.7893817169267833},\n",
       "   {'num_leaves': 30.79024866189696,\n",
       "    'colsample_bytree': 0.7941411912296157,\n",
       "    'min_data_in_leaf': 11.46016027775584,\n",
       "    'subsample': 0.5211249361352355,\n",
       "    'max_depth': 6.384877359860868,\n",
       "    'reg_alpha': 0.410353354949744,\n",
       "    'reg_lambda': 9.79987877501182,\n",
       "    'min_split_gain': 0.9636237963578534,\n",
       "    'min_child_weight': 43.90926383324988,\n",
       "    'min_child_samples': 9.127735471879577,\n",
       "    'feature_fraction': 0.8984918333298707,\n",
       "    'bagging_freq': 6.6191722280547305,\n",
       "    'bagging_fraction': 0.981706903258783},\n",
       "   {'num_leaves': 43.60759072352756,\n",
       "    'colsample_bytree': 0.5071001144349105,\n",
       "    'min_data_in_leaf': 10.8240271007337,\n",
       "    'subsample': 0.24478539932198407,\n",
       "    'max_depth': 5.851152845432389,\n",
       "    'reg_alpha': 2.109806295761852,\n",
       "    'reg_lambda': 1.6165954115147274,\n",
       "    'min_split_gain': 0.2662742038524255,\n",
       "    'min_child_weight': 44.99627825892776,\n",
       "    'min_child_samples': 6.1468041142363905,\n",
       "    'feature_fraction': 0.7573469420909088,\n",
       "    'bagging_freq': 16.893571614070208,\n",
       "    'bagging_fraction': 0.7806192246264951},\n",
       "   {'num_leaves': 30.5239097492504,\n",
       "    'colsample_bytree': 0.1343411408759144,\n",
       "    'min_data_in_leaf': 44.885565047355456,\n",
       "    'subsample': 0.7184866504855356,\n",
       "    'max_depth': 12.472523705713412,\n",
       "    'reg_alpha': 7.643761197558674,\n",
       "    'reg_lambda': 9.32708916530678,\n",
       "    'min_split_gain': 0.16587620337664244,\n",
       "    'min_child_weight': 44.882782488797595,\n",
       "    'min_child_samples': 49.34505806913339,\n",
       "    'feature_fraction': 0.9406419088629788,\n",
       "    'bagging_freq': 0.8812498931732993,\n",
       "    'bagging_fraction': 0.8281963425047447},\n",
       "   {'num_leaves': 43.065873112579425,\n",
       "    'colsample_bytree': 0.2923086181278334,\n",
       "    'min_data_in_leaf': 11.169989758962034,\n",
       "    'subsample': 0.40641178827387614,\n",
       "    'max_depth': 5.693406316702953,\n",
       "    'reg_alpha': 2.1300965733742148,\n",
       "    'reg_lambda': 9.271313258866728,\n",
       "    'min_split_gain': 0.26605398252230583,\n",
       "    'min_child_weight': 31.96670641329302,\n",
       "    'min_child_samples': 5.815442661493324,\n",
       "    'feature_fraction': 0.6452528753954976,\n",
       "    'bagging_freq': 0.5456659716704104,\n",
       "    'bagging_fraction': 0.6454153506473076},\n",
       "   {'num_leaves': 39.17457023916751,\n",
       "    'colsample_bytree': 0.3159846242869565,\n",
       "    'min_data_in_leaf': 10.137551737553993,\n",
       "    'subsample': 0.6890798311840739,\n",
       "    'max_depth': 14.789416409643849,\n",
       "    'reg_alpha': 1.0995728590918463,\n",
       "    'reg_lambda': 8.333921863146973,\n",
       "    'min_split_gain': 0.02324209376299302,\n",
       "    'min_child_weight': 42.29382896778092,\n",
       "    'min_child_samples': 49.21892582151328,\n",
       "    'feature_fraction': 0.7213358041987954,\n",
       "    'bagging_freq': 2.021104254096764,\n",
       "    'bagging_fraction': 0.9553864209231829},\n",
       "   {'num_leaves': 31.50333865418951,\n",
       "    'colsample_bytree': 0.7579535134271741,\n",
       "    'min_data_in_leaf': 97.31368311741092,\n",
       "    'subsample': 0.6982832827744639,\n",
       "    'max_depth': 14.567404825358828,\n",
       "    'reg_alpha': 8.773145480552133,\n",
       "    'reg_lambda': 2.2592360156554325,\n",
       "    'min_split_gain': 0.6113680170708282,\n",
       "    'min_child_weight': 42.8341977083092,\n",
       "    'min_child_samples': 5.937437357340582,\n",
       "    'feature_fraction': 0.8106850654997882,\n",
       "    'bagging_freq': 16.76979398200125,\n",
       "    'bagging_fraction': 0.7373768428773851},\n",
       "   {'num_leaves': 31.072061784328408,\n",
       "    'colsample_bytree': 0.4448765704288923,\n",
       "    'min_data_in_leaf': 99.63889422553513,\n",
       "    'subsample': 0.882624743986136,\n",
       "    'max_depth': 14.281276378506245,\n",
       "    'reg_alpha': 0.7690334076160898,\n",
       "    'reg_lambda': 9.040523936000337,\n",
       "    'min_split_gain': 0.7393948072794634,\n",
       "    'min_child_weight': 34.10192644401565,\n",
       "    'min_child_samples': 44.887217309597695,\n",
       "    'feature_fraction': 0.8127266358759727,\n",
       "    'bagging_freq': 5.727315600161013,\n",
       "    'bagging_fraction': 0.9239366126144042},\n",
       "   {'num_leaves': 43.15393134779763,\n",
       "    'colsample_bytree': 0.24168093592987894,\n",
       "    'min_data_in_leaf': 10.934065912905348,\n",
       "    'subsample': 0.26071232704118674,\n",
       "    'max_depth': 5.254676441096715,\n",
       "    'reg_alpha': 9.225711070877086,\n",
       "    'reg_lambda': 2.0458863191128263,\n",
       "    'min_split_gain': 0.7800200138868887,\n",
       "    'min_child_weight': 43.47411257322655,\n",
       "    'min_child_samples': 20.996727249628695,\n",
       "    'feature_fraction': 0.8862882939322009,\n",
       "    'bagging_freq': 0.21695896551224614,\n",
       "    'bagging_fraction': 0.9891360902872229},\n",
       "   {'num_leaves': 32.03636549627204,\n",
       "    'colsample_bytree': 0.428678733212115,\n",
       "    'min_data_in_leaf': 31.1664654210826,\n",
       "    'subsample': 0.44147543203610384,\n",
       "    'max_depth': 5.880364244269254,\n",
       "    'reg_alpha': 1.0239083615304434,\n",
       "    'reg_lambda': 9.357096195673439,\n",
       "    'min_split_gain': 0.8572692352419506,\n",
       "    'min_child_weight': 44.8047203749468,\n",
       "    'min_child_samples': 36.75144603218002,\n",
       "    'feature_fraction': 0.926127639081919,\n",
       "    'bagging_freq': 19.7856309790971,\n",
       "    'bagging_fraction': 0.9165249360056994},\n",
       "   {'num_leaves': 32.21917395030592,\n",
       "    'colsample_bytree': 0.9840002002998568,\n",
       "    'min_data_in_leaf': 47.36666942180771,\n",
       "    'subsample': 0.5750365511214317,\n",
       "    'max_depth': 14.616254837899396,\n",
       "    'reg_alpha': 0.22694543994745464,\n",
       "    'reg_lambda': 7.893478100819276,\n",
       "    'min_split_gain': 0.63493574168868,\n",
       "    'min_child_weight': 30.213312843415913,\n",
       "    'min_child_samples': 5.036066494278504,\n",
       "    'feature_fraction': 0.7047090787996909,\n",
       "    'bagging_freq': 4.223647165320656,\n",
       "    'bagging_fraction': 0.9736926197782839},\n",
       "   {'num_leaves': 32.34637624872364,\n",
       "    'colsample_bytree': 0.9054020388033445,\n",
       "    'min_data_in_leaf': 98.62322625139583,\n",
       "    'subsample': 0.9697428539472596,\n",
       "    'max_depth': 5.040523844793143,\n",
       "    'reg_alpha': 0.762707326316705,\n",
       "    'reg_lambda': 9.227979302511535,\n",
       "    'min_split_gain': 0.3479030233990634,\n",
       "    'min_child_weight': 30.946010824248656,\n",
       "    'min_child_samples': 17.550190663117508,\n",
       "    'feature_fraction': 0.15435950930143072,\n",
       "    'bagging_freq': 19.579666870728904,\n",
       "    'bagging_fraction': 0.8242888828628858},\n",
       "   {'num_leaves': 44.83529298266032,\n",
       "    'colsample_bytree': 0.7480196465138075,\n",
       "    'min_data_in_leaf': 98.81463316288368,\n",
       "    'subsample': 0.7820763162614687,\n",
       "    'max_depth': 5.32917005115954,\n",
       "    'reg_alpha': 9.768697420968348,\n",
       "    'reg_lambda': 3.8525637658659484,\n",
       "    'min_split_gain': 0.37190326602500723,\n",
       "    'min_child_weight': 44.78091989568811,\n",
       "    'min_child_samples': 49.66162027703913,\n",
       "    'feature_fraction': 0.3594629304121142,\n",
       "    'bagging_freq': 0.7375031055006187,\n",
       "    'bagging_fraction': 0.6611619361173771},\n",
       "   {'num_leaves': 30.264128961692645,\n",
       "    'colsample_bytree': 0.579629558814932,\n",
       "    'min_data_in_leaf': 94.75452616789445,\n",
       "    'subsample': 0.8236074287648191,\n",
       "    'max_depth': 14.967558928984268,\n",
       "    'reg_alpha': 8.1947596388401,\n",
       "    'reg_lambda': 9.87504778218452,\n",
       "    'min_split_gain': 0.964845290392349,\n",
       "    'min_child_weight': 30.845852416143504,\n",
       "    'min_child_samples': 7.342366442123581,\n",
       "    'feature_fraction': 0.8839067308033589,\n",
       "    'bagging_freq': 1.0997056389036541,\n",
       "    'bagging_fraction': 0.6011590647598003},\n",
       "   {'num_leaves': 32.19842840115861,\n",
       "    'colsample_bytree': 0.23596558976131254,\n",
       "    'min_data_in_leaf': 71.72142767480184,\n",
       "    'subsample': 0.7830738661829164,\n",
       "    'max_depth': 14.086772495591688,\n",
       "    'reg_alpha': 8.751613481640968,\n",
       "    'reg_lambda': 1.6754064650538314,\n",
       "    'min_split_gain': 0.7483740494419304,\n",
       "    'min_child_weight': 43.79529839285796,\n",
       "    'min_child_samples': 42.36834852139792,\n",
       "    'feature_fraction': 0.540161901709116,\n",
       "    'bagging_freq': 0.2968738698108897,\n",
       "    'bagging_fraction': 0.8211302458310942},\n",
       "   {'num_leaves': 44.95472419348616,\n",
       "    'colsample_bytree': 0.4542862893717283,\n",
       "    'min_data_in_leaf': 91.4737925130207,\n",
       "    'subsample': 0.7070147346125071,\n",
       "    'max_depth': 5.469240095034183,\n",
       "    'reg_alpha': 8.752662983860603,\n",
       "    'reg_lambda': 0.22072335070139282,\n",
       "    'min_split_gain': 0.4404773161071487,\n",
       "    'min_child_weight': 31.487513090745257,\n",
       "    'min_child_samples': 49.359426675999266,\n",
       "    'feature_fraction': 0.57280282368447,\n",
       "    'bagging_freq': 4.915928933458272,\n",
       "    'bagging_fraction': 0.8110730232166176},\n",
       "   {'num_leaves': 44.29875031981314,\n",
       "    'colsample_bytree': 0.5543267428799973,\n",
       "    'min_data_in_leaf': 83.86922829434688,\n",
       "    'subsample': 0.9220544223732967,\n",
       "    'max_depth': 5.525053124582345,\n",
       "    'reg_alpha': 0.8993976869162967,\n",
       "    'reg_lambda': 0.058334266641487664,\n",
       "    'min_split_gain': 0.6233861884440426,\n",
       "    'min_child_weight': 40.2971603026709,\n",
       "    'min_child_samples': 49.23833663906039,\n",
       "    'feature_fraction': 0.10591662594242675,\n",
       "    'bagging_freq': 15.402604371720667,\n",
       "    'bagging_fraction': 0.7382838673805635},\n",
       "   {'num_leaves': 30.991415786175445,\n",
       "    'colsample_bytree': 0.5405196933382675,\n",
       "    'min_data_in_leaf': 84.85395472440774,\n",
       "    'subsample': 0.43900160754833295,\n",
       "    'max_depth': 14.871250570205598,\n",
       "    'reg_alpha': 4.780650124409639,\n",
       "    'reg_lambda': 8.435348996577282,\n",
       "    'min_split_gain': 0.9948788906771557,\n",
       "    'min_child_weight': 44.90548892877153,\n",
       "    'min_child_samples': 48.59365316060146,\n",
       "    'feature_fraction': 0.27878528207550674,\n",
       "    'bagging_freq': 3.7740735627150235,\n",
       "    'bagging_fraction': 0.9749122583235942},\n",
       "   {'num_leaves': 32.81938478365652,\n",
       "    'colsample_bytree': 0.584333374309048,\n",
       "    'min_data_in_leaf': 86.57184292961573,\n",
       "    'subsample': 0.9792105948396782,\n",
       "    'max_depth': 14.30256708544671,\n",
       "    'reg_alpha': 8.902002652711813,\n",
       "    'reg_lambda': 9.601598859343255,\n",
       "    'min_split_gain': 0.9659028088087832,\n",
       "    'min_child_weight': 36.593537413668585,\n",
       "    'min_child_samples': 46.86166704826553,\n",
       "    'feature_fraction': 0.8999319868523807,\n",
       "    'bagging_freq': 17.885559710688174,\n",
       "    'bagging_fraction': 0.9519508192496566},\n",
       "   {'num_leaves': 44.5345199963607,\n",
       "    'colsample_bytree': 0.9782017440948415,\n",
       "    'min_data_in_leaf': 83.08144763478718,\n",
       "    'subsample': 0.6657919263792551,\n",
       "    'max_depth': 11.711845274947411,\n",
       "    'reg_alpha': 9.28247535909888,\n",
       "    'reg_lambda': 0.6226786960127706,\n",
       "    'min_split_gain': 0.9344153505640409,\n",
       "    'min_child_weight': 35.71975859705468,\n",
       "    'min_child_samples': 37.44722957323224,\n",
       "    'feature_fraction': 0.9078703148515322,\n",
       "    'bagging_freq': 9.847736104430362,\n",
       "    'bagging_fraction': 0.8920059048958394},\n",
       "   {'num_leaves': 36.925030514338985,\n",
       "    'colsample_bytree': 0.8060222653467388,\n",
       "    'min_data_in_leaf': 10.232870106392918,\n",
       "    'subsample': 0.6342298140024112,\n",
       "    'max_depth': 6.590234654880934,\n",
       "    'reg_alpha': 9.922073676472822,\n",
       "    'reg_lambda': 1.1887960650676088,\n",
       "    'min_split_gain': 0.03544951977321753,\n",
       "    'min_child_weight': 44.22343879924531,\n",
       "    'min_child_samples': 5.3970456587966416,\n",
       "    'feature_fraction': 0.6798753706150211,\n",
       "    'bagging_freq': 0.47765021388036955,\n",
       "    'bagging_fraction': 0.5974139622396398},\n",
       "   {'num_leaves': 30.025732919313924,\n",
       "    'colsample_bytree': 0.904566780014574,\n",
       "    'min_data_in_leaf': 12.450826205137638,\n",
       "    'subsample': 0.6127984876428776,\n",
       "    'max_depth': 9.362791502762434,\n",
       "    'reg_alpha': 0.7581789039118125,\n",
       "    'reg_lambda': 0.46586311690330007,\n",
       "    'min_split_gain': 0.22837215927620858,\n",
       "    'min_child_weight': 44.10227361125613,\n",
       "    'min_child_samples': 9.62167518976998,\n",
       "    'feature_fraction': 0.41766202707149347,\n",
       "    'bagging_freq': 1.449273994590894,\n",
       "    'bagging_fraction': 0.9684537861265574},\n",
       "   {'num_leaves': 30.283691776300977,\n",
       "    'colsample_bytree': 0.9640541935746403,\n",
       "    'min_data_in_leaf': 99.52471996795724,\n",
       "    'subsample': 0.6744106099227206,\n",
       "    'max_depth': 14.144334165160966,\n",
       "    'reg_alpha': 2.7337615317660644,\n",
       "    'reg_lambda': 0.38178096493571845,\n",
       "    'min_split_gain': 0.9680598162378288,\n",
       "    'min_child_weight': 44.49663839926213,\n",
       "    'min_child_samples': 47.989702152979326,\n",
       "    'feature_fraction': 0.7210307444839114,\n",
       "    'bagging_freq': 7.428794581060649,\n",
       "    'bagging_fraction': 0.9548216470746105},\n",
       "   {'num_leaves': 41.1698843401438,\n",
       "    'colsample_bytree': 0.7528108974286383,\n",
       "    'min_data_in_leaf': 38.889948906436835,\n",
       "    'subsample': 0.19270580055173672,\n",
       "    'max_depth': 5.811487616727287,\n",
       "    'reg_alpha': 2.6797990050861897,\n",
       "    'reg_lambda': 9.813258889117947,\n",
       "    'min_split_gain': 0.9715766702211073,\n",
       "    'min_child_weight': 32.207299122096245,\n",
       "    'min_child_samples': 24.236375731365037,\n",
       "    'feature_fraction': 0.5496360241391368,\n",
       "    'bagging_freq': 18.73402681310607,\n",
       "    'bagging_fraction': 0.9677288599152852},\n",
       "   {'num_leaves': 43.7910006558377,\n",
       "    'colsample_bytree': 0.683356874233985,\n",
       "    'min_data_in_leaf': 99.85790143748159,\n",
       "    'subsample': 0.13786736187712983,\n",
       "    'max_depth': 13.576901891644805,\n",
       "    'reg_alpha': 9.611585413806251,\n",
       "    'reg_lambda': 9.44894155619947,\n",
       "    'min_split_gain': 0.3000753538670101,\n",
       "    'min_child_weight': 30.002787216849825,\n",
       "    'min_child_samples': 7.397736760502367,\n",
       "    'feature_fraction': 0.4009426239268866,\n",
       "    'bagging_freq': 16.573895932271554,\n",
       "    'bagging_fraction': 0.9482760457557305},\n",
       "   {'num_leaves': 34.694933641160006,\n",
       "    'colsample_bytree': 0.1356913321910409,\n",
       "    'min_data_in_leaf': 18.905557901979257,\n",
       "    'subsample': 0.8169453991490149,\n",
       "    'max_depth': 14.136023223752405,\n",
       "    'reg_alpha': 1.409941742863997,\n",
       "    'reg_lambda': 1.3377987373107647,\n",
       "    'min_split_gain': 0.8665170719209443,\n",
       "    'min_child_weight': 32.77452296768694,\n",
       "    'min_child_samples': 49.333365912341115,\n",
       "    'feature_fraction': 0.13328943335948745,\n",
       "    'bagging_freq': 19.958295468604465,\n",
       "    'bagging_fraction': 0.9648817018460326},\n",
       "   {'num_leaves': 32.782333072377234,\n",
       "    'colsample_bytree': 0.14191060071836134,\n",
       "    'min_data_in_leaf': 99.12547133331665,\n",
       "    'subsample': 0.6185895582783775,\n",
       "    'max_depth': 13.30188768033511,\n",
       "    'reg_alpha': 0.35358341841731034,\n",
       "    'reg_lambda': 9.94900591052366,\n",
       "    'min_split_gain': 0.03452632122132615,\n",
       "    'min_child_weight': 41.57963851776144,\n",
       "    'min_child_samples': 5.417559218614245,\n",
       "    'feature_fraction': 0.22974160797084645,\n",
       "    'bagging_freq': 13.825707029393204,\n",
       "    'bagging_fraction': 0.7142730501177892},\n",
       "   {'num_leaves': 38.13793147084583,\n",
       "    'colsample_bytree': 0.34669031948129275,\n",
       "    'min_data_in_leaf': 10.536681043499609,\n",
       "    'subsample': 0.857444472535009,\n",
       "    'max_depth': 5.309421906843945,\n",
       "    'reg_alpha': 4.0995136577326665,\n",
       "    'reg_lambda': 9.359498373861774,\n",
       "    'min_split_gain': 0.544982203156127,\n",
       "    'min_child_weight': 31.191590552350775,\n",
       "    'min_child_samples': 49.00952897736902,\n",
       "    'feature_fraction': 0.8417944616822085,\n",
       "    'bagging_freq': 4.7517229309473645,\n",
       "    'bagging_fraction': 0.9615941114455584},\n",
       "   {'num_leaves': 34.15601293734748,\n",
       "    'colsample_bytree': 0.6702370151789131,\n",
       "    'min_data_in_leaf': 81.46432604822446,\n",
       "    'subsample': 0.6345852592900708,\n",
       "    'max_depth': 5.449134056114811,\n",
       "    'reg_alpha': 9.695085364517142,\n",
       "    'reg_lambda': 1.5862021263682613,\n",
       "    'min_split_gain': 0.03684925868427935,\n",
       "    'min_child_weight': 30.557767195878675,\n",
       "    'min_child_samples': 5.070493667511843,\n",
       "    'feature_fraction': 0.8948776001561525,\n",
       "    'bagging_freq': 19.0082293602311,\n",
       "    'bagging_fraction': 0.8823500606116791},\n",
       "   {'num_leaves': 41.227638881273776,\n",
       "    'colsample_bytree': 0.9023774671929563,\n",
       "    'min_data_in_leaf': 38.72784881953639,\n",
       "    'subsample': 0.9224138461132037,\n",
       "    'max_depth': 5.5607603420915375,\n",
       "    'reg_alpha': 1.30825957965796,\n",
       "    'reg_lambda': 0.7605030935835411,\n",
       "    'min_split_gain': 0.24220987821663142,\n",
       "    'min_child_weight': 44.67585112516335,\n",
       "    'min_child_samples': 7.053167708030479,\n",
       "    'feature_fraction': 0.12806963872450433,\n",
       "    'bagging_freq': 14.143930294407568,\n",
       "    'bagging_fraction': 0.7316740527007364},\n",
       "   {'num_leaves': 32.90893411302621,\n",
       "    'colsample_bytree': 0.32627322078015863,\n",
       "    'min_data_in_leaf': 12.383036071345115,\n",
       "    'subsample': 0.5057263923174856,\n",
       "    'max_depth': 5.286405346346124,\n",
       "    'reg_alpha': 9.707348909068571,\n",
       "    'reg_lambda': 1.1306791492126778,\n",
       "    'min_split_gain': 0.051764299243348355,\n",
       "    'min_child_weight': 38.83207417585245,\n",
       "    'min_child_samples': 48.937616003454636,\n",
       "    'feature_fraction': 0.7558835702496507,\n",
       "    'bagging_freq': 18.42350541738598,\n",
       "    'bagging_fraction': 0.9511160733104165},\n",
       "   {'num_leaves': 30.26725886936457,\n",
       "    'colsample_bytree': 0.9406141957495744,\n",
       "    'min_data_in_leaf': 43.35225408699839,\n",
       "    'subsample': 0.14045460884426655,\n",
       "    'max_depth': 14.588022886303367,\n",
       "    'reg_alpha': 1.3683120690272321,\n",
       "    'reg_lambda': 9.152211739767736,\n",
       "    'min_split_gain': 0.7556397237759123,\n",
       "    'min_child_weight': 44.02339409886022,\n",
       "    'min_child_samples': 24.07930748587072,\n",
       "    'feature_fraction': 0.20336376014778051,\n",
       "    'bagging_freq': 5.446859947617813,\n",
       "    'bagging_fraction': 0.9433876859720087},\n",
       "   {'num_leaves': 42.17142717805021,\n",
       "    'colsample_bytree': 0.6670138464868892,\n",
       "    'min_data_in_leaf': 63.32294525877759,\n",
       "    'subsample': 0.7046407479256054,\n",
       "    'max_depth': 14.618015328189923,\n",
       "    'reg_alpha': 4.003361400023769,\n",
       "    'reg_lambda': 8.72524361910812,\n",
       "    'min_split_gain': 0.16909795288706042,\n",
       "    'min_child_weight': 41.939710702224275,\n",
       "    'min_child_samples': 48.44410042256193,\n",
       "    'feature_fraction': 0.7339826949848357,\n",
       "    'bagging_freq': 13.176943800738975,\n",
       "    'bagging_fraction': 0.9652326747905731},\n",
       "   {'num_leaves': 43.08616640543394,\n",
       "    'colsample_bytree': 0.26903755229307746,\n",
       "    'min_data_in_leaf': 95.96597129643888,\n",
       "    'subsample': 0.6041935318844307,\n",
       "    'max_depth': 14.91208886596329,\n",
       "    'reg_alpha': 2.9372825621725718,\n",
       "    'reg_lambda': 6.548190190652289,\n",
       "    'min_split_gain': 0.2236387249444336,\n",
       "    'min_child_weight': 30.142858810238426,\n",
       "    'min_child_samples': 5.200691807670042,\n",
       "    'feature_fraction': 0.9319445336843488,\n",
       "    'bagging_freq': 1.380864812703071,\n",
       "    'bagging_fraction': 0.8215023705777497},\n",
       "   {'num_leaves': 30.417411866992094,\n",
       "    'colsample_bytree': 0.6641143222351285,\n",
       "    'min_data_in_leaf': 99.24244161714128,\n",
       "    'subsample': 0.9700506931060903,\n",
       "    'max_depth': 13.646939823476266,\n",
       "    'reg_alpha': 8.556755641657928,\n",
       "    'reg_lambda': 1.1545867811063526,\n",
       "    'min_split_gain': 0.010888246227736986,\n",
       "    'min_child_weight': 44.706925060125926,\n",
       "    'min_child_samples': 36.22441575653067,\n",
       "    'feature_fraction': 0.666064492692613,\n",
       "    'bagging_freq': 12.391756971096594,\n",
       "    'bagging_fraction': 0.8972856722666454},\n",
       "   {'num_leaves': 37.444307093409776,\n",
       "    'colsample_bytree': 0.8906814122156111,\n",
       "    'min_data_in_leaf': 96.46437680445835,\n",
       "    'subsample': 0.9681503253328672,\n",
       "    'max_depth': 14.48520806204548,\n",
       "    'reg_alpha': 0.8734564102500375,\n",
       "    'reg_lambda': 9.405643032234927,\n",
       "    'min_split_gain': 0.20479932167784487,\n",
       "    'min_child_weight': 30.61476156375053,\n",
       "    'min_child_samples': 48.36714415960036,\n",
       "    'feature_fraction': 0.4663464567345851,\n",
       "    'bagging_freq': 15.520253755534593,\n",
       "    'bagging_fraction': 0.9591006972974798},\n",
       "   {'num_leaves': 31.996843931025822,\n",
       "    'colsample_bytree': 0.33611830249638486,\n",
       "    'min_data_in_leaf': 92.08402890536607,\n",
       "    'subsample': 0.5620356299652008,\n",
       "    'max_depth': 14.924100450695818,\n",
       "    'reg_alpha': 9.220838172949938,\n",
       "    'reg_lambda': 8.087441825149408,\n",
       "    'min_split_gain': 0.03232352430027485,\n",
       "    'min_child_weight': 31.31761458597267,\n",
       "    'min_child_samples': 5.473396781723409,\n",
       "    'feature_fraction': 0.8518014260704982,\n",
       "    'bagging_freq': 10.89447988109783,\n",
       "    'bagging_fraction': 0.9738538363485912},\n",
       "   {'num_leaves': 44.52492421176259,\n",
       "    'colsample_bytree': 0.8852056364930433,\n",
       "    'min_data_in_leaf': 99.51744469289707,\n",
       "    'subsample': 0.6403944220963389,\n",
       "    'max_depth': 14.262746162602294,\n",
       "    'reg_alpha': 1.106575796049697,\n",
       "    'reg_lambda': 0.05299410238372326,\n",
       "    'min_split_gain': 0.8006869589471239,\n",
       "    'min_child_weight': 30.86291348577351,\n",
       "    'min_child_samples': 11.026969973917566,\n",
       "    'feature_fraction': 0.8328351176992861,\n",
       "    'bagging_freq': 18.264469024631993,\n",
       "    'bagging_fraction': 0.7792272288454511},\n",
       "   {'num_leaves': 43.10675744398569,\n",
       "    'colsample_bytree': 0.34737837509340064,\n",
       "    'min_data_in_leaf': 99.606475438895,\n",
       "    'subsample': 0.7631746237380469,\n",
       "    'max_depth': 14.015353801748837,\n",
       "    'reg_alpha': 1.3208403368766652,\n",
       "    'reg_lambda': 9.679791181562152,\n",
       "    'min_split_gain': 0.1612797760637077,\n",
       "    'min_child_weight': 40.95003691419315,\n",
       "    'min_child_samples': 32.82804572997819,\n",
       "    'feature_fraction': 0.4465100070732918,\n",
       "    'bagging_freq': 18.391055056732,\n",
       "    'bagging_fraction': 0.9849652306956523},\n",
       "   {'num_leaves': 32.870702020748766,\n",
       "    'colsample_bytree': 0.9893426478350624,\n",
       "    'min_data_in_leaf': 33.819995736073565,\n",
       "    'subsample': 0.7859223288949687,\n",
       "    'max_depth': 9.199565331274453,\n",
       "    'reg_alpha': 8.526147259990628,\n",
       "    'reg_lambda': 8.541196107702511,\n",
       "    'min_split_gain': 0.5630015763986446,\n",
       "    'min_child_weight': 38.10270848911046,\n",
       "    'min_child_samples': 49.77831492374064,\n",
       "    'feature_fraction': 0.8173132807770149,\n",
       "    'bagging_freq': 19.611279038307604,\n",
       "    'bagging_fraction': 0.9668918949147556},\n",
       "   {'num_leaves': 32.33218188374647,\n",
       "    'colsample_bytree': 0.14694046072519276,\n",
       "    'min_data_in_leaf': 98.8504807270504,\n",
       "    'subsample': 0.7012378474376775,\n",
       "    'max_depth': 14.709124351548347,\n",
       "    'reg_alpha': 6.2401348267022545,\n",
       "    'reg_lambda': 0.18618379539847352,\n",
       "    'min_split_gain': 0.3124507601883538,\n",
       "    'min_child_weight': 30.82406318642045,\n",
       "    'min_child_samples': 9.296520573932707,\n",
       "    'feature_fraction': 0.8751480726336107,\n",
       "    'bagging_freq': 19.570541849042986,\n",
       "    'bagging_fraction': 0.9441750010213856},\n",
       "   {'num_leaves': 34.158770254490015,\n",
       "    'colsample_bytree': 0.2415920905330608,\n",
       "    'min_data_in_leaf': 47.41859235669605,\n",
       "    'subsample': 0.6507092880486689,\n",
       "    'max_depth': 5.010578349400832,\n",
       "    'reg_alpha': 8.839699181820322,\n",
       "    'reg_lambda': 1.6446080974208899,\n",
       "    'min_split_gain': 0.9369113130963277,\n",
       "    'min_child_weight': 39.050074933621715,\n",
       "    'min_child_samples': 14.89867617088996,\n",
       "    'feature_fraction': 0.7551110779537434,\n",
       "    'bagging_freq': 13.874250552188528,\n",
       "    'bagging_fraction': 0.9881585904285473},\n",
       "   {'num_leaves': 30.82128866278462,\n",
       "    'colsample_bytree': 0.7843008479303617,\n",
       "    'min_data_in_leaf': 10.456592784462986,\n",
       "    'subsample': 0.3541461467104864,\n",
       "    'max_depth': 9.784324463782532,\n",
       "    'reg_alpha': 3.065969369190138,\n",
       "    'reg_lambda': 2.952476201113594,\n",
       "    'min_split_gain': 0.8396255707196437,\n",
       "    'min_child_weight': 37.969025211944185,\n",
       "    'min_child_samples': 48.792717250073366,\n",
       "    'feature_fraction': 0.8827302764178999,\n",
       "    'bagging_freq': 0.08872901581131742,\n",
       "    'bagging_fraction': 0.9600534887303164},\n",
       "   {'num_leaves': 41.18905482019168,\n",
       "    'colsample_bytree': 0.13275458552938912,\n",
       "    'min_data_in_leaf': 10.821270360819724,\n",
       "    'subsample': 0.7562845673548876,\n",
       "    'max_depth': 14.530517235049992,\n",
       "    'reg_alpha': 8.780065248231857,\n",
       "    'reg_lambda': 8.918253079663796,\n",
       "    'min_split_gain': 0.12948015522116518,\n",
       "    'min_child_weight': 34.12862073863084,\n",
       "    'min_child_samples': 49.35527663132452,\n",
       "    'feature_fraction': 0.9436747136475625,\n",
       "    'bagging_freq': 0.027760046113309844,\n",
       "    'bagging_fraction': 0.6921393685675377},\n",
       "   {'num_leaves': 30.033114636456304,\n",
       "    'colsample_bytree': 0.1488108115429232,\n",
       "    'min_data_in_leaf': 98.0016908487756,\n",
       "    'subsample': 0.9295741848889649,\n",
       "    'max_depth': 11.334297597575624,\n",
       "    'reg_alpha': 8.172904129260555,\n",
       "    'reg_lambda': 9.55218970980669,\n",
       "    'min_split_gain': 0.21670147976345877,\n",
       "    'min_child_weight': 43.65108445952462,\n",
       "    'min_child_samples': 5.217837352147383,\n",
       "    'feature_fraction': 0.26779446629853865,\n",
       "    'bagging_freq': 0.8398032281835444,\n",
       "    'bagging_fraction': 0.145965291275635},\n",
       "   {'num_leaves': 40.20024481370142,\n",
       "    'colsample_bytree': 0.15864521326388856,\n",
       "    'min_data_in_leaf': 99.9468808483797,\n",
       "    'subsample': 0.9684844504968685,\n",
       "    'max_depth': 7.520174996220804,\n",
       "    'reg_alpha': 9.807296571213797,\n",
       "    'reg_lambda': 7.965745384557779,\n",
       "    'min_split_gain': 0.8911407967465671,\n",
       "    'min_child_weight': 43.64378300355199,\n",
       "    'min_child_samples': 6.260022499669484,\n",
       "    'feature_fraction': 0.8845586246167383,\n",
       "    'bagging_freq': 17.28802424016021,\n",
       "    'bagging_fraction': 0.8972625395830816},\n",
       "   {'num_leaves': 39.332222765215576,\n",
       "    'colsample_bytree': 0.1269794520646335,\n",
       "    'min_data_in_leaf': 98.78070749628584,\n",
       "    'subsample': 0.7320616107897935,\n",
       "    'max_depth': 13.693612961253232,\n",
       "    'reg_alpha': 8.944420358904958,\n",
       "    'reg_lambda': 5.724690177012327,\n",
       "    'min_split_gain': 0.5885320183786877,\n",
       "    'min_child_weight': 31.53037184643099,\n",
       "    'min_child_samples': 49.59667231773153,\n",
       "    'feature_fraction': 0.5413395601032338,\n",
       "    'bagging_freq': 3.972612108829614,\n",
       "    'bagging_fraction': 0.7986660394453805},\n",
       "   {'num_leaves': 44.91796771302461,\n",
       "    'colsample_bytree': 0.5374200742020923,\n",
       "    'min_data_in_leaf': 53.24114563056191,\n",
       "    'subsample': 0.9931666228299763,\n",
       "    'max_depth': 14.775213095385109,\n",
       "    'reg_alpha': 4.793105958886565,\n",
       "    'reg_lambda': 0.13806808895536649,\n",
       "    'min_split_gain': 0.7719579969148591,\n",
       "    'min_child_weight': 44.427964452509045,\n",
       "    'min_child_samples': 5.376532716480828,\n",
       "    'feature_fraction': 0.9462400089286498,\n",
       "    'bagging_freq': 19.058716163613603,\n",
       "    'bagging_fraction': 0.9529900208531357},\n",
       "   {'num_leaves': 44.224868220313155,\n",
       "    'colsample_bytree': 0.47566042032361,\n",
       "    'min_data_in_leaf': 98.57501972820752,\n",
       "    'subsample': 0.9935858544980087,\n",
       "    'max_depth': 5.331069529340871,\n",
       "    'reg_alpha': 9.708996331146164,\n",
       "    'reg_lambda': 9.791667238823052,\n",
       "    'min_split_gain': 0.15549960746698122,\n",
       "    'min_child_weight': 32.6642128360575,\n",
       "    'min_child_samples': 44.2495300984328,\n",
       "    'feature_fraction': 0.8569808395932934,\n",
       "    'bagging_freq': 19.474272050132157,\n",
       "    'bagging_fraction': 0.8655841082038478},\n",
       "   {'num_leaves': 44.24328337957363,\n",
       "    'colsample_bytree': 0.7877594493179544,\n",
       "    'min_data_in_leaf': 30.502801246815476,\n",
       "    'subsample': 0.11018159148710535,\n",
       "    'max_depth': 13.50263456845495,\n",
       "    'reg_alpha': 0.9390513603110762,\n",
       "    'reg_lambda': 0.278871098040292,\n",
       "    'min_split_gain': 0.9655560526275935,\n",
       "    'min_child_weight': 44.14414875630408,\n",
       "    'min_child_samples': 49.75320771710763,\n",
       "    'feature_fraction': 0.7005482606404966,\n",
       "    'bagging_freq': 16.473137171567725,\n",
       "    'bagging_fraction': 0.9644328880449494},\n",
       "   {'num_leaves': 30.0893208558703,\n",
       "    'colsample_bytree': 0.448433305291537,\n",
       "    'min_data_in_leaf': 89.0875076748507,\n",
       "    'subsample': 0.934568925191856,\n",
       "    'max_depth': 14.511815796708659,\n",
       "    'reg_alpha': 0.2612709114548917,\n",
       "    'reg_lambda': 1.6526373783681003,\n",
       "    'min_split_gain': 0.7639314391097217,\n",
       "    'min_child_weight': 37.13017244997577,\n",
       "    'min_child_samples': 35.97058232769413,\n",
       "    'feature_fraction': 0.7962458947607144,\n",
       "    'bagging_freq': 12.94326081954728,\n",
       "    'bagging_fraction': 0.9869885351434498},\n",
       "   {'num_leaves': 38.388388395983384,\n",
       "    'colsample_bytree': 0.3614353598846488,\n",
       "    'min_data_in_leaf': 12.7724956133825,\n",
       "    'subsample': 0.38843639799276564,\n",
       "    'max_depth': 6.189850601142616,\n",
       "    'reg_alpha': 0.9436444767692542,\n",
       "    'reg_lambda': 0.37090814685776907,\n",
       "    'min_split_gain': 0.0005888899058528185,\n",
       "    'min_child_weight': 42.27140439623024,\n",
       "    'min_child_samples': 7.014702455740176,\n",
       "    'feature_fraction': 0.5957183617517727,\n",
       "    'bagging_freq': 0.8114673122682126,\n",
       "    'bagging_fraction': 0.8443148941134415},\n",
       "   {'num_leaves': 40.86087389996849,\n",
       "    'colsample_bytree': 0.20140935437834026,\n",
       "    'min_data_in_leaf': 55.01192147648458,\n",
       "    'subsample': 0.9088242996778916,\n",
       "    'max_depth': 14.843447197301124,\n",
       "    'reg_alpha': 0.009398428209728138,\n",
       "    'reg_lambda': 9.784784852440717,\n",
       "    'min_split_gain': 0.07729060082586015,\n",
       "    'min_child_weight': 38.76421650743638,\n",
       "    'min_child_samples': 11.872752018426432,\n",
       "    'feature_fraction': 0.8380551448895476,\n",
       "    'bagging_freq': 3.5912479749756154,\n",
       "    'bagging_fraction': 0.9830646517879905},\n",
       "   {'num_leaves': 37.55106097181441,\n",
       "    'colsample_bytree': 0.21483060641004156,\n",
       "    'min_data_in_leaf': 11.695883775326454,\n",
       "    'subsample': 0.8970294502086763,\n",
       "    'max_depth': 9.615772085622801,\n",
       "    'reg_alpha': 7.356266369773011,\n",
       "    'reg_lambda': 0.09638189431268596,\n",
       "    'min_split_gain': 0.9779948421832692,\n",
       "    'min_child_weight': 44.97754347542015,\n",
       "    'min_child_samples': 46.05110779840404,\n",
       "    'feature_fraction': 0.9351529843773371,\n",
       "    'bagging_freq': 18.93855955318788,\n",
       "    'bagging_fraction': 0.5118328141907414},\n",
       "   {'num_leaves': 43.26859060628306,\n",
       "    'colsample_bytree': 0.13098865259980727,\n",
       "    'min_data_in_leaf': 75.61635367703812,\n",
       "    'subsample': 0.821355350513739,\n",
       "    'max_depth': 14.239898361113429,\n",
       "    'reg_alpha': 9.436673607448292,\n",
       "    'reg_lambda': 0.1478725526770508,\n",
       "    'min_split_gain': 0.36379726555058,\n",
       "    'min_child_weight': 42.523425341239495,\n",
       "    'min_child_samples': 49.66585202387825,\n",
       "    'feature_fraction': 0.34162361498702304,\n",
       "    'bagging_freq': 3.778197059484374,\n",
       "    'bagging_fraction': 0.8837978663766897},\n",
       "   {'num_leaves': 34.756699921590716,\n",
       "    'colsample_bytree': 0.12207140009656199,\n",
       "    'min_data_in_leaf': 98.89966310550535,\n",
       "    'subsample': 0.8069846134933103,\n",
       "    'max_depth': 6.3394284601201,\n",
       "    'reg_alpha': 6.795212608451163,\n",
       "    'reg_lambda': 1.5773263700445284,\n",
       "    'min_split_gain': 0.9473595706021246,\n",
       "    'min_child_weight': 38.52606643709138,\n",
       "    'min_child_samples': 48.87275237389182,\n",
       "    'feature_fraction': 0.945196178675325,\n",
       "    'bagging_freq': 10.19115918280389,\n",
       "    'bagging_fraction': 0.9491071074758426},\n",
       "   {'num_leaves': 41.64572978965851,\n",
       "    'colsample_bytree': 0.7592091035055213,\n",
       "    'min_data_in_leaf': 29.36459141201398,\n",
       "    'subsample': 0.6720053201137944,\n",
       "    'max_depth': 7.344316841162587,\n",
       "    'reg_alpha': 0.02350571054167916,\n",
       "    'reg_lambda': 9.220498973979216,\n",
       "    'min_split_gain': 0.7563572251452084,\n",
       "    'min_child_weight': 36.697637754773545,\n",
       "    'min_child_samples': 48.87828011413639,\n",
       "    'feature_fraction': 0.8394705343559351,\n",
       "    'bagging_freq': 19.97340124682712,\n",
       "    'bagging_fraction': 0.8765377290117202},\n",
       "   {'num_leaves': 34.69871680389586,\n",
       "    'colsample_bytree': 0.31209797616177726,\n",
       "    'min_data_in_leaf': 58.68963097096849,\n",
       "    'subsample': 0.16167551159663074,\n",
       "    'max_depth': 5.108654509339275,\n",
       "    'reg_alpha': 0.16491585727261615,\n",
       "    'reg_lambda': 6.736419818885125,\n",
       "    'min_split_gain': 0.7114765978389905,\n",
       "    'min_child_weight': 30.22684851028031,\n",
       "    'min_child_samples': 5.558379295412537,\n",
       "    'feature_fraction': 0.9159375177355263,\n",
       "    'bagging_freq': 19.848478878150427,\n",
       "    'bagging_fraction': 0.8831572499977555},\n",
       "   {'num_leaves': 44.68180829692393,\n",
       "    'colsample_bytree': 0.6945782276560809,\n",
       "    'min_data_in_leaf': 96.5747213413293,\n",
       "    'subsample': 0.588157543898956,\n",
       "    'max_depth': 14.904573950567523,\n",
       "    'reg_alpha': 5.410814227964938,\n",
       "    'reg_lambda': 1.464400841784227,\n",
       "    'min_split_gain': 0.05314258279799744,\n",
       "    'min_child_weight': 30.753506136529797,\n",
       "    'min_child_samples': 39.043587711766136,\n",
       "    'feature_fraction': 0.19081472691804305,\n",
       "    'bagging_freq': 1.5228099402935658,\n",
       "    'bagging_fraction': 0.8265286996999891},\n",
       "   {'num_leaves': 33.20317654502635,\n",
       "    'colsample_bytree': 0.36313865876409657,\n",
       "    'min_data_in_leaf': 99.1767034320778,\n",
       "    'subsample': 0.17503717721366724,\n",
       "    'max_depth': 14.370188755065518,\n",
       "    'reg_alpha': 3.346735501285708,\n",
       "    'reg_lambda': 9.863086944542278,\n",
       "    'min_split_gain': 0.806506309256663,\n",
       "    'min_child_weight': 30.065917907763964,\n",
       "    'min_child_samples': 26.91329437801303,\n",
       "    'feature_fraction': 0.8763250111590793,\n",
       "    'bagging_freq': 16.239815497661123,\n",
       "    'bagging_fraction': 0.8660101429374436},\n",
       "   {'num_leaves': 33.807386694624455,\n",
       "    'colsample_bytree': 0.5217194647036646,\n",
       "    'min_data_in_leaf': 48.02887606016989,\n",
       "    'subsample': 0.9051018828029649,\n",
       "    'max_depth': 13.271376713509724,\n",
       "    'reg_alpha': 4.914678289203987,\n",
       "    'reg_lambda': 1.9670880217658193,\n",
       "    'min_split_gain': 0.6321610276459664,\n",
       "    'min_child_weight': 44.71699755395207,\n",
       "    'min_child_samples': 48.652644830995065,\n",
       "    'feature_fraction': 0.5282615975996277,\n",
       "    'bagging_freq': 18.073336233446895,\n",
       "    'bagging_fraction': 0.9251909447356158},\n",
       "   {'num_leaves': 44.405208988895566,\n",
       "    'colsample_bytree': 0.5147771430071186,\n",
       "    'min_data_in_leaf': 10.86150495929861,\n",
       "    'subsample': 0.419523447689494,\n",
       "    'max_depth': 5.101747472288497,\n",
       "    'reg_alpha': 6.8873922852249745,\n",
       "    'reg_lambda': 9.222685126376506,\n",
       "    'min_split_gain': 0.0034898927198805385,\n",
       "    'min_child_weight': 43.16110539829452,\n",
       "    'min_child_samples': 5.042180841029607,\n",
       "    'feature_fraction': 0.3767828760744536,\n",
       "    'bagging_freq': 1.0523037845933603,\n",
       "    'bagging_fraction': 0.9165772516578925},\n",
       "   {'num_leaves': 42.52295294354966,\n",
       "    'colsample_bytree': 0.4729722644131258,\n",
       "    'min_data_in_leaf': 10.557665493988388,\n",
       "    'subsample': 0.9177209809036259,\n",
       "    'max_depth': 14.858712585033276,\n",
       "    'reg_alpha': 5.181809350621122,\n",
       "    'reg_lambda': 0.23375727622001574,\n",
       "    'min_split_gain': 0.9761231691911532,\n",
       "    'min_child_weight': 39.15498831879736,\n",
       "    'min_child_samples': 5.138810045461053,\n",
       "    'feature_fraction': 0.7210321140893649,\n",
       "    'bagging_freq': 5.00263824987472,\n",
       "    'bagging_fraction': 0.9626220201446466},\n",
       "   {'num_leaves': 38.6293253853782,\n",
       "    'colsample_bytree': 0.1141927333099644,\n",
       "    'min_data_in_leaf': 99.36367868279004,\n",
       "    'subsample': 0.6026280924048876,\n",
       "    'max_depth': 14.835929446922599,\n",
       "    'reg_alpha': 5.61947587629477,\n",
       "    'reg_lambda': 8.253198936397153,\n",
       "    'min_split_gain': 0.43091084224006193,\n",
       "    'min_child_weight': 44.96643473068354,\n",
       "    'min_child_samples': 13.159982184292291,\n",
       "    'feature_fraction': 0.8692466312696352,\n",
       "    'bagging_freq': 1.3933985766386203,\n",
       "    'bagging_fraction': 0.9777087042812305},\n",
       "   {'num_leaves': 44.49148516844067,\n",
       "    'colsample_bytree': 0.2857134000748047,\n",
       "    'min_data_in_leaf': 10.260266561880263,\n",
       "    'subsample': 0.3085724903907964,\n",
       "    'max_depth': 5.157179462169552,\n",
       "    'reg_alpha': 6.283547130309256,\n",
       "    'reg_lambda': 9.41789297605295,\n",
       "    'min_split_gain': 0.8745958980207005,\n",
       "    'min_child_weight': 44.01025902128689,\n",
       "    'min_child_samples': 49.17204170278415,\n",
       "    'feature_fraction': 0.15183801309430747,\n",
       "    'bagging_freq': 2.7970118263453214,\n",
       "    'bagging_fraction': 0.9110229465570402},\n",
       "   {'num_leaves': 31.823689477753874,\n",
       "    'colsample_bytree': 0.16137010729800977,\n",
       "    'min_data_in_leaf': 10.453072516770089,\n",
       "    'subsample': 0.5251386693082826,\n",
       "    'max_depth': 14.751473738363922,\n",
       "    'reg_alpha': 0.24066531926936974,\n",
       "    'reg_lambda': 9.796109440311984,\n",
       "    'min_split_gain': 0.43469510272323875,\n",
       "    'min_child_weight': 30.19281228549879,\n",
       "    'min_child_samples': 19.49769855711444,\n",
       "    'feature_fraction': 0.442577153595917,\n",
       "    'bagging_freq': 0.2993081444635015,\n",
       "    'bagging_fraction': 0.919318983733491},\n",
       "   {'num_leaves': 32.3310012277121,\n",
       "    'colsample_bytree': 0.3116291359010458,\n",
       "    'min_data_in_leaf': 99.58146936817909,\n",
       "    'subsample': 0.8062149377638007,\n",
       "    'max_depth': 12.685426052663917,\n",
       "    'reg_alpha': 6.620978307390524,\n",
       "    'reg_lambda': 9.54154162949116,\n",
       "    'min_split_gain': 0.27104744586215557,\n",
       "    'min_child_weight': 41.854291319476715,\n",
       "    'min_child_samples': 49.897102897609315,\n",
       "    'feature_fraction': 0.3319146423910995,\n",
       "    'bagging_freq': 1.7723179445808412,\n",
       "    'bagging_fraction': 0.7686697137120547},\n",
       "   {'num_leaves': 43.19144797301847,\n",
       "    'colsample_bytree': 0.9228236451367797,\n",
       "    'min_data_in_leaf': 11.806525329583925,\n",
       "    'subsample': 0.20427175264554515,\n",
       "    'max_depth': 5.802846734635796,\n",
       "    'reg_alpha': 7.674795386298882,\n",
       "    'reg_lambda': 1.760643157585653,\n",
       "    'min_split_gain': 0.9467225122335589,\n",
       "    'min_child_weight': 31.0306758872507,\n",
       "    'min_child_samples': 6.236067489170676,\n",
       "    'feature_fraction': 0.5515515674408188,\n",
       "    'bagging_freq': 19.038924391697954,\n",
       "    'bagging_fraction': 0.8318546710711922},\n",
       "   {'num_leaves': 32.715298187118144,\n",
       "    'colsample_bytree': 0.9210233316840564,\n",
       "    'min_data_in_leaf': 11.537376362680169,\n",
       "    'subsample': 0.2179230518037233,\n",
       "    'max_depth': 6.769768873108639,\n",
       "    'reg_alpha': 1.1549434072278297,\n",
       "    'reg_lambda': 9.001938130429854,\n",
       "    'min_split_gain': 0.7082141444910997,\n",
       "    'min_child_weight': 41.50052171341108,\n",
       "    'min_child_samples': 49.6760390663266,\n",
       "    'feature_fraction': 0.16998909120137431,\n",
       "    'bagging_freq': 19.967046074683303,\n",
       "    'bagging_fraction': 0.9852982807788245},\n",
       "   {'num_leaves': 30.16993978323773,\n",
       "    'colsample_bytree': 0.5871824692506076,\n",
       "    'min_data_in_leaf': 10.521170673681313,\n",
       "    'subsample': 0.8757506190391466,\n",
       "    'max_depth': 11.112762882411023,\n",
       "    'reg_alpha': 2.770062357959179,\n",
       "    'reg_lambda': 0.38857321838466574,\n",
       "    'min_split_gain': 0.549759303629901,\n",
       "    'min_child_weight': 31.24845761823491,\n",
       "    'min_child_samples': 5.199391498426667,\n",
       "    'feature_fraction': 0.4482800820580628,\n",
       "    'bagging_freq': 17.982066650443937,\n",
       "    'bagging_fraction': 0.7005921697147127},\n",
       "   {'num_leaves': 30.856694695340618,\n",
       "    'colsample_bytree': 0.7459619451286474,\n",
       "    'min_data_in_leaf': 10.052870835510383,\n",
       "    'subsample': 0.280438767883174,\n",
       "    'max_depth': 13.825923468965538,\n",
       "    'reg_alpha': 5.662548690463644,\n",
       "    'reg_lambda': 9.603928092296908,\n",
       "    'min_split_gain': 0.7451935108320797,\n",
       "    'min_child_weight': 35.94635061470582,\n",
       "    'min_child_samples': 49.94413499240968,\n",
       "    'feature_fraction': 0.8821779638660371,\n",
       "    'bagging_freq': 6.0649481183401965,\n",
       "    'bagging_fraction': 0.6651149832971209},\n",
       "   {'num_leaves': 37.96896562012008,\n",
       "    'colsample_bytree': 0.6983540987121741,\n",
       "    'min_data_in_leaf': 15.99493344001733,\n",
       "    'subsample': 0.9164292654900463,\n",
       "    'max_depth': 5.005454436044171,\n",
       "    'reg_alpha': 0.024896969444728745,\n",
       "    'reg_lambda': 8.701311644300082,\n",
       "    'min_split_gain': 0.8455877572342577,\n",
       "    'min_child_weight': 31.25867305755992,\n",
       "    'min_child_samples': 24.952948202072008,\n",
       "    'feature_fraction': 0.4952420010122671,\n",
       "    'bagging_freq': 0.5325425238671211,\n",
       "    'bagging_fraction': 0.9481332772300577},\n",
       "   {'num_leaves': 33.75666875369966,\n",
       "    'colsample_bytree': 0.9487665577702247,\n",
       "    'min_data_in_leaf': 99.57203804373107,\n",
       "    'subsample': 0.9249134183896071,\n",
       "    'max_depth': 9.772259169612244,\n",
       "    'reg_alpha': 4.27124810570163,\n",
       "    'reg_lambda': 9.968091139039558,\n",
       "    'min_split_gain': 0.13081300343962554,\n",
       "    'min_child_weight': 32.764114254518134,\n",
       "    'min_child_samples': 6.495607087283611,\n",
       "    'feature_fraction': 0.44004005856079653,\n",
       "    'bagging_freq': 2.846121545146736,\n",
       "    'bagging_fraction': 0.907936844347967},\n",
       "   {'num_leaves': 33.94067244401424,\n",
       "    'colsample_bytree': 0.9650335980080292,\n",
       "    'min_data_in_leaf': 33.12899832149576,\n",
       "    'subsample': 0.9494246480002826,\n",
       "    'max_depth': 14.479951597555194,\n",
       "    'reg_alpha': 2.9013714272628564,\n",
       "    'reg_lambda': 9.915696094251745,\n",
       "    'min_split_gain': 0.9512153033138331,\n",
       "    'min_child_weight': 44.281717609513215,\n",
       "    'min_child_samples': 46.38098556250218,\n",
       "    'feature_fraction': 0.6245420018606054,\n",
       "    'bagging_freq': 0.6669793412962566,\n",
       "    'bagging_fraction': 0.9501682072340393},\n",
       "   {'num_leaves': 33.28490036847393,\n",
       "    'colsample_bytree': 0.6540447272991085,\n",
       "    'min_data_in_leaf': 58.51258225024919,\n",
       "    'subsample': 0.9942308352289467,\n",
       "    'max_depth': 14.558110908437795,\n",
       "    'reg_alpha': 9.509946811084351,\n",
       "    'reg_lambda': 8.300241305337824,\n",
       "    'min_split_gain': 0.9507660497509353,\n",
       "    'min_child_weight': 31.092280808872804,\n",
       "    'min_child_samples': 25.27287830398331,\n",
       "    'feature_fraction': 0.7352194815648297,\n",
       "    'bagging_freq': 2.4861204759276356,\n",
       "    'bagging_fraction': 0.9435488471580658},\n",
       "   {'num_leaves': 44.37499079708034,\n",
       "    'colsample_bytree': 0.2718416694855105,\n",
       "    'min_data_in_leaf': 97.81581552309804,\n",
       "    'subsample': 0.8541731423621648,\n",
       "    'max_depth': 6.183499373560148,\n",
       "    'reg_alpha': 6.744134080279094,\n",
       "    'reg_lambda': 1.5847321628810607,\n",
       "    'min_split_gain': 0.7632072137485137,\n",
       "    'min_child_weight': 30.91104528793058,\n",
       "    'min_child_samples': 7.155899840028679,\n",
       "    'feature_fraction': 0.48042252504646166,\n",
       "    'bagging_freq': 19.583277581047994,\n",
       "    'bagging_fraction': 0.8232442852865428},\n",
       "   {'num_leaves': 30.37291195012973,\n",
       "    'colsample_bytree': 0.21555419789470665,\n",
       "    'min_data_in_leaf': 62.62547484786698,\n",
       "    'subsample': 0.6273287627757048,\n",
       "    'max_depth': 13.620773745168176,\n",
       "    'reg_alpha': 2.8599948014415255,\n",
       "    'reg_lambda': 0.43610974135304015,\n",
       "    'min_split_gain': 0.38564184032619186,\n",
       "    'min_child_weight': 30.147812283279524,\n",
       "    'min_child_samples': 6.7549572613360835,\n",
       "    'feature_fraction': 0.8599198597157255,\n",
       "    'bagging_freq': 19.90991836291052,\n",
       "    'bagging_fraction': 0.8072386551302931},\n",
       "   {'num_leaves': 30.866699600097924,\n",
       "    'colsample_bytree': 0.48702479584867253,\n",
       "    'min_data_in_leaf': 23.18543278011397,\n",
       "    'subsample': 0.10010456824799685,\n",
       "    'max_depth': 5.488162611745318,\n",
       "    'reg_alpha': 2.920526740324283,\n",
       "    'reg_lambda': 0.5393877432040717,\n",
       "    'min_split_gain': 0.18653242818482685,\n",
       "    'min_child_weight': 30.155427154360403,\n",
       "    'min_child_samples': 6.236154390135635,\n",
       "    'feature_fraction': 0.5986809206860687,\n",
       "    'bagging_freq': 18.784090222168533,\n",
       "    'bagging_fraction': 0.9881162910203848},\n",
       "   {'num_leaves': 33.021773675517615,\n",
       "    'colsample_bytree': 0.6514978854216357,\n",
       "    'min_data_in_leaf': 43.942047168023535,\n",
       "    'subsample': 0.7512186461616861,\n",
       "    'max_depth': 13.939973238002581,\n",
       "    'reg_alpha': 1.0898543532033877,\n",
       "    'reg_lambda': 6.81070930516791,\n",
       "    'min_split_gain': 0.21230614887180133,\n",
       "    'min_child_weight': 37.557711731983375,\n",
       "    'min_child_samples': 5.810911436515961,\n",
       "    'feature_fraction': 0.5219630809354019,\n",
       "    'bagging_freq': 18.80976499854677,\n",
       "    'bagging_fraction': 0.9234875056104017},\n",
       "   {'num_leaves': 41.73948899373256,\n",
       "    'colsample_bytree': 0.46563272696145475,\n",
       "    'min_data_in_leaf': 10.311467105066885,\n",
       "    'subsample': 0.7978385134063808,\n",
       "    'max_depth': 5.591480191030746,\n",
       "    'reg_alpha': 0.24258163111460118,\n",
       "    'reg_lambda': 3.218859877713751,\n",
       "    'min_split_gain': 0.15472628162346524,\n",
       "    'min_child_weight': 31.14636382737047,\n",
       "    'min_child_samples': 5.037121171315359,\n",
       "    'feature_fraction': 0.9135579004126804,\n",
       "    'bagging_freq': 19.95903132146188,\n",
       "    'bagging_fraction': 0.7013364525454561},\n",
       "   {'num_leaves': 32.081586440043885,\n",
       "    'colsample_bytree': 0.9734063065279552,\n",
       "    'min_data_in_leaf': 14.491464363610909,\n",
       "    'subsample': 0.396297340263316,\n",
       "    'max_depth': 14.555543313851901,\n",
       "    'reg_alpha': 9.604259872844484,\n",
       "    'reg_lambda': 8.764585243797187,\n",
       "    'min_split_gain': 0.6528628583825393,\n",
       "    'min_child_weight': 30.76037861111148,\n",
       "    'min_child_samples': 8.602916255820446,\n",
       "    'feature_fraction': 0.8174060956353356,\n",
       "    'bagging_freq': 0.33190883002986116,\n",
       "    'bagging_fraction': 0.8209669841683683},\n",
       "   {'num_leaves': 30.66833356200549,\n",
       "    'colsample_bytree': 0.2626210298809042,\n",
       "    'min_data_in_leaf': 99.64740632515625,\n",
       "    'subsample': 0.9300299567317766,\n",
       "    'max_depth': 12.928934542767792,\n",
       "    'reg_alpha': 7.911156907508637,\n",
       "    'reg_lambda': 4.082774890302394,\n",
       "    'min_split_gain': 0.24689906119678995,\n",
       "    'min_child_weight': 43.38557702829692,\n",
       "    'min_child_samples': 5.347557953087737,\n",
       "    'feature_fraction': 0.15700764707667214,\n",
       "    'bagging_freq': 1.2026870970376824,\n",
       "    'bagging_fraction': 0.8284623255718788},\n",
       "   {'num_leaves': 39.599620096664864,\n",
       "    'colsample_bytree': 0.3988821931156231,\n",
       "    'min_data_in_leaf': 87.36693368951443,\n",
       "    'subsample': 0.9156618977730132,\n",
       "    'max_depth': 14.478429478686609,\n",
       "    'reg_alpha': 4.322056306918625,\n",
       "    'reg_lambda': 0.5707905815970549,\n",
       "    'min_split_gain': 0.22631869107056724,\n",
       "    'min_child_weight': 43.57533858669637,\n",
       "    'min_child_samples': 27.77426138288066,\n",
       "    'feature_fraction': 0.8701416292876752,\n",
       "    'bagging_freq': 8.225862162894302,\n",
       "    'bagging_fraction': 0.9613075214243154},\n",
       "   {'num_leaves': 44.66833581215061,\n",
       "    'colsample_bytree': 0.3484539690920905,\n",
       "    'min_data_in_leaf': 99.98603697088429,\n",
       "    'subsample': 0.898794384312563,\n",
       "    'max_depth': 13.846666116882629,\n",
       "    'reg_alpha': 3.357372736362173,\n",
       "    'reg_lambda': 8.14296189579261,\n",
       "    'min_split_gain': 0.8779295687838029,\n",
       "    'min_child_weight': 44.0344995971608,\n",
       "    'min_child_samples': 9.342926128996506,\n",
       "    'feature_fraction': 0.12312728839667315,\n",
       "    'bagging_freq': 9.961044669706563,\n",
       "    'bagging_fraction': 0.216659740400956},\n",
       "   {'num_leaves': 30.503604010037684,\n",
       "    'colsample_bytree': 0.9568476937766385,\n",
       "    'min_data_in_leaf': 73.70024651022496,\n",
       "    'subsample': 0.19056403228353513,\n",
       "    'max_depth': 14.953898956125585,\n",
       "    'reg_alpha': 6.072777658781674,\n",
       "    'reg_lambda': 7.949314298481237,\n",
       "    'min_split_gain': 0.08810565695246753,\n",
       "    'min_child_weight': 43.80529239775696,\n",
       "    'min_child_samples': 7.790718928975345,\n",
       "    'feature_fraction': 0.8633156120790864,\n",
       "    'bagging_freq': 17.892161899862277,\n",
       "    'bagging_fraction': 0.9159619653011649},\n",
       "   {'num_leaves': 33.613539682471526,\n",
       "    'colsample_bytree': 0.8722836115847488,\n",
       "    'min_data_in_leaf': 96.44272631552404,\n",
       "    'subsample': 0.4810566505629801,\n",
       "    'max_depth': 12.284022840579425,\n",
       "    'reg_alpha': 2.0859252188758237,\n",
       "    'reg_lambda': 8.561875315550441,\n",
       "    'min_split_gain': 0.6643529443578553,\n",
       "    'min_child_weight': 43.947521216587454,\n",
       "    'min_child_samples': 30.710661127295147,\n",
       "    'feature_fraction': 0.8708401440725179,\n",
       "    'bagging_freq': 0.11612986722986385,\n",
       "    'bagging_fraction': 0.783717235145438},\n",
       "   {'num_leaves': 33.58479236133961,\n",
       "    'colsample_bytree': 0.23091587640285763,\n",
       "    'min_data_in_leaf': 95.89786480002262,\n",
       "    'subsample': 0.8882308692582952,\n",
       "    'max_depth': 14.768168159400002,\n",
       "    'reg_alpha': 2.8890691767492918,\n",
       "    'reg_lambda': 0.6783769603568179,\n",
       "    'min_split_gain': 0.7327834328369083,\n",
       "    'min_child_weight': 31.48770364528983,\n",
       "    'min_child_samples': 48.198739243758524,\n",
       "    'feature_fraction': 0.7625059337958572,\n",
       "    'bagging_freq': 0.5476517917110413,\n",
       "    'bagging_fraction': 0.917486063699548},\n",
       "   {'num_leaves': 30.148454348413864,\n",
       "    'colsample_bytree': 0.4843911777476727,\n",
       "    'min_data_in_leaf': 10.196473747004621,\n",
       "    'subsample': 0.7801559385929139,\n",
       "    'max_depth': 5.209036301228105,\n",
       "    'reg_alpha': 7.716706831132098,\n",
       "    'reg_lambda': 7.8113196081269205,\n",
       "    'min_split_gain': 0.11185260967431765,\n",
       "    'min_child_weight': 30.955303132269243,\n",
       "    'min_child_samples': 5.297493606650286,\n",
       "    'feature_fraction': 0.5682320735283353,\n",
       "    'bagging_freq': 18.98165674310566,\n",
       "    'bagging_fraction': 0.3617143219730485},\n",
       "   {'num_leaves': 41.52089280904817,\n",
       "    'colsample_bytree': 0.24034698128861953,\n",
       "    'min_data_in_leaf': 63.61732979911937,\n",
       "    'subsample': 0.946273995863973,\n",
       "    'max_depth': 13.652363242963872,\n",
       "    'reg_alpha': 9.178137787108689,\n",
       "    'reg_lambda': 5.787981566082172,\n",
       "    'min_split_gain': 0.04673325367063119,\n",
       "    'min_child_weight': 32.547517663256336,\n",
       "    'min_child_samples': 6.197842311744936,\n",
       "    'feature_fraction': 0.9038380743540091,\n",
       "    'bagging_freq': 19.476861870799954,\n",
       "    'bagging_fraction': 0.8733870809776244},\n",
       "   {'num_leaves': 44.930523321045214,\n",
       "    'colsample_bytree': 0.6935493488170683,\n",
       "    'min_data_in_leaf': 59.76694601540201,\n",
       "    'subsample': 0.7429658079131216,\n",
       "    'max_depth': 7.496549737764956,\n",
       "    'reg_alpha': 9.070935205655655,\n",
       "    'reg_lambda': 0.4644676183770535,\n",
       "    'min_split_gain': 0.5949482860905904,\n",
       "    'min_child_weight': 44.05562638085144,\n",
       "    'min_child_samples': 48.96361098312495,\n",
       "    'feature_fraction': 0.1312073641016595,\n",
       "    'bagging_freq': 2.4312052199007472,\n",
       "    'bagging_fraction': 0.8425045073525615},\n",
       "   {'num_leaves': 44.40644929436652,\n",
       "    'colsample_bytree': 0.6093434265893853,\n",
       "    'min_data_in_leaf': 99.75137705528566,\n",
       "    'subsample': 0.9178434455749865,\n",
       "    'max_depth': 13.055024984751004,\n",
       "    'reg_alpha': 4.058978408156224,\n",
       "    'reg_lambda': 9.608951745522049,\n",
       "    'min_split_gain': 0.36126791333302843,\n",
       "    'min_child_weight': 44.26092997064043,\n",
       "    'min_child_samples': 47.42826660220748,\n",
       "    'feature_fraction': 0.7905811741969612,\n",
       "    'bagging_freq': 6.538869204890323,\n",
       "    'bagging_fraction': 0.9751567159170257},\n",
       "   {'num_leaves': 34.31284040743265,\n",
       "    'colsample_bytree': 0.1724244255962195,\n",
       "    'min_data_in_leaf': 94.82503530302145,\n",
       "    'subsample': 0.5820891208830821,\n",
       "    'max_depth': 11.36008912399397,\n",
       "    'reg_alpha': 7.443769399738189,\n",
       "    'reg_lambda': 9.846957053120736,\n",
       "    'min_split_gain': 0.23793404450080202,\n",
       "    'min_child_weight': 44.189508550295855,\n",
       "    'min_child_samples': 17.194311119392033,\n",
       "    'feature_fraction': 0.8842779886549511,\n",
       "    'bagging_freq': 19.890274946551322,\n",
       "    'bagging_fraction': 0.8453205588861933},\n",
       "   {'num_leaves': 33.1893017140462,\n",
       "    'colsample_bytree': 0.877817791793743,\n",
       "    'min_data_in_leaf': 99.98763137268895,\n",
       "    'subsample': 0.3526076039656525,\n",
       "    'max_depth': 7.92774876753834,\n",
       "    'reg_alpha': 9.62627441049675,\n",
       "    'reg_lambda': 9.630709165240473,\n",
       "    'min_split_gain': 0.3106183667338437,\n",
       "    'min_child_weight': 35.44319654184548,\n",
       "    'min_child_samples': 6.165236261069412,\n",
       "    'feature_fraction': 0.9382262376021197,\n",
       "    'bagging_freq': 13.563723223214279,\n",
       "    'bagging_fraction': 0.9281484322875865},\n",
       "   {'num_leaves': 41.096538675383485,\n",
       "    'colsample_bytree': 0.8278672705139122,\n",
       "    'min_data_in_leaf': 99.74026989799162,\n",
       "    'subsample': 0.9064564406292843,\n",
       "    'max_depth': 8.885172185763789,\n",
       "    'reg_alpha': 7.1815764564496245,\n",
       "    'reg_lambda': 2.1124390226308556,\n",
       "    'min_split_gain': 0.36268619209830755,\n",
       "    'min_child_weight': 44.174764214369674,\n",
       "    'min_child_samples': 33.12716584289151,\n",
       "    'feature_fraction': 0.8050703103873165,\n",
       "    'bagging_freq': 19.97758030857557,\n",
       "    'bagging_fraction': 0.9286291046756682},\n",
       "   {'num_leaves': 33.87760056317484,\n",
       "    'colsample_bytree': 0.18043465919073765,\n",
       "    'min_data_in_leaf': 31.978504487901972,\n",
       "    'subsample': 0.9872696536670685,\n",
       "    'max_depth': 9.20202991757761,\n",
       "    'reg_alpha': 0.11161881053097455,\n",
       "    'reg_lambda': 9.424791620130973,\n",
       "    'min_split_gain': 0.294951766796683,\n",
       "    'min_child_weight': 43.55219616283882,\n",
       "    'min_child_samples': 6.586107436604826,\n",
       "    'feature_fraction': 0.8920650875732025,\n",
       "    'bagging_freq': 0.6354348541534494,\n",
       "    'bagging_fraction': 0.7846880065157122},\n",
       "   {'num_leaves': 39.65201259655589,\n",
       "    'colsample_bytree': 0.11549281408115207,\n",
       "    'min_data_in_leaf': 92.22908598052317,\n",
       "    'subsample': 0.4055647998604288,\n",
       "    'max_depth': 13.47433930663534,\n",
       "    'reg_alpha': 8.014074426031527,\n",
       "    'reg_lambda': 2.495666271900646,\n",
       "    'min_split_gain': 0.12866856591428988,\n",
       "    'min_child_weight': 31.536112031594715,\n",
       "    'min_child_samples': 17.350040519084253,\n",
       "    'feature_fraction': 0.8903767074006464,\n",
       "    'bagging_freq': 19.595413391591315,\n",
       "    'bagging_fraction': 0.8099484393404639},\n",
       "   {'num_leaves': 31.396483820068433,\n",
       "    'colsample_bytree': 0.2617288405423467,\n",
       "    'min_data_in_leaf': 12.796602148438293,\n",
       "    'subsample': 0.15171875938214166,\n",
       "    'max_depth': 6.425273928797669,\n",
       "    'reg_alpha': 8.711871281851586,\n",
       "    'reg_lambda': 0.3801865991414388,\n",
       "    'min_split_gain': 0.5166074635719018,\n",
       "    'min_child_weight': 42.03735318021062,\n",
       "    'min_child_samples': 6.1887053950272035,\n",
       "    'feature_fraction': 0.9068068433130093,\n",
       "    'bagging_freq': 19.468954543264996,\n",
       "    'bagging_fraction': 0.9478218258977151},\n",
       "   {'num_leaves': 40.15982700372195,\n",
       "    'colsample_bytree': 0.1803085053016073,\n",
       "    'min_data_in_leaf': 99.45231456082001,\n",
       "    'subsample': 0.8731650301812868,\n",
       "    'max_depth': 5.6312107112357275,\n",
       "    'reg_alpha': 0.7498380429731466,\n",
       "    'reg_lambda': 1.642440356802517,\n",
       "    'min_split_gain': 0.5456103877402574,\n",
       "    'min_child_weight': 30.91380613383902,\n",
       "    'min_child_samples': 6.921459338950715,\n",
       "    'feature_fraction': 0.7312214249832153,\n",
       "    'bagging_freq': 14.04398272666668,\n",
       "    'bagging_fraction': 0.9464681371162451},\n",
       "   {'num_leaves': 33.01413160848952,\n",
       "    'colsample_bytree': 0.48447275739620843,\n",
       "    'min_data_in_leaf': 65.30471112550622,\n",
       "    'subsample': 0.9884048966028024,\n",
       "    'max_depth': 13.72022644291674,\n",
       "    'reg_alpha': 2.295901620131585,\n",
       "    'reg_lambda': 1.988998130891244,\n",
       "    'min_split_gain': 0.9518574307794689,\n",
       "    'min_child_weight': 44.56782261561678,\n",
       "    'min_child_samples': 48.84389767709303,\n",
       "    'feature_fraction': 0.5668778748001133,\n",
       "    'bagging_freq': 18.29380669147431,\n",
       "    'bagging_fraction': 0.9320533113251298},\n",
       "   {'num_leaves': 35.109401896728755,\n",
       "    'colsample_bytree': 0.39342535636963305,\n",
       "    'min_data_in_leaf': 99.56160075535036,\n",
       "    'subsample': 0.8512143544641781,\n",
       "    'max_depth': 14.110273527972236,\n",
       "    'reg_alpha': 3.8832215530617678,\n",
       "    'reg_lambda': 8.16106181268128,\n",
       "    'min_split_gain': 0.7190082166355029,\n",
       "    'min_child_weight': 44.684548863385494,\n",
       "    'min_child_samples': 39.48814125606797,\n",
       "    'feature_fraction': 0.8979375649792989,\n",
       "    'bagging_freq': 13.669998481325747,\n",
       "    'bagging_fraction': 0.9764202813091271},\n",
       "   {'num_leaves': 30.534380646764955,\n",
       "    'colsample_bytree': 0.19770460596340395,\n",
       "    'min_data_in_leaf': 75.68372644254889,\n",
       "    'subsample': 0.5797356832991994,\n",
       "    'max_depth': 14.358605107980539,\n",
       "    'reg_alpha': 5.1013244527789166,\n",
       "    'reg_lambda': 9.211013708678424,\n",
       "    'min_split_gain': 0.734701566361131,\n",
       "    'min_child_weight': 38.54839020902096,\n",
       "    'min_child_samples': 23.246347778478164,\n",
       "    'feature_fraction': 0.9020745912831797,\n",
       "    'bagging_freq': 0.8061455897268854,\n",
       "    'bagging_fraction': 0.9845319721401429},\n",
       "   {'num_leaves': 40.16052649189825,\n",
       "    'colsample_bytree': 0.5747690919212066,\n",
       "    'min_data_in_leaf': 97.07875846446866,\n",
       "    'subsample': 0.6803748926856155,\n",
       "    'max_depth': 13.57478714992445,\n",
       "    'reg_alpha': 0.45365237577979944,\n",
       "    'reg_lambda': 9.397638550303522,\n",
       "    'min_split_gain': 0.009361267890409253,\n",
       "    'min_child_weight': 30.332473194630346,\n",
       "    'min_child_samples': 17.605987256030517,\n",
       "    'feature_fraction': 0.9337016055223868,\n",
       "    'bagging_freq': 1.4172627260510207,\n",
       "    'bagging_fraction': 0.8969605001667571},\n",
       "   {'num_leaves': 32.802139860821626,\n",
       "    'colsample_bytree': 0.863640732902806,\n",
       "    'min_data_in_leaf': 44.537945164698634,\n",
       "    'subsample': 0.9846013266229018,\n",
       "    'max_depth': 13.553507784273034,\n",
       "    'reg_alpha': 0.6549160724342851,\n",
       "    'reg_lambda': 0.4738975690798586,\n",
       "    'min_split_gain': 0.8011239839356392,\n",
       "    'min_child_weight': 32.138634909337185,\n",
       "    'min_child_samples': 15.135929132958177,\n",
       "    'feature_fraction': 0.8381932480036988,\n",
       "    'bagging_freq': 16.170801365474723,\n",
       "    'bagging_fraction': 0.9869434460611629},\n",
       "   {'num_leaves': 35.70075580576804,\n",
       "    'colsample_bytree': 0.13043035462863287,\n",
       "    'min_data_in_leaf': 62.56082074087391,\n",
       "    'subsample': 0.7157334385420514,\n",
       "    'max_depth': 14.268506247290949,\n",
       "    'reg_alpha': 9.224836851657743,\n",
       "    'reg_lambda': 6.4194896135075465,\n",
       "    'min_split_gain': 0.9437998302147369,\n",
       "    'min_child_weight': 44.299880846194895,\n",
       "    'min_child_samples': 47.61353920785524,\n",
       "    'feature_fraction': 0.184424555638811,\n",
       "    'bagging_freq': 4.736529884900613,\n",
       "    'bagging_fraction': 0.9520897099478317},\n",
       "   {'num_leaves': 37.06582917442459,\n",
       "    'colsample_bytree': 0.15344522539692804,\n",
       "    'min_data_in_leaf': 80.90339325683702,\n",
       "    'subsample': 0.37649561312871305,\n",
       "    'max_depth': 11.858233374662788,\n",
       "    'reg_alpha': 4.616854613886561,\n",
       "    'reg_lambda': 0.28969166353666087,\n",
       "    'min_split_gain': 0.31588533211566416,\n",
       "    'min_child_weight': 39.98424985276587,\n",
       "    'min_child_samples': 47.17099778392217,\n",
       "    'feature_fraction': 0.8147199864029253,\n",
       "    'bagging_freq': 0.3032441530975727,\n",
       "    'bagging_fraction': 0.9595311696730037},\n",
       "   {'num_leaves': 30.147828251182514,\n",
       "    'colsample_bytree': 0.8028099432835363,\n",
       "    'min_data_in_leaf': 19.17433756330286,\n",
       "    'subsample': 0.3684901239150724,\n",
       "    'max_depth': 13.658876265162595,\n",
       "    'reg_alpha': 0.32998616738156406,\n",
       "    'reg_lambda': 1.9717385957876565,\n",
       "    'min_split_gain': 0.07984482191582698,\n",
       "    'min_child_weight': 44.37569243118797,\n",
       "    'min_child_samples': 48.96115427113043,\n",
       "    'feature_fraction': 0.7715524412757163,\n",
       "    'bagging_freq': 19.045547735430304,\n",
       "    'bagging_fraction': 0.9468835934953251},\n",
       "   {'num_leaves': 44.95270624698121,\n",
       "    'colsample_bytree': 0.2894989721711131,\n",
       "    'min_data_in_leaf': 15.75656998874793,\n",
       "    'subsample': 0.8402057847652942,\n",
       "    'max_depth': 5.468720049171575,\n",
       "    'reg_alpha': 9.345675009801145,\n",
       "    'reg_lambda': 0.488677496661869,\n",
       "    'min_split_gain': 0.39030448485995006,\n",
       "    'min_child_weight': 44.453519183469965,\n",
       "    'min_child_samples': 49.28915706039488,\n",
       "    'feature_fraction': 0.5182200926535057,\n",
       "    'bagging_freq': 8.266926745295917,\n",
       "    'bagging_fraction': 0.871690346911762},\n",
       "   {'num_leaves': 32.18688101472624,\n",
       "    'colsample_bytree': 0.40617109581470323,\n",
       "    'min_data_in_leaf': 86.03704226414375,\n",
       "    'subsample': 0.9929291507895224,\n",
       "    'max_depth': 5.880925904108565,\n",
       "    'reg_alpha': 9.908991446833182,\n",
       "    'reg_lambda': 1.4231627235657007,\n",
       "    'min_split_gain': 0.12389064455598287,\n",
       "    'min_child_weight': 43.99483780148738,\n",
       "    'min_child_samples': 31.07954376393236,\n",
       "    'feature_fraction': 0.6866920479279476,\n",
       "    'bagging_freq': 16.097003303579104,\n",
       "    'bagging_fraction': 0.8345810921445186},\n",
       "   {'num_leaves': 44.95992046804926,\n",
       "    'colsample_bytree': 0.11226254487884654,\n",
       "    'min_data_in_leaf': 55.66518729117224,\n",
       "    'subsample': 0.4301121327142694,\n",
       "    'max_depth': 10.563845418664581,\n",
       "    'reg_alpha': 8.575825710982354,\n",
       "    'reg_lambda': 0.29418571455507747,\n",
       "    'min_split_gain': 0.9128056902889328,\n",
       "    'min_child_weight': 33.889994232379294,\n",
       "    'min_child_samples': 11.634816327649668,\n",
       "    'feature_fraction': 0.7391670933820484,\n",
       "    'bagging_freq': 1.6375317842697767,\n",
       "    'bagging_fraction': 0.9419399751605967},\n",
       "   {'num_leaves': 43.66221722237065,\n",
       "    'colsample_bytree': 0.5314808875225786,\n",
       "    'min_data_in_leaf': 57.562109332525964,\n",
       "    'subsample': 0.5556305669512623,\n",
       "    'max_depth': 6.568996058947894,\n",
       "    'reg_alpha': 7.195411628354597,\n",
       "    'reg_lambda': 2.9035543097209517,\n",
       "    'min_split_gain': 0.06291619111136837,\n",
       "    'min_child_weight': 42.802200065545485,\n",
       "    'min_child_samples': 21.446287889161184,\n",
       "    'feature_fraction': 0.8728394274575323,\n",
       "    'bagging_freq': 0.2138545012749149,\n",
       "    'bagging_fraction': 0.9857921872197233},\n",
       "   {'num_leaves': 41.983539504464034,\n",
       "    'colsample_bytree': 0.9888829666699742,\n",
       "    'min_data_in_leaf': 10.65711905105823,\n",
       "    'subsample': 0.2046290572174454,\n",
       "    'max_depth': 6.287256791996763,\n",
       "    'reg_alpha': 0.8007017648398351,\n",
       "    'reg_lambda': 1.0992231391689233,\n",
       "    'min_split_gain': 0.4849482878458652,\n",
       "    'min_child_weight': 44.910103489501516,\n",
       "    'min_child_samples': 6.182622878186249,\n",
       "    'feature_fraction': 0.47510270426051293,\n",
       "    'bagging_freq': 0.048401321463422686,\n",
       "    'bagging_fraction': 0.7889168895268824},\n",
       "   {'num_leaves': 30.46198802495598,\n",
       "    'colsample_bytree': 0.33511665394719625,\n",
       "    'min_data_in_leaf': 72.10468627726695,\n",
       "    'subsample': 0.4918744153202783,\n",
       "    'max_depth': 14.306463774887723,\n",
       "    'reg_alpha': 1.072299071149695,\n",
       "    'reg_lambda': 9.243631834002118,\n",
       "    'min_split_gain': 0.5415864771375303,\n",
       "    'min_child_weight': 30.75626543329745,\n",
       "    'min_child_samples': 45.780705082809106,\n",
       "    'feature_fraction': 0.6578521029703839,\n",
       "    'bagging_freq': 19.03321024407653,\n",
       "    'bagging_fraction': 0.7542337220155491},\n",
       "   {'num_leaves': 30.191253115908715,\n",
       "    'colsample_bytree': 0.6485877306323158,\n",
       "    'min_data_in_leaf': 92.80543268966954,\n",
       "    'subsample': 0.7256614829936894,\n",
       "    'max_depth': 14.367489674517403,\n",
       "    'reg_alpha': 1.4815480032242079,\n",
       "    'reg_lambda': 9.787133442785837,\n",
       "    'min_split_gain': 0.28291125294807384,\n",
       "    'min_child_weight': 41.727972301653146,\n",
       "    'min_child_samples': 6.914463177579435,\n",
       "    'feature_fraction': 0.7717624271026765,\n",
       "    'bagging_freq': 2.611040025318292,\n",
       "    'bagging_fraction': 0.8253381107806491},\n",
       "   {'num_leaves': 33.99991342100338,\n",
       "    'colsample_bytree': 0.17737843283002863,\n",
       "    'min_data_in_leaf': 10.30875928230465,\n",
       "    'subsample': 0.9840486746980055,\n",
       "    'max_depth': 14.669041302229015,\n",
       "    'reg_alpha': 1.109643695729391,\n",
       "    'reg_lambda': 1.4385261490946044,\n",
       "    'min_split_gain': 0.9019523521736734,\n",
       "    'min_child_weight': 33.76967235219637,\n",
       "    'min_child_samples': 5.259364382003803,\n",
       "    'feature_fraction': 0.792118564107287,\n",
       "    'bagging_freq': 0.25093569772328017,\n",
       "    'bagging_fraction': 0.8021478865188538},\n",
       "   {'num_leaves': 30.32615314359708,\n",
       "    'colsample_bytree': 0.9716590907037005,\n",
       "    'min_data_in_leaf': 24.499792719570458,\n",
       "    'subsample': 0.5743066000739901,\n",
       "    'max_depth': 5.853909885394532,\n",
       "    'reg_alpha': 5.3879763261722236,\n",
       "    'reg_lambda': 8.931822908208634,\n",
       "    'min_split_gain': 0.11850545006894886,\n",
       "    'min_child_weight': 32.22617353835771,\n",
       "    'min_child_samples': 24.918650480446438,\n",
       "    'feature_fraction': 0.7489237984266224,\n",
       "    'bagging_freq': 5.495090055677081,\n",
       "    'bagging_fraction': 0.8823076160992754},\n",
       "   {'num_leaves': 44.728243039371606,\n",
       "    'colsample_bytree': 0.27482169208030005,\n",
       "    'min_data_in_leaf': 94.99674138350186,\n",
       "    'subsample': 0.7616812203633088,\n",
       "    'max_depth': 14.66224964357248,\n",
       "    'reg_alpha': 5.021427935705166,\n",
       "    'reg_lambda': 9.663175759648848,\n",
       "    'min_split_gain': 0.43141775896386936,\n",
       "    'min_child_weight': 32.15645725356288,\n",
       "    'min_child_samples': 49.294716845440995,\n",
       "    'feature_fraction': 0.1771184643320589,\n",
       "    'bagging_freq': 1.4845071618355643,\n",
       "    'bagging_fraction': 0.958363579999138},\n",
       "   {'num_leaves': 31.42807420175093,\n",
       "    'colsample_bytree': 0.23732015129316975,\n",
       "    'min_data_in_leaf': 41.480242441928354,\n",
       "    'subsample': 0.14341993333961628,\n",
       "    'max_depth': 13.859421280568608,\n",
       "    'reg_alpha': 1.5020333692537624,\n",
       "    'reg_lambda': 9.342770677110684,\n",
       "    'min_split_gain': 0.3098879088786579,\n",
       "    'min_child_weight': 42.883801011222076,\n",
       "    'min_child_samples': 49.60911408764669,\n",
       "    'feature_fraction': 0.905277461541676,\n",
       "    'bagging_freq': 19.762506052000784,\n",
       "    'bagging_fraction': 0.5404604225017569},\n",
       "   {'num_leaves': 44.81126157615631,\n",
       "    'colsample_bytree': 0.5791211408665194,\n",
       "    'min_data_in_leaf': 18.092642507177526,\n",
       "    'subsample': 0.1150741643743019,\n",
       "    'max_depth': 6.767350927848559,\n",
       "    'reg_alpha': 8.784784038157381,\n",
       "    'reg_lambda': 0.1883553270267424,\n",
       "    'min_split_gain': 0.15809841560572824,\n",
       "    'min_child_weight': 41.733477395220206,\n",
       "    'min_child_samples': 49.991389488186385,\n",
       "    'feature_fraction': 0.4367473480777655,\n",
       "    'bagging_freq': 18.133516091749463,\n",
       "    'bagging_fraction': 0.9626773149110026},\n",
       "   {'num_leaves': 44.75065218933048,\n",
       "    'colsample_bytree': 0.3470483729746153,\n",
       "    'min_data_in_leaf': 98.51996236020037,\n",
       "    'subsample': 0.4778680233205199,\n",
       "    'max_depth': 9.400529379541847,\n",
       "    'reg_alpha': 2.503872034278851,\n",
       "    'reg_lambda': 7.183383323636914,\n",
       "    'min_split_gain': 0.27073870145545387,\n",
       "    'min_child_weight': 42.97070254628693,\n",
       "    'min_child_samples': 49.97463286868246,\n",
       "    'feature_fraction': 0.21166803282922947,\n",
       "    'bagging_freq': 19.075213153853344,\n",
       "    'bagging_fraction': 0.7698353568144432},\n",
       "   {'num_leaves': 43.90381276869017,\n",
       "    'colsample_bytree': 0.8191675592909521,\n",
       "    'min_data_in_leaf': 10.092007573553737,\n",
       "    'subsample': 0.11855602932171302,\n",
       "    'max_depth': 13.208534031153365,\n",
       "    'reg_alpha': 7.883514687087163,\n",
       "    'reg_lambda': 0.8087756651314437,\n",
       "    'min_split_gain': 0.21078971272374392,\n",
       "    'min_child_weight': 42.93483952078449,\n",
       "    'min_child_samples': 6.89660111657868,\n",
       "    'feature_fraction': 0.849564008515097,\n",
       "    'bagging_freq': 18.143138732497306,\n",
       "    'bagging_fraction': 0.9696654042154832},\n",
       "   {'num_leaves': 44.76768601568613,\n",
       "    'colsample_bytree': 0.16060772792027384,\n",
       "    'min_data_in_leaf': 35.03801519468941,\n",
       "    'subsample': 0.709795272612563,\n",
       "    'max_depth': 6.580835366854743,\n",
       "    'reg_alpha': 4.732128691314207,\n",
       "    'reg_lambda': 1.532030308468325,\n",
       "    'min_split_gain': 0.8004752444096244,\n",
       "    'min_child_weight': 44.33529177452786,\n",
       "    'min_child_samples': 45.743714152186534,\n",
       "    'feature_fraction': 0.8334288203330488,\n",
       "    'bagging_freq': 18.39589779672443,\n",
       "    'bagging_fraction': 0.9821434328910901},\n",
       "   {'num_leaves': 30.246728873153533,\n",
       "    'colsample_bytree': 0.514363404244975,\n",
       "    'min_data_in_leaf': 83.87814034339861,\n",
       "    'subsample': 0.8536528384435058,\n",
       "    'max_depth': 5.1287481305385585,\n",
       "    'reg_alpha': 6.407510508209706,\n",
       "    'reg_lambda': 8.26875358957662,\n",
       "    'min_split_gain': 0.42211084140318866,\n",
       "    'min_child_weight': 44.57610800689727,\n",
       "    'min_child_samples': 5.240017514572121,\n",
       "    'feature_fraction': 0.9330059588977002,\n",
       "    'bagging_freq': 19.292595699651297,\n",
       "    'bagging_fraction': 0.7571931448511721},\n",
       "   {'num_leaves': 31.514774640466385,\n",
       "    'colsample_bytree': 0.4314319464306331,\n",
       "    'min_data_in_leaf': 99.06387199690282,\n",
       "    'subsample': 0.9998977884930761,\n",
       "    'max_depth': 12.986992286875985,\n",
       "    'reg_alpha': 0.3887033122652639,\n",
       "    'reg_lambda': 9.747898998124034,\n",
       "    'min_split_gain': 0.9090707036517822,\n",
       "    'min_child_weight': 44.26704709277921,\n",
       "    'min_child_samples': 13.60924713292877,\n",
       "    'feature_fraction': 0.7541927279441675,\n",
       "    'bagging_freq': 0.07203018276029205,\n",
       "    'bagging_fraction': 0.9891984903371702},\n",
       "   {'num_leaves': 32.76875403663242,\n",
       "    'colsample_bytree': 0.7805200744300944,\n",
       "    'min_data_in_leaf': 85.38585722700671,\n",
       "    'subsample': 0.6865915748838,\n",
       "    'max_depth': 13.614040357379917,\n",
       "    'reg_alpha': 7.299637700685117,\n",
       "    'reg_lambda': 8.653259086061516,\n",
       "    'min_split_gain': 0.20743446461817783,\n",
       "    'min_child_weight': 37.99530800866948,\n",
       "    'min_child_samples': 36.44961663471845,\n",
       "    'feature_fraction': 0.7696736967035623,\n",
       "    'bagging_freq': 5.082664453258348,\n",
       "    'bagging_fraction': 0.8418971127299577},\n",
       "   {'num_leaves': 44.415294032143784,\n",
       "    'colsample_bytree': 0.6815975320242641,\n",
       "    'min_data_in_leaf': 10.293973768674885,\n",
       "    'subsample': 0.24172818298740387,\n",
       "    'max_depth': 8.976314987799322,\n",
       "    'reg_alpha': 9.24488741226989,\n",
       "    'reg_lambda': 0.2096234792584073,\n",
       "    'min_split_gain': 0.017009341332509087,\n",
       "    'min_child_weight': 30.48716589181395,\n",
       "    'min_child_samples': 8.240765920848117,\n",
       "    'feature_fraction': 0.493960408923362,\n",
       "    'bagging_freq': 3.8665209559667013,\n",
       "    'bagging_fraction': 0.2826215250529634},\n",
       "   {'num_leaves': 32.61975243296686,\n",
       "    'colsample_bytree': 0.39277307854405863,\n",
       "    'min_data_in_leaf': 39.64127866199658,\n",
       "    'subsample': 0.9040625370401906,\n",
       "    'max_depth': 12.956272894710505,\n",
       "    'reg_alpha': 4.941266362249741,\n",
       "    'reg_lambda': 9.890559793863893,\n",
       "    'min_split_gain': 0.7851664677054103,\n",
       "    'min_child_weight': 32.572141950313934,\n",
       "    'min_child_samples': 17.855952693390208,\n",
       "    'feature_fraction': 0.8803554346396941,\n",
       "    'bagging_freq': 0.08736986402251068,\n",
       "    'bagging_fraction': 0.9848529158057172},\n",
       "   {'num_leaves': 30.338158050482427,\n",
       "    'colsample_bytree': 0.35937738817948606,\n",
       "    'min_data_in_leaf': 95.05977266955307,\n",
       "    'subsample': 0.7956605554179611,\n",
       "    'max_depth': 6.520393167691837,\n",
       "    'reg_alpha': 8.850703176438683,\n",
       "    'reg_lambda': 0.5144741148155252,\n",
       "    'min_split_gain': 0.8760549248019636,\n",
       "    'min_child_weight': 31.58984852437561,\n",
       "    'min_child_samples': 36.076517161072516,\n",
       "    'feature_fraction': 0.8019297205209044,\n",
       "    'bagging_freq': 0.12460387459009459,\n",
       "    'bagging_fraction': 0.9433180894530703},\n",
       "   {'num_leaves': 44.56979352500952,\n",
       "    'colsample_bytree': 0.9063109767915135,\n",
       "    'min_data_in_leaf': 69.49126946342557,\n",
       "    'subsample': 0.8100304643623201,\n",
       "    'max_depth': 13.406622218920386,\n",
       "    'reg_alpha': 1.2828517583649857,\n",
       "    'reg_lambda': 0.1614351121080415,\n",
       "    'min_split_gain': 0.18201495896491293,\n",
       "    'min_child_weight': 30.19654166750217,\n",
       "    'min_child_samples': 6.29809834965595,\n",
       "    'feature_fraction': 0.14170161037890405,\n",
       "    'bagging_freq': 15.472756414173407,\n",
       "    'bagging_fraction': 0.891116800484526},\n",
       "   {'num_leaves': 33.02352070242379,\n",
       "    'colsample_bytree': 0.781892811446765,\n",
       "    'min_data_in_leaf': 35.52290086961858,\n",
       "    'subsample': 0.12155261211054197,\n",
       "    'max_depth': 14.016917703335398,\n",
       "    'reg_alpha': 9.60587431907868,\n",
       "    'reg_lambda': 1.2237148210417959,\n",
       "    'min_split_gain': 0.8458806977212088,\n",
       "    'min_child_weight': 44.87209299680694,\n",
       "    'min_child_samples': 6.586718553885801,\n",
       "    'feature_fraction': 0.9241826638882735,\n",
       "    'bagging_freq': 16.04591207876351,\n",
       "    'bagging_fraction': 0.9353307627952013},\n",
       "   {'num_leaves': 44.936546603395385,\n",
       "    'colsample_bytree': 0.23513202341306239,\n",
       "    'min_data_in_leaf': 49.804449291650634,\n",
       "    'subsample': 0.15346743656411882,\n",
       "    'max_depth': 12.554390947654543,\n",
       "    'reg_alpha': 0.49647559318462653,\n",
       "    'reg_lambda': 8.97899140934727,\n",
       "    'min_split_gain': 0.810215134049892,\n",
       "    'min_child_weight': 31.31121040265547,\n",
       "    'min_child_samples': 7.620565304813628,\n",
       "    'feature_fraction': 0.8429949599262654,\n",
       "    'bagging_freq': 13.493117227405031,\n",
       "    'bagging_fraction': 0.8721378925367562},\n",
       "   {'num_leaves': 44.58129919607278,\n",
       "    'colsample_bytree': 0.19516107087269513,\n",
       "    'min_data_in_leaf': 63.12841130550337,\n",
       "    'subsample': 0.7881185907960219,\n",
       "    'max_depth': 14.368424110997791,\n",
       "    'reg_alpha': 9.153660032132473,\n",
       "    'reg_lambda': 1.1559756513989827,\n",
       "    'min_split_gain': 0.2582729107169245,\n",
       "    'min_child_weight': 30.590553562376368,\n",
       "    'min_child_samples': 33.640509050533616,\n",
       "    'feature_fraction': 0.4013764622798397,\n",
       "    'bagging_freq': 0.17417000904358382,\n",
       "    'bagging_fraction': 0.9536966475179027},\n",
       "   {'num_leaves': 41.64033763757227,\n",
       "    'colsample_bytree': 0.22615428119884745,\n",
       "    'min_data_in_leaf': 76.45408645629593,\n",
       "    'subsample': 0.7636442030517647,\n",
       "    'max_depth': 14.696385627240879,\n",
       "    'reg_alpha': 0.5056278315123808,\n",
       "    'reg_lambda': 9.876148406708499,\n",
       "    'min_split_gain': 0.787290786923269,\n",
       "    'min_child_weight': 30.509289641798766,\n",
       "    'min_child_samples': 37.36258889175981,\n",
       "    'feature_fraction': 0.1811800453609879,\n",
       "    'bagging_freq': 18.4989875199748,\n",
       "    'bagging_fraction': 0.8492998655829375},\n",
       "   {'num_leaves': 41.066817319276915,\n",
       "    'colsample_bytree': 0.6446671544350221,\n",
       "    'min_data_in_leaf': 53.433141748299576,\n",
       "    'subsample': 0.1635492744697265,\n",
       "    'max_depth': 14.936489881705025,\n",
       "    'reg_alpha': 2.752949709709992,\n",
       "    'reg_lambda': 2.2640491958953914,\n",
       "    'min_split_gain': 0.1260946224734938,\n",
       "    'min_child_weight': 35.38538067159442,\n",
       "    'min_child_samples': 18.781049214076525,\n",
       "    'feature_fraction': 0.9268328999823621,\n",
       "    'bagging_freq': 0.5292024435110187,\n",
       "    'bagging_fraction': 0.9486978737561347},\n",
       "   {'num_leaves': 31.59809217095461,\n",
       "    'colsample_bytree': 0.14488895608204605,\n",
       "    'min_data_in_leaf': 33.335897876984774,\n",
       "    'subsample': 0.39122872492721583,\n",
       "    'max_depth': 14.6214235135392,\n",
       "    'reg_alpha': 0.6709834880753429,\n",
       "    'reg_lambda': 9.898366825717131,\n",
       "    'min_split_gain': 0.8512438144715662,\n",
       "    'min_child_weight': 30.069729793133032,\n",
       "    'min_child_samples': 37.463222756903946,\n",
       "    'feature_fraction': 0.7702946665463181,\n",
       "    'bagging_freq': 19.49018317457271,\n",
       "    'bagging_fraction': 0.8668830802879697},\n",
       "   {'num_leaves': 32.88082410061725,\n",
       "    'colsample_bytree': 0.4542709059201444,\n",
       "    'min_data_in_leaf': 98.81715829835707,\n",
       "    'subsample': 0.9652875860737365,\n",
       "    'max_depth': 14.583086818862723,\n",
       "    'reg_alpha': 9.516951682285136,\n",
       "    'reg_lambda': 0.43612297853785176,\n",
       "    'min_split_gain': 0.643783280046816,\n",
       "    'min_child_weight': 44.649354206415914,\n",
       "    'min_child_samples': 47.64446292338683,\n",
       "    'feature_fraction': 0.789489129276128,\n",
       "    'bagging_freq': 1.8722732184125457,\n",
       "    'bagging_fraction': 0.972986638214206},\n",
       "   {'num_leaves': 44.39912427672092,\n",
       "    'colsample_bytree': 0.8657192226183562,\n",
       "    'min_data_in_leaf': 67.73118736769217,\n",
       "    'subsample': 0.9941038197066552,\n",
       "    'max_depth': 13.316314325650566,\n",
       "    'reg_alpha': 9.692518887440283,\n",
       "    'reg_lambda': 3.0126935255903864,\n",
       "    'min_split_gain': 0.9427006363215026,\n",
       "    'min_child_weight': 30.076501223339537,\n",
       "    'min_child_samples': 49.91689454340991,\n",
       "    'feature_fraction': 0.9059265599421374,\n",
       "    'bagging_freq': 19.784777273326824,\n",
       "    'bagging_fraction': 0.11038307951568235},\n",
       "   {'num_leaves': 41.670937346463944,\n",
       "    'colsample_bytree': 0.3891084466215262,\n",
       "    'min_data_in_leaf': 50.811719570553336,\n",
       "    'subsample': 0.3623776774669426,\n",
       "    'max_depth': 6.725134977363801,\n",
       "    'reg_alpha': 7.81663639835629,\n",
       "    'reg_lambda': 7.689858948047079,\n",
       "    'min_split_gain': 0.4415430793384649,\n",
       "    'min_child_weight': 30.314868629855244,\n",
       "    'min_child_samples': 6.412737936968764,\n",
       "    'feature_fraction': 0.9481030203130064,\n",
       "    'bagging_freq': 0.21005079173628927,\n",
       "    'bagging_fraction': 0.9755918307773511},\n",
       "   {'num_leaves': 35.85923453115292,\n",
       "    'colsample_bytree': 0.15006837216116456,\n",
       "    'min_data_in_leaf': 86.83335689129663,\n",
       "    'subsample': 0.8560969749892996,\n",
       "    'max_depth': 13.490422686889506,\n",
       "    'reg_alpha': 5.131514565150146,\n",
       "    'reg_lambda': 9.836347591698905,\n",
       "    'min_split_gain': 0.1884132273808512,\n",
       "    'min_child_weight': 31.690886298416395,\n",
       "    'min_child_samples': 6.2435335870092565,\n",
       "    'feature_fraction': 0.7449760375488246,\n",
       "    'bagging_freq': 19.96759661732956,\n",
       "    'bagging_fraction': 0.8902687598610899},\n",
       "   {'num_leaves': 30.35837786161419,\n",
       "    'colsample_bytree': 0.9019134454801516,\n",
       "    'min_data_in_leaf': 34.07176092993416,\n",
       "    'subsample': 0.3158088112981428,\n",
       "    'max_depth': 5.26829081493479,\n",
       "    'reg_alpha': 8.249442351520539,\n",
       "    'reg_lambda': 1.7012352301127065,\n",
       "    'min_split_gain': 0.2853906268622459,\n",
       "    'min_child_weight': 44.432489013756275,\n",
       "    'min_child_samples': 30.403069991588147,\n",
       "    'feature_fraction': 0.28372830195622234,\n",
       "    'bagging_freq': 1.6574842706041393,\n",
       "    'bagging_fraction': 0.8814939765627796},\n",
       "   {'num_leaves': 32.274870982427025,\n",
       "    'colsample_bytree': 0.22661634246080847,\n",
       "    'min_data_in_leaf': 54.314709667506,\n",
       "    'subsample': 0.7925977830459632,\n",
       "    'max_depth': 8.704691186705361,\n",
       "    'reg_alpha': 8.807507826128191,\n",
       "    'reg_lambda': 9.799001844912352,\n",
       "    'min_split_gain': 0.8999392194428952,\n",
       "    'min_child_weight': 30.38215370872514,\n",
       "    'min_child_samples': 5.816343628951998,\n",
       "    'feature_fraction': 0.29291044778240205,\n",
       "    'bagging_freq': 15.083961177872387,\n",
       "    'bagging_fraction': 0.9233968703387001},\n",
       "   {'num_leaves': 30.907366024881465,\n",
       "    'colsample_bytree': 0.953970496676957,\n",
       "    'min_data_in_leaf': 25.135433827223977,\n",
       "    'subsample': 0.615041154090003,\n",
       "    'max_depth': 5.087048045878355,\n",
       "    'reg_alpha': 7.715197012575853,\n",
       "    'reg_lambda': 1.3309458801075968,\n",
       "    'min_split_gain': 0.5966913869830052,\n",
       "    'min_child_weight': 44.59143138570376,\n",
       "    'min_child_samples': 49.912816603061565,\n",
       "    'feature_fraction': 0.1811855601419587,\n",
       "    'bagging_freq': 18.143152378552063,\n",
       "    'bagging_fraction': 0.5623104708780914},\n",
       "   {'num_leaves': 30.57574560667913,\n",
       "    'colsample_bytree': 0.24992534711355338,\n",
       "    'min_data_in_leaf': 79.81339939893668,\n",
       "    'subsample': 0.954807965654217,\n",
       "    'max_depth': 8.420503636942842,\n",
       "    'reg_alpha': 8.410468684196099,\n",
       "    'reg_lambda': 0.9801443083734196,\n",
       "    'min_split_gain': 0.04364593707461839,\n",
       "    'min_child_weight': 30.288307518531575,\n",
       "    'min_child_samples': 22.146712220862288,\n",
       "    'feature_fraction': 0.44979195508923564,\n",
       "    'bagging_freq': 10.937736867723816,\n",
       "    'bagging_fraction': 0.9872018757057716},\n",
       "   {'num_leaves': 33.89992720167557,\n",
       "    'colsample_bytree': 0.47991784530208037,\n",
       "    'min_data_in_leaf': 41.202483841967315,\n",
       "    'subsample': 0.7887372914381076,\n",
       "    'max_depth': 5.7410721901978725,\n",
       "    'reg_alpha': 9.104143722101236,\n",
       "    'reg_lambda': 0.024181288863645012,\n",
       "    'min_split_gain': 0.31947014201335155,\n",
       "    'min_child_weight': 44.51980030114424,\n",
       "    'min_child_samples': 5.737425966540992,\n",
       "    'feature_fraction': 0.5336219065399884,\n",
       "    'bagging_freq': 2.257220904867112,\n",
       "    'bagging_fraction': 0.9557148708530808},\n",
       "   {'num_leaves': 30.614076217069407,\n",
       "    'colsample_bytree': 0.14592712529520843,\n",
       "    'min_data_in_leaf': 46.522784910566834,\n",
       "    'subsample': 0.739541078847042,\n",
       "    'max_depth': 7.862363620897421,\n",
       "    'reg_alpha': 5.812914022180957,\n",
       "    'reg_lambda': 0.2411820045899149,\n",
       "    'min_split_gain': 0.13608017616264023,\n",
       "    'min_child_weight': 30.158945501059396,\n",
       "    'min_child_samples': 5.727433854017583,\n",
       "    'feature_fraction': 0.2599313745982166,\n",
       "    'bagging_freq': 4.188875979292678,\n",
       "    'bagging_fraction': 0.9741488335798407},\n",
       "   {'num_leaves': 41.98202433669876,\n",
       "    'colsample_bytree': 0.7441233140798353,\n",
       "    'min_data_in_leaf': 45.27629806877212,\n",
       "    'subsample': 0.5007803095321961,\n",
       "    'max_depth': 11.544883109500471,\n",
       "    'reg_alpha': 0.43975698284257403,\n",
       "    'reg_lambda': 7.983063023578519,\n",
       "    'min_split_gain': 0.9582670108521246,\n",
       "    'min_child_weight': 44.62062878560183,\n",
       "    'min_child_samples': 37.77213161270784,\n",
       "    'feature_fraction': 0.48047310142974775,\n",
       "    'bagging_freq': 18.707960544973552,\n",
       "    'bagging_fraction': 0.7366137488233758},\n",
       "   {'num_leaves': 44.63389132012727,\n",
       "    'colsample_bytree': 0.8629873198486575,\n",
       "    'min_data_in_leaf': 90.77088650450278,\n",
       "    'subsample': 0.14583442832368473,\n",
       "    'max_depth': 6.159342270917751,\n",
       "    'reg_alpha': 7.554116018948679,\n",
       "    'reg_lambda': 5.147278577643963,\n",
       "    'min_split_gain': 0.28606407983865156,\n",
       "    'min_child_weight': 43.234945957310515,\n",
       "    'min_child_samples': 44.63375116369468,\n",
       "    'feature_fraction': 0.870694167679273,\n",
       "    'bagging_freq': 6.450191608009512,\n",
       "    'bagging_fraction': 0.968197578328532},\n",
       "   {'num_leaves': 31.876559167196767,\n",
       "    'colsample_bytree': 0.14827852284151302,\n",
       "    'min_data_in_leaf': 69.24182537637796,\n",
       "    'subsample': 0.9003561860648592,\n",
       "    'max_depth': 14.735810372623972,\n",
       "    'reg_alpha': 9.713041761762288,\n",
       "    'reg_lambda': 0.3634067078471359,\n",
       "    'min_split_gain': 0.6034097410717657,\n",
       "    'min_child_weight': 44.75119463974241,\n",
       "    'min_child_samples': 27.12075795126182,\n",
       "    'feature_fraction': 0.8533136747228965,\n",
       "    'bagging_freq': 9.855671826706065,\n",
       "    'bagging_fraction': 0.8894867005855571},\n",
       "   {'num_leaves': 30.204560793952975,\n",
       "    'colsample_bytree': 0.903045692024601,\n",
       "    'min_data_in_leaf': 90.13751004959951,\n",
       "    'subsample': 0.9577794912645227,\n",
       "    'max_depth': 14.786687563553796,\n",
       "    'reg_alpha': 2.035569087826109,\n",
       "    'reg_lambda': 0.5606602014982454,\n",
       "    'min_split_gain': 0.3839433416989334,\n",
       "    'min_child_weight': 39.57091117474692,\n",
       "    'min_child_samples': 47.39513990213025,\n",
       "    'feature_fraction': 0.450673156590224,\n",
       "    'bagging_freq': 19.094352150728014,\n",
       "    'bagging_fraction': 0.5134272354771519},\n",
       "   {'num_leaves': 31.511094788112004,\n",
       "    'colsample_bytree': 0.13240659640254124,\n",
       "    'min_data_in_leaf': 10.995700446329701,\n",
       "    'subsample': 0.8444823970452848,\n",
       "    'max_depth': 14.687482749341237,\n",
       "    'reg_alpha': 4.475293457236184,\n",
       "    'reg_lambda': 8.806357059906038,\n",
       "    'min_split_gain': 0.03909648917489772,\n",
       "    'min_child_weight': 30.54927806714548,\n",
       "    'min_child_samples': 5.196619862054705,\n",
       "    'feature_fraction': 0.5869775732161717,\n",
       "    'bagging_freq': 13.629644323388783,\n",
       "    'bagging_fraction': 0.871002755748146},\n",
       "   {'num_leaves': 30.212835582567607,\n",
       "    'colsample_bytree': 0.9243751265773582,\n",
       "    'min_data_in_leaf': 12.675969464567153,\n",
       "    'subsample': 0.2910099338251101,\n",
       "    'max_depth': 5.522273944195036,\n",
       "    'reg_alpha': 9.243341614364745,\n",
       "    'reg_lambda': 4.651500475052204,\n",
       "    'min_split_gain': 0.6278741056551225,\n",
       "    'min_child_weight': 34.522281676217425,\n",
       "    'min_child_samples': 32.19511922205593,\n",
       "    'feature_fraction': 0.23873424486362965,\n",
       "    'bagging_freq': 0.6230550525927114,\n",
       "    'bagging_fraction': 0.962420046894841},\n",
       "   {'num_leaves': 44.86916505719251,\n",
       "    'colsample_bytree': 0.3640082753121223,\n",
       "    'min_data_in_leaf': 49.49239251368519,\n",
       "    'subsample': 0.7774774530456467,\n",
       "    'max_depth': 14.857851732510728,\n",
       "    'reg_alpha': 4.988676196214227,\n",
       "    'reg_lambda': 8.572389604556761,\n",
       "    'min_split_gain': 0.9557855945322394,\n",
       "    'min_child_weight': 42.79259732712469,\n",
       "    'min_child_samples': 49.82597368711425,\n",
       "    'feature_fraction': 0.4176349721339735,\n",
       "    'bagging_freq': 9.953478138791787,\n",
       "    'bagging_fraction': 0.9785481575732008},\n",
       "   {'num_leaves': 30.422284968204547,\n",
       "    'colsample_bytree': 0.46387279462799136,\n",
       "    'min_data_in_leaf': 49.66651410314964,\n",
       "    'subsample': 0.8767428256495834,\n",
       "    'max_depth': 10.696398808160717,\n",
       "    'reg_alpha': 2.868069536086686,\n",
       "    'reg_lambda': 9.380732274373813,\n",
       "    'min_split_gain': 0.29549332929756134,\n",
       "    'min_child_weight': 44.287046731046956,\n",
       "    'min_child_samples': 6.179965314434812,\n",
       "    'feature_fraction': 0.6697563722390186,\n",
       "    'bagging_freq': 10.701873961669238,\n",
       "    'bagging_fraction': 0.8451149627584863},\n",
       "   {'num_leaves': 30.615091024658557,\n",
       "    'colsample_bytree': 0.9898386242635461,\n",
       "    'min_data_in_leaf': 22.57156325623138,\n",
       "    'subsample': 0.14179581473548122,\n",
       "    'max_depth': 14.23379363541885,\n",
       "    'reg_alpha': 4.437776183060345,\n",
       "    'reg_lambda': 0.4654513894761392,\n",
       "    'min_split_gain': 0.6114695557593178,\n",
       "    'min_child_weight': 41.52044608926044,\n",
       "    'min_child_samples': 5.994888944990805,\n",
       "    'feature_fraction': 0.5087955299839939,\n",
       "    'bagging_freq': 14.79188311303323,\n",
       "    'bagging_fraction': 0.9458018159017751},\n",
       "   {'num_leaves': 30.609527330429362,\n",
       "    'colsample_bytree': 0.9707453782017507,\n",
       "    'min_data_in_leaf': 11.120367435313279,\n",
       "    'subsample': 0.21026491671785136,\n",
       "    'max_depth': 13.98915578700884,\n",
       "    'reg_alpha': 0.554059718662927,\n",
       "    'reg_lambda': 9.268205064412328,\n",
       "    'min_split_gain': 0.030463340265902694,\n",
       "    'min_child_weight': 43.685780653976096,\n",
       "    'min_child_samples': 49.024062903763465,\n",
       "    'feature_fraction': 0.5489060927521844,\n",
       "    'bagging_freq': 0.17091559194621686,\n",
       "    'bagging_fraction': 0.9557074989949264},\n",
       "   {'num_leaves': 41.594825670945,\n",
       "    'colsample_bytree': 0.3251016571261057,\n",
       "    'min_data_in_leaf': 99.63214107262351,\n",
       "    'subsample': 0.2972449908866236,\n",
       "    'max_depth': 7.3598334601939115,\n",
       "    'reg_alpha': 7.456458807312172,\n",
       "    'reg_lambda': 9.288920981936773,\n",
       "    'min_split_gain': 0.2333799329648959,\n",
       "    'min_child_weight': 30.074252903444194,\n",
       "    'min_child_samples': 5.183070624481748,\n",
       "    'feature_fraction': 0.5393807296829142,\n",
       "    'bagging_freq': 2.3983556907789128,\n",
       "    'bagging_fraction': 0.8357045043793895},\n",
       "   {'num_leaves': 33.765513394125534,\n",
       "    'colsample_bytree': 0.8298725054900392,\n",
       "    'min_data_in_leaf': 28.041390627747994,\n",
       "    'subsample': 0.5735691769451116,\n",
       "    'max_depth': 14.240984947841559,\n",
       "    'reg_alpha': 8.453046428753222,\n",
       "    'reg_lambda': 0.12064086150709308,\n",
       "    'min_split_gain': 0.6563446553633118,\n",
       "    'min_child_weight': 43.90613725957841,\n",
       "    'min_child_samples': 49.029413983944245,\n",
       "    'feature_fraction': 0.714057961665528,\n",
       "    'bagging_freq': 1.863280058647765,\n",
       "    'bagging_fraction': 0.9233845549030744},\n",
       "   {'num_leaves': 43.935191968814465,\n",
       "    'colsample_bytree': 0.5168733817693527,\n",
       "    'min_data_in_leaf': 97.72819684977678,\n",
       "    'subsample': 0.44501228590568165,\n",
       "    'max_depth': 8.1207152002574,\n",
       "    'reg_alpha': 4.236484268794172,\n",
       "    'reg_lambda': 0.277072409278446,\n",
       "    'min_split_gain': 0.08646823918274205,\n",
       "    'min_child_weight': 30.287648895356895,\n",
       "    'min_child_samples': 27.180852181054885,\n",
       "    'feature_fraction': 0.7502014430369275,\n",
       "    'bagging_freq': 11.553166969732942,\n",
       "    'bagging_fraction': 0.9317758033437596},\n",
       "   {'num_leaves': 31.47123801309207,\n",
       "    'colsample_bytree': 0.8162368190458064,\n",
       "    'min_data_in_leaf': 99.86305950370325,\n",
       "    'subsample': 0.768701590262567,\n",
       "    'max_depth': 6.672021872044018,\n",
       "    'reg_alpha': 8.557273581474478,\n",
       "    'reg_lambda': 0.7471262464973061,\n",
       "    'min_split_gain': 0.7552923216950106,\n",
       "    'min_child_weight': 30.426958363080196,\n",
       "    'min_child_samples': 49.42012109414356,\n",
       "    'feature_fraction': 0.21949159696051312,\n",
       "    'bagging_freq': 1.0351519515636531,\n",
       "    'bagging_fraction': 0.7292226056330168},\n",
       "   {'num_leaves': 41.71085889764104,\n",
       "    'colsample_bytree': 0.39248473115011717,\n",
       "    'min_data_in_leaf': 39.870016260211756,\n",
       "    'subsample': 0.7650039570865174,\n",
       "    'max_depth': 12.735021295160044,\n",
       "    'reg_alpha': 8.859434155542694,\n",
       "    'reg_lambda': 1.6336570792252147,\n",
       "    'min_split_gain': 0.9685209624351979,\n",
       "    'min_child_weight': 31.14141453182148,\n",
       "    'min_child_samples': 5.127169349469041,\n",
       "    'feature_fraction': 0.18395769251328514,\n",
       "    'bagging_freq': 15.347502399165274,\n",
       "    'bagging_fraction': 0.826681567451662},\n",
       "   {'num_leaves': 30.502526817020886,\n",
       "    'colsample_bytree': 0.4894463770665134,\n",
       "    'min_data_in_leaf': 79.73699807253232,\n",
       "    'subsample': 0.7641739399288414,\n",
       "    'max_depth': 14.749335942180194,\n",
       "    'reg_alpha': 3.789784713819623,\n",
       "    'reg_lambda': 7.9638792545631905,\n",
       "    'min_split_gain': 0.9942039520030681,\n",
       "    'min_child_weight': 30.097693364386675,\n",
       "    'min_child_samples': 20.90366080968032,\n",
       "    'feature_fraction': 0.6048532772741949,\n",
       "    'bagging_freq': 17.134491199649805,\n",
       "    'bagging_fraction': 0.947113852860877},\n",
       "   {'num_leaves': 30.07649458624537,\n",
       "    'colsample_bytree': 0.6669813047708181,\n",
       "    'min_data_in_leaf': 10.69178647174326,\n",
       "    'subsample': 0.10827401142748772,\n",
       "    'max_depth': 8.30233899504873,\n",
       "    'reg_alpha': 9.881451490130162,\n",
       "    'reg_lambda': 1.555519585010089,\n",
       "    'min_split_gain': 0.3994557466558448,\n",
       "    'min_child_weight': 34.62117132194147,\n",
       "    'min_child_samples': 5.7255224378815495,\n",
       "    'feature_fraction': 0.41892782976514287,\n",
       "    'bagging_freq': 9.919893007980523,\n",
       "    'bagging_fraction': 0.7885220612462756},\n",
       "   {'num_leaves': 44.54859255781692,\n",
       "    'colsample_bytree': 0.11535870936282398,\n",
       "    'min_data_in_leaf': 62.54342580160378,\n",
       "    'subsample': 0.930234725075436,\n",
       "    'max_depth': 8.342545530059233,\n",
       "    'reg_alpha': 8.629978576000973,\n",
       "    'reg_lambda': 0.5649495380209446,\n",
       "    'min_split_gain': 0.9716398522070743,\n",
       "    'min_child_weight': 31.556950121447073,\n",
       "    'min_child_samples': 23.07822418669451,\n",
       "    'feature_fraction': 0.7436993717426249,\n",
       "    'bagging_freq': 6.998678427808258,\n",
       "    'bagging_fraction': 0.913149599815373},\n",
       "   {'num_leaves': 33.46195887219708,\n",
       "    'colsample_bytree': 0.34226993913804327,\n",
       "    'min_data_in_leaf': 99.60866168976494,\n",
       "    'subsample': 0.8281831890580449,\n",
       "    'max_depth': 14.319505301259683,\n",
       "    'reg_alpha': 2.791553382894041,\n",
       "    'reg_lambda': 3.1207619450308313,\n",
       "    'min_split_gain': 0.0015541798588393219,\n",
       "    'min_child_weight': 41.273820620429206,\n",
       "    'min_child_samples': 30.005419680427693,\n",
       "    'feature_fraction': 0.8564866175609596,\n",
       "    'bagging_freq': 5.169353560312051,\n",
       "    'bagging_fraction': 0.7862999061708408},\n",
       "   {'num_leaves': 41.355546429283436,\n",
       "    'colsample_bytree': 0.21637357924691542,\n",
       "    'min_data_in_leaf': 98.88163442949022,\n",
       "    'subsample': 0.9025446795503077,\n",
       "    'max_depth': 13.302203469350385,\n",
       "    'reg_alpha': 4.366317826765291,\n",
       "    'reg_lambda': 4.10523679255045,\n",
       "    'min_split_gain': 0.3350502093719606,\n",
       "    'min_child_weight': 30.105898586485274,\n",
       "    'min_child_samples': 5.033080403363718,\n",
       "    'feature_fraction': 0.9071085209740776,\n",
       "    'bagging_freq': 9.46035519196123,\n",
       "    'bagging_fraction': 0.886645464920843},\n",
       "   {'num_leaves': 30.42591316087357,\n",
       "    'colsample_bytree': 0.14382154589112772,\n",
       "    'min_data_in_leaf': 87.94311273464969,\n",
       "    'subsample': 0.36384646600390347,\n",
       "    'max_depth': 6.252339243441058,\n",
       "    'reg_alpha': 8.607873544480801,\n",
       "    'reg_lambda': 8.455068219339605,\n",
       "    'min_split_gain': 0.4259561474491015,\n",
       "    'min_child_weight': 30.022090920919297,\n",
       "    'min_child_samples': 8.299846986998602,\n",
       "    'feature_fraction': 0.6270408454786056,\n",
       "    'bagging_freq': 1.907938384295933,\n",
       "    'bagging_fraction': 0.9470560490668667},\n",
       "   {'num_leaves': 31.913990489209315,\n",
       "    'colsample_bytree': 0.18113402479256216,\n",
       "    'min_data_in_leaf': 55.6861227210163,\n",
       "    'subsample': 0.45065552596572955,\n",
       "    'max_depth': 14.474728050970935,\n",
       "    'reg_alpha': 2.5024708903491066,\n",
       "    'reg_lambda': 9.938237283813079,\n",
       "    'min_split_gain': 0.8983026765381428,\n",
       "    'min_child_weight': 30.829125675465097,\n",
       "    'min_child_samples': 11.13072077561607,\n",
       "    'feature_fraction': 0.22121700371225078,\n",
       "    'bagging_freq': 14.905109490387328,\n",
       "    'bagging_fraction': 0.9730251840750056},\n",
       "   {'num_leaves': 30.998395685341567,\n",
       "    'colsample_bytree': 0.11267060500553805,\n",
       "    'min_data_in_leaf': 99.48957929537654,\n",
       "    'subsample': 0.37783138444076625,\n",
       "    'max_depth': 14.641564274846385,\n",
       "    'reg_alpha': 6.909045543673504,\n",
       "    'reg_lambda': 4.476731692062364,\n",
       "    'min_split_gain': 0.7481485960615339,\n",
       "    'min_child_weight': 30.47359475125913,\n",
       "    'min_child_samples': 48.20702011317255,\n",
       "    'feature_fraction': 0.10678296520199025,\n",
       "    'bagging_freq': 18.259709174941413,\n",
       "    'bagging_fraction': 0.9552704046141405},\n",
       "   {'num_leaves': 42.6713765994532,\n",
       "    'colsample_bytree': 0.11271396366171038,\n",
       "    'min_data_in_leaf': 49.098850218805666,\n",
       "    'subsample': 0.14874510186563494,\n",
       "    'max_depth': 9.148862913512772,\n",
       "    'reg_alpha': 9.686420774598202,\n",
       "    'reg_lambda': 8.086180728755814,\n",
       "    'min_split_gain': 0.008649773164584262,\n",
       "    'min_child_weight': 35.593478379619114,\n",
       "    'min_child_samples': 5.2128052311758575,\n",
       "    'feature_fraction': 0.9455522714513028,\n",
       "    'bagging_freq': 12.095557361012537,\n",
       "    'bagging_fraction': 0.9567445787706127},\n",
       "   {'num_leaves': 40.36886835767429,\n",
       "    'colsample_bytree': 0.10798111391617472,\n",
       "    'min_data_in_leaf': 58.429533416167686,\n",
       "    'subsample': 0.9753081974535361,\n",
       "    'max_depth': 14.534012404871069,\n",
       "    'reg_alpha': 4.122229211413582,\n",
       "    'reg_lambda': 8.687491394936997,\n",
       "    'min_split_gain': 0.8406841691863316,\n",
       "    'min_child_weight': 43.96637876584241,\n",
       "    'min_child_samples': 29.607816382439065,\n",
       "    'feature_fraction': 0.9280661459779022,\n",
       "    'bagging_freq': 1.8540395406321197,\n",
       "    'bagging_fraction': 0.8994636130732395},\n",
       "   {'num_leaves': 30.73484454495759,\n",
       "    'colsample_bytree': 0.11091507725159909,\n",
       "    'min_data_in_leaf': 66.27854079642016,\n",
       "    'subsample': 0.48823273444031734,\n",
       "    'max_depth': 12.126142024119257,\n",
       "    'reg_alpha': 8.795155720475593,\n",
       "    'reg_lambda': 0.07699902030491423,\n",
       "    'min_split_gain': 0.045334848575760645,\n",
       "    'min_child_weight': 44.874520995326186,\n",
       "    'min_child_samples': 5.15095858286905,\n",
       "    'feature_fraction': 0.20884272533509565,\n",
       "    'bagging_freq': 19.205779792208624,\n",
       "    'bagging_fraction': 0.7059576904418738},\n",
       "   {'num_leaves': 44.47655711747271,\n",
       "    'colsample_bytree': 0.35470969929276686,\n",
       "    'min_data_in_leaf': 98.49423660707295,\n",
       "    'subsample': 0.655347345444872,\n",
       "    'max_depth': 9.360443712854995,\n",
       "    'reg_alpha': 2.7626709242035608,\n",
       "    'reg_lambda': 7.552666847444758,\n",
       "    'min_split_gain': 0.7073797565173466,\n",
       "    'min_child_weight': 30.02153721915646,\n",
       "    'min_child_samples': 12.161403268861669,\n",
       "    'feature_fraction': 0.8722642279147298,\n",
       "    'bagging_freq': 19.877351135944025,\n",
       "    'bagging_fraction': 0.9826029292294146},\n",
       "   {'num_leaves': 30.20859078929688,\n",
       "    'colsample_bytree': 0.7135777578857687,\n",
       "    'min_data_in_leaf': 11.31716308044998,\n",
       "    'subsample': 0.8696562006215124,\n",
       "    'max_depth': 5.720039044651177,\n",
       "    'reg_alpha': 5.722017176963146,\n",
       "    'reg_lambda': 6.684416910261457,\n",
       "    'min_split_gain': 0.08302097985591772,\n",
       "    'min_child_weight': 41.876093516241156,\n",
       "    'min_child_samples': 5.164615373117578,\n",
       "    'feature_fraction': 0.7212910702777292,\n",
       "    'bagging_freq': 0.9020795570602158,\n",
       "    'bagging_fraction': 0.9809912758790303},\n",
       "   {'num_leaves': 33.11008257667721,\n",
       "    'colsample_bytree': 0.9134233638367919,\n",
       "    'min_data_in_leaf': 87.0970046978347,\n",
       "    'subsample': 0.9068191464740546,\n",
       "    'max_depth': 9.237960343218512,\n",
       "    'reg_alpha': 6.853254757375147,\n",
       "    'reg_lambda': 9.377860555331658,\n",
       "    'min_split_gain': 0.6313992576736729,\n",
       "    'min_child_weight': 31.197602154400954,\n",
       "    'min_child_samples': 49.25438310128344,\n",
       "    'feature_fraction': 0.4702736367416728,\n",
       "    'bagging_freq': 0.3973962513260254,\n",
       "    'bagging_fraction': 0.8462656811201018},\n",
       "   {'num_leaves': 31.158617459999963,\n",
       "    'colsample_bytree': 0.8129690357943068,\n",
       "    'min_data_in_leaf': 80.22577912841267,\n",
       "    'subsample': 0.6130049088365017,\n",
       "    'max_depth': 14.967532680389928,\n",
       "    'reg_alpha': 3.9842786605635636,\n",
       "    'reg_lambda': 9.675618366934929,\n",
       "    'min_split_gain': 0.5103447837794313,\n",
       "    'min_child_weight': 31.8530537536367,\n",
       "    'min_child_samples': 49.139533904565184,\n",
       "    'feature_fraction': 0.2867873562438721,\n",
       "    'bagging_freq': 9.424346903536891,\n",
       "    'bagging_fraction': 0.6641231384792591},\n",
       "   {'num_leaves': 30.45386036536742,\n",
       "    'colsample_bytree': 0.7478942796680209,\n",
       "    'min_data_in_leaf': 74.0900431345343,\n",
       "    'subsample': 0.8706640070592662,\n",
       "    'max_depth': 14.151050007875451,\n",
       "    'reg_alpha': 2.599180004303151,\n",
       "    'reg_lambda': 9.865645067616239,\n",
       "    'min_split_gain': 0.8171403682521563,\n",
       "    'min_child_weight': 32.029957949841176,\n",
       "    'min_child_samples': 38.93157987835245,\n",
       "    'feature_fraction': 0.6325302617593735,\n",
       "    'bagging_freq': 19.33168610946867,\n",
       "    'bagging_fraction': 0.8467482236603012},\n",
       "   {'num_leaves': 34.32055727728389,\n",
       "    'colsample_bytree': 0.4665360425318833,\n",
       "    'min_data_in_leaf': 94.6599551011224,\n",
       "    'subsample': 0.34850912239512577,\n",
       "    'max_depth': 14.151220585214935,\n",
       "    'reg_alpha': 8.903591599794936,\n",
       "    'reg_lambda': 9.37331536493989,\n",
       "    'min_split_gain': 0.10257842792709615,\n",
       "    'min_child_weight': 30.500650703232846,\n",
       "    'min_child_samples': 5.04571417454141,\n",
       "    'feature_fraction': 0.4112178641215273,\n",
       "    'bagging_freq': 19.963995540468247,\n",
       "    'bagging_fraction': 0.8917967015795072},\n",
       "   {'num_leaves': 44.725051829882744,\n",
       "    'colsample_bytree': 0.5107317987984815,\n",
       "    'min_data_in_leaf': 57.80009380398783,\n",
       "    'subsample': 0.3444687872496509,\n",
       "    'max_depth': 14.688622761576964,\n",
       "    'reg_alpha': 0.16405760059179264,\n",
       "    'reg_lambda': 4.057129035705556,\n",
       "    'min_split_gain': 0.15034775839015024,\n",
       "    'min_child_weight': 42.091859283573555,\n",
       "    'min_child_samples': 43.98341330011349,\n",
       "    'feature_fraction': 0.902177372867029,\n",
       "    'bagging_freq': 19.621990483954956,\n",
       "    'bagging_fraction': 0.8975574997972178}]}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bo.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
